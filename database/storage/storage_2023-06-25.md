# arxiv-daily latest papers around wearable device
Automated deployment @ 2023-06-25 12:05:20 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`]({repo_url}/blob/main/database/topic.yml).
> You can also view historical data through the [storage]({repo_url}/blob/main/database/storage).

## smart glass

### smart glass
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**A multi-wavelength analysis of BL Her stars: Models versus Observations**|S. Das et.al.|[2306.12892v1](http://arxiv.org/abs/2306.12892v1)|null|We present new theoretical period--luminosity (PL) and period--radius (PR) relations at multiple wavelengths (Johnson--Cousins--Glass and {\sl Gaia} passbands) for a fine grid of BL~Herculis models computed using {\sc mesa-rsp}. The non-linear models were computed for periods typical of BL~Her stars, i.e. $1\leq P ({\rm days}) \leq4$, covering a wide range of input parameters: metallicity ($-$2.0 dex $\leq$ [Fe/H] $\leq$ 0.0 dex), stellar mass (0.5--0.8 M$_{\odot}$), luminosity (50--300 L$_{\odot}$) and effective temperature (full extent of the instability strip; in steps of 50K). We investigate the impact of four sets of convection parameters on multi-wavelength properties. Most empirical relations match well with theoretical relations from the BL~Her models computed using the four sets of convection parameters. No significant metallicity effects are seen in the PR relations. Another important result from our grid of BL~Her models is that it supports combining PL relations of RR Lyrae and Type~II Cepheids together as an alternative to classical Cepheids for the extragalactic distance scale calibration.|
|**2023-06-22**|**MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge**|Sokratis Nikolaidis et.al.|[2306.12830v1](http://arxiv.org/abs/2306.12830v1)|null|Cascade systems comprise a two-model sequence, with a lightweight model processing all samples and a heavier, higher-accuracy model conditionally refining harder samples to improve accuracy. By placing the light model on the device side and the heavy model on a server, model cascades constitute a widely used distributed inference approach. With the rapid expansion of intelligent indoor environments, such as smart homes, the new setting of Multi-Device Cascade is emerging where multiple and diverse devices are to simultaneously use a shared heavy model on the same server, typically located within or close to the consumer environment. This work presents MultiTASC, a multi-tenancy-aware scheduler that adaptively controls the forwarding decision functions of the devices in order to maximize the system throughput, while sustaining high accuracy and low latency. By explicitly considering device heterogeneity, our scheduler improves the latency service-level objective (SLO) satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade methods in highly heterogeneous setups, while serving over 40 devices, showcasing its scalability.|
|**2023-06-22**|**Self-compression of femtosecond pulses in normally dispersive media**|Renjing Chen et.al.|[2306.12743v1](http://arxiv.org/abs/2306.12743v1)|null|Self-compression is a simple method to achieve ultrashort and ultraintense pulses. By solving a modified nonlinear Schrodinger equation considering the fifth-order susceptibility, it is found that self-compression appeared even in normally dispersive media owing to the negative fifth-order susceptibility inducing a mass of negative frequency chirp. Furthermore, negatively pre-chirped pulses help to achieve pulse self-compression at lower input peak intensity which will avoid the damage of media. The optimized-choosing of pre-chirp, input intensity and length of media are numerically analyzed. Proof-of-principle experiments successfully prove the above theoretical findings. It is expected that petawatt laser pulses with 25 fs/15 fs transform limited pulse duration can be self-compressed to about 10.7 fs/8.8 fs in normally dispersive media such as fused silica glass plates.|
|**2023-06-22**|**The dual Derrida-Retaux conjecture**|Xinxing Chen et.al.|[2306.12717v1](http://arxiv.org/abs/2306.12717v1)|null|We consider a recursive system $(X_n)$ which was introduced by Collet et al. [10] as a spin glass model, and later by Derrida, Hakim, and Vannimenus [13] and by Derrida and Retaux [14] as a simplified hierarchical renormalization model. The system $(X_n)$ is expected to possess highly nontrivial universalities at or near criticality. In the nearly supercritical regime, Derrida and Retaux [14] conjectured that the free energy of the system decays exponentially with exponent $(p-p_c)^{-\frac12}$ as $p \downarrow p_c$. We study the nearly subcritical regime ($p \uparrow p_c$) and aim at a dual version of the Derrida-Retaux conjecture; our main result states that as $n \to \infty$, both $\E(X_n)$ and $\P(X_n\neq 0)$ decay exponentially with exponent $(p_c-p)^{\frac12 +o(1)}$, where $o(1) \to 0$ as $p \uparrow p_c$.|
|**2023-06-21**|**Localised Dynamics in the Floquet Quantum East Model**|Bruno Bertini et.al.|[2306.12467v1](http://arxiv.org/abs/2306.12467v1)|null|We introduce and study the discrete-time version of the Quantum East model, an interacting quantum spin chain inspired by simple kinetically constrained models of classical glasses. Previous work has established that its continuous-time counterpart displays a disorder-free localisation transition signalled by the appearance of an exponentially large (in the volume) family of non-thermal, localised eigenstates. Here we combine analytical and numerical approaches to show that: i) The transition persists for discrete times, in fact, it is present for any finite value of the time step apart from a zero measure set; ii) It is directly detected by following the non-equilibrium dynamics of the fully polarised state. Our findings imply that the transition is currently observable in state-of-the-art platforms for digital quantum simulation.|
|**2023-06-21**|**Do you still need a manual smart contract audit?**|Isaac David et.al.|[2306.12338v2](http://arxiv.org/abs/2306.12338v2)|null|We investigate the feasibility of employing large language models (LLMs) for conducting the security audit of smart contracts, a traditionally time-consuming and costly process. Our research focuses on the optimization of prompt engineering for enhanced security analysis, and we evaluate the performance and accuracy of LLMs using a benchmark dataset comprising 52 Decentralized Finance (DeFi) smart contracts that have previously been compromised.   Our findings reveal that, when applied to vulnerable contracts, both GPT-4 and Claude models correctly identify the vulnerability type in 40% of the cases. However, these models also demonstrate a high false positive rate, necessitating continued involvement from manual auditors. The LLMs tested outperform a random model by 20% in terms of F1-score.   To ensure the integrity of our study, we conduct mutation testing on five newly developed and ostensibly secure smart contracts, into which we manually insert two and 15 vulnerabilities each. This testing yielded a remarkable best-case 78.7% true positive rate for the GPT-4-32k model. We tested both, asking the models to perform a binary classification on whether a contract is vulnerable, and a non-binary prompt. We also examined the influence of model temperature variations and context length on the LLM's performance.   Despite the potential for many further enhancements, this work lays the groundwork for a more efficient and economical approach to smart contract security audits.|
|**2023-06-21**|**Chili Pepper Disease Diagnosis via Image Reconstruction Using GrabCut and Generative Adversarial Serial Autoencoder**|Jongwook Si et.al.|[2306.12057v1](http://arxiv.org/abs/2306.12057v1)|null|With the recent development of smart farms, researchers are very interested in such fields. In particular, the field of disease diagnosis is the most important factor. Disease diagnosis belongs to the field of anomaly detection and aims to distinguish whether plants or fruits are normal or abnormal. The problem can be solved by binary or multi-classification based on CNN, but it can also be solved by image reconstruction. However, due to the limitation of the performance of image generation, SOTA's methods propose a score calculation method using a latent vector error. In this paper, we propose a network that focuses on chili peppers and proceeds with background removal through Grabcut. It shows high performance through image-based score calculation method. Due to the difficulty of reconstructing the input image, the difference between the input and output images is large. However, the serial autoencoder proposed in this paper uses the difference between the two fake images except for the actual input as a score. We propose a method of generating meaningful images using the GAN structure and classifying three results simultaneously by one discriminator. The proposed method showed higher performance than previous researches, and image-based scores showed the best performanc|
|**2023-06-21**|**Learning When to Trust Which Teacher for Weakly Supervised ASR**|Aakriti Agrawal et.al.|[2306.12012v1](http://arxiv.org/abs/2306.12012v1)|null|Automatic speech recognition (ASR) training can utilize multiple experts as teacher models, each trained on a specific domain or accent. Teacher models may be opaque in nature since their architecture may be not be known or their training cadence is different from that of the student ASR model. Still, the student models are updated incrementally using the pseudo-labels generated independently by the expert teachers. In this paper, we exploit supervision from multiple domain experts in training student ASR models. This training strategy is especially useful in scenarios where few or no human transcriptions are available. To that end, we propose a Smart-Weighter mechanism that selects an appropriate expert based on the input audio, and then trains the student model in an unsupervised setting. We show the efficacy of our approach using LibriSpeech and LibriLight benchmarks and find an improvement of 4 to 25\% over baselines that uniformly weight all the experts, use a single expert model, or combine experts using ROVER.|
|**2023-06-21**|**LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System (ACM)(Draft) LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System**|Ashish Bastola et.al.|[2306.11980v1](http://arxiv.org/abs/2306.11980v1)|null|CSCW studies have increasingly explored AI's role in enhancing communication efficiency and productivity in collaborative tasks. AI tools such as chatbots, smart replies, and language models aim to optimize conversation management and improve team performance. Early AI assistants, such as Gmail smart reply, were limited by predefined knowledge bases and decision trees. However, the advent of large language models (LLMs) such as ChatGPT has revolutionized AI assistants, employing advanced deep learning architecture to generate context-aware, coherent, and personalized responses. Consequently, ChatGPT-based AI assistants provide a more natural and efficient user experience across various tasks and domains. In this paper, we formalize the concept of AI Collaborative Tools (ACT) as AI technologies in human collaborative work and discuss how the emergence of ChatGPT has transformed the AI landscape and increased focus on ACT for improving team performance. Meanwhile, we present an LLM-based Smart Reply (LSR) system utilizing the ChatGPT API to generate personalized responses in daily collaborative scenarios, considering context, tone, and communication style. Our two-step process involves generating a preliminary response type (e.g., Agree, Disagree) to provide a generalized direction for message generation, thus reducing response drafting time. We conducted an experiment in which participants completed simulated work tasks, involving Google Calendar manipulation and a double-back N-back test, while interacting with researchers posing as teammates requesting scheduling changes. Our findings indicate that the AI teammate increases perceived performance and reduces mental demand, as measured by the NASA TLX, and improves performance in the N-back task. We also provide qualitative feedback on participants' experiences working with the AI teammate.|
|**2023-06-21**|**Multimodality Fusion for Smart Healthcare: a Journey from Data, Information, Knowledge to Wisdom**|Thanveer Shaik et.al.|[2306.11963v1](http://arxiv.org/abs/2306.11963v1)|null|Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data, information, and knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. A comprehensive review of multimodal medical data fusion focuses on the integration of various data modalities are presented. It explores different approaches such as Feature selection, Rule-based systems, Machine learning, Deep learning, and Natural Language Processing for fusing and analyzing multimodal data. The paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and insights, a generic framework for multimodal medical data fusion is proposed while aligning with the DIKW mechanism. Moreover, it discusses future directions aligned with the four pillars of healthcare: Predictive, Preventive, Personalized, and Participatory approaches based on the DIKW and the generic framework. The components from this comprehensive survey form the foundation for the successful implementation of multimodal fusion in smart healthcare. The findings of this survey can guide researchers and practitioners in leveraging the power of multimodal fusion with the approaches to revolutionize healthcare and improve patient outcomes.|
|**2023-06-20**|**Replica-symmetry breaking transitions in the large deviations of the ground-state of a spherical spin-glass**|Bertrand Lacroix-A-Chez-Toine et.al.|[2306.11927v1](http://arxiv.org/abs/2306.11927v1)|null|We derive, within the replica formalism, a generalisation of the Crisanti-Sommers formula to describe the large deviation function (LDF) ${\cal L}(e)$ for the speed-$N$ atypical fluctuations of the intensive ground-state energy $e$ of a generic spherical spin-glass in the presence of a random external magnetic field of variance $\Gamma$. We then analyse our exact formula for the LDF in much detail for the Replica symmetric, single step Replica Symmetry Breaking (1-RSB) and Full Replica Symmetry Breaking (FRSB) situations. Our main qualitative conclusion is that the level of RSB governing the LDF may be different from that for the typical ground state. We find that while the deepest ground-states are always controlled by a LDF of replica symmetric form, beyond a finite threshold $e\geq e_{t}$ a replica-symmetry breaking starts to be operative. These findings resolve the puzzling discrepancy between our earlier replica calculations for the $p=2$ spherical spin-glass and the rigorous results by Dembo and Zeitouni which we are able to reproduce invoking an 1-RSB pattern. Finally at an even larger critical energy $e_{c}\geq e_{t}$, acting as a "wall", the LDF diverges logarithmically, which we interpret as a change in the large deviation speed from $N$ to a faster growth. In addition, we show that in the limit $\Gamma \to 0$ the LDF takes non-trivial scaling forms (i) ${\cal L}(e) \sim G((e-e_c)/\Gamma)$ in the vicinity of the wall (ii) ${\cal L}(e) \sim \Gamma^{\eta \nu} F((e-e_{\rm typ})/\Gamma^{\nu})$ in the vicinity of the typical energy, characterised by two new exponents $\eta\geq 1$ and $\nu$ characterising universality classes. Via matching the latter allows us to formulate several conjectures concerning the regime of {\it typical fluctuations}, identified as $e-e_{\rm typ} \sim N^{-1/\eta}$ and $\Gamma \sim N^{-1/(\eta \nu)}$.|
|**2023-06-20**|**A Unified Understanding of Minimum Lattice Thermal Conductivity**|Yi Xia et.al.|[2306.11917v1](http://arxiv.org/abs/2306.11917v1)|[link](https://github.com/yimavxia/minikappa)|We propose a first-principles model of minimum lattice thermal conductivity ($\kappa_{\rm L}^{\rm min}$) based on a unified theoretical treatment of thermal transport in crystals and glasses. We apply this model to thousands of inorganic compounds and discover a universal behavior of $\kappa_{\rm L}^{\rm min}$ in crystals in the high-temperature limit: the isotropically averaged $\kappa_{\rm L}^{\rm min}$ is independent of structural complexity and bounded within a range from $\sim$0.1 to $\sim$2.6 W/[m$\cdot$K], in striking contrast to the conventional phonon gas model which predicts no lower bound. We unveil the underlying physics by showing that for a given parent compound $\kappa_{\rm L}^{\rm min}$ is bounded from below by a value that is approximately insensitive to disorder, but the relative importance of different heat transport channels (phonon gas versus diffuson) depends strongly on the degree of disorder. Moreover, we propose that the diffuson-dominated $\kappa_{\rm L}^{\rm min}$ in complex and disordered compounds might be effectively approximated by the phonon gas model for an ordered compound by averaging out disorder and applying phonon unfolding. With these insights, we further bridge the knowledge gap between our model and the well-known Cahill-Watson-Pohl (CWP) model, rationalizing the successes and limitations of the CWP model in the absence of heat transfer mediated by diffusons. Finally, we construct graph network and random forest machine learning models to extend our predictions to all compounds within the Inorganic Crystal Structure Database (ICSD), which were validated against thermoelectric materials possessing experimentally measured ultralow $\kappa_{\rm L}$. Our work offers a unified understanding of $\kappa_{\rm L}^{\rm min}$, which can guide the rational engineering of materials to achieve $\kappa_{\rm L}^{\rm min}$.|
|**2023-06-20**|**Protecting the Decentralized Future: An Exploration of Common Blockchain Attacks and their Countermeasures**|Bilash Saha et.al.|[2306.11884v1](http://arxiv.org/abs/2306.11884v1)|null|Blockchain technology transformed the digital sphere by providing a transparent, secure, and decentralized platform for data security across a range of industries, including cryptocurrencies and supply chain management. Blockchain's integrity and dependability have been jeopardized by the rising number of security threats, which have attracted cybercriminals as a target. By summarizing suggested fixes, this research aims to offer a thorough analysis of mitigating blockchain attacks. The objectives of the paper include identifying weak blockchain attacks, evaluating various solutions, and determining how effective and effective they are at preventing these attacks. The study also highlights how crucial it is to take into account the particular needs of every blockchain application. This study provides beneficial perspectives and insights for blockchain researchers and practitioners, making it essential reading for those interested in current and future trends in blockchain security research.|
|**2023-06-20**|**Predicting Strategic Energy Storage Behaviors**|Yuexin Bian et.al.|[2306.11872v1](http://arxiv.org/abs/2306.11872v1)|[link](https://github.com/alwaysbyx/predicting-strategic-energy-storage-behaviors)|Energy storage are strategic participants in electricity markets to arbitrage price differences. Future power system operators must understand and predict strategic storage arbitrage behaviors for market power monitoring and capacity adequacy planning. This paper proposes a novel data-driven approach that incorporates prior model knowledge for predicting the strategic behaviors of price-taker energy storage systems. We propose a gradient-descent method to find the storage model parameters given the historical price signals and observations. We prove that the identified model parameters will converge to the true user parameters under a class of quadratic objective and linear equality-constrained storage models. We demonstrate the effectiveness of our approach through numerical experiments with synthetic and real-world storage behavior data. The proposed approach significantly improves the accuracy of storage model identification and behavior forecasting compared to previous blackbox data-driven approaches.|
|**2023-06-20**|**Retrieval-Based Transformer for Table Augmentation**|Michael Glass et.al.|[2306.11843v1](http://arxiv.org/abs/2306.11843v1)|[link](https://github.com/ibm/retrieval-table-augmentation)|Data preparation, also called data wrangling, is considered one of the most expensive and time-consuming steps when performing analytics or building machine learning models. Preparing data typically involves collecting and merging data from complex heterogeneous, and often large-scale data sources, such as data lakes. In this paper, we introduce a novel approach toward automatic data wrangling in an attempt to alleviate the effort of end-users, e.g. data analysts, in structuring dynamic views from data lakes in the form of tabular data. We aim to address table augmentation tasks, including row/column population and data imputation. Given a corpus of tables, we propose a retrieval augmented self-trained transformer model. Our self-learning strategy consists in randomly ablating tables from the corpus and training the retrieval-based model to reconstruct the original values or headers given the partial tables as input. We adopt this strategy to first train the dense neural retrieval model encoding table-parts to vectors, and then the end-to-end model trained to perform table augmentation tasks. We test on EntiTables, the standard benchmark for table augmentation, as well as introduce a new benchmark to advance further research: WebTables. Our model consistently and substantially outperforms both supervised statistical methods and the current state-of-the-art transformer-based models.|
|**2023-06-20**|**Surface Direct Conversion of 511 keV Gamma Rays in Large-Area Laminated Multichannel-Plate Electron Multipliers**|Kepler Domurat-Sousa et.al.|[2306.11701v1](http://arxiv.org/abs/2306.11701v1)|null|We have used the TOPAS simulation framework to model the direct conversion of 511 keV gamma rays to electrons in a micro-channel plate (MCP) constructed from thin laminae of a heavy-metal-loaded dielectric such as lead-glass, patterned with micro-channels (LMCP). The laminae serve as the converter of the gamma ray to a primary electron within a depth from a channel-forming surface such that the electron penetrates the channel surface ('surface direct conversion'). The channels are coated with a secondary-emitting material to produce electron multiplication in the channels. The laminae are stacked on edge with the channels running from the top of the resulting 'slab' to the bottom; after assembly the slab is metalized top and bottom to form the finished LMCP.   The shape of the perimeter of a lamina determines the dimensions of the slab at the lamina location in the slab, allowing non-uniform cross-sections in slab thickness, width, and length. The slab also can be non-planar, allowing curved surfaces in both lateral dimensions. The laminar construction allows incorporating structural elements in the LMCP for modular assembly in large-area arrays.   The channels can be patterned on the laminae surfaces with internal shapes and structure, texture, and coatings optimized for specific applications and performance. The channels can be non-uniform across the LMCP and need not be parallel in either transverse direction.   Surface direct conversion of the gamma ray to an electron eliminates the common two-step conversion of the gamma ray into an optical photon in a scintillator followed by the conversion of the photon into an electron in a photodetector. The simulations predict an efficiency for conversion of 511 keV gamma rays of approximately greater than 30% for a 2.54 cm-thick Pb-glass LMCP. The elimination of the photocathode allows assembly at atmospheric pressure.|
|**2023-06-20**|**Droplet Interferometry: A Schlick Way to Consider Interfacial Energetics**|Jean-Felix Milette et.al.|[2306.11684v2](http://arxiv.org/abs/2306.11684v2)|null|We verify the use of an evaporating sessile water droplet as a source of dynamic interference fringes in a Fizeau-like interferometer. Experimentally-obtained interference patterns are compared with those produced by a geometrical optics-based computational model to demonstrate the potential for classical optical theory to enhance the analysis of interfacial energetics. A detailed description of the process taken to optimize fringe visibility is presented, and a comparison is made between various droplet substrates. Silicon-based substrates appear to be superior than glass-based substrates in their ability to image a clear dynamic interference pattern.|
|**2023-06-20**|**SkyGPT: Probabilistic Short-term Solar Forecasting Using Synthetic Sky Videos from Physics-constrained VideoGPT**|Yuhao Nie et.al.|[2306.11682v1](http://arxiv.org/abs/2306.11682v1)|null|In recent years, deep learning-based solar forecasting using all-sky images has emerged as a promising approach for alleviating uncertainty in PV power generation. However, the stochastic nature of cloud movement remains a major challenge for accurate and reliable solar forecasting. With the recent advances in generative artificial intelligence, the synthesis of visually plausible yet diversified sky videos has potential for aiding in forecasts. In this study, we introduce \emph{SkyGPT}, a physics-informed stochastic video prediction model that is able to generate multiple possible future images of the sky with diverse cloud motion patterns, by using past sky image sequences as input. Extensive experiments and comparison with benchmark video prediction models demonstrate the effectiveness of the proposed model in capturing cloud dynamics and generating future sky images with high realism and diversity. Furthermore, we feed the generated future sky images from the video prediction models for 15-minute-ahead probabilistic solar forecasting for a 30-kW roof-top PV system, and compare it with an end-to-end deep learning baseline model SUNSET and a smart persistence model. Better PV output prediction reliability and sharpness is observed by using the predicted sky images generated with SkyGPT compared with other benchmark models, achieving a continuous ranked probability score (CRPS) of 2.81 (13\% better than SUNSET and 23\% better than smart persistence) and a Winkler score of 26.70 for the test set. Although an arbitrary number of futures can be generated from a historical sky image sequence, the results suggest that 10 future scenarios is a good choice that balances probabilistic solar forecasting performance and computational cost.|
|**2023-06-20**|**Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes**|Mathilde Leuridan et.al.|[2306.11553v1](http://arxiv.org/abs/2306.11553v1)|[link](https://github.com/ecmwf/polytope)|Data extraction algorithms on data hypercubes, or datacubes, are traditionally only capable of cutting boxes of data along the datacube axes. For many use cases however, this is not a sufficient approach and returns more data than users might actually need. This not only forces users to apply post-processing after extraction, but more importantly this consumes more I/O resources than is necessary. When considering very large datacubes from which users only want to extract small non-rectangular subsets, the box approach does not scale well. Indeed, with this traditional approach, I/O systems quickly reach capacity, trying to read and return unwanted data to users. In this paper, we propose a novel technique, based on computational geometry concepts, which instead carefully pre-selects the precise bytes of data which the user needs in order to then only read those from the datacube. As we discuss later on, this novel extraction method will considerably help scale access to large petabyte size data hypercubes in a variety of scientific fields.|
|**2023-06-20**|**UUKG: Unified Urban Knowledge Graph Dataset for Urban Spatiotemporal Prediction**|Yansong Ning et.al.|[2306.11443v1](http://arxiv.org/abs/2306.11443v1)|[link](https://github.com/usail-hkust/uukg)|Accurate Urban SpatioTemporal Prediction (USTP) is of great importance to the development and operation of the smart city. As an emerging building block, multi-sourced urban data are usually integrated as urban knowledge graphs (UrbanKGs) to provide critical knowledge for urban spatiotemporal prediction models. However, existing UrbanKGs are often tailored for specific downstream prediction tasks and are not publicly available, which limits the potential advancement. This paper presents UUKG, the unified urban knowledge graph dataset for knowledge-enhanced urban spatiotemporal predictions. Specifically, we first construct UrbanKGs consisting of millions of triplets for two metropolises by connecting heterogeneous urban entities such as administrative boroughs, POIs, and road segments. Moreover, we conduct qualitative and quantitative analysis on constructed UrbanKGs and uncover diverse high-order structural patterns, such as hierarchies and cycles, that can be leveraged to benefit downstream USTP tasks. To validate and facilitate the use of UrbanKGs, we implement and evaluate 15 KG embedding methods on the KG completion task and integrate the learned KG embeddings into 9 spatiotemporal models for five different USTP tasks. The extensive experimental results not only provide benchmarks of knowledge-enhanced USTP models under different task settings but also highlight the potential of state-of-the-art high-order structure-aware UrbanKG embedding methods. We hope the proposed UUKG fosters research on urban knowledge graphs and broad smart city applications. The dataset and source code are available at https://github.com/usail-hkust/UUKG/.|
|**2023-06-20**|**Ultrafast Self-powered Visible Blind UV Photodetectors based on MgZnO Vertical Schottky Junction in Crossbar Geometry**|Amit K Das et.al.|[2306.11340v1](http://arxiv.org/abs/2306.11340v1)|null|In order to achieve ultrafast response in MgZnO based self-powered Schottky type photodetectors, it is crucial to decrease both the junction capacitance and carrier transit time. To meet these criteria, Au/MgZnO/ITO Schottky junction photodetectors have been realised in crossbar pattern, wherein the thickness of the MgZnO thin film deposited on patterned ITO-glass substrate is ~ 200 nm and the cross-sectional area of the devices is 0.032 mm2. The semi-transparent 10 nm Au electrode on top of the MgZnO film serves as the Schottky electrode through which light enters the devices. The vertical geometry of the crossbar pattern and the associated small device cross-section results in a low junction capacitance of the devices of ~ 27 pF at zero bias, which in turn produces very fast visible blind self-powered ultraviolet (UV) photoresponse with both the rise and fall times of ~ 1.5 microsecond. The devices also demonstrate a peak responsivity of ~ 49 mA/W at ~ 280 nm with a cut-off wavelength of 336 nm. These Au/MgZnO/ITO Schottky photodetectors in crossbar pattern, with optimized device area, could be useful in applications requiring fast response, such as UV communication and UV imaging.|
|**2023-06-20**|**An Introduction to the Compute Express Link (CXL) Interconnect**|Debendra Das Sharma et.al.|[2306.11227v1](http://arxiv.org/abs/2306.11227v1)|null|The Compute Express Link (CXL) is an open industry-standard interconnect between processors and devices such as accelerators, memory buffers, smart network interfaces, persistent memory, and solid-state drives. CXL offers coherency and memory semantics with bandwidth that scales with PCIe bandwidth while achieving significantly lower latency than PCIe. All major CPU vendors, device vendors, and datacenter operators have adopted CXL as a common standard. This enables an inter-operable ecosystem that supports key computing use cases including highly efficient accelerators, server memory bandwidth and capacity expansion, multi-server resource pooling and sharing, and efficient peer-to-peer communication. This survey provides an introduction to CXL covering the standards CXL 1.0, CXL 2.0, and CXL 3.0. We further survey CXL implementations, discuss CXL's impact on the datacenter landscape, and future directions.|
|**2023-06-19**|**Static and Dynamic Jamming Games Over Wireless Channels With Mobile Strategic Players**|Giovanni Perin et.al.|[2306.10956v1](http://arxiv.org/abs/2306.10956v1)|null|We study a wireless jamming problem consisting of the competition between a legitimate receiver and a jammer, as a zero-sum game with the value to maximize/minimize being the channel capacity at the receiver's side. Most of the approaches found in the literature consider the two players to be stationary nodes. Instead, we investigate what happens when they can change location, specifically moving along a linear geometry. We frame this at first as a static game, which can be solved in closed form, and subsequently we extend it to a dynamic game, under three different versions for what concerns completeness/perfection of mutual information about the adversary's position, corresponding to different assumptions of concealment/sequentiality of the moves, respectively. We first provide some theoretical conditions that hold for the static game and also help identify good strategies valid under any setup, including dynamic games. Since dynamic games, although more realistic, are characterized by an exploding strategy space, we exploit reinforcement learning to obtain efficient strategies leading to equilibrium outcomes. We show how theoretical findings can be used to train smart agents to play the game, and validate our approach in practical setups.|
|**2023-06-19**|**Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network**|Ahmad A. Mubarak et.al.|[2306.10946v1](http://arxiv.org/abs/2306.10946v1)|null|The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendation of tourist attractions and can make more recommendations for tourists' choices.|
|**2023-06-19**|**Transformer Training Strategies for Forecasting Multiple Load Time Series**|Matthias Hertel et.al.|[2306.10891v1](http://arxiv.org/abs/2306.10891v1)|null|Recent work uses Transformers for load forecasting, which are the state of the art for sequence modeling tasks in data-rich domains. In the smart grid of the future, accurate load forecasts must be provided on the level of individual clients of an energy supplier. While the total amount of electrical load data available to an energy supplier will increase with the ongoing smart meter rollout, the amount of data per client will always be limited. We test whether the Transformer benefits from a transfer learning strategy, where a global model is trained on the load time series data from multiple clients. We find that the global model is superior to two other training strategies commonly used in related work: multivariate models and local models. A comparison to linear models and multi-layer perceptrons shows that Transformers are effective for electrical load forecasting when they are trained with the right strategy.|
|**2023-06-19**|**The 3d and 5d electronic structures and orbital hybridization in Ba- and Ca-doped La2CoIrO6 double perovskite**|J. R. L. Mardegan et.al.|[2306.10883v1](http://arxiv.org/abs/2306.10883v1)|null|Here we present a detailed investigation of the Co and Ir local electronic structures in La1.5A0.5CoIrO6 (A = Ba, Ca) compounds in order to unravel the orbital hybridization mechanism in these CoIr-based double perovskites. Our results of x-ray powder diffraction, ac and dc magnetization, Co and Ir L2,3-edges and Co K-edge x-ray absorption spectroscopy and x-ray magnetic circular dichroism suggest a competition between magnetic interactions. A dominant antiferromagnetic coupling is found to be responsible for the ferrimagnetic behavior observed for A = Ca below approximately 96 K, the competing magnetic phases and the cationic disorder in this compound giving rise to a spin-glass state at low temperatures. For the A = Ba, on the other hand, there is no evidence of long range order down to its spin-glass transition temperature. The remarkably different magnetic properties observed between these two compounds is discussed in terms of the structural distortion that alters the strength of the Co - Ir couplings, with a relevant role played by the Co 3d eg - Ir 5d j = 1/2 hybridization.|
|**2023-06-19**|**Detection of Sensor-To-Sensor Variations using Explainable AI**|Sarah Seifi et.al.|[2306.10850v1](http://arxiv.org/abs/2306.10850v1)|null|With the growing concern for air quality and its impact on human health, interest in environmental gas monitoring has increased. However, chemi-resistive gas sensing devices are plagued by issues of sensor reproducibility during manufacturing. This study proposes a novel approach for detecting sensor-to-sensor variations in sensing devices using the explainable AI (XAI) method of SHapley Additive exPlanations (SHAP). This is achieved by identifying sensors that contribute the most to environmental gas concentration estimation via machine learning, and measuring the similarity of feature rankings between sensors to flag deviations or outliers. The methodology is tested using artificial and realistic Ozone concentration profiles to train a Gated Recurrent Unit (GRU) model. Two applications were explored in the study: the detection of wrong behaviors of sensors in the train dataset, and the detection of deviations in the test dataset. By training the GRU with the pruned train dataset, we could reduce computational costs while improving the model performance. Overall, the results show that our approach improves the understanding of sensor behavior, successfully detects sensor deviations down to 5-10% from the normal behavior, and leads to more efficient model preparation and calibration. Our method provides a novel solution for identifying deviating sensors, linking inconsistencies in hardware to sensor-to-sensor variations in the manufacturing process on an AI model-level.|
|**2023-06-19**|**Blockchain-Enabled Federated Learning: A Reference Architecture Incorporating a DID Access System**|Eunsu Goh et.al.|[2306.10841v1](http://arxiv.org/abs/2306.10841v1)|null|Recently, Blockchain-Enabled Federated Learning (BCFL), an innovative approach that combines the advantages of Federated Learning and Blockchain technology, is receiving great attention. Federated Learning (FL) allows multiple participants to jointly train machine learning models in a decentralized manner while maintaining data privacy and security. This paper proposes a reference architecture for blockchain-enabled federated learning, which enables multiple entities to collaboratively train machine learning models while preserving data privacy and security. A critical component of this architecture is the implementation of a decentralized identifier (DID)-based access system. DID introduces a decentralized, self-sovereign identity (ID) management system that allows participants to manage their IDs independently of central authorities. Within this proposed architecture, participants can authenticate and gain access to the federated learning platform via their DIDs, which are securely stored on the blockchain. The access system administers access control and permissions through the execution of smart contracts, further enhancing the security and decentralization of the system. This approach, integrating blockchain-enabled federated learning with a DID access system, offers a robust solution for collaborative machine learning in a distributed and secure manner. As a result, participants can contribute to global model training while maintaining data privacy and identity control without the need to share local data. These DIDs are stored on the blockchain and the access system uses smart contracts to manage access control and permissions. The source code will be available to the public soon.|
|**2023-06-19**|**Impact of Dynamic Tariffs for Smart EV Charging on LV Distribution Network Operation**|Flore Verbist et.al.|[2306.10775v1](http://arxiv.org/abs/2306.10775v1)|null|With a growing share of electric vehicles (EVs) in our distribution grids, the need for smart charging becomes indispensable to minimise grid reinforcement. To circumvent the associated capacity limitations, this paper evaluates the effectiveness of different levels of network constraints and different dynamic tariffs, including a dynamic network tariff. A detailed optimisation model is first developed for public charging electric vehicles in a representative Dutch low voltage (LV) distribution network, susceptible to congestion and voltage problems by 2050 without smart charging of EVs. Later, a detailed reflection is made to assess the influence of the modelled features on the distribution system operator (DSO), charge point operator (CPO) costs, and the EVs' final state-of-charge (SOC) for both mono- (V1G) and bi-directional (V2G) charging. Results show that the dynamic network tariff outperforms other flat tariffs by increasing valley-filling. Consequently, compared to regular day-ahead pricing, a {significant} reduction in the frequency of congestion in the lines is achieved. In addition, V2G ensures the joint optimum for different stakeholders causing adequate EV user satisfaction, decreased CPO costs compared to conventional charging and fewer violations of grid constraints for the DSOs.|
|**2023-06-19**|**Learning an Interpretable End-to-End Network for Real-Time Acoustic Beamforming**|Hao Liang et.al.|[2306.10772v1](http://arxiv.org/abs/2306.10772v1)|null|Recently, many forms of audio industrial applications, such as sound monitoring and source localization, have begun exploiting smart multi-modal devices equipped with a microphone array. Regrettably, model-based methods are often difficult to employ for such devices due to their high computational complexity, as well as the difficulty of appropriately selecting the user-determined parameters. As an alternative, one may use deep network-based methods, but these are often difficult to generalize, nor can they generate the desired beamforming map directly. In this paper, a computationally efficient acoustic beamforming algorithm is proposed, which may be unrolled to form a model-based deep learning network for real-time imaging, here termed the DAMAS-FISTA-Net. By exploiting the natural structure of an acoustic beamformer, the proposed network inherits the physical knowledge of the acoustic system, and thus learns the underlying physical properties of the propagation. As a result, all the network parameters may be learned end-to-end, guided by a model-based prior using back-propagation. Notably, the proposed network enables an excellent interpretability and the ability of being able to process the raw data directly. Extensive numerical experiments using both simulated and real-world data illustrate the preferable performance of the DAMAS-FISTA-Net as compared to alternative approaches.|

## apple

### apple watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Characteristic length for pinning force density in $Nb{_3}Sn$**|E. F. Talantsev et.al.|[2306.13071v1](http://arxiv.org/abs/2306.13071v1)|null|The pinning force density $F{_p}(J{_c},B)=J{_c} \times B$ (where $J_c$ is the critical current density, $B$ is applied magnetic field) is one of main quantities which characterizes the resilience of a superconductor to carry dissipative-free transport current in applied magnetic field. Kramer (1973 J. Appl. Phys. 44 1360) and Dew-Hughes (1974 Phil. Mag. 30 293) proposed a widely used scaling law for the pinning force density amplitude: $F{_p}(B)=F{_{p,max}}((p+q){^{(p+q)}}/({p^p}{q^q}))(B/B_{c2}){^p}(1-B/B{_{c2}})^q$, where $F{_{p,max}}$, $B{_{c2}}$, $p$, and $q$ are free-fitting parameters. Since late 1970-s till now, several research groups reported experimental data for the dependence of $F_{p,max}$ on the average grain size, $d$, in $Nb{_3}Sn$-based conductors. Godeke (2006 Supercond. Sci. Techn. 19 R68) proposed that the dependence obeys the law $|F{_{p,max}}(d)|=A \times log(1/d)+B $. However, this scaling law has several problems, for instance, the logarithm is taken from a non-dimensionless variable, and $|F{_{p,max}}(d)|< 0 $ for large grain sizes and $|F{_{p,max}}(d)|\rightarrow \infty $ for $d \rightarrow 0$. Here we reanalysed full inventory of publicly available $|F{_{p,max}}(d)|$ data for $Nb{_3}Sn$ conductors and found that the dependence can be described by $F_{p,max}(d)= F_{p,max}(0)exp(-d/{\delta})$ law, where the characteristic length, ${\delta}$, is varying within a remarkably narrow range, i.e. ${\delta}=(175 \pm 13) nm$, for samples fabricated by different technologies. The interpretation of the result is based on an idea that the in-field supercurrent is flowing within a thin surface layer (the thickness of ${\delta}$) near the grain boundary surfaces. Alternative interpretation is that ${\delta}$ represents characteristic length for the exponentially decay flux pinning potential from dominant defects in $Nb{_3}Sn$ superconductors, which are grain boundaries.|
|**2023-06-21**|**Borodin-Kostochka conjecture for a class of P_6-free graphs**|Di Wu et.al.|[2306.12062v1](http://arxiv.org/abs/2306.12062v1)|null|Borodin and Kostochka conjectured that every graph $G$ with $\Delta\ge9$ satisfies $\chi\le$ max $\{\omega, \Delta-1\}$. This conjecture is still open for general graphs. In this note, we prove the Borodin-Kostochka conjecture for ($P_6$, apple, torch)-free graphs, that is, graphs with no induced $P_6$, no induced $C_5$ with a hanging edge and no induced $C_5$ and $C_4$ sharing exactly two edges.|
|**2023-06-21**|**On the accumulation points of non-periodic orbits of a difference equation of fourth order**|Antonio Linero Bas et.al.|[2306.12061v1](http://arxiv.org/abs/2306.12061v1)|null|In this paper, we are interested in analyzing the dynamics of the fourth-order difference equation $x_{n+4} = \max\{x_{n+3},x_{n+2},x_{n+1},0\}-x_n$, with arbitrary real initial conditions. We fully determine the accumulation point sets of the non-periodic solutions that, in fact, are configured as proper compact intervals of the real line. This study complements the previous knowledge of the dynamics of the difference equation already achieved in [M. Cs\"ornyei, M. Laczkovich, Monatsh. Math. 132 (2001), 215-236] and [A. Linero Bas, D. Nieves Rold\'an, J. Difference Equ. Appl. 27 (2021), no. 11, 1608-1645].|
|**2023-06-20**|**Exploring the Effectiveness of Dataset Synthesis: An application of Apple Detection in Orchards**|Alexander van Meekeren et.al.|[2306.11763v1](http://arxiv.org/abs/2306.11763v1)|null|Deep object detection models have achieved notable successes in recent years, but one major obstacle remains: the requirement for a large amount of training data. Obtaining such data is a tedious process and is mainly time consuming, leading to the exploration of new research avenues like synthetic data generation techniques. In this study, we explore the usability of Stable Diffusion 2.1-base for generating synthetic datasets of apple trees for object detection and compare it to a baseline model trained on real-world data. After creating a dataset of realistic apple trees with prompt engineering and utilizing a previously trained Stable Diffusion model, the custom dataset was annotated and evaluated by training a YOLOv5m object detection model to predict apples in a real-world apple detection dataset. YOLOv5m was chosen for its rapid inference time and minimal hardware demands. Results demonstrate that the model trained on generated data is slightly underperforming compared to a baseline model trained on real-world images when evaluated on a set of real-world images. However, these findings remain highly promising, as the average precision difference is only 0.09 and 0.06, respectively. Qualitative results indicate that the model can accurately predict the location of apples, except in cases of heavy shading. These findings illustrate the potential of synthetic data generation techniques as a viable alternative to the collection of extensive training data for object detection models.|
|**2023-06-20**|**Discriminating the Phase of a Coherent Tone with a Flux-Switchable Superconducting Circuit**|Luigi Di Palma et.al.|[2306.11364v1](http://arxiv.org/abs/2306.11364v1)|null|We propose a new phase detection technique based on a flux-switchable superconducting circuit, the Josephson digital phase detector (JDPD), which is capable of discriminating between two phase values of a coherent input tone. When properly excited by an external flux, the JDPD is able to switch from a single-minimum to a double-minima potential and, consequently, relax in one of the two stable configurations depending on the phase sign of the input tone. The result of this operation is digitally encoded in the occupation probability of a phase particle in either of the two JDPD wells. In this work, we demonstrate the working principle of the JDPD up to a frequency of 400 MHz with a remarkable agreement with theoretical expectations. As a future scenario, we discuss the implementation of this technique to superconducting qubit readout. We also examine the JDPD compatibility with the single-flux-quantum architecture, employed to fast-drive and measure the device state.|
|**2023-06-20**|**Exploring Antitrust and Platform Power in Generative AI**|Konrad Kollnig et.al.|[2306.11342v2](http://arxiv.org/abs/2306.11342v2)|null|The concentration of power in a few digital technology companies has become a subject of increasing interest in both academic and non-academic discussions. One of the most noteworthy contributions to the debate is Lina Khan's Amazon's Antitrust Paradox. In this work, Khan contends that Amazon has systematically exerted its dominance in online retail to eliminate competitors and subsequently charge above-market prices. This work contributed to Khan's appointment as the chair of the US Federal Trade Commission (FTC), one of the most influential antitrust organizations. Today, several ongoing antitrust lawsuits in the US and Europe involve major technology companies like Apple, Google/Alphabet, and Facebook/Meta. In the realm of generative AI, we are once again witnessing the same companies taking the lead in technological advancements, leaving little room for others to compete. This article examines the market dominance of these corporations in the technology stack behind generative AI from an antitrust law perspective.|
|**2023-06-19**|**Quasipolynomiality of the Smallest Missing Induced Subgraph**|David Eppstein et.al.|[2306.11185v1](http://arxiv.org/abs/2306.11185v1)|null|We study the problem of finding the smallest graph that does not occur as an induced subgraph of a given graph. This missing induced subgraph has at most logarithmic size and can be found by a brute-force search, in an $n$-vertex graph, in time $n^{O(\log n)}$. We show that under the Exponential Time Hypothesis this quasipolynomial time bound is optimal. We also consider variations of the problem in which either the missing subgraph or the given graph comes from a restricted graph family; for instance, we prove that the smallest missing planar induced subgraph of a given planar graph can be found in polynomial time.|
|**2023-06-19**|**Filtral pretoposes and compact Hausdorff locales**|Célia Borlido et.al.|[2306.11169v1](http://arxiv.org/abs/2306.11169v1)|null|We address the problem of characterising the category of compact Hausdorff locales, in analogy with the characterisation of the category of compact Hausdorff spaces as a pretopos recently obtained by V. Marra and L. Reggio (Theory Appl. Categ., 2020). Utilising the concept of filtrality introduced in op. cit., we identify sufficient conditions on a filtral pretopos ensuring that it can be embedded into the category of compact Hausdorff locales. Whereas the latter result is valid in the internal logic of a topos, if we assume the principle of weak excluded middle and the existence of copowers of the terminal object in the pretopos, the image of the embedding contains all spatial compact Hausdorff locales. Thus, provided that compact Hausdorff locales have enough points in the ambient logic, the embedding is an equivalence of categories. If the ambient logic is classical, we recover the aforementioned characterisation of compact Hausdorff spaces.|
|**2023-06-19**|**Toward the Cure of Privacy Policy Reading Phobia: Automated Generation of Privacy Nutrition Labels From Privacy Policies**|Shidong Pan et.al.|[2306.10923v1](http://arxiv.org/abs/2306.10923v1)|null|Software applications have become an omnipresent part of modern society. The consequent privacy policies of these applications play a significant role in informing customers how their personal information is collected, stored, and used. However, customers rarely read and often fail to understand privacy policies because of the ``Privacy Policy Reading Phobia'' (PPRP). To tackle this emerging challenge, we propose the first framework that can automatically generate privacy nutrition labels from privacy policies. Based on our ground truth applications about the Data Safety Report from the Google Play app store, our framework achieves a 0.75 F1-score on generating first-party data collection practices and an average of 0.93 F1-score on general security practices. We also analyse the inconsistencies between ground truth and curated privacy nutrition labels on the market, and our framework can detect 90.1% under-claim issues. Our framework demonstrates decent generalizability across different privacy nutrition label formats, such as Google's Data Safety Report and Apple's App Privacy Details.|
|**2023-06-19**|**Ion Intercalation in Lanthanum Strontium Ferrite for Aqueous Electrochemical Energy Storage Devices**|Yunqing Tang et.al.|[2306.10887v1](http://arxiv.org/abs/2306.10887v1)|null|Ion intercalation of perovskite oxides in liquid electrolytes is a very promising method for controlling their functional properties while storing charge, which opens the potential application in different energy and information technologies. Although the role of defect chemistry in the oxygen intercalation in a gaseous environment is well established, the mechanism of ion intercalation in liquid electrolytes at room temperature is poorly understood. In this study, the defect chemistry during ion intercalation of La0.5Sr0.5FeO3-{\delta} thin films in alkaline electrolytes is studied. Oxygen and proton intercalation into the LSF perovskite structure is observed at moderate electrochemical potentials (0.5 V to -0.4 V), giving rise to a change in the oxidation state of Fe (as a charge compensation mechanism). The variation of the concentration of holes as a function of the intercalation potential was characterized by in-situ ellipsometry and the concentration of electron holes was indirectly quantified for different electrochemical potentials. Finally, a dilute defect chemistry model that describes the variation of defect species during ionic intercalation was developed.|
|**2023-06-19**|**SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces**|Ziqiao Peng et.al.|[2306.10799v1](http://arxiv.org/abs/2306.10799v1)|null|Speech-driven 3D face animation technique, extending its applications to various multimedia fields. Previous research has generated promising realistic lip movements and facial expressions from audio signals. However, traditional regression models solely driven by data face several essential problems, such as difficulties in accessing precise labels and domain gaps between different modalities, leading to unsatisfactory results lacking precision and coherence. To enhance the visual accuracy of generated lip movement while reducing the dependence on labeled data, we propose a novel framework SelfTalk, by involving self-supervision in a cross-modals network system to learn 3D talking faces. The framework constructs a network system consisting of three modules: facial animator, speech recognizer, and lip-reading interpreter. The core of SelfTalk is a commutative training diagram that facilitates compatible features exchange among audio, text, and lip shape, enabling our models to learn the intricate connection between these factors. The proposed framework leverages the knowledge learned from the lip-reading interpreter to generate more plausible lip shapes. Extensive experiments and user studies demonstrate that our proposed approach achieves state-of-the-art performance both qualitatively and quantitatively. We recommend watching the supplementary video.|
|**2023-06-17**|**Enhancing the Prediction of Emotional Experience in Movies using Deep Neural Networks: The Significance of Audio and Language**|Sogand Mehrpour Mohammadi et.al.|[2306.10397v1](http://arxiv.org/abs/2306.10397v1)|null|Our paper focuses on making use of deep neural network models to accurately predict the range of human emotions experienced during watching movies. In this certain setup, there exist three clear-cut input modalities that considerably influence the experienced emotions: visual cues derived from RGB video frames, auditory components encompassing sounds, speech, and music, and linguistic elements encompassing actors' dialogues. Emotions are commonly described using a two-factor model including valence (ranging from happy to sad) and arousal (indicating the intensity of the emotion). In this regard, a Plethora of works have presented a multitude of models aiming to predict valence and arousal from video content. However, non of these models contain all three modalities, with language being consistently eliminated across all of them. In this study, we comprehensively combine all modalities and conduct an analysis to ascertain the importance of each in predicting valence and arousal. Making use of pre-trained neural networks, we represent each input modality in our study. In order to process visual input, we employ pre-trained convolutional neural networks to recognize scenes[1], objects[2], and actions[3,4]. For audio processing, we utilize a specialized neural network designed for handling sound-related tasks, namely SoundNet[5]. Finally, Bidirectional Encoder Representations from Transformers (BERT) models are used to extract linguistic features[6] in our analysis. We report results on the COGNIMUSE dataset[7], where our proposed model outperforms the current state-of-the-art approaches. Surprisingly, our findings reveal that language significantly influences the experienced arousal, while sound emerges as the primary determinant for predicting valence. In contrast, the visual modality exhibits the least impact among all modalities in predicting emotions.|
|**2023-06-16**|**The Big Data Myth: Using Diffusion Models for Dataset Generation to Train Deep Detection Models**|Roy Voetman et.al.|[2306.09762v1](http://arxiv.org/abs/2306.09762v1)|null|Despite the notable accomplishments of deep object detection models, a major challenge that persists is the requirement for extensive amounts of training data. The process of procuring such real-world data is a laborious undertaking, which has prompted researchers to explore new avenues of research, such as synthetic data generation techniques. This study presents a framework for the generation of synthetic datasets by fine-tuning pretrained stable diffusion models. The synthetic datasets are then manually annotated and employed for training various object detection models. These detectors are evaluated on a real-world test set of 331 images and compared against a baseline model that was trained on real-world images. The results of this study reveal that the object detection models trained on synthetic data perform similarly to the baseline model. In the context of apple detection in orchards, the average precision deviation with the baseline ranges from 0.09 to 0.12. This study illustrates the potential of synthetic data generation techniques as a viable alternative to the collection of extensive training data for the training of deep models.|
|**2023-06-15**|**Cuspidal crosscaps and folded singularities on a maxface and a minface**|Rivu Bardhan et.al.|[2306.09241v1](http://arxiv.org/abs/2306.09241v1)|null|For a given zero mean curvature surface $X$ (in the Lorentz Minkowski space) having folded singularity, we construct a family of maxface and minface, having increasing cuspidal crosscaps, converging to $X$. We include a general discussion of this.|
|**2023-06-14**|**A pose and shear-based tactile robotic system for object tracking, surface following and object pushing**|John Lloyd et.al.|[2306.08560v1](http://arxiv.org/abs/2306.08560v1)|null|Tactile perception is a crucial sensing modality in robotics, particularly in scenarios that require precise manipulation and safe interaction with other objects. Previous research in this area has focused extensively on tactile perception of contact poses as this is an important capability needed for tasks such as traversing an object's surface or edge, manipulating an object, or pushing an object along a predetermined path. Another important capability needed for tasks such as object tracking and manipulation is estimation of post-contact shear but this has received much less attention. Indeed, post-contact shear has often been considered a "nuisance variable" and is removed if possible because it can have an adverse effect on other types of tactile perception such as contact pose estimation. This paper proposes a tactile robotic system that can simultaneously estimate both the contact pose and post-contact shear, and use this information to control its interaction with other objects. Moreover, our new system is capable of interacting with other objects in a smooth and continuous manner, unlike the stepwise, position-controlled systems we have used in the past. We demonstrate the capabilities of our new system using several different controller configurations, on tasks including object tracking, surface following, single-arm object pushing, and dual-arm object pushing.|
|**2023-06-11**|**Characterizing the effect of retractions on scientific careers**|Shahan Ali Memon et.al.|[2306.06710v1](http://arxiv.org/abs/2306.06710v1)|[link](https://github.com/samemon/retraction_effects_on_academic_careers)|Retracting academic papers is a fundamental tool of quality control when the validity of papers or the integrity of authors is questioned post-publication. While retractions do not completely eliminate papers from the record, they have far-reaching consequences for retracted authors and their careers, serving as a visible and permanent signal of potential transgressions. Previous studies have highlighted the adverse effects of retractions on citation counts and co-authors' citations; however, the underlying mechanisms driving these effects and the broader impacts beyond these traditional metrics have not been fully explored. We address this gap leveraging Retraction Watch, the most extensive data set on retractions and link it to Microsoft Academic Graph, a comprehensive data set of scientific publications and their citation networks, and Altmetric that monitors online attention to scientific output. Our investigation focuses on: 1) the likelihood of authors exiting scientific publishing following retraction, and 2) the evolution of collaboration networks among authors who continue publishing after retraction. Our empirical analysis reveals that retracted authors, particularly those with less experience, tend to leave scientific publishing in the aftermath of retraction, particularly if their retractions attract widespread attention. Furthermore, we uncover a pattern whereby retracted authors who remain active in publishing tend to maintain and establish more collaborations compared to their similar non-retracted counterparts. Taken together, notwithstanding the indispensable role of retractions in upholding the integrity of the academic community, our findings shed light on the disproportionate impact that retractions impose on early-career researchers as opposed to those with more established careers.|
|**2023-06-11**|**Stability of isometric immersions of hypersurfaces**|Itai Alpern et.al.|[2306.06654v2](http://arxiv.org/abs/2306.06654v2)|null|We prove a stability result of isometric immersions of hypersurfaces in Riemannian manifolds, with respect to $L^p$-perturbations of their fundamental forms: For a manifold $M^d$ endowed with a reference metric and a reference shape operator, we show that a sequence of immersions $f_n:M^d\to N^{d+1}$, whose pullback metrics and shape operators are arbitrary close in $L^p$ to the reference ones, converge to an isometric immersion having the reference shape operator. This result is motivated by elasticity theory and generalizes a previous result by the authors to a general target manifold $N$, removing a constant curvature assumption. The method of proof differs from that in Alpern et al.: it extends a Young measure approach that was used in codimension-0 stability results, together with an appropriate relaxation of the energy and a regularity result for immersions satisfying given fundamental forms. In addition, we prove two related quantitative (rather than asymptotic) stability results: a codimension-1 result in the case of Euclidean target, similar to Ciarlet et al. (Anal. Appl. 2019) but with no a-priori assumed bounds, and a codimension-0 result between spheres, strengthening a result in Chen et al. (J. Math. Pures Appl. 2022).|
|**2023-06-09**|**Strategic Apple Tasting**|Keegan Harris et.al.|[2306.06250v1](http://arxiv.org/abs/2306.06250v1)|null|Algorithmic decision-making in high-stakes domains often involves assigning decisions to agents with incentives to strategically modify their input to the algorithm. In addition to dealing with incentives, in many domains of interest (e.g. lending and hiring) the decision-maker only observes feedback regarding their policy for rounds in which they assign a positive decision to the agent; this type of feedback is often referred to as apple tasting (or one-sided) feedback. We formalize this setting as an online learning problem with apple-tasting feedback where a principal makes decisions about a sequence of $T$ agents, each of which is represented by a context that may be strategically modified. Our goal is to achieve sublinear strategic regret, which compares the performance of the principal to that of the best fixed policy in hindsight, if the agents were truthful when revealing their contexts. Our main result is a learning algorithm which incurs $\tilde{\mathcal{O}}(\sqrt{T})$ strategic regret when the sequence of agents is chosen stochastically. We also give an algorithm capable of handling adversarially-chosen agents, albeit at the cost of $\tilde{\mathcal{O}}(T^{(d+1)/(d+2)})$ strategic regret (where $d$ is the dimension of the context). Our algorithms can be easily adapted to the setting where the principal receives bandit feedback -- this setting generalizes both the linear contextual bandit problem (by considering agents with incentives) and the strategic classification problem (by allowing for partial feedback).|
|**2023-06-09**|**Digital Twin-Assisted Resource Demand Prediction for Multicast Short Video Streaming**|Xinyu Huang et.al.|[2306.05946v1](http://arxiv.org/abs/2306.05946v1)|null|In this paper, we propose a digital twin (DT)-assisted resource demand prediction scheme to enhance prediction accuracy for multicast short video streaming. Particularly, we construct user DTs (UDTs) for collecting real-time user status, including channel condition, location, watching duration, and preference. A reinforcement learning-empowered K-means++ algorithm is developed to cluster users based on the collected user status in UDTs, which can effectively employ the mined users' intrinsic correlation to improve the accuracy of user clustering. We then analyze users' video watching duration and preferences in each multicast group to obtain the swiping probability distribution and recommended videos, respectively. The obtained information is utilized to predict radio and computing resource demand of each multicast group. Initial results demonstrate that the proposed scheme can effectively abstract multicast groups' swiping probability distributions for accurate resource demand prediction.|
|**2023-06-09**|**Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots**|Jiange Yang et.al.|[2306.05716v1](http://arxiv.org/abs/2306.05716v1)|null|Improving the generalization capabilities of general-purpose robotic agents has long been a significant challenge actively pursued by research communities. Existing approaches often rely on collecting large-scale real-world robotic data, such as the RT-1 dataset. However, these approaches typically suffer from low efficiency, limiting their capability in open-domain scenarios with new objects, and diverse backgrounds. In this paper, we propose a novel paradigm that effectively leverages language-grounded segmentation masks generated by state-of-the-art foundation models, to address a wide range of pick-and-place robot manipulation tasks in everyday scenarios. By integrating precise semantics and geometries conveyed from masks into our multi-view policy model, our approach can perceive accurate object poses and enable sample-efficient learning. Besides, such design facilitates effective generalization for grasping new objects with similar shapes observed during training. Our approach consists of two distinct steps. First, we introduce a series of foundation models to accurately ground natural language demands across multiple tasks. Second, we develop a Multi-modal Multi-view Policy Model that incorporates inputs such as RGB images, semantic masks, and robot proprioception states to jointly predict precise and executable robot actions. Extensive real-world experiments conducted on a Franka Emika robot arm validate the effectiveness of our proposed paradigm. Real-world demos are shown in YouTube (https://www.youtube.com/watch?v=1m9wNzfp_4E ) and Bilibili (https://www.bilibili.com/video/BV178411Z7H2/ ).|
|**2023-06-09**|**On the Mathematics of RNA Velocity II: Algorithmic Aspects**|Tiejun Li et.al.|[2306.05707v1](http://arxiv.org/abs/2306.05707v1)|null|In a previous paper [CSIAM Trans. Appl. Math. 2 (2021), 1-55], the authors proposed a theoretical framework for the analysis of RNA velocity, which is a promising concept in scRNA-seq data analysis to reveal the cell state-transition dynamical processes underlying snapshot data. The current paper is devoted to the algorithmic study of some key components in RNA velocity workflow. Four important points are addressed in this paper: (1) We construct a rational time-scale fixation method which can determine the global gene-shared latent time for cells. (2) We present an uncertainty quantification strategy for the inferred parameters obtained through the EM algorithm. (3) We establish the optimal criterion for the choice of velocity kernel bandwidth with respect to the sample size in the downstream analysis and discuss its implications. (4) We propose a temporal distance estimation approach between two cell clusters along the cellular development path. Some illustrative numerical tests are also carried out to verify our analysis. These results are intended to provide tools and insights in further development of RNA velocity type methods in the future.|
|**2023-06-09**|**Bound excitons and bandgap engineering in violet phosphorus**|Zhenyu Sun et.al.|[2306.05638v1](http://arxiv.org/abs/2306.05638v1)|null|Violet phosphorus (VP), the most stable phosphorus allotrope, is a van der Waals semiconductor that can be used to construct $\textit{p}$-type nanodevices. Recently, high-quality VP crystals have been synthesized while a deep insight into their excitonic properties and bandgap tailoring approaches, which are crucial for their optoelectronic device applications, is still lacking. Here, we study the optical properties of ultrathin VP by second harmonic generation, photoluminescence, and optical absorption spectroscopy. We observed strong bound exciton emission that is 0.48 eV away from the free exciton emission, which is among the largest in 2D materials. In addition, the bandgaps of VP are highly sensitive to the number of layers and external strain, which provides convenient approaches for bandgap engineering. The strong bound exciton emission and tunable bandgaps make VP a promising material in optoelectronic devices.|
|**2023-06-06**|**On Rado numbers for equations with unit fractions**|Collier Gaiser et.al.|[2306.04029v1](http://arxiv.org/abs/2306.04029v1)|null|Let $f_r(k)$ be the smallest positive integer $n$ such that every $r$-coloring of $\{1,2,...,n\}$ has a monochromatic solution to the nonlinear equation \[1/x_1+\cdots+1/x_k=1/y,\] where $x_1,...,x_k$ are not necessarily distinct. Brown and R\"{o}dl [Bull. Aust. Math. Soc. 43(1991): 387-392] proved that $f_2(k)=O(k^6)$. In this paper, we prove that $f_2(k)=O(k^3)$.   The main ingredient in our proof is a finite set $A\subseteq\mathbb{N}$ such that every $2$-coloring of $A$ has a monochromatic solution to the linear equation $x_1+\cdots+x_k=y$ and the least common multiple of $A$ is sufficiently small. This approach can also be used to study $f_r(k)$ with $r>2$. For example, a recent result of Boza, Mar\'{i}n, Revuelta, and Sanz [Discrete Appl. Math. 263(2019): 59-68] implies that $f_3(k)=O(k^{43})$.|
|**2023-06-06**|**Agent Performing Autonomous Stock Trading under Good and Bad Situations**|Yunfei Luo et.al.|[2306.03985v1](http://arxiv.org/abs/2306.03985v1)|[link](https://github.com/yunfeiluo/autonomous-stock-trading)|Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft, and IBM. These stocks are among the popular ones, and the changes in trends are representative in terms of having good and bad situations. We showed that before 2021, the three reinforcement methods we have tried always provide promising profit returns with total annual rates around $70\%$ to $90\%$, while maintain a positive profit return after 2021 with total annual rates around 2% to 7%.|
|**2023-06-06**|**Minimizing Hitting Time between Disparate Groups with Shortcut Edges**|Florian Adriaens et.al.|[2306.03571v2](http://arxiv.org/abs/2306.03571v2)|null|Structural bias or segregation of networks refers to situations where two or more disparate groups are present in the network, so that the groups are highly connected internally, but loosely connected to each other. In many cases it is of interest to increase the connectivity of disparate groups so as to, e.g., minimize social friction, or expose individuals to diverse viewpoints. A commonly-used mechanism for increasing the network connectivity is to add edge shortcuts between pairs of nodes. In many applications of interest, edge shortcuts typically translate to recommendations, e.g., what video to watch, or what news article to read next. The problem of reducing structural bias or segregation via edge shortcuts has recently been studied in the literature, and random walks have been an essential tool for modeling navigation and connectivity in the underlying networks. Existing methods, however, either do not offer approximation guarantees, or engineer the objective so that it satisfies certain desirable properties that simplify the optimization~task. In this paper we address the problem of adding a given number of shortcut edges in the network so as to directly minimize the average hitting time and the maximum hitting time between two disparate groups. Our algorithm for minimizing average hitting time is a greedy bicriteria that relies on supermodularity. In contrast, maximum hitting time is not supermodular. Despite, we develop an approximation algorithm for that objective as well, by leveraging connections with average hitting time and the asymmetric k-center problem.|
|**2023-06-06**|**Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation**|Xiao Lin et.al.|[2306.03392v1](http://arxiv.org/abs/2306.03392v1)|null|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|
|**2023-06-05**|**Spin Hall magnetoresistance in Pt/Y$_{3}$Fe$_{5}$O$_{12}$ bilayers grown on Si and Gd$_{3}$Ga$_{5}$O$_{12}$ substrates**|Kenta Fukushima et.al.|[2306.02575v1](http://arxiv.org/abs/2306.02575v1)|null|We study spin Hall magnetoresistance (SMR) in Pt/ferrimagnetic insulator Y$_{3}$Fe$_{5}$O$_{12}$ (YIG) bilayers by focusing on crystallinity, magnetization, and interface roughness by controlling post-annealing temperatures. The SMR in the Pt/YIG grown on Si substrate is comparable to that grown on widely used Gd$_{3}$Ga$_{5}$O$_{12}$ substrate, indicating that the large SMR can be achieved irrespective to the crystallinity. We deduced the spin mixing conductance from the Pt thickness dependence of the SMR to find the high interface quality of the optimized Pt/YIG grown on Si in terms of spin current. We also clarified that the SMR correlates well with the magnetization, the interface roughness, and carrier density. These findings highlight that optimizing YIG properties is a key to control of magnetization by spin current, leading to the development of low power consumption spintronic device based on the magnetic insulator.|
|**2023-06-05**|**Spin-orbit torque generation in bilayers composed of CoFeB and epitaxial SrIrO$_{3}$ grown on an orthorhombic DyScO$_{3}$ substrate**|Sosuke Hori et.al.|[2306.02567v1](http://arxiv.org/abs/2306.02567v1)|null|We report on the highly efficient spin-orbit torque (SOT) generation in epitaxial SrIrO$_{3}$(SIO), which is grown on an orthorhombic DyScO$_{3}$(110) substrate. By conducting harmonic Hall measurement in Co$_{20}$Fe$_{60}$B$_{20}$ (CoFeB)/SIO bilayers, we characterize two kinds of the SOTs, i.e., dampinglike (DL) and fieldlike ones to find that the former is much larger than the latter. By comparison with the Pt control sample with the same CoFeB thickness, the observed DL SOT efficiency $\xi$$_{DL}$ of SIO ($\sim$0.32) is three times higher than that of Pt ($\sim$0.093). The $\xi$$_{DL}$ is nearly constant as a function of the CoFeB thickness, suggesting that the SIO plays a crucial role in the large SOT generation. These results on the CoFeB/SIO bilayers highlight that the epitaxial SIO is promising for low-current and reliable spin-orbit torque-controlled devices.|
|**2023-06-04**|**Star dynamics: collapse vs. expansion**|Mahir Hadzic et.al.|[2306.02445v1](http://arxiv.org/abs/2306.02445v1)|null|We review a series of recent results on global dynamic properties of radially symmetric self-gravitating compressible Euler flows, which naturally arise in the mathematical description of stars. We focus on the role of scaling invariances and how they interact with nonlinearities to generate imploding finite-time singularities as well as expanding star solutions, arising from smooth initial data. This review paper is based on joint works with Y. Guo, J. Jang, and M. Schrecker.|
|**2023-06-04**|**Simple realization of a hybrid controlled-controlled-Z gate with photonic control qubits encoded via eigenstates of the photon-number parity operator**|Qi-Ping Su et.al.|[2306.02229v1](http://arxiv.org/abs/2306.02229v1)|null|We propose a simple method to realize a hybrid controlled-controlled-Z (CCZ) gate with two photonic qubits simultaneously controlling a superconducting (SC) target qubit, by employing two microwave cavities coupled to a SC ququart (a four-level quantum system). In this proposal, each control qubit is a photonic qubit, which is encoded by two arbitrary orthogonal eigenstates (with eigenvalues 1 and -1, respectively) of the photon-number parity operator. Since the two arbitrary encoding states can take various quantum states, this proposal can be applied to realize the hybrid CCZ gate, for which the two control photonic qubits can have various encodings. The gate realization is quite simple because only a basic operation is needed. During the gate operation, the higher energy intermediate levels of the ququart are not occupied, and, thus, decoherence from these levels is greatly suppressed. We further discuss how to apply this gate to generate a hybrid Greenberger-Horne-Zeilinger (GHZ) entangled state of a SC qubit and two photonic qubits, which takes a general form. As an example, our numerical simulation demonstrates that high-fidelity generation of a cat-cat-spin hybrid GHZ state is feasible within current circuit QED technology. This proposal is quite general, which can be applied to realize the hybrid CCZ gate as well as to prepare various hybrid GHZ states of a matter qubit and two photonic qubits in other physical systems, such as two microwave or optical cavities coupled to a four-level natural or artificial atom.|

## wearable device

### wearable device
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Investigating the Usability of Collaborative Robot control through Hands-Free Operation using Eye gaze and Augmented Reality**|Joosun Lee et.al.|[2306.13072v1](http://arxiv.org/abs/2306.13072v1)|null|This paper proposes a novel operation for controlling a mobile robot using a head-mounted device. Conventionally, robots are operated using computers or a joystick, which creates limitations in usability and flexibility because control equipment has to be carried by hand. This lack of flexibility may prevent workers from multitasking or carrying objects while operating the robot. To address this limitation, we propose a hands-free method to operate the mobile robot with a human gaze in an Augmented Reality (AR) environment. The proposed work is demonstrated using the HoloLens 2 to control the mobile robot, Robotnik Summit-XL, through the eye-gaze in AR. Stable speed control and navigation of the mobile robot were achieved through admittance control which was calculated using the gaze position. The experiment was conducted to compare the usability between the joystick and the proposed operation, and the results were validated through surveys (i.e., SUS, SEQ). The survey results from the participants after the experiments showed that the wearer of the HoloLens accurately operated the mobile robot in a collaborative manner. The results for both the joystick and the HoloLens were marked as easy to use with above-average usability. This suggests that the HoloLens can be used as a replacement for the joystick to allow hands-free robot operation and has the potential to increase the efficiency of human-robot collaboration in situations when hands-free controls are needed.|
|**2023-06-22**|**The deformed Inozemtsev spin chain**|Rob Klabbers et.al.|[2306.13066v1](http://arxiv.org/abs/2306.13066v1)|null|We present two new quantum-integrable models with long-range spin interactions. First, a partially isotropic (xxz-type) spin chain that unifies the Inozemtsev and partially isotropic Haldane-Shastry chains. Its short-range limit is a variant of the twisted Heisenberg xxz chain. Second, a quantum many-body system that generalises the elliptic Ruijsenaars model by including spins with interactions mediated by dynamical R-matrices. It unifies the elliptic Calogero-Sutherland and trigonometric Ruijsenaars-Macdonald models with spins, and gives our spin chain by 'freezing'.|
|**2023-06-22**|**Spin fractionalization in a Kondo-lattice superconductor heterostructure**|Ethan Huecker et.al.|[2306.13051v1](http://arxiv.org/abs/2306.13051v1)|null|Kondo lattices are one of the classic models of strongly correlated systems where despite a long history, a full understanding of the excitation spectra is still not available. Here we propose that recent progress in engineering heterostructures can be leveraged to gain insight into and even tune this spectra. We use a strong Kondo coupling expansion to study spin-1 excitations of a Kondo lattice in both one and two-dimension to see whether or not paramagnons in a Kondo insulator fractionalize into spin-1/2 excitations. We show that while paramagnons are stable in the strong Kondo coupling limit, presence of sufficient proximity-induced superconducting pairing can favor fractionalization. Our results can be checked using a neutron scattering study of Kondo lattice heterostructures and paves the way toward engineering strongly correlated electronic systems.|
|**2023-06-22**|**Global existence of 2D electron MHD near a steady state**|Mimi Dai et.al.|[2306.13036v1](http://arxiv.org/abs/2306.13036v1)|null|We study the electron magnetohydrodynamics (MHD) in two dimensional geometry, which has a rich family of steady states. In an anisotropic resistivity context, we show global in time existence of small smooth solution near a shear type steady state. Convergence rate of the solution to the steady state is also obtained.|
|**2023-06-22**|**Strain-induced frustrated helimagnetism and topological spin textures in LiCrTe$_{2}$**|Weiyi Pan et.al.|[2306.13035v1](http://arxiv.org/abs/2306.13035v1)|null|By performing first-principles calculations in conjunction with Monte Carlo simulations, we systematically investigated the frustrated magnetic states induced by in-plane compressive strain in LiCrTe$_{2}$. Our calculations support that the magnetic ground state of LiCrTe$_{2}$ crystal is A-type antiferromagnetic (AFM), with an in-plane ferromagnetic (FM) state and interlayer AFM coupling. Furthermore, it is found that compressive strain can significantly alter the magnetic interactions, giving rise to a transition from an in-plane FM to an AFM state, undergoing a helimagnetic phase. Remarkably, a highly frustrated helimagnetic state with disordered spin spirals under moderate strain arises from the competition between spiral propagation modes along distinct directions. In addition, various topological spin defects emerge in this frustrated helimagnetic phase, which are assembled from various domain wall units. These topological defects can be further tuned with external magnetic fields. Our calculations not only uncover the origin of exotic frustrated magnetism in triangular lattice magnetic systems, but also offer a promising route to engineer the frustrated and topological magnetic state, which is of significance in both fundamental research and technological applications.|
|**2023-06-22**|**Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection**|Mert Nakıp et.al.|[2306.13029v1](http://arxiv.org/abs/2306.13029v1)|null|Cyberattacks are increasingly threatening networked systems, often with the emergence of new types of unknown (zero-day) attacks and the rise of vulnerable devices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs) have been shown to be extremely promising in detecting these attacks, the need to learn large amounts of labelled data often limits the applicability of ML-based IDSs to cybersystems that only have access to private local data. To address this issue, this paper proposes a novel Decentralized and Online Federated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is a collaborative learning system that allows each IDS used for a cybersystem to learn from experience gained in other cybersystems in addition to its own local data without violating the data privacy of other systems. As the performance evaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID significantly improves the intrusion detection performance in all collaborating nodes simultaneously with acceptable computation time for online learning.|
|**2023-06-22**|**Enhancing ReaxFF for Molecular Dynamics Simulations of Lithium-Ion Batteries: An interactive reparameterization protocol**|Paolo De Angelis et.al.|[2306.13027v1](http://arxiv.org/abs/2306.13027v1)|[link](https://github.com/paolodeangelis/enhancing_reaxff)|Lithium-ion batteries (LIBs) are crucial for the green economy, powering portable electronics, electric vehicles, and renewable energy systems. The solid-electrolyte interphase (SEI) is vital for LIB operation, performance, and safety. SEI forms due to thermal instability at the anode-electrolyte interface, with electrolyte reduction products stabilizing it as an electrochemical buffer. This article aims to enhance the parametrization of the ReaxFF force field for accurate molecular dynamics (MD) simulations of SEI in LIBs.   Focus is on Lithium Fluoride (LiF), an inorganic salt with favorable properties in the passivation layer. The protocol heavily relies on Python libraries for atomistic simulations, enabling robust automation of reparameterization steps. The proposed configurations and dataset enable the new ReaxFF to accurately represent the solid nature of LiF and improve mass transport property prediction in MD simulations. Optimized ReaxFF surpasses previous force fields by adjusting lithium diffusivity, resulting in a significant improvement in room temperature prediction by two orders of magnitude.   However, our comprehensive investigation reveals ReaxFF's strong sensitivity to the training set, challenging its ability to interpolate the potential energy surface. Consequently, the current ReaxFF formulation is suitable for modeling specific phenomena by utilizing the proposed interactive reparameterization protocol and constructing a dataset. This work is an important step towards refining ReaxFF for precise reactive MD simulations, shedding light on challenges and limitations in force field parametrization. The demonstrated limitations underscore the potential for developing more advanced force fields through our interactive reparameterization protocol, enabling accurate and comprehensive MD simulations in the future.|
|**2023-06-22**|**A quantum coherent spin in a two-dimensional material at room temperature**|Hannah L. Stern et.al.|[2306.13025v1](http://arxiv.org/abs/2306.13025v1)|null|Quantum networks and sensing require solid-state spin-photon interfaces that combine single-photon generation and long-lived spin coherence with scalable device integration, ideally at ambient conditions. Despite rapid progress reported across several candidate systems, those possessing quantum coherent single spins at room temperature remain extremely rare. Here, we report quantum coherent control under ambient conditions of a single-photon emitting defect spin in a a two-dimensional material, hexagonal boron nitride. We identify that the carbon-related defect has a spin-triplet electronic ground-state manifold. We demonstrate that the spin coherence is governed predominantly by coupling to only a few proximal nuclei and is prolonged by decoupling protocols. Our results allow for a room-temperature spin qubit coupled to a multi-qubit quantum register or quantum sensor with nanoscale sample proximity.|
|**2023-06-22**|**Magnetic Dirac semimetal state of (Mn,Ge)Bi$_2$Te$_4$**|Alexander S. Frolov et.al.|[2306.13024v1](http://arxiv.org/abs/2306.13024v1)|null|For quantum electronics, the possibility to finely tune the properties of magnetic topological insulators (TIs) is a key issue. We studied solid solutions between two isostructural Z$_2$ TIs, magnetic MnBi$_2$Te$_4$ and nonmagnetic GeBi$_2$Te$_4$, with Z$_2$ invariants of 1;000 and 1;001, respectively. For high-quality, large mixed crystals of Ge$_x$Mn$_{1-x}$Bi$_2$Te$_4$, we observed linear x-dependent magnetic properties, composition-independent pairwise exchange interactions along with an easy magnetization axis. The bulk band gap gradually decreases to zero for $x$ from 0 to 0.4, before reopening for $x>0.6$, evidencing topological phase transitions (TPTs) between topologically nontrivial phases and the semimetal state. The TPTs are driven purely by the variation of orbital contributions. By tracing the x-dependent $6p$ contribution to the states near the fundamental gap, the effective spin-orbit coupling variation is extracted. As $x$ varies, the maximum of this contribution switches from the valence to the conduction band, thereby driving two TPTs. The gapless state observed at $x=0.42$ closely resembles a Dirac semimetal above the Neel temperature and shows a magnetic gap below, which is clearly visible in raw photoemission data. The observed behavior of the Ge$_x$Mn$_{1-x}$Bi$_2$Te$_4$ system thereby demonstrates an ability to precisely control topological and magnetic properties of TIs.|
|**2023-06-22**|**Modelling non-Markovian noise in driven superconducting qubits**|Abhishek Agarwal et.al.|[2306.13021v1](http://arxiv.org/abs/2306.13021v1)|null|Non-Markovian noise can be a significant source of errors in superconducting qubits. We develop gate sequences utilising mirrored pseudoidentities that allow us to characterise and model the effects of non-Markovian noise on both idle and driven qubits. We compare three approaches to modelling the observed noise: (i) a Markovian noise model, (ii) a model including interactions with a two-level system (TLS), (iii) a model utilising the post Markovian master equation (PMME), which we show to be equivalent to the qubit-TLS model in certain regimes. When running our noise characterisation circuits on a superconducting qubit device we find that purely Markovian noise models cannot reproduce the experimental data. Our model based on a qubit-TLS interaction, on the other hand, is able to closely capture the observed experimental behaviour for both idle and driven qubits. We investigate the stability of the noise properties of the hardware over time, and find that the parameter governing the qubit-TLS interaction strength fluctuates significantly even over short time-scales of a few minutes. Finally, we evaluate the changes in the noise parameters when increasing the qubit drive pulse amplitude. We find that although the hardware noise parameters fluctuate significantly over different days, their drive pulse induced relative variation is rather well defined within computed uncertainties: both the phase error and the qubit-TLS interaction strength change significantly with the pulse strength, with the phase error changing quadratically with the amplitude of the applied pulse. Since our noise model can closely describe the behaviour of idle and driven qubits, it is ideally suited to be used in the development of quantum error mitigation and correction methods.|
|**2023-06-22**|**Gilbert damping in metallic ferromagnets from Schwinger-Keldysh field theory: Nonlocality, nonuniformity, and anisotropy in the presence of spin-orbit coupling**|Felipe Reyes-Osorio et.al.|[2306.13013v1](http://arxiv.org/abs/2306.13013v1)|null|Understanding the origin of damping mechanisms in magnetization dynamics of metallic ferromagnets is a fundamental problem for nonequilibrium many-body physics of systems where quantum conduction electrons interact with localized spins assumed to be governed by the classical Landau-Lifshitz-Gilbert (LLG) equation. It is also of critical importance for applications as damping affects energy consumption and speed of spintronic and magnonic devices. Since the 1970s, a variety of linear-response and scattering theory approaches have been developed to produce widely used formulas for computation of spatially-independent Gilbert scalar parameter as the magnitude of the Gilbert damping term in the LLG equation. The largely-unexploited-for-this-purpose Schwinger-Keldysh field theory (SKFT) offers additional possibilities, such as rigorously deriving an extended LLG equation by integrating quantum electrons out. Here we derive such equation whose Gilbert damping for metallic ferromagnets in $d=1$-$3$ dimensions is nonlocal-i.e., dependent on position of all localized spins at a given time-and nonuniform, even if all localized spins are collinear and spin-orbit coupling (SOC) is absent. This is in sharp contrast to standard lore, where nonlocal damping is possible only if localized spins are noncollinear, while SOC is required to obtain a standard Gilbert damping scalar parameter for collinear localized spins. The same mechanism, which is physically due to retarded response of conduction electronic spins to the motion of localized spins, generates wavevector-dependent damping on spin waves, whereas nonzero SOC makes nonlocal damping anisotropic. Our analytical formulas, with their nonlocality being more prominent in low spatial dimensions $d \le 2$, are fully corroborated by numerically exact $d=1$ quantum-classical simulations.|
|**2023-06-22**|**Collider Signatures of Near-Continuum Dark Matter**|Steven Ferrante et.al.|[2306.13009v1](http://arxiv.org/abs/2306.13009v1)|[link](https://github.com/sferrante/vegasmc_wic)|In this paper we study a near-continuum dark matter model, in which dark sector consists of a tower of closely spaced states with weak-scale masses. We construct a five-dimensional model which naturally realizes this spectrum. The dark matter is described by a bulk field, which interacts with the brane-localized Standard Model sector via a Z portal. We then study collider signatures of this model. Near-continuum dark matter states produced in a collider undergo cascade decays, resulting in events with high multiplicity of jets and leptons, large missing energy, and displaced vertices. A custom-built Monte Carlo tool described in this paper allows for detailed simulation of the signal events. We present results of such simulations for the case of electron-positron collisions.|
|**2023-06-22**|**Stabilization of symmetry-protected long-range entanglement in stochastic quantum circuits**|Iosifina Angelidi et.al.|[2306.13008v1](http://arxiv.org/abs/2306.13008v1)|null|Long-range entangled states are vital for quantum information processing and quantum metrology. Preparing such entangled states by combining measurements with unitary gates has opened new possibilities for efficient protocols with finite-depth quantum circuits. The complexity of these algorithms is crucial for the resource requirements on a quantum device. The stability of the preparation protocols to perturbations decides the fate of their implementation in large-scale noisy quantum devices. In this work, we consider stochastic quantum circuits in one and two dimensions consisting of randomly applied unitary gates and local measurements. These quantum operations preserve a class of discrete local symmetries, which can be broken due to the stochasticity arising from timing and gate imperfections. In the absence of randomness, the protocol is known to generate a symmetry-protected long-range entangled state in a finite-depth circuit. In the general case, by studying the time evolution under this hybrid quantum circuit, we analyze the time to reach the target entangled state. We find two important time scales which we associate with the emergence of certain symmetry generators. The quantum trajectories embody the local symmetry with a time that scales logarithmically with system size, whereas global symmetries require exponentially long times to appear. We devise error-mitigation protocols that provide significant improvement on both time scales and investigate the stability of the algorithm to perturbations that naturally arise in experiments. We also generalize the protocol to realize the toric code and Xu-Moore states in two dimensions, and open avenues for future studies of anyonic excitations present in those systems. Our work paves the way for efficient error correction for quantum state preparation.|
|**2023-06-22**|**Strong-field photoionization by circularly polarized light**|Jonathan Dubois et.al.|[2306.12999v1](http://arxiv.org/abs/2306.12999v1)|null|We demonstrate that strong-field ionization of atoms driven by circularly polarized light becomes an adiabatic process when described in the frame rotating with the laser field. As a direct consequence, a conservation law emerges: in the rotating frame the energy of the tunneling electron is conserved for rotationally invariant potentials. This conservation law, arising from a classical picture, is retrieved through a proper classical-quantum correspondence when considering the full quantum system, beyond the Strong Field Approximation.|
|**2023-06-22**|**Transversity distributions and tensor charges of the nucleon: extraction from dihadron production and their universal nature**|C. Cocuzza et.al.|[2306.12998v1](http://arxiv.org/abs/2306.12998v1)|null|We perform the first global quantum chromodynamics (QCD) analysis of dihadron production for a comprehensive set of data in electron-positron annihilation, semi-inclusive deep-inelastic scattering, and proton-proton collisions, from which we extract simultaneously the transversity distributions of the nucleon and $\pi^+\pi^-$ dihadron fragmentation functions. We incorporate in our fits known theoretical constraints on transversity, namely, its small-$x$ asymptotic behavior and the Soffer bound. We furthermore show that lattice-QCD results for the tensor charges can be successfully included in the analysis. This resolves the previously reported incompatibility between the tensor charges extracted from dihadron production data and lattice QCD. We also find agreement with results for the transversity and tensor charges obtained from measurements on single-hadron production. Overall, our work demonstrates for the first time the universal nature of all available information for the transversity distributions and the tensor charges of the nucleon.|
|**2023-06-22**|**Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers**|Qi Jiang et.al.|[2306.12992v1](http://arxiv.org/abs/2306.12992v1)|[link](https://github.com/zju-jiangqi/pcie-part)|High-quality panoramic images with a Field of View (FoV) of 360-degree are essential for contemporary panoramic computer vision tasks. However, conventional imaging systems come with sophisticated lens designs and heavy optical components. This disqualifies their usage in many mobile and wearable applications where thin and portable, minimalist imaging systems are desired. In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to address minimalist and high-quality panoramic imaging. With less than three spherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is constructed based on the design of the Panoramic Annular Lens (PAL), but with low-quality imaging results due to aberrations and small image plane size. We propose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and Aberration Correction (SR&AC), to solve the image quality problems of MPIP, with imaging sensors of small and large pixel size, respectively. To provide a universal network for the two pipelines, we leverage the information from the Point Spread Function (PSF) of the optical system and design a PSF-aware Aberration-image Recovery Transformer (PART), in which the self-attention calculation and feature extraction are guided via PSF-aware mechanisms. We train PART on synthetic image pairs from simulation and put forward the PALHQ dataset to fill the gap of real-world high-quality PAL images for low-level vision. A comprehensive variety of experiments on synthetic and real-world benchmarks demonstrates the impressive imaging results of PCIE and the effectiveness of plug-and-play PSF-aware mechanisms. We further deliver heuristic experimental findings for minimalist and high-quality panoramic imaging. Our dataset and code will be available at https://github.com/zju-jiangqi/PCIE-PART.|
|**2023-06-22**|**Inclusive probability to record an electron in elastic electromagnetic scattering by a spin one-half hadron wave packet**|P. O. Kazinski et.al.|[2306.12987v1](http://arxiv.org/abs/2306.12987v1)|null|The inclusive probability to record an electron in elastic electromagnetic scattering of an electron by a spin one-half hadron is obtained, the initial quantum states of the electron and the hadron being described by the density matrices of a general form. Contrary to the Rosenbluth formula for the differential cross-section for this process, the first nontrivial contribution to the inclusive probability turns out to be of order $\alpha$ and not $\alpha^2$. This contribution describes the interference between the trivial contribution to the $S$-matrix and the leading contribution to its connected part. The explicit expression for this interference terms is derived. It is shown that the same interference term arises when the electron is scattered by the classical electromagnetic field produced by the hadron electromagnetic current averaged with respect to the free evolving density matrix of the hadron, even in the case of a single hadron. The interference term describes coherent scattering of the electron by the hadron wave packet and is immune to the quantum recoil experienced by a hadron due to scattering. The effective electron mass operator is found on the mass-shell.|
|**2023-06-22**|**Single-file transport of binary hard-sphere mixtures through periodic potentials**|David Voráč et.al.|[2306.12979v1](http://arxiv.org/abs/2306.12979v1)|null|Single-file transport occurs in various scientific fields, including diffusion through nanopores, nanofluidic devices, and cellular processes. We here investigate the impact of polydispersity on particle currents for single-file Brownian motion of hard spheres, when they are driven through periodic potentials by a constant drag force. Through theoretical analysis and extensive Brownian dynamics simulations, we unveil the behavior of particle currents for random binary mixtures. The particle currents show a recurring pattern in dependence of the hard-sphere diameters and mixing ratio. We explain this recurrent behavior by showing that a basic unit cell exists in the space of the two hard-sphere diameters. Once the behavior of an observable inside the unit cell is determined, it can be inferred for any diameter. The overall variation of particle currents with the mixing ratio and hard-sphere diameters is reflected by their variation in the limit where the system is fully covered by hard spheres. In this limit, the currents can be predicted analytically. Our analysis explains the occurrence of pronounced maxima and minima of the currents by changes of an effective potential barrier for the center-of-mass motion.|
|**2023-06-22**|**Generating optical cat states via quantum interference of multi-path free-electron-photons interactions**|Feng-Xiao Sun et.al.|[2306.12959v1](http://arxiv.org/abs/2306.12959v1)|null|The novel quantum effects induced by the free-electron-photons interaction have attracted increasing interest due to their potential applications in ultrafast quantum information processing. Here, we propose a scheme to generate optical cat states based on the quantum interference of multi-path free-electron-photons interactions that take place simultaneously with strong coupling strength. By performing a projection measurement on the electron, the state of light changes significantly from a coherent state into a non-Gaussian state with either Wigner negativity or squeezing property, both possess metrological power to achieve quantum advantage. More importantly, we show that the Wigner negativity oscillates with the coupling strength, and the optical cat states are successfully generated with high fidelity at all the oscillation peaks. This oscillation reveals the quantum interference effect of the multiple quantum pathways in the interaction of the electron with photons, by that various nonclassical states of light are promising to be fast prepared and manipulated. These findings inspire further exploration of emergent quantum phenomena and advanced quantum technologies with free electrons.|
|**2023-06-22**|**Pauli blocking effects on pair creation in strong electric field**|Mikalai Prakapenia et.al.|[2306.12956v1](http://arxiv.org/abs/2306.12956v1)|null|The process of electron-positron pair creation and oscillation in uniform electric field is studied, taking into account Pauli exclusion principle. Generally, we find that pair creation is suppressed, hence coherent oscillations occur on longer time scales. Considering pair creation in already existing electron-positron plasma we find that the dynamics depends on pair distribution function. We considered Fermi-Dirac distribution of pairs and found that for small temperatures pair creation is suppressed, while for small chemical potentials it increases: heating leads to enhancement of pair creation.|
|**2023-06-22**|**The source of electrons at comet 67P**|P. Stephenson et.al.|[2306.12942v1](http://arxiv.org/abs/2306.12942v1)|null|We examine the origin of electrons in a weakly outgassing comet, using Rosetta mission data and a 3D collisional model of electrons at a comet. We have calculated a new dataset of electron-impact ionization (EII) frequency throughout the Rosetta escort phase, with measurements of the Rosetta Plasma Consortium's Ion and Electron Sensor (RPC/IES). The EII frequency is evaluated in 15-minute intervals and compared to other Rosetta datasets.   Electron-impact ionization is the dominant source of electrons at 67P away from perihelion and is highly variable (by up to three orders of magnitude). Around perihelion, EII is much less variable and less efficient than photoionization at Rosetta. Several drivers of the EII frequency are identified, including magnetic field strength and the outgassing rate. Energetic electrons are correlated to the Rosetta-upstream solar wind potential difference, confirming that the ionizing electrons are solar wind electrons accelerated by an ambipolar field.   The collisional test particle model incorporates a spherically symmetric, pure water coma and all the relevant electron-neutral collision processes. Electric and magnetic fields are stationary model inputs, and are computed using a fully-kinetic, collisionless Particle-in-Cell simulation. Collisional electrons are modelled at outgassing rates of $Q=10^{26}$ s$^{-1}$ and $Q=1.5\times10^{27}$ s$^{-1}$. Secondary electrons are the dominant population within a weakly outgassing comet. These are produced by collisions of solar wind electrons with the neutral coma.   The implications of large ion flow speed estimates at Rosetta, away from perihelion, are discussed in relation to multi-instrument studies and the new results of the EII frequency obtained in the present study.|
|**2023-06-22**|**Watt-class CMOS-compatible power amplifier**|Neetesh Singh et.al.|[2306.12940v1](http://arxiv.org/abs/2306.12940v1)|null|Power amplifier is becoming a critical component for integrated photonics as the integrated devices try to carve out a niche in the world of real-world applications of photonics. That is because the signal generated from an integrated device severely lacks in power which is due mainly to the small size which, although gives size and weight advantage, limits the energy storage capacity of an integrated device due to the small volume, causing it to rely on its bench-top counterpart for signal amplification downstream. Therefore, an integrated high-power signal booster can play a major role by replacing these large solid-state and fiber-based benchtop systems. For decades, large mode area (LMA) technology has played a disruptive role by increasing the signal power and energy by orders of magnitude in the fiber-based lasers and amplifiers. Thanks to the capability of LMA fiber to support significantly larger optical modes the energy storage and handling capability has significantly increased. Such an LMA device on an integrated platform can play an important role for high power applications. In this work, we demonstrate LMA waveguide based CMOS compatible watt-class power amplifier with an on-chip output power reaching ~ 1W within a footprint of ~4mm2.The power achieved is comparable and even surpasses many fiber-based amplifiers. We believe this work opens up opportunities for integrated photonics to find real world application on-par with its benchtop counterpart.|
|**2023-06-22**|**Development of Impedance Sheath Boundary Condition in Stix Finite Element RF Code**|Christina Migliore et.al.|[2306.12930v1](http://arxiv.org/abs/2306.12930v1)|null|Ion cyclotron radio frequency range (ICRF) power plays an important role in heating and current drive in fusion devices. However, experiments show that in the ICRF regime there is a formation of a radio frequency (RF) sheath at the material and antenna boundaries that influences sputtering and power dissipation. Given the size of the sheath relative to the scale of the device, it can be approximated as a boundary condition (BC). Electromagnetic field solvers in the ICRF regime typically treat material boundaries as perfectly conducting, thus ignoring the effect of the RF sheath. Here we describe progress on implementing a model for the RF sheath based on a finite impedance sheath BC formulated by J. Myra and D. A. D'Ippolito, Physics of Plasmas 22 (2015) which provides a representation of the RF rectified sheath including capacitive and resistive effects. This research will discuss the results from the development of a parallelized cold-plasma wave equation solver Stix that implements this non-linear sheath impedance BC through the method of finite elements in pseudo-1D and pseudo-2D using the MFEM library. The verification and comparison of the sheath BC from Stix with results from H. Kohno and J. Myra, Computer Physics Communications 220 129-142 (2017) will also be discussed.|
|**2023-06-22**|**Superconducting stripes in the hole-doped three-band Hubbard model**|Boris Ponsioen et.al.|[2306.12910v1](http://arxiv.org/abs/2306.12910v1)|null|We study the ground state properties of the hole-doped three-band Hubbard (Emery) model, describing the copper-oxygen planes of the cuprates, using large-scale 2D tensor network calculations. Our simulations reveal a period 4 stripe state with spin and weak charge order over an extended doping range beyond $\delta\sim0.12$ and stripes with larger periods at smaller doping. The period 4 stripe exhibits coexisting $d$-wave superconductivity in the doping range $0.15 \lesssim \delta < 0.25$, while at smaller doping around $\delta \sim 1/8$ we find a strong competition between superconducting and non-superconducting stripes, including also pair density-wave states with alternating sign structure on neighboring stripes, suggesting that the fate of superconductivity around 1/8 doping may be sensitive on the model parameters.|
|**2023-06-22**|**Out-of-equilibrium charge redistribution in a copper-oxide based superconductor by time-resolved X-ray photoelectron spectroscopy**|Denny Puntel et.al.|[2306.12905v1](http://arxiv.org/abs/2306.12905v1)|null|Charge-transfer excitations are of paramount importance for understanding the electronic structure of copper-oxide based high-temperature superconductors. In this study, we investigate the response of a Bi$_2$Sr$_2$CaCu$_2$O$_{\mathrm{8}+ \delta}$ crystal to the charge redistribution induced by an infrared ultrashort pulse. Element-selective time-resolved core-level photoelectron spectroscopy with a high energy resolution allows disentangling the dynamics of oxygen ions with different coordination and bonds thanks to their different chemical shifts. Our experiment shows that the O\,$1s$ component arising from the Cu-O planes is significantly perturbed by the infrared light pulse. Conversely, the apical oxygen, also coordinated with Sr ions in the Sr-O planes, remains unaffected. This result highlights the peculiar behavior of the electronic structure of the Cu-O planes. It also unlocks the way to study the out-of-equilibrium electronic structure of copper-oxide-based high-temperature superconductors by identifying the O\,$1s$ core-level emission originating from the oxygen ions in the Cu-O planes. This ability could be critical to gain information about the strongly-correlated electron ultrafast dynamical mechanisms in the Cu-O plane in the normal and superconducting phases.|
|**2023-06-22**|**On the nature of the two-positron bond: Evidence for a novel bond type**|Mohammad Goli et.al.|[2306.12899v1](http://arxiv.org/abs/2306.12899v1)|null|The nature of the newly proposed two-positron bond in (PsH)2, which is composed of two protons, four electrons and two positrons, is considered in this contribution. The study is done at the multi-component-Hartree-Fock (MC-HF) and the Diffusion Monte Carlo (DMC) levels of theory by comparing ab initio data, analyzing the spatial structure of the DMC wavefunction, and applying the multi-component quantum theory of atoms in molecules and the two-component interacting quantum atoms energy partitioning schemes to the MC-HF wavefunction. The analysis demonstrates that (PsH)2 to a good approximation may be conceived of two slightly perturbed PsH atoms, bonded through a two-positron bond. In contrast to the usual two-electron bonds, the positron exchange phenomenon is marginal in the considered two-positron bond. The main stabilizing mechanism of bonding is a novel type of classical electrostatic interaction between the positrons, which are mainly localized between nuclei, and the surrounding electrons. To emphasize its uniqueness, this mechanism of bonding is proposed to be called gluonic which has also been previously identified as the main deriving mechanism behind formation of the one-positron bond in [H-, e+, H-] . We conclude that the studied two-positron bond should not be classified as a covalent bond and it must be seen as a brand-new type of bond, foreign to the electronic bonding modes discovered so far in the purely electronic systems.|
|**2023-06-22**|**Machine-Learning-Assisted and Real-Time-Feedback-Controlled Growth of InAs/GaAs Quantum Dots**|Chao Shen et.al.|[2306.12898v1](http://arxiv.org/abs/2306.12898v1)|null|Self-assembled InAs/GaAs quantum dots (QDs) have properties highly valuable for developing various optoelectronic devices such as QD lasers and single photon sources. The applications strongly rely on the density and quality of these dots, which has motivated studies of the growth process control to realize high-quality epi-wafers and devices. Establishing the process parameters in molecular beam epitaxy (MBE) for a specific density of QDs is a multidimensional optimization challenge, usually addressed through time-consuming and iterative trial-and-error. Meanwhile, reflective high-energy electron diffraction (RHEED) has been widely used to capture a wealth of growth information in situ. However, it still faces the challenges of extracting information from noisy and overlapping images. Here, based on 3D ResNet, we developed a machine learning (ML) model specially designed for training RHEED videos instead of static images and providing real-time feedback on surface morphologies for process control. We demonstrated that ML from previous growth could predict the post-growth density of QDs, by successfully tuning the QD densities in near-real time from 1.5E10 cm-2 down to 3.8E8 cm-2 or up to 1.4 E11 cm-2. Compared to traditional methods, our approach, with in-situ tuning capabilities and excellent reliability, can dramatically expedite the material optimization process and improve the reproducibility of MBE growth, constituting significant progress for thin film growth techniques. The concepts and methodologies proved feasible in this work are promising to be applied to a variety of material growth processes, which will revolutionize semiconductor manufacturing for microelectronic and optoelectronic industries.|
|**2023-06-22**|**Future accelerator projects: new physics at the energy frontier**|Anadi Canepa et.al.|[2306.12897v1](http://arxiv.org/abs/2306.12897v1)|null|High-energy colliders provide direct access to the energy frontier, allowing to search for new physics at scales as high as the machine's center-of-mass energy, perform precision measurements of the Standard Model (SM) parameters, including those related to the flavor sector, and determine the Higgs boson properties and their connection to electroweak symmetry breaking. Each proposed future collider option has its own specific science goals and capabilities, depending on the designed running energy (energies) amongst other parameters. In this paper, an overview of the discovery potential of future circular and linear colliders is presented. Results from searches for beyond the Standard Model (BSM) phenomena at proton-proton, proton-electron, electron-positron, and muon-antimuon colliders are summarized.|
|**2023-06-22**|**Normal and superconducting currents through the Sachdev-Ye-Kitaev model**|Gianluca Francica et.al.|[2306.12875v1](http://arxiv.org/abs/2306.12875v1)|null|We study the current driven by an applied voltage as a function of time through the Sachdev-Ye-Kitaev model when coupled to two normal or superconducting reservoirs. For normal leads, in the strong coupling limit and for small bias, the current through the Sachdev-Ye-Kitaev model, described by a quartic interaction term, reaches monotonically the stationarity, in contrast to the case of a disordered quadratic interaction where the current has a peak before reaching the stationary phase. For superconducting leads the current have oscillations whose frequencies are determined by the gap and the voltage, and are suppressed in the strong coupling limit. Moreover, due to different short time scales between the normal and the oscillating part of the superconducting current, a peak appears before reaching the stationarity.|
|**2023-06-22**|**Spin light emitting diode based on exciton fine structure tuning in quantum dots**|A. V. Shumilin et.al.|[2306.12868v1](http://arxiv.org/abs/2306.12868v1)|null|We propose a concept of quantum dot based light emitting diode that produces circularly polarized light due to the tuning of the exciton fine structure by magnetic field and electron nuclear hyperfine interaction. The device operates under injection of electrons and holes from nonmagnetic contacts in a small field of the order of milliteslas. Its size can be parametrically smaller than the light wavelength, and circular polarization degree of electroluminescence can reach 100%. The proposed concept is compatible with the micropillar cavities, which allows for the deterministic electrical generation of single circularly polarized photons.|

## smart watch

### smart watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge**|Sokratis Nikolaidis et.al.|[2306.12830v1](http://arxiv.org/abs/2306.12830v1)|null|Cascade systems comprise a two-model sequence, with a lightweight model processing all samples and a heavier, higher-accuracy model conditionally refining harder samples to improve accuracy. By placing the light model on the device side and the heavy model on a server, model cascades constitute a widely used distributed inference approach. With the rapid expansion of intelligent indoor environments, such as smart homes, the new setting of Multi-Device Cascade is emerging where multiple and diverse devices are to simultaneously use a shared heavy model on the same server, typically located within or close to the consumer environment. This work presents MultiTASC, a multi-tenancy-aware scheduler that adaptively controls the forwarding decision functions of the devices in order to maximize the system throughput, while sustaining high accuracy and low latency. By explicitly considering device heterogeneity, our scheduler improves the latency service-level objective (SLO) satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade methods in highly heterogeneous setups, while serving over 40 devices, showcasing its scalability.|
|**2023-06-21**|**Do you still need a manual smart contract audit?**|Isaac David et.al.|[2306.12338v2](http://arxiv.org/abs/2306.12338v2)|null|We investigate the feasibility of employing large language models (LLMs) for conducting the security audit of smart contracts, a traditionally time-consuming and costly process. Our research focuses on the optimization of prompt engineering for enhanced security analysis, and we evaluate the performance and accuracy of LLMs using a benchmark dataset comprising 52 Decentralized Finance (DeFi) smart contracts that have previously been compromised.   Our findings reveal that, when applied to vulnerable contracts, both GPT-4 and Claude models correctly identify the vulnerability type in 40% of the cases. However, these models also demonstrate a high false positive rate, necessitating continued involvement from manual auditors. The LLMs tested outperform a random model by 20% in terms of F1-score.   To ensure the integrity of our study, we conduct mutation testing on five newly developed and ostensibly secure smart contracts, into which we manually insert two and 15 vulnerabilities each. This testing yielded a remarkable best-case 78.7% true positive rate for the GPT-4-32k model. We tested both, asking the models to perform a binary classification on whether a contract is vulnerable, and a non-binary prompt. We also examined the influence of model temperature variations and context length on the LLM's performance.   Despite the potential for many further enhancements, this work lays the groundwork for a more efficient and economical approach to smart contract security audits.|
|**2023-06-21**|**Chili Pepper Disease Diagnosis via Image Reconstruction Using GrabCut and Generative Adversarial Serial Autoencoder**|Jongwook Si et.al.|[2306.12057v1](http://arxiv.org/abs/2306.12057v1)|null|With the recent development of smart farms, researchers are very interested in such fields. In particular, the field of disease diagnosis is the most important factor. Disease diagnosis belongs to the field of anomaly detection and aims to distinguish whether plants or fruits are normal or abnormal. The problem can be solved by binary or multi-classification based on CNN, but it can also be solved by image reconstruction. However, due to the limitation of the performance of image generation, SOTA's methods propose a score calculation method using a latent vector error. In this paper, we propose a network that focuses on chili peppers and proceeds with background removal through Grabcut. It shows high performance through image-based score calculation method. Due to the difficulty of reconstructing the input image, the difference between the input and output images is large. However, the serial autoencoder proposed in this paper uses the difference between the two fake images except for the actual input as a score. We propose a method of generating meaningful images using the GAN structure and classifying three results simultaneously by one discriminator. The proposed method showed higher performance than previous researches, and image-based scores showed the best performanc|
|**2023-06-21**|**Learning When to Trust Which Teacher for Weakly Supervised ASR**|Aakriti Agrawal et.al.|[2306.12012v1](http://arxiv.org/abs/2306.12012v1)|null|Automatic speech recognition (ASR) training can utilize multiple experts as teacher models, each trained on a specific domain or accent. Teacher models may be opaque in nature since their architecture may be not be known or their training cadence is different from that of the student ASR model. Still, the student models are updated incrementally using the pseudo-labels generated independently by the expert teachers. In this paper, we exploit supervision from multiple domain experts in training student ASR models. This training strategy is especially useful in scenarios where few or no human transcriptions are available. To that end, we propose a Smart-Weighter mechanism that selects an appropriate expert based on the input audio, and then trains the student model in an unsupervised setting. We show the efficacy of our approach using LibriSpeech and LibriLight benchmarks and find an improvement of 4 to 25\% over baselines that uniformly weight all the experts, use a single expert model, or combine experts using ROVER.|
|**2023-06-21**|**LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System (ACM)(Draft) LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System**|Ashish Bastola et.al.|[2306.11980v1](http://arxiv.org/abs/2306.11980v1)|null|CSCW studies have increasingly explored AI's role in enhancing communication efficiency and productivity in collaborative tasks. AI tools such as chatbots, smart replies, and language models aim to optimize conversation management and improve team performance. Early AI assistants, such as Gmail smart reply, were limited by predefined knowledge bases and decision trees. However, the advent of large language models (LLMs) such as ChatGPT has revolutionized AI assistants, employing advanced deep learning architecture to generate context-aware, coherent, and personalized responses. Consequently, ChatGPT-based AI assistants provide a more natural and efficient user experience across various tasks and domains. In this paper, we formalize the concept of AI Collaborative Tools (ACT) as AI technologies in human collaborative work and discuss how the emergence of ChatGPT has transformed the AI landscape and increased focus on ACT for improving team performance. Meanwhile, we present an LLM-based Smart Reply (LSR) system utilizing the ChatGPT API to generate personalized responses in daily collaborative scenarios, considering context, tone, and communication style. Our two-step process involves generating a preliminary response type (e.g., Agree, Disagree) to provide a generalized direction for message generation, thus reducing response drafting time. We conducted an experiment in which participants completed simulated work tasks, involving Google Calendar manipulation and a double-back N-back test, while interacting with researchers posing as teammates requesting scheduling changes. Our findings indicate that the AI teammate increases perceived performance and reduces mental demand, as measured by the NASA TLX, and improves performance in the N-back task. We also provide qualitative feedback on participants' experiences working with the AI teammate.|
|**2023-06-21**|**Multimodality Fusion for Smart Healthcare: a Journey from Data, Information, Knowledge to Wisdom**|Thanveer Shaik et.al.|[2306.11963v1](http://arxiv.org/abs/2306.11963v1)|null|Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data, information, and knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. A comprehensive review of multimodal medical data fusion focuses on the integration of various data modalities are presented. It explores different approaches such as Feature selection, Rule-based systems, Machine learning, Deep learning, and Natural Language Processing for fusing and analyzing multimodal data. The paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and insights, a generic framework for multimodal medical data fusion is proposed while aligning with the DIKW mechanism. Moreover, it discusses future directions aligned with the four pillars of healthcare: Predictive, Preventive, Personalized, and Participatory approaches based on the DIKW and the generic framework. The components from this comprehensive survey form the foundation for the successful implementation of multimodal fusion in smart healthcare. The findings of this survey can guide researchers and practitioners in leveraging the power of multimodal fusion with the approaches to revolutionize healthcare and improve patient outcomes.|
|**2023-06-20**|**Protecting the Decentralized Future: An Exploration of Common Blockchain Attacks and their Countermeasures**|Bilash Saha et.al.|[2306.11884v1](http://arxiv.org/abs/2306.11884v1)|null|Blockchain technology transformed the digital sphere by providing a transparent, secure, and decentralized platform for data security across a range of industries, including cryptocurrencies and supply chain management. Blockchain's integrity and dependability have been jeopardized by the rising number of security threats, which have attracted cybercriminals as a target. By summarizing suggested fixes, this research aims to offer a thorough analysis of mitigating blockchain attacks. The objectives of the paper include identifying weak blockchain attacks, evaluating various solutions, and determining how effective and effective they are at preventing these attacks. The study also highlights how crucial it is to take into account the particular needs of every blockchain application. This study provides beneficial perspectives and insights for blockchain researchers and practitioners, making it essential reading for those interested in current and future trends in blockchain security research.|
|**2023-06-20**|**Predicting Strategic Energy Storage Behaviors**|Yuexin Bian et.al.|[2306.11872v1](http://arxiv.org/abs/2306.11872v1)|[link](https://github.com/alwaysbyx/predicting-strategic-energy-storage-behaviors)|Energy storage are strategic participants in electricity markets to arbitrage price differences. Future power system operators must understand and predict strategic storage arbitrage behaviors for market power monitoring and capacity adequacy planning. This paper proposes a novel data-driven approach that incorporates prior model knowledge for predicting the strategic behaviors of price-taker energy storage systems. We propose a gradient-descent method to find the storage model parameters given the historical price signals and observations. We prove that the identified model parameters will converge to the true user parameters under a class of quadratic objective and linear equality-constrained storage models. We demonstrate the effectiveness of our approach through numerical experiments with synthetic and real-world storage behavior data. The proposed approach significantly improves the accuracy of storage model identification and behavior forecasting compared to previous blackbox data-driven approaches.|
|**2023-06-20**|**SkyGPT: Probabilistic Short-term Solar Forecasting Using Synthetic Sky Videos from Physics-constrained VideoGPT**|Yuhao Nie et.al.|[2306.11682v1](http://arxiv.org/abs/2306.11682v1)|null|In recent years, deep learning-based solar forecasting using all-sky images has emerged as a promising approach for alleviating uncertainty in PV power generation. However, the stochastic nature of cloud movement remains a major challenge for accurate and reliable solar forecasting. With the recent advances in generative artificial intelligence, the synthesis of visually plausible yet diversified sky videos has potential for aiding in forecasts. In this study, we introduce \emph{SkyGPT}, a physics-informed stochastic video prediction model that is able to generate multiple possible future images of the sky with diverse cloud motion patterns, by using past sky image sequences as input. Extensive experiments and comparison with benchmark video prediction models demonstrate the effectiveness of the proposed model in capturing cloud dynamics and generating future sky images with high realism and diversity. Furthermore, we feed the generated future sky images from the video prediction models for 15-minute-ahead probabilistic solar forecasting for a 30-kW roof-top PV system, and compare it with an end-to-end deep learning baseline model SUNSET and a smart persistence model. Better PV output prediction reliability and sharpness is observed by using the predicted sky images generated with SkyGPT compared with other benchmark models, achieving a continuous ranked probability score (CRPS) of 2.81 (13\% better than SUNSET and 23\% better than smart persistence) and a Winkler score of 26.70 for the test set. Although an arbitrary number of futures can be generated from a historical sky image sequence, the results suggest that 10 future scenarios is a good choice that balances probabilistic solar forecasting performance and computational cost.|
|**2023-06-20**|**Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes**|Mathilde Leuridan et.al.|[2306.11553v1](http://arxiv.org/abs/2306.11553v1)|[link](https://github.com/ecmwf/polytope)|Data extraction algorithms on data hypercubes, or datacubes, are traditionally only capable of cutting boxes of data along the datacube axes. For many use cases however, this is not a sufficient approach and returns more data than users might actually need. This not only forces users to apply post-processing after extraction, but more importantly this consumes more I/O resources than is necessary. When considering very large datacubes from which users only want to extract small non-rectangular subsets, the box approach does not scale well. Indeed, with this traditional approach, I/O systems quickly reach capacity, trying to read and return unwanted data to users. In this paper, we propose a novel technique, based on computational geometry concepts, which instead carefully pre-selects the precise bytes of data which the user needs in order to then only read those from the datacube. As we discuss later on, this novel extraction method will considerably help scale access to large petabyte size data hypercubes in a variety of scientific fields.|
|**2023-06-20**|**UUKG: Unified Urban Knowledge Graph Dataset for Urban Spatiotemporal Prediction**|Yansong Ning et.al.|[2306.11443v1](http://arxiv.org/abs/2306.11443v1)|[link](https://github.com/usail-hkust/uukg)|Accurate Urban SpatioTemporal Prediction (USTP) is of great importance to the development and operation of the smart city. As an emerging building block, multi-sourced urban data are usually integrated as urban knowledge graphs (UrbanKGs) to provide critical knowledge for urban spatiotemporal prediction models. However, existing UrbanKGs are often tailored for specific downstream prediction tasks and are not publicly available, which limits the potential advancement. This paper presents UUKG, the unified urban knowledge graph dataset for knowledge-enhanced urban spatiotemporal predictions. Specifically, we first construct UrbanKGs consisting of millions of triplets for two metropolises by connecting heterogeneous urban entities such as administrative boroughs, POIs, and road segments. Moreover, we conduct qualitative and quantitative analysis on constructed UrbanKGs and uncover diverse high-order structural patterns, such as hierarchies and cycles, that can be leveraged to benefit downstream USTP tasks. To validate and facilitate the use of UrbanKGs, we implement and evaluate 15 KG embedding methods on the KG completion task and integrate the learned KG embeddings into 9 spatiotemporal models for five different USTP tasks. The extensive experimental results not only provide benchmarks of knowledge-enhanced USTP models under different task settings but also highlight the potential of state-of-the-art high-order structure-aware UrbanKG embedding methods. We hope the proposed UUKG fosters research on urban knowledge graphs and broad smart city applications. The dataset and source code are available at https://github.com/usail-hkust/UUKG/.|
|**2023-06-20**|**An Introduction to the Compute Express Link (CXL) Interconnect**|Debendra Das Sharma et.al.|[2306.11227v1](http://arxiv.org/abs/2306.11227v1)|null|The Compute Express Link (CXL) is an open industry-standard interconnect between processors and devices such as accelerators, memory buffers, smart network interfaces, persistent memory, and solid-state drives. CXL offers coherency and memory semantics with bandwidth that scales with PCIe bandwidth while achieving significantly lower latency than PCIe. All major CPU vendors, device vendors, and datacenter operators have adopted CXL as a common standard. This enables an inter-operable ecosystem that supports key computing use cases including highly efficient accelerators, server memory bandwidth and capacity expansion, multi-server resource pooling and sharing, and efficient peer-to-peer communication. This survey provides an introduction to CXL covering the standards CXL 1.0, CXL 2.0, and CXL 3.0. We further survey CXL implementations, discuss CXL's impact on the datacenter landscape, and future directions.|
|**2023-06-19**|**Static and Dynamic Jamming Games Over Wireless Channels With Mobile Strategic Players**|Giovanni Perin et.al.|[2306.10956v1](http://arxiv.org/abs/2306.10956v1)|null|We study a wireless jamming problem consisting of the competition between a legitimate receiver and a jammer, as a zero-sum game with the value to maximize/minimize being the channel capacity at the receiver's side. Most of the approaches found in the literature consider the two players to be stationary nodes. Instead, we investigate what happens when they can change location, specifically moving along a linear geometry. We frame this at first as a static game, which can be solved in closed form, and subsequently we extend it to a dynamic game, under three different versions for what concerns completeness/perfection of mutual information about the adversary's position, corresponding to different assumptions of concealment/sequentiality of the moves, respectively. We first provide some theoretical conditions that hold for the static game and also help identify good strategies valid under any setup, including dynamic games. Since dynamic games, although more realistic, are characterized by an exploding strategy space, we exploit reinforcement learning to obtain efficient strategies leading to equilibrium outcomes. We show how theoretical findings can be used to train smart agents to play the game, and validate our approach in practical setups.|
|**2023-06-19**|**Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network**|Ahmad A. Mubarak et.al.|[2306.10946v1](http://arxiv.org/abs/2306.10946v1)|null|The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendation of tourist attractions and can make more recommendations for tourists' choices.|
|**2023-06-19**|**Transformer Training Strategies for Forecasting Multiple Load Time Series**|Matthias Hertel et.al.|[2306.10891v1](http://arxiv.org/abs/2306.10891v1)|null|Recent work uses Transformers for load forecasting, which are the state of the art for sequence modeling tasks in data-rich domains. In the smart grid of the future, accurate load forecasts must be provided on the level of individual clients of an energy supplier. While the total amount of electrical load data available to an energy supplier will increase with the ongoing smart meter rollout, the amount of data per client will always be limited. We test whether the Transformer benefits from a transfer learning strategy, where a global model is trained on the load time series data from multiple clients. We find that the global model is superior to two other training strategies commonly used in related work: multivariate models and local models. A comparison to linear models and multi-layer perceptrons shows that Transformers are effective for electrical load forecasting when they are trained with the right strategy.|
|**2023-06-19**|**Detection of Sensor-To-Sensor Variations using Explainable AI**|Sarah Seifi et.al.|[2306.10850v1](http://arxiv.org/abs/2306.10850v1)|null|With the growing concern for air quality and its impact on human health, interest in environmental gas monitoring has increased. However, chemi-resistive gas sensing devices are plagued by issues of sensor reproducibility during manufacturing. This study proposes a novel approach for detecting sensor-to-sensor variations in sensing devices using the explainable AI (XAI) method of SHapley Additive exPlanations (SHAP). This is achieved by identifying sensors that contribute the most to environmental gas concentration estimation via machine learning, and measuring the similarity of feature rankings between sensors to flag deviations or outliers. The methodology is tested using artificial and realistic Ozone concentration profiles to train a Gated Recurrent Unit (GRU) model. Two applications were explored in the study: the detection of wrong behaviors of sensors in the train dataset, and the detection of deviations in the test dataset. By training the GRU with the pruned train dataset, we could reduce computational costs while improving the model performance. Overall, the results show that our approach improves the understanding of sensor behavior, successfully detects sensor deviations down to 5-10% from the normal behavior, and leads to more efficient model preparation and calibration. Our method provides a novel solution for identifying deviating sensors, linking inconsistencies in hardware to sensor-to-sensor variations in the manufacturing process on an AI model-level.|
|**2023-06-19**|**Blockchain-Enabled Federated Learning: A Reference Architecture Incorporating a DID Access System**|Eunsu Goh et.al.|[2306.10841v1](http://arxiv.org/abs/2306.10841v1)|null|Recently, Blockchain-Enabled Federated Learning (BCFL), an innovative approach that combines the advantages of Federated Learning and Blockchain technology, is receiving great attention. Federated Learning (FL) allows multiple participants to jointly train machine learning models in a decentralized manner while maintaining data privacy and security. This paper proposes a reference architecture for blockchain-enabled federated learning, which enables multiple entities to collaboratively train machine learning models while preserving data privacy and security. A critical component of this architecture is the implementation of a decentralized identifier (DID)-based access system. DID introduces a decentralized, self-sovereign identity (ID) management system that allows participants to manage their IDs independently of central authorities. Within this proposed architecture, participants can authenticate and gain access to the federated learning platform via their DIDs, which are securely stored on the blockchain. The access system administers access control and permissions through the execution of smart contracts, further enhancing the security and decentralization of the system. This approach, integrating blockchain-enabled federated learning with a DID access system, offers a robust solution for collaborative machine learning in a distributed and secure manner. As a result, participants can contribute to global model training while maintaining data privacy and identity control without the need to share local data. These DIDs are stored on the blockchain and the access system uses smart contracts to manage access control and permissions. The source code will be available to the public soon.|
|**2023-06-19**|**SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces**|Ziqiao Peng et.al.|[2306.10799v1](http://arxiv.org/abs/2306.10799v1)|null|Speech-driven 3D face animation technique, extending its applications to various multimedia fields. Previous research has generated promising realistic lip movements and facial expressions from audio signals. However, traditional regression models solely driven by data face several essential problems, such as difficulties in accessing precise labels and domain gaps between different modalities, leading to unsatisfactory results lacking precision and coherence. To enhance the visual accuracy of generated lip movement while reducing the dependence on labeled data, we propose a novel framework SelfTalk, by involving self-supervision in a cross-modals network system to learn 3D talking faces. The framework constructs a network system consisting of three modules: facial animator, speech recognizer, and lip-reading interpreter. The core of SelfTalk is a commutative training diagram that facilitates compatible features exchange among audio, text, and lip shape, enabling our models to learn the intricate connection between these factors. The proposed framework leverages the knowledge learned from the lip-reading interpreter to generate more plausible lip shapes. Extensive experiments and user studies demonstrate that our proposed approach achieves state-of-the-art performance both qualitatively and quantitatively. We recommend watching the supplementary video.|
|**2023-06-19**|**Impact of Dynamic Tariffs for Smart EV Charging on LV Distribution Network Operation**|Flore Verbist et.al.|[2306.10775v1](http://arxiv.org/abs/2306.10775v1)|null|With a growing share of electric vehicles (EVs) in our distribution grids, the need for smart charging becomes indispensable to minimise grid reinforcement. To circumvent the associated capacity limitations, this paper evaluates the effectiveness of different levels of network constraints and different dynamic tariffs, including a dynamic network tariff. A detailed optimisation model is first developed for public charging electric vehicles in a representative Dutch low voltage (LV) distribution network, susceptible to congestion and voltage problems by 2050 without smart charging of EVs. Later, a detailed reflection is made to assess the influence of the modelled features on the distribution system operator (DSO), charge point operator (CPO) costs, and the EVs' final state-of-charge (SOC) for both mono- (V1G) and bi-directional (V2G) charging. Results show that the dynamic network tariff outperforms other flat tariffs by increasing valley-filling. Consequently, compared to regular day-ahead pricing, a {significant} reduction in the frequency of congestion in the lines is achieved. In addition, V2G ensures the joint optimum for different stakeholders causing adequate EV user satisfaction, decreased CPO costs compared to conventional charging and fewer violations of grid constraints for the DSOs.|
|**2023-06-19**|**Learning an Interpretable End-to-End Network for Real-Time Acoustic Beamforming**|Hao Liang et.al.|[2306.10772v1](http://arxiv.org/abs/2306.10772v1)|null|Recently, many forms of audio industrial applications, such as sound monitoring and source localization, have begun exploiting smart multi-modal devices equipped with a microphone array. Regrettably, model-based methods are often difficult to employ for such devices due to their high computational complexity, as well as the difficulty of appropriately selecting the user-determined parameters. As an alternative, one may use deep network-based methods, but these are often difficult to generalize, nor can they generate the desired beamforming map directly. In this paper, a computationally efficient acoustic beamforming algorithm is proposed, which may be unrolled to form a model-based deep learning network for real-time imaging, here termed the DAMAS-FISTA-Net. By exploiting the natural structure of an acoustic beamformer, the proposed network inherits the physical knowledge of the acoustic system, and thus learns the underlying physical properties of the propagation. As a result, all the network parameters may be learned end-to-end, guided by a model-based prior using back-propagation. Notably, the proposed network enables an excellent interpretability and the ability of being able to process the raw data directly. Extensive numerical experiments using both simulated and real-world data illustrate the preferable performance of the DAMAS-FISTA-Net as compared to alternative approaches.|
|**2023-06-18**|**Understanding and Characterizing Cryptocurrency Free Giveaway and Arbitrage Bot Scams In the Wild**|Kai Li et.al.|[2306.10634v1](http://arxiv.org/abs/2306.10634v1)|[link](https://github.com/likai1993/cryptoscamhunter)|This paper presents a large-scale analysis of two prevalent cryptocurrency scams disseminated through Twitter and YouTube. The first scam involves free giveaway schemes where scammers publish fake giveaway websites to deceive victims and steal funds. The second scam revolves around arbitrage bots and publishes videos to entice victims into executing malicious smart contracts. To collect and analyze these scams in the wild, we developed a fully automated scam detection system called \textit{CryptoScamHunter}, which collects data from Twitter and YouTube and employs Nature-Language-Processing (NLP) models to automatically identify scams and extract the associated cryptocurrency address.   By deploying \textit{CryptoScamHunter} over 11 months spanning from June 2022 to May 2023, we detected 95,111 free giveaway scam lists on Twitter and 10,442 arbitrage bot scam videos on YouTube that were disseminated through thousands of social network accounts and have reached millions of users. Through analysis of the scam creator accounts, we discovered that the scammers combined different strategies to spread each scam, including compromising popular accounts and registering spam accounts. Our findings indicate that 28.7% to 43.9% of these spam accounts remain active as of this writing. Furthermore, from the identified scams, we extracted 327 URLs associated with giveaway scams, 808 malicious contracts in arbitrage bot scams, and 429 scam cryptocurrency addresses. By analyzing the transaction history of the extracted scam addresses, we estimated that over 9,717 victims fell prey to these scams, resulting in a loss of up to 3.8 million USD.   Overall, this study sheds light on the tactics, scale, and impact of cryptocurrency scams on social media and blockchain platforms, emphasizing the urgent need for effective detection and prevention mechanisms to protect users from these fraudulent activities.|
|**2023-06-17**|**Federated Learning Based Distributed Localization of False Data Injection Attacks on Smart Grids**|Cihat Keçeci et.al.|[2306.10420v1](http://arxiv.org/abs/2306.10420v1)|null|Data analysis and monitoring on smart grids are jeopardized by attacks on cyber-physical systems. False data injection attack (FDIA) is one of the classes of those attacks that target the smart measurement devices by injecting malicious data. The employment of machine learning techniques in the detection and localization of FDIA is proven to provide effective results. Training of such models requires centralized processing of sensitive user data that may not be plausible in a practical scenario. By employing federated learning for the detection of FDIA attacks, it is possible to train a model for the detection and localization of the attacks while preserving the privacy of sensitive user data. However, federated learning introduces new problems such as the personalization of the detectors in each node. In this paper, we propose a federated learning-based scheme combined with a hybrid deep neural network architecture that exploits the local correlations between the connected power buses by employing graph neural networks as well as the temporal patterns in the data by using LSTM layers. The proposed mechanism offers flexible and efficient training of an FDIA detector in a distributed setup while preserving the privacy of the clients. We validate the proposed architecture by extensive simulations on the IEEE 57, 118, and 300 bus systems and real electricity load data.|
|**2023-06-17**|**Enhancing the Prediction of Emotional Experience in Movies using Deep Neural Networks: The Significance of Audio and Language**|Sogand Mehrpour Mohammadi et.al.|[2306.10397v1](http://arxiv.org/abs/2306.10397v1)|null|Our paper focuses on making use of deep neural network models to accurately predict the range of human emotions experienced during watching movies. In this certain setup, there exist three clear-cut input modalities that considerably influence the experienced emotions: visual cues derived from RGB video frames, auditory components encompassing sounds, speech, and music, and linguistic elements encompassing actors' dialogues. Emotions are commonly described using a two-factor model including valence (ranging from happy to sad) and arousal (indicating the intensity of the emotion). In this regard, a Plethora of works have presented a multitude of models aiming to predict valence and arousal from video content. However, non of these models contain all three modalities, with language being consistently eliminated across all of them. In this study, we comprehensively combine all modalities and conduct an analysis to ascertain the importance of each in predicting valence and arousal. Making use of pre-trained neural networks, we represent each input modality in our study. In order to process visual input, we employ pre-trained convolutional neural networks to recognize scenes[1], objects[2], and actions[3,4]. For audio processing, we utilize a specialized neural network designed for handling sound-related tasks, namely SoundNet[5]. Finally, Bidirectional Encoder Representations from Transformers (BERT) models are used to extract linguistic features[6] in our analysis. We report results on the COGNIMUSE dataset[7], where our proposed model outperforms the current state-of-the-art approaches. Surprisingly, our findings reveal that language significantly influences the experienced arousal, while sound emerges as the primary determinant for predicting valence. In contrast, the visual modality exhibits the least impact among all modalities in predicting emotions.|
|**2023-06-17**|**A Survey of Contextual Optimization Methods for Decision Making under Uncertainty**|Utsav Sadana et.al.|[2306.10374v1](http://arxiv.org/abs/2306.10374v1)|null|Recently there has been a surge of interest in operations research (OR) and the machine learning (ML) community in combining prediction algorithms and optimization techniques to solve decision-making problems in the face of uncertainty. This gave rise to the field of contextual optimization, under which data-driven procedures are developed to prescribe actions to the decision-maker that make the best use of the most recently updated information. A large variety of models and methods have been presented in both OR and ML literature under a variety of names, including data-driven optimization, prescriptive optimization, predictive stochastic programming, policy optimization, (smart) predict/estimate-then-optimize, decision-focused learning, (task-based) end-to-end learning/forecasting/optimization, etc. Focusing on single and two-stage stochastic programming problems, this review article identifies three main frameworks for learning policies from data and discusses their strengths and limitations. We present the existing models and methods under a uniform notation and terminology and classify them according to the three main frameworks identified. Our objective with this survey is to both strengthen the general understanding of this active field of research and stimulate further theoretical and algorithmic advancements in integrating ML and stochastic programming.|
|**2023-06-17**|**Multi-wavelength temporal variability of the blazar PKS 1510-089**|Q. Yuan et.al.|[2306.10248v1](http://arxiv.org/abs/2306.10248v1)|null|We perform correlation and periodicity search analyses on long-term multi-band light curves of the FSRQ 1510-089 observed by the space-based Fermi--Large Area Telescope in gamma-rays, the SMARTS and Steward Observatory telescopes in optical and near-infrared (NIR) and the 13.7 m radio telescope in Metsahovi Radio Observatory between 2008 and 2018. The z-transform discrete correlation function method is applied to study the correlation and possible time lags among these multi band light curves. Among all pairs of wavelengths, the gamma-ray vs. optical/NIR and optical vs. NIR correlations show zero time lags; however, both the gamma-ray and optical/NIR emissions precede the radio radiation. The Generalized Lomb-Scargle periodogram, Weighted Wavelet Z-transform, and REDFIT techniques are employed to investigate the unresolved-core-emission dominated 37 GHz light curve and yield evidence for a quasi-period around 1540 days, although given the length of the whole data set it cannot be claimed to be significant. We also investigate the optical/NIR color variability and find that this source shows a simple redder-when-brighter behavior over time, even in the low flux state.|
|**2023-06-16**|**Vehicle Occurrence-based Parking Space Detection**|Paulo R. Lisboa de Almeida et.al.|[2306.09940v1](http://arxiv.org/abs/2306.09940v1)|null|Smart-parking solutions use sensors, cameras, and data analysis to improve parking efficiency and reduce traffic congestion. Computer vision-based methods have been used extensively in recent years to tackle the problem of parking lot management, but most of the works assume that the parking spots are manually labeled, impacting the cost and feasibility of deployment. To fill this gap, this work presents an automatic parking space detection method, which receives a sequence of images of a parking lot and returns a list of coordinates identifying the detected parking spaces. The proposed method employs instance segmentation to identify cars and, using vehicle occurrence, generate a heat map of parking spaces. The results using twelve different subsets from the PKLot and CNRPark-EXT parking lot datasets show that the method achieved an AP25 score up to 95.60\% and AP50 score up to 79.90\%.|
|**2023-06-16**|**Smart Sentiment Analysis-based Search Engine Classification Intelligence**|Mike Nkongolo et.al.|[2306.09777v1](http://arxiv.org/abs/2306.09777v1)|null|Search engines are widely used for finding information on the internet. However, there are limitations in the current search approach, such as providing popular but not necessarily relevant results. This research addresses the issue of polysemy in search results by implementing a search function that determines the sentimentality of the retrieved information. The study utilizes a web crawler to collect data from the British Broadcasting Corporation (BBC) news site, and the sentimentality of the news articles is determined using the Sentistrength program. The results demonstrate that the proposed search function improves recall value while accurately retrieving nonpolysemous news. Furthermore, Sentistrength outperforms deep learning and clustering methods in classifying search results. The methodology presented in this article can be applied to analyze the sentimentality and reputation of entities on the internet.|
|**2023-06-15**|**Web of Things and Trends in Agriculture: A Systematic Literature Review**|Muhammad Shoaib Farooq et.al.|[2306.09079v1](http://arxiv.org/abs/2306.09079v1)|null|In the past few years, the Web of Things (WOT) became a beneficial game-changing technology within the Agriculture domain as it introduces innovative and promising solutions to the Internet of Things (IoT) agricultural applications problems by providing its services. WOT provides the support for integration, interoperability for heterogeneous devices, infrastructures, platforms, and the emergence of various other technologies. The main aim of this study is about understanding and providing a growing and existing research content, issues, and directions for the future regarding WOT-based agriculture. Therefore, a systematic literature review (SLR) of research articles is presented by categorizing the selected studies published between 2010 and 2020 into the following categories: research type, approaches, and their application domains. Apart from reviewing the state-of-the-art articles on WOT solutions for the agriculture field, a taxonomy of WOT-base agriculture application domains has also been presented in this study. A model has also presented to show the picture of WOT based Smart Agriculture. Lastly, the findings of this SLR and the research gaps in terms of open issues have been presented to provide suggestions on possible future directions for the researchers for future research.|
|**2023-06-15**|**Physarum polycephalum: Smart network adaptation**|Mathieu Le Verge-Serandour et.al.|[2306.09063v1](http://arxiv.org/abs/2306.09063v1)|null|Life evolved organisms to adapt dynamically to their environment and autonomously exhibit behaviours. While complex behaviours in organisms are typically associated with the capability of neurons to process information, the unicellular organism Physarum polycephalum disabuses us by solving complex tasks despite being just a single although gigantic cell shaped into a mesmerizing tubular network. In Physarum, smart behaviours arise as network tubes grow or shrink due to the mechanochemical coupling of contractile tubes, fluid flows and transport across the network. Here, from a physicist's perspective, we introduce the biology and active chemo-mechanics of this living matter network. We then review Physarum's global response in migration and dynamic state to its environment before revisiting its network architecture and flow and transport patterns. Finally, we summarize recent studies on storing and processing information to mount well-informed behaviours.|
|**2023-06-15**|**A Learning Assisted Method for Uncovering Power Grid Generation and Distribution System Vulnerabilities**|Suman Maiti et.al.|[2306.09057v1](http://arxiv.org/abs/2306.09057v1)|null|Intelligent attackers can suitably tamper sensor/actuator data at various Smart grid surfaces causing intentional power oscillations, which if left undetected, can lead to voltage disruptions. We develop a novel combination of formal methods and machine learning tools that learns power system dynamics with the objective of generating unsafe yet stealthy false data based attack sequences. We enable the grid with anomaly detectors in a generalized manner so that it is difficult for an attacker to remain undetected. Our methodology, when applied on an IEEE 14 bus power grid model, uncovers stealthy attack vectors even in presence of such detectors.|

## Electroencephalography

### Electroencephalography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-21**|**Reporting existing datasets for automatic epilepsy diagnosis and seizure detection**|Palak Handa et.al.|[2306.12292v1](http://arxiv.org/abs/2306.12292v1)|null|More than 50 million individuals are affected by epilepsy, a chronic neurological disorder characterized by unprovoked, recurring seizures and psychological symptoms. Researchers are working to automatically detect or predict epileptic episodes through Electroencephalography (EEG) signal analysis, and machine, and deep learning methods. Good quality, open-source, and free EEG data acts as a catalyst in this ongoing battle to manage this disease. This article presents 40+ publicly available EEG datasets for adult and pediatric human populations from 2001-2023. A comparative analysis and discussion on open and private EEG datasets have been done based on objective parameters in this domain. Bonn and CHB-MIT remain the benchmark datasets used for the automatic detection of epileptic and seizure EEG signals. Meta-data has also been released for large EEG data like CHB-MIT. This article will be updated every year to report the progress and changing trends in the development of EEG datasets in this field.|
|**2023-06-13**|**Empirical Measurement of Aesthetic Experience of Music**|Abhishek Gupta et.al.|[2306.07802v1](http://arxiv.org/abs/2306.07802v1)|null|Chills or goosebumps, also called frisson, is a phenomenon that is often associated with an aesthetic experience e.g., music or some other ecstatic experience. The temporal and spatial cause of frisson in the brain has been one of the biggest mysteries of human nature. Accumulating evidence suggests that aesthetic, namely subjective, affective, and evaluative processes are at play while listening to music, hence, it is an important subjective stimulus for systematic investigation. Advances in neuroimaging and cognitive neuroscience, have given impetus to neuro-aesthetics, a novel approach to music providing a phenomenological brain-based framework for the aesthetic experience of music with the potential to open the scope for future research. In this paper, we present an affordable, wearable, easy-to-carry device to measure phenomenological goosebumps intensity on our skin with respect to real-time data using IoT devices (Raspberry pi 3, model B). To test the device subjects were asked to provide a list of songs that elicit goosebumps. Wireless earphones were provided, allowing participants to walk around and dance while listening to their music. (Some subjects moved during sessions). Results indicate that goosebumps were reliably detected by the device after visual inspection of the videos/music. The effective measurement when interfaced with neurophysiological devices such as electroencephalography (EEG) can help interpret biomarkers of ecstatic emotions. The second part of the study focuses on identifying primary brain regions involved in goosebump experience during musical stimulation.|
|**2023-06-10**|**TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological Representation Learning**|Philipp Hallgarten et.al.|[2306.06522v1](http://arxiv.org/abs/2306.06522v1)|[link](https://github.com/philipph77/ts-moco)|Limited availability of labeled physiological data often prohibits the use of powerful supervised deep learning models in the biomedical machine intelligence domain. We approach this problem and propose a novel encoding framework that relies on self-supervised learning with momentum contrast to learn representations from multivariate time-series of various physiological domains without needing labels. Our model uses a transformer architecture that can be easily adapted to classification problems by optimizing a linear output classification layer. We experimentally evaluate our framework using two publicly available physiological datasets from different domains, i.e., human activity recognition from embedded inertial sensory and emotion recognition from electroencephalography. We show that our self-supervised learning approach can indeed learn discriminative features which can be exploited in downstream classification tasks. Our work enables the development of domain-agnostic intelligent systems that can effectively analyze multivariate time-series data from physiological domains.|
|**2023-06-05**|**Gotta Go Fast: Measuring Input/Output Latencies of Virtual Reality 3D Engines for Cognitive Experiments**|Taeho Kang et.al.|[2306.02637v1](http://arxiv.org/abs/2306.02637v1)|null|Virtual Reality (VR) is seeing increased adoption across many fields. The field of experimental cognitive science is also testing utilization of the technology combined with physiological measures such as electroencephalography (EEG) and eye tracking. Quantitative measures of human behavior and cognition process, however, are sensitive to minuscule time resolutions that are often overlooked in the scope of consumer-level VR hardware and software stacks. In this preliminary study, we implement VR testing environments in two prominent 3D Virtual Reality frameworks (Unity and Unreal Engine) to measure latency values for stimulus onset execution code to Head-Mount Display (HMD) pixel change, as well as the latency between human behavioral response input to its registration in the engine environment under a typical cognitive experiment hardware setup. We find that whereas the specifics of the latency may further be influenced by different hardware and software setups, the variations in consumer hardware is apparent regardless and report detailed statistics on these latencies. Such consideration should be taken into account when designing VR-based cognitive experiments that measure human behavior.|
|**2023-05-22**|**Towards Ultrasound Tongue Image prediction from EEG during speech production**|Tamás Gábor Csapó et.al.|[2306.05374v1](http://arxiv.org/abs/2306.05374v1)|[link](https://github.com/bme-smartlab/eeg-to-uti)|Previous initial research has already been carried out to propose speech-based BCI using brain signals (e.g.~non-invasive EEG and invasive sEEG / ECoG), but there is a lack of combined methods that investigate non-invasive brain, articulation, and speech signals together and analyze the cognitive processes in the brain, the kinematics of the articulatory movement and the resulting speech signal. In this paper, we describe our multimodal (electroencephalography, ultrasound tongue imaging, and speech) analysis and synthesis experiments, as a feasibility study. We extend the analysis of brain signals recorded during speech production with ultrasound-based articulation data. From the brain signal measured with EEG, we predict ultrasound images of the tongue with a fully connected deep neural network. The results show that there is a weak but noticeable relationship between EEG and ultrasound tongue images, i.e. the network can differentiate articulated speech and neutral tongue position.|
|**2023-05-19**|**Energy-efficient memcapacitive physical reservoir computing system for temporal data processing**|Md Razuan Hossain et.al.|[2305.12025v1](http://arxiv.org/abs/2305.12025v1)|null|Reservoir computing is a highly efficient machine learning framework for processing temporal data by extracting features from the input signal and mapping them into higher dimensional spaces. Physical reservoir layers have been realized using spintronic oscillators, atomic switch networks, silicon photonic modules, ferroelectric transistors, and volatile memristors. However, these devices are intrinsically energy-dissipative due to their resistive nature, which leads to increased power consumption. Therefore, capacitive memory devices can provide a more energy-efficient approach. Here, we leverage volatile biomembrane-based memcapacitors that closely mimic certain short-term synaptic plasticity functions as reservoirs to solve classification tasks and analyze time-series data in simulation and experimentally. Our system achieves a 98% accuracy rate for spoken digit classification and a normalized mean square error of 0.0012 in a second-order non-linear regression task. Further, to demonstrate the device's real-time temporal data processing capability, we demonstrate a 100% accuracy for an electroencephalography (EEG) signal classification problem for epilepsy detection. Most importantly, we demonstrate that for a random input sequence, each memcapacitor consumes on average 41.5fJ of energy per spike, irrespective of the chosen input voltage pulse width, and 415fW of average power for 100 ms pulse width, orders of magnitude lower than the state-of-the-art devices. Lastly, we believe the biocompatible, soft nature of our memcapacitor makes it highly suitable for computing and signal-processing applications in biological environments.|
|**2023-05-18**|**Temporal Aware Mixed Attention-based Convolution and Transformer Network (MACTN) for EEG Emotion Recognition**|Xiaopeng Si et.al.|[2305.18234v1](http://arxiv.org/abs/2305.18234v1)|null|Emotion recognition plays a crucial role in human-computer interaction, and electroencephalography (EEG) is advantageous for reflecting human emotional states. In this study, we propose MACTN, a hierarchical hybrid model for jointly modeling local and global temporal information. The model is inspired by neuroscience research on the temporal dynamics of emotions. MACTN extracts local emotional features through a convolutional neural network (CNN) and integrates sparse global emotional features through a transformer. Moreover, we employ channel attention mechanisms to identify the most task-relevant channels. Through extensive experimentation on two publicly available datasets, namely THU-EP and DEAP, our proposed method, MACTN, consistently achieves superior classification accuracy and F1 scores compared to other existing methods in most experimental settings. Furthermore, ablation studies have shown that the integration of both self-attention mechanisms and channel attention mechanisms leads to improved classification performance. Finally, an earlier version of this method, which shares the same ideas, won the Emotional BCI Competition's final championship in the 2022 World Robot Contest.|
|**2023-05-18**|**Robust inference of causality in high-dimensional dynamical processes from the Information Imbalance of distance ranks**|Vittorio Del Tatto et.al.|[2305.10817v2](http://arxiv.org/abs/2305.10817v2)|[link](https://github.com/vdeltatto/imbalance-gain-causality)|We introduce an approach which allows inferring causal relationships between variables for which the time evolution is available. Our method builds on the ideas of Granger Causality and Transfer Entropy, but overcomes most of their limitations. Specifically, our approach tests whether the predictability of a putative driven system Y can be improved by incorporating information from a potential driver system X, without making assumptions on the underlying dynamics and without the need to compute probability densities of the dynamic variables. Causality is assessed by a rigorous variational scheme based on the Information Imbalance of distance ranks, a recently developed statistical test capable of inferring the relative information content of different distance measures. This framework makes causality detection possible even for high-dimensional systems where only few of the variables are known or measured. Benchmark tests on coupled dynamical systems demonstrate that our approach outperforms other model-free causality detection methods, successfully handling both unidirectional and bidirectional couplings, and it is capable of detecting the arrow of time when present. We also show that the method can be used to robustly detect causality in electroencephalography data in humans.|
|**2023-05-17**|**BASEN: Time-Domain Brain-Assisted Speech Enhancement Network with Convolutional Cross Attention in Multi-talker Conditions**|Jie Zhang et.al.|[2305.09994v1](http://arxiv.org/abs/2305.09994v1)|[link](https://github.com/jzhangu/basen)|Time-domain single-channel speech enhancement (SE) still remains challenging to extract the target speaker without any prior information on multi-talker conditions. It has been shown via auditory attention decoding that the brain activity of the listener contains the auditory information of the attended speaker. In this paper, we thus propose a novel time-domain brain-assisted SE network (BASEN) incorporating electroencephalography (EEG) signals recorded from the listener for extracting the target speaker from monaural speech mixtures. The proposed BASEN is based on the fully-convolutional time-domain audio separation network. In order to fully leverage the complementary information contained in the EEG signals, we further propose a convolutional multi-layer cross attention module to fuse the dual-branch features. Experimental results on a public dataset show that the proposed model outperforms the state-of-the-art method in several evaluation metrics. The reproducible code is available at https://github.com/jzhangU/Basen.git.|
|**2023-04-24**|**Time delay multi-feature correlation analysis to extract subtle dependencies from EEG signals**|Jarek Duda et.al.|[2305.09478v2](http://arxiv.org/abs/2305.09478v2)|null|Electroencephalography (EEG) signals are resultants of extremely complex brain activity. Some details of this hidden dynamics might be accessible through e.g. joint distributions $\rho_{\Delta t}$ of signals of pairs of electrodes shifted by various time delays (lag $\Delta t$). A standard approach is monitoring a single evaluation of such joint distributions, like Pearson correlation (or mutual information), which turns out relatively uninteresting - as expected, there is usually a small peak for zero delay and nearly symmetric drop with delay. In contrast, such a complex signal might be composed of multiple types of statistical dependencies - this article proposes approach to automatically decompose and extract them. Specifically, we model such joint distributions as polynomials, estimated separately for all considered lag dependencies, then with PCA dimensionality reduction we find the dominant joint density distortion directions $f_v$. This way we get a few lag dependent features $a_i(\Delta t)$ describing separate dominating statistical dependencies of known contributions: $\rho_{\Delta t}(y,z)\approx \sum_{i=1}^r a_i(\Delta t)\, f_{v_i}(y,z)$. Such features complement Pearson correlation, extracting hidden more complex behavior, e.g. with asymmetry which might be related with direction of information transfer, extrema suggesting characteristic delays, or oscillatory behavior suggesting some periodicity. There is also discussed extension of Granger causality to such multi-feature joint density analysis, suggesting e.g. two separate causality waves. While this early article is initial fundamental research, in future it might help e.g. with understanding of cortex hidden dynamics, diagnosis of pathologies like epilepsy, determination of precise electrode position, or building brain-computer interface.|
|**2023-04-21**|**A Convolutional Spiking Network for Gesture Recognition in Brain-Computer Interfaces**|Yiming Ai et.al.|[2304.11106v2](http://arxiv.org/abs/2304.11106v2)|null|Brain-computer interfaces are being explored for a wide variety of therapeutic applications. Typically, this involves measuring and analyzing continuous-time electrical brain activity via techniques such as electrocorticogram (ECoG) or electroencephalography (EEG) to drive external devices. However, due to the inherent noise and variability in the measurements, the analysis of these signals is challenging and requires offline processing with significant computational resources. In this paper, we propose a simple yet efficient machine learning-based approach for the exemplary problem of hand gesture classification based on brain signals. We use a hybrid machine learning approach that uses a convolutional spiking neural network employing a bio-inspired event-driven synaptic plasticity rule for unsupervised feature learning of the measured analog signals encoded in the spike domain. We demonstrate that this approach generalizes to different subjects with both EEG and ECoG data and achieves superior accuracy in the range of 92.74-97.07% in identifying different hand gesture classes and motor imagery tasks.|
|**2023-04-21**|**Interpretable and Robust AI in EEG Systems: A Survey**|Xinliang Zhou et.al.|[2304.10755v1](http://arxiv.org/abs/2304.10755v1)|null|The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it into three types: backpropagation, perturbation, and inherently interpretable methods. Then we classify the robustness mechanisms into four classes: noise and artifacts, human variability, data acquisition instability, and adversarial attacks. Finally, we identify several critical and unresolved challenges for interpretable and robust AI in EEG systems and further discuss their future directions.|
|**2023-04-12**|**Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data**|Dominik Klepl et.al.|[2304.05874v1](http://arxiv.org/abs/2304.05874v1)|null|Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the proposed AGGCN model generates consistent explanations of its predictions that might be relevant for further study of AD-related alterations of brain networks.|
|**2023-04-12**|**Dynamic Graph Representation Learning with Neural Networks: A Survey**|Leshanshui Yang et.al.|[2304.05729v1](http://arxiv.org/abs/2304.05729v1)|null|In recent years, Dynamic Graph (DG) representations have been increasingly used for modeling dynamic systems due to their ability to integrate both topological and temporal information in a compact representation. Dynamic graphs allow to efficiently handle applications such as social network prediction, recommender systems, traffic forecasting or electroencephalography analysis, that can not be adressed using standard numeric representations. As a direct consequence of the emergence of dynamic graph representations, dynamic graph learning has emerged as a new machine learning problem, combining challenges from both sequential/temporal data processing and static graph learning. In this research area, Dynamic Graph Neural Network (DGNN) has became the state of the art approach and plethora of models have been proposed in the very recent years. This paper aims at providing a review of problems and models related to dynamic graph learning. The various dynamic graph supervised learning settings are analysed and discussed. We identify the similarities and differences between existing models with respect to the way time information is modeled. Finally, general guidelines for a DGNN designer when faced with a dynamic graph learning problem are provided.|
|**2023-04-01**|**Upper Limb Movement Execution Classification using Electroencephalography for Brain Computer Interface**|Saadat Ullah Khan et.al.|[2304.06036v1](http://arxiv.org/abs/2304.06036v1)|null|An accurate classification of upper limb movements using electroencephalography (EEG) signals is gaining significant importance in recent years due to the prevalence of brain-computer interfaces. The upper limbs in the human body are crucial since different skeletal segments combine to make a range of motion that helps us in our trivial daily tasks. Decoding EEG-based upper limb movements can be of great help to people with spinal cord injury (SCI) or other neuro-muscular diseases such as amyotrophic lateral sclerosis (ALS), primary lateral sclerosis, and periodic paralysis. This can manifest in a loss of sensory and motor function, which could make a person reliant on others to provide care in day-to-day activities. We can detect and classify upper limb movement activities, whether they be executed or imagined using an EEG-based brain-computer interface (BCI). Toward this goal, we focus our attention on decoding movement execution (ME) of the upper limb in this study. For this purpose, we utilize a publicly available EEG dataset that contains EEG signal recordings from fifteen subjects acquired using a 61-channel EEG device. We propose a method to classify four ME classes for different subjects using spectrograms of the EEG data through pre-trained deep learning (DL) models. Our proposed method of using EEG spectrograms for the classification of ME has shown significant results, where the highest average classification accuracy (for four ME classes) obtained is 87.36%, with one subject achieving the best classification accuracy of 97.03%.|
|**2023-03-29**|**Parkinsons Disease Detection via Resting-State Electroencephalography Using Signal Processing and Machine Learning Techniques**|Krish Desai et.al.|[2304.01214v1](http://arxiv.org/abs/2304.01214v1)|null|Parkinsons Disease (PD) is a neurodegenerative disorder resulting in motor deficits due to advancing degeneration of dopaminergic neurons. PD patients report experiencing tremor, rigidity, visual impairment, bradykinesia, and several cognitive deficits. Although Electroencephalography (EEG) indicates abnormalities in PD patients, one major challenge is the lack of a consistent, accurate, and systemic biomarker for PD in order to closely monitor the disease with therapeutic treatments and medication. In this study, we collected Electroencephalographic data from 15 PD patients and 16 Healthy Controls (HC). We first preprocessed every EEG signal using several techniques and extracted relevant features using many feature extraction algorithms. Afterwards, we applied several machine learning algorithms to classify PD versus HC. We found the most significant metrics to be achieved by the Random Forest ensemble learning approach, with an accuracy, precision, recall, F1 score, and AUC of 97.5%, 100%, 95%, 0.967, and 0.975, respectively. The results of this study show promise for exposing PD abnormalities using EEG during clinical diagnosis, and automating this process using signal processing techniques and ML algorithms to evaluate the difference between healthy individuals and PD patients.|
|**2023-03-27**|**EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition**|Rushuang Zhou et.al.|[2304.06496v1](http://arxiv.org/abs/2304.06496v1)|[link](https://github.com/kazabana/eegmatch)|Electroencephalography (EEG) is an objective tool for emotion recognition and shows promising performance. However, the label scarcity problem is a main challenge in this field, which limits the wide application of EEG-based emotion recognition. In this paper, we propose a novel semi-supervised learning framework (EEGMatch) to leverage both labeled and unlabeled EEG data. First, an EEG-Mixup based data augmentation method is developed to generate more valid samples for model learning. Second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between EEG data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among EEG data. Third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled source domain, unlabeled source domain, and target domain), where the distribution mismatch is alleviated. Extensive experiments are conducted on two benchmark databases (SEED and SEED-IV) under a cross-subject leave-one-subject-out cross-validation evaluation protocol. The results show the proposed EEGmatch performs better than the state-of-the-art methods under different incomplete label conditions (with 6.89% improvement on SEED and 1.44% improvement on SEED-IV), which demonstrates the effectiveness of the proposed EEGMatch in dealing with the label scarcity problem in emotion recognition using EEG signals. The source code is available at https://github.com/KAZABANA/EEGMatch.|
|**2023-03-26**|**Driver Drowsiness Detection with Commercial EEG Headsets**|Qazal Rezaee et.al.|[2303.14841v1](http://arxiv.org/abs/2303.14841v1)|null|Driver Drowsiness is one of the leading causes of road accidents. Electroencephalography (EEG) is highly affected by drowsiness; hence, EEG-based methods detect drowsiness with the highest accuracy. Developments in manufacturing dry electrodes and headsets have made recording EEG more convenient. Vehicle-based features used for detecting drowsiness are easy to capture but do not have the best performance. In this paper, we investigated the performance of EEG signals recorded in 4 channels with commercial headsets against the vehicle-based technique in drowsiness detection. We recorded EEG signals of 50 volunteers driving a simulator in drowsy and alert states by commercial devices. The observer rating of the drowsiness method was used to determine the drowsiness level of the subjects. The meaningful separation of vehicle-based features, recorded by the simulator, and EEG-based features of the two states of drowsiness and alertness have been investigated. The comparison results indicated that the EEG-based features are separated with lower p-values than the vehicle-based ones in the two states. It is concluded that EEG headsets can be feasible alternatives with better performance compared to vehicle-based methods for detecting drowsiness.|
|**2023-03-20**|**Relate auditory speech to EEG by shallow-deep attention-based network**|Fan Cui et.al.|[2303.10897v1](http://arxiv.org/abs/2303.10897v1)|null|Electroencephalography (EEG) plays a vital role in detecting how brain responses to different stimulus. In this paper, we propose a novel Shallow-Deep Attention-based Network (SDANet) to classify the correct auditory stimulus evoking the EEG signal. It adopts the Attention-based Correlation Module (ACM) to discover the connection between auditory speech and EEG from global aspect, and the Shallow-Deep Similarity Classification Module (SDSCM) to decide the classification result via the embeddings learned from the shallow and deep layers. Moreover, various training strategies and data augmentation are used to boost the model robustness. Experiments are conducted on the dataset provided by Auditory EEG challenge (ICASSP Signal Processing Grand Challenge 2023). Results show that the proposed model has a significant gain over the baseline on the match-mismatch track.|
|**2023-03-19**|**Enabling Immersion and Presence in the Metaverse with Over-the-Air Brain-Computer Interface**|Nguyen Quang Hieu et.al.|[2303.10577v1](http://arxiv.org/abs/2303.10577v1)|null|Decoding brain signals can not only reveal Metaverse users' expectations but also early detect error-related behaviors such as stress, drowsiness, and motion sickness. For that, this article proposes a pioneering framework using wireless/over-the-air Brain-Computer Interface (BCI) to assist creation of virtual avatars as human representation in the Metaverse. Specifically, to eliminate the computational burden for Metaverse users' devices, we leverage Wireless Edge Servers (WES) that are popular in 5G architecture and therein URLLC, enhanced broadband features to obtain and process the brain activities, i.e., electroencephalography (EEG) signals (via uplink wireless channels). As a result, the WES can learn human behaviors, adapt system configurations, and allocate radio resources to create individualized settings and enhance user experiences. Despite the potential of BCI, the inherent noisy/fading wireless channels and the uncertainty in Metaverse users' demands and behaviors make the related resource allocation and learning/classification problems particularly challenging. We formulate the joint learning and resource allocation problem as a Quality-of-Experience (QoE) maximization problem that takes into the latency, brain classification accuracy, and resources of the system. To tackle this mixed integer programming problem, we then propose two novel algorithms that are (i) a hybrid learning algorithm to maximize the user QoE and (ii) a meta-learning algorithm to exploit the neurodiversity of the brain signals among multiple Metaverse users. The extensive experiment results with different BCI datasets show that our proposed algorithms can not only provide low delay for virtual reality (VR) applications but also can achieve high classification accuracy for the collected brain signals.|
|**2023-03-13**|**Correlates of Programmer Efficacy and Their Link to Experience: A Combined EEG and Eye-Tracking Study**|Norman Peitek et.al.|[2303.07071v1](http://arxiv.org/abs/2303.07071v1)|[link](https://github.com/brains-on-code/novicevsexpert)|Background: Despite similar education and background, programmers can exhibit vast differences in efficacy. While research has identified some potential factors, such as programming experience and domain knowledge, the effect of these factors on programmers' efficacy is not well understood.   Aims: We aim at unraveling the relationship between efficacy (speed and correctness) and measures of programming experience. We further investigate the correlates of programmer efficacy in terms of reading behavior and cognitive load.   Method: For this purpose, we conducted a controlled experiment with 37~participants using electroencephalography (EEG) and eye tracking. We asked participants to comprehend up to 32 Java source-code snippets and observed their eye gaze and neural correlates of cognitive load. We analyzed the correlation of participants' efficacy with popular programming experience measures.   Results: We found that programmers with high efficacy read source code more targeted and with lower cognitive load. Commonly used experience levels do not predict programmer efficacy well, but self-estimation and indicators of learning eagerness are fairly accurate.   Implications: The identified correlates of programmer efficacy can be used for future research and practice (e.g., hiring). Future research should also consider efficacy as a group sampling method, rather than using simple experience measures.|
|**2023-03-11**|**Assessing gender fairness in EEG-based machine learning detection of Parkinson's disease: A multi-center study**|Anna Kurbatskaya et.al.|[2303.06376v1](http://arxiv.org/abs/2303.06376v1)|[link](https://github.com/biomedical-data-analysis-laboratory/multicentric-ml-parkinson-detection)|As the number of automatic tools based on machine learning (ML) and resting-state electroencephalography (rs-EEG) for Parkinson's disease (PD) detection keeps growing, the assessment of possible exacerbation of health disparities by means of fairness and bias analysis becomes more relevant. Protected attributes, such as gender, play an important role in PD diagnosis development. However, analysis of sub-group populations stemming from different genders is seldom taken into consideration in ML models' development or the performance assessment for PD detection. In this work, we perform a systematic analysis of the detection ability for gender sub-groups in a multi-center setting of a previously developed ML algorithm based on power spectral density (PSD) features of rs-EEG. We find significant differences in the PD detection ability for males and females at testing time (80.5% vs. 63.7% accuracy) and significantly higher activity for a set of parietal and frontal EEG channels and frequency sub-bands for PD and non-PD males that might explain the differences in the PD detection ability for the gender sub-groups.|
|**2023-03-07**|**Sufficient dimension reduction for feature matrices**|Chanwoo Lee et.al.|[2303.04286v1](http://arxiv.org/abs/2303.04286v1)|null|We address the problem of sufficient dimension reduction for feature matrices, which arises often in sensor network localization, brain neuroimaging, and electroencephalography analysis. In general, feature matrices have both row- and column-wise interpretations and contain structural information that can be lost with naive vectorization approaches. To address this, we propose a method called principal support matrix machine (PSMM) for the matrix sufficient dimension reduction. The PSMM converts the sufficient dimension reduction problem into a series of classification problems by dividing the response variables into slices. It effectively utilizes the matrix structure by finding hyperplanes with rank-1 normal matrix that optimally separate the sliced responses. Additionally, we extend our approach to the higher-order tensor case. Our numerical analysis demonstrates that the PSMM outperforms existing methods and has strong interpretability in real data applications.|
|**2023-03-06**|**EEG Synthetic Data Generation Using Probabilistic Diffusion Models**|Giulio Tosato et.al.|[2303.06068v1](http://arxiv.org/abs/2303.06068v1)|[link](https://github.com/devjake/eeg-diffusion-pytorch)|Electroencephalography (EEG) plays a significant role in the Brain Computer Interface (BCI) domain, due to its non-invasive nature, low cost, and ease of use, making it a highly desirable option for widespread adoption by the general public. This technology is commonly used in conjunction with deep learning techniques, the success of which is largely dependent on the quality and quantity of data used for training. To address the challenge of obtaining sufficient EEG data from individual participants while minimizing user effort and maintaining accuracy, this study proposes an advanced methodology for data augmentation: generating synthetic EEG data using denoising diffusion probabilistic models. The synthetic data are generated from electrode-frequency distribution maps (EFDMs) of emotionally labeled EEG recordings. To assess the validity of the synthetic data generated, both a qualitative and a quantitative comparison with real EEG data were successfully conducted. This study opens up the possibility for an open\textendash source accessible and versatile toolbox that can process and generate data in both time and frequency dimensions, regardless of the number of channels involved. Finally, the proposed methodology has potential implications for the broader field of neuroscience research by enabling the creation of large, publicly available synthetic EEG datasets without privacy concerns.|
|**2023-02-27**|**Predicting EEG Responses to Attended Speech via Deep Neural Networks for Speech**|Emina Alickovic et.al.|[2302.13553v1](http://arxiv.org/abs/2302.13553v1)|null|Attending to the speech stream of interest in multi-talker environments can be a challenging task, particularly for listeners with hearing impairment. Research suggests that neural responses assessed with electroencephalography (EEG) are modulated by listener`s auditory attention, revealing selective neural tracking (NT) of the attended speech. NT methods mostly rely on hand-engineered acoustic and linguistic speech features to predict the neural response. Only recently, deep neural network (DNN) models without specific linguistic information have been used to extract speech features for NT, demonstrating that speech features in hierarchical DNN layers can predict neural responses throughout the auditory pathway. In this study, we go one step further to investigate the suitability of similar DNN models for speech to predict neural responses to competing speech observed in EEG. We recorded EEG data using a 64-channel acquisition system from 17 listeners with normal hearing instructed to attend to one of two competing talkers. Our data revealed that EEG responses are significantly better predicted by DNN-extracted speech features than by hand-engineered acoustic features. Furthermore, analysis of hierarchical DNN layers showed that early layers yielded the highest predictions. Moreover, we found a significant increase in auditory attention classification accuracies with the use of DNN-extracted speech features over the use of hand-engineered acoustic features. These findings open a new avenue for development of new NT measures to evaluate and further advance hearing technology.|
|**2023-02-25**|**Partial Label Learning for Emotion Recognition from EEG**|Guangyi Zhang et.al.|[2302.13170v1](http://arxiv.org/abs/2302.13170v1)|[link](https://github.com/guangyizhangbci/pll-emotion-eeg)|Fully supervised learning has recently achieved promising performance in various electroencephalography (EEG) learning tasks by training on large datasets with ground truth labels. However, labeling EEG data for affective experiments is challenging, as it can be difficult for participants to accurately distinguish between similar emotions, resulting in ambiguous labeling (reporting multiple emotions for one EEG instance). This notion could cause model performance degradation, as the ground truth is hidden within multiple candidate labels. To address this issue, Partial Label Learning (PLL) has been proposed to identify the ground truth from candidate labels during the training phase, and has shown good performance in the computer vision domain. However, PLL methods have not yet been adopted for EEG representation learning or implemented for emotion recognition tasks. In this paper, we adapt and re-implement six state-of-the-art PLL approaches for emotion recognition from EEG on a large emotion dataset (SEED-V, containing five emotion classes). We evaluate the performance of all methods in classical and real-world experiments. The results show that PLL methods can achieve strong results in affective computing from EEG and achieve comparable performance to fully supervised learning. We also investigate the effect of label disambiguation, a key step in many PLL methods. The results show that in most cases, label disambiguation would benefit the model when the candidate labels are generated based on their similarities to the ground truth rather than obeying a uniform distribution. This finding suggests the potential of using label disambiguation-based PLL methods for real-world affective tasks. We make the source code of this paper publicly available at: https://github.com/guangyizhangbci/PLL-Emotion-EEG.|
|**2023-02-24**|**Annotating Covert Hazardous Driving Scenarios Online: Utilizing Drivers' Electroencephalography (EEG) Signals**|Chen Zheng et.al.|[2302.12424v1](http://arxiv.org/abs/2302.12424v1)|null|As autonomous driving systems prevail, it is becoming increasingly critical that the systems learn from databases containing fine-grained driving scenarios. Most databases currently available are human-annotated; they are expensive, time-consuming, and subject to behavioral biases. In this paper, we provide initial evidence supporting a novel technique utilizing drivers' electroencephalography (EEG) signals to implicitly label hazardous driving scenarios while passively viewing recordings of real-road driving, thus sparing the need for manual annotation and avoiding human annotators' behavioral biases during explicit report. We conducted an EEG experiment using real-life and animated recordings of driving scenarios and asked participants to report danger explicitly whenever necessary. Behavioral results showed the participants tended to report danger only when overt hazards (e.g., a vehicle or a pedestrian appearing unexpectedly from behind an occlusion) were in view. By contrast, their EEG signals were enhanced at the sight of both an overt hazard and a covert hazard (e.g., an occlusion signalling possible appearance of a vehicle or a pedestrian from behind). Thus, EEG signals were more sensitive to driving hazards than explicit reports. Further, the Time-Series AI (TSAI) successfully classified EEG signals corresponding to overt and covert hazards. We discuss future steps necessary to materialize the technique in real life.|
|**2023-02-19**|**Electrode Clustering and Bandpass Analysis of EEG Data for Gaze Estimation**|Ard Kastrati et.al.|[2302.12710v1](http://arxiv.org/abs/2302.12710v1)|null|In this study, we validate the findings of previously published papers, showing the feasibility of an Electroencephalography (EEG) based gaze estimation. Moreover, we extend previous research by demonstrating that with only a slight drop in model performance, we can significantly reduce the number of electrodes, indicating that a high-density, expensive EEG cap is not necessary for the purposes of EEG-based eye tracking. Using data-driven approaches, we establish which electrode clusters impact gaze estimation and how the different types of EEG data preprocessing affect the models' performance. Finally, we also inspect which recorded frequencies are most important for the defined tasks.|
|**2023-02-17**|**Deep comparisons of Neural Networks from the EEGNet family**|Csaba Márton Köllőd et.al.|[2302.08797v1](http://arxiv.org/abs/2302.08797v1)|[link](https://github.com/kolcs/bionic_apps)|Most of the Brain-Computer Interface (BCI) publications, which propose artificial neural networks for Motor Imagery (MI) Electroencephalography (EEG) signal classification, are presented using one of the BCI Competition datasets. However, these databases contain MI EEG data from less than or equal to 10 subjects . In addition, these algorithms usually include only bandpass filtering to reduce noise and increase signal quality. In this article, we compared 5 well-known neural networks (Shallow ConvNet, Deep ConvNet, EEGNet, EEGNet Fusion, MI-EEGNet) using open-access databases with many subjects next to the BCI Competition 4 2a dataset to acquire statistically significant results. We removed artifacts from the EEG using the FASTER algorithm as a signal processing step. Moreover, we investigated whether transfer learning can further improve the classification results on artifact filtered data. We aimed to rank the neural networks; therefore, next to the classification accuracy, we introduced two additional metrics: the accuracy improvement from chance level and the effect of transfer learning. The former can be used with different class-numbered databases, while the latter can highlight neural networks with sufficient generalization abilities. Our metrics showed that the researchers should not avoid Shallow ConvNet and Deep ConvNet because they can perform better than the later published ones from the EEGNet family.|
|**2023-02-17**|**Sleep Model -- A Sequence Model for Predicting the Next Sleep Stage**|Iksoo Choi et.al.|[2302.12709v1](http://arxiv.org/abs/2302.12709v1)|null|As sleep disorders are becoming more prevalent there is an urgent need to classify sleep stages in a less disturbing way.In particular, sleep-stage classification using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical $n$-gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the $n$-gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.|

## heart rate

### heart rate
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Improved Signal Detection for Ambient Backscatter Communications**|S. Zargari et.al.|[2306.13083v1](http://arxiv.org/abs/2306.13083v1)|null|In ambient backscatter communication (AmBC) systems, passive tags connect to a reader by reflecting an ambient radio frequency (RF) signal. However, the reader may not know the channel states and RF source parameters and can experience interference. The traditional energy detector (TED) appears to be an ideal solution. However, it performs poorly under these conditions. To address this, we propose two new detectors: (1) A joint correlation-energy detector (JCED) based on the first-order correlation of the received samples and (2) An improved energy detector (IED) based on the p-th norm of the received signal vector. We compare the performance of the IED and TED under generalized noise modeled using the McLeish distribution and derive a general analytical formula for the area under the receiver operating characteristic (ROC) curves. Based on our results, both detectors outperform TED. For example, the probability of detection with a false alarm rate of 1% for JCED and IED is 14% and 5% higher, respectively, compared to TED. These gains are even higher using the direct interference cancellation (DIC) technique, with increases of 16% and 7%, respectively. Overall, our proposed detectors offer better performance than the TED, making them useful tools for improving AmBC system performance.|
|**2023-06-22**|**Armed Conflict and Early Human Capital Accumulation: Evidence from Cameroon's Anglophone Conflict**|Hector Galindo-Silva et.al.|[2306.13070v1](http://arxiv.org/abs/2306.13070v1)|null|This paper examines the impact of the Anglophone Conflict in Cameroon on human capital accumulation. Using high-quality individual-level data on test scores and information on conflict-related violent events, a difference-in-differences design is employed to estimate the conflict's causal effects. The results show that an increase in violent events and conflict-related deaths causes a significant decline in test scores in reading and mathematics. The conflict also leads to higher rates of teacher absenteeism and reduced access to electricity in schools. These findings highlight the adverse consequences of conflict-related violence on human capital accumulation, particularly within the Anglophone subsystem. The study emphasizes the disproportionate burden faced by Anglophone pupils due to language-rooted tensions and segregated educational systems.|
|**2023-06-22**|**Data augmentation for recommender system: A semi-supervised approach using maximum margin matrix factorization**|Shamal Shaikh et.al.|[2306.13050v1](http://arxiv.org/abs/2306.13050v1)|null|Collaborative filtering (CF) has become a popular method for developing recommender systems (RS) where ratings of a user for new items is predicted based on her past preferences and available preference information of other users. Despite the popularity of CF-based methods, their performance is often greatly limited by the sparsity of observed entries. In this study, we explore the data augmentation and refinement aspects of Maximum Margin Matrix Factorization (MMMF), a widely accepted CF technique for the rating predictions, which have not been investigated before. We exploit the inherent characteristics of CF algorithms to assess the confidence level of individual ratings and propose a semi-supervised approach for rating augmentation based on self-training. We hypothesize that any CF algorithm's predictions with low confidence are due to some deficiency in the training data and hence, the performance of the algorithm can be improved by adopting a systematic data augmentation strategy. We iteratively use some of the ratings predicted with high confidence to augment the training data and remove low-confidence entries through a refinement process. By repeating this process, the system learns to improve prediction accuracy. Our method is experimentally evaluated on several state-of-the-art CF algorithms and leads to informative rating augmentation, improving the performance of the baseline approaches.|
|**2023-06-22**|**GT-TSCH: Game-Theoretic Distributed TSCH Scheduler for Low-Power IoT Networks**|Omid Tavallaie et.al.|[2306.13039v1](http://arxiv.org/abs/2306.13039v1)|null|Time-Slotted Channel Hopping (TSCH) is a synchronous medium access mode of the IEEE 802.15.4e standard designed for providing low-latency and highly-reliable end-to-end communication. TSCH constructs a communication schedule by combining frequency channel hopping with Time Division Multiple Access (TDMA). In recent years, IETF designed several standards to define general mechanisms for the implementation of TSCH. However, the problem of updating the TSCH schedule according to the changes of the wireless link quality and node's traffic load left unresolved. In this paper, we use non-cooperative game theory to propose GT-TSCH, a distributed TSCH scheduler designed for low-power IoT applications. By considering selfish behavior of nodes in packet forwarding, GT-TSCH updates the TSCH schedule in a distributed approach with low control overhead by monitoring the queue length, the place of the node in the Directed Acyclic Graph (DAG) topology, the quality of the wireless link, and the data packet generation rate. We prove the existence and uniqueness of Nash equilibrium in our game model and we find the optimal number of TSCH Tx timeslots to update the TSCH slotframe. To examine the performance of our contribution, we implement GT-TSCH on Zolertia Firefly IoT motes and the Contiki-NG Operating System (OS). The evaluation results reveal that GT-TSCH improves performance in terms of throughput and end-to-end delay compared to the state-of-the-art method.|
|**2023-06-22**|**Global existence of 2D electron MHD near a steady state**|Mimi Dai et.al.|[2306.13036v1](http://arxiv.org/abs/2306.13036v1)|null|We study the electron magnetohydrodynamics (MHD) in two dimensional geometry, which has a rich family of steady states. In an anisotropic resistivity context, we show global in time existence of small smooth solution near a shear type steady state. Convergence rate of the solution to the steady state is also obtained.|
|**2023-06-22**|**Toward Automated Detection of Microbleeds with Anatomical Scale Localization: A Complete Clinical Diagnosis Support Using Deep Learning**|Jun-Ho Kim et.al.|[2306.13020v1](http://arxiv.org/abs/2306.13020v1)|null|Cerebral Microbleeds (CMBs) are chronic deposits of small blood products in the brain tissues, which have explicit relation to various cerebrovascular diseases depending on their anatomical location, including cognitive decline, intracerebral hemorrhage, and cerebral infarction. However, manual detection of CMBs is a time-consuming and error-prone process because of their sparse and tiny structural properties. The detection of CMBs is commonly affected by the presence of many CMB mimics that cause a high false-positive rate (FPR), such as calcification and pial vessels. This paper proposes a novel 3D deep learning framework that does not only detect CMBs but also inform their anatomical location in the brain (i.e., lobar, deep, and infratentorial regions). For the CMB detection task, we propose a single end-to-end model by leveraging the U-Net as a backbone with Region Proposal Network (RPN). To significantly reduce the FPs within the same single model, we develop a new scheme, containing Feature Fusion Module (FFM) that detects small candidates utilizing contextual information and Hard Sample Prototype Learning (HSPL) that mines CMB mimics and generates additional loss term called concentration loss using Convolutional Prototype Learning (CPL). The anatomical localization task does not only tell to which region the CMBs belong but also eliminate some FPs from the detection task by utilizing anatomical information. The results show that the proposed RPN that utilizes the FFM and HSPL outperforms the vanilla RPN and achieves a sensitivity of 94.66% vs. 93.33% and an average number of false positives per subject (FPavg) of 0.86 vs. 14.73. Also, the anatomical localization task further improves the detection performance by reducing the FPavg to 0.56 while maintaining the sensitivity of 94.66%.|
|**2023-06-22**|**Generation of heralded optical `Schroedinger cat' states by photon-addition**|Yi-Ru Chen et.al.|[2306.13011v1](http://arxiv.org/abs/2306.13011v1)|null|Optical "Schr\"odinger cat" states, the non-classical superposition of two quasi-classical coherent states, serve as a basis for gedanken experiments testing quantum physics on mesoscopic scales and are increasingly recognized as a resource for quantum information processing. Here, we report the first experimental realization of optical "Schr\"odinger cats" by adding a photon to a squeezed vacuum state, so far only photon-subtraction protocols have been realized. Photon-addition gives us the advantage of using heralded signal photons as experimental triggers, and we can generate "Schr\"odinger cats" at rates exceeding $8.5 \times 10^4$ counts per second; at least one order of magnitude higher than all previously reported realizations. Wigner distributions with pronounced negative parts are demonstrated at down to -8.89 dB squeezing, even when the initial squeezed vacuum input state has low purity. Benchmarking against such a degraded squeezed input state we report a maximum fidelity of more than 80% with a maximum cat amplitude of $|\alpha| \approx 1.66$. Our experiment uses photon-addition from pairs, one of those photons is used for monitoring, giving us enhanced control; moreover the pair production rates are high and should allow for repeated application of photon-addition via repeat-stages.|
|**2023-06-22**|**Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers**|Qi Jiang et.al.|[2306.12992v1](http://arxiv.org/abs/2306.12992v1)|[link](https://github.com/zju-jiangqi/pcie-part)|High-quality panoramic images with a Field of View (FoV) of 360-degree are essential for contemporary panoramic computer vision tasks. However, conventional imaging systems come with sophisticated lens designs and heavy optical components. This disqualifies their usage in many mobile and wearable applications where thin and portable, minimalist imaging systems are desired. In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to address minimalist and high-quality panoramic imaging. With less than three spherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is constructed based on the design of the Panoramic Annular Lens (PAL), but with low-quality imaging results due to aberrations and small image plane size. We propose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and Aberration Correction (SR&AC), to solve the image quality problems of MPIP, with imaging sensors of small and large pixel size, respectively. To provide a universal network for the two pipelines, we leverage the information from the Point Spread Function (PSF) of the optical system and design a PSF-aware Aberration-image Recovery Transformer (PART), in which the self-attention calculation and feature extraction are guided via PSF-aware mechanisms. We train PART on synthetic image pairs from simulation and put forward the PALHQ dataset to fill the gap of real-world high-quality PAL images for low-level vision. A comprehensive variety of experiments on synthetic and real-world benchmarks demonstrates the impressive imaging results of PCIE and the effectiveness of plug-and-play PSF-aware mechanisms. We further deliver heuristic experimental findings for minimalist and high-quality panoramic imaging. Our dataset and code will be available at https://github.com/zju-jiangqi/PCIE-PART.|
|**2023-06-22**|**Slowly Rotating Accretion Flow Around SMBH in Elliptical Galaxy: Case With Outflow**|Razieh Ranjbar et.al.|[2306.12990v1](http://arxiv.org/abs/2306.12990v1)|null|Observational evidence and many numerical simulations show the existence of wind (i.e., uncollimated outflow) in accretion systems of the elliptical galaxy center. One of the primary aims of this study is to investigate the solutions of slowly rotating accretion flows around the supermassive black hole with outflow. This paper presents two distinct physical regions: supersonic and subsonic, that extend from the outer boundary to the black hole. In our numerical solution, the outer boundary is chosen beyond the Bondi radius. Due to strong gravity, we ignore outflow (i.e., $s = 0$) in the inner region (within $\sim 10 r_s$). The radial velocity of the flow at the outer region is significantly increased due to the presence of the outflow. Compared to previous works, the one accretion mode - namely, slowly rotating case, which corresponds to low accretion rates that have general wind output is carefully described, and the effect of galaxy potential and the feedback effects by the wind in this mode are taken into account. Since the power-law form of the mass accretion rate is mathematically compatible with our equations, we consider a radius-dependent mass accretion rate ($\dot{M}_{in} \propto r^s$), where $s$ is a free parameter and shows the intensity of outflow. There is an unknown mechanism for removing the mass, angular momentum, and energy by outflows in this study. The effects of the outflow appear well on the outer edge of the flow.|
|**2023-06-22**|**Rate-Splitting Multiple Access for 6G Networks: Ten Promising Scenarios and Applications**|Jeonghun Park et.al.|[2306.12978v1](http://arxiv.org/abs/2306.12978v1)|null|In the upcoming 6G era, multiple access (MA) will play an essential role in achieving high throughput performances required in a wide range of wireless applications. Since MA and interference management are closely related issues, the conventional MA techniques are limited in that they cannot provide near-optimal performance in universal interference regimes. Recently, rate-splitting multiple access (RSMA) has been gaining much attention. RSMA splits an individual message into two parts: a common part, decodable by every user, and a private part, decodable only by the intended user. Each user first decodes the common message and then decodes its private message by applying successive interference cancellation (SIC). By doing so, RSMA not only embraces the existing MA techniques as special cases but also provides significant performance gains by efficiently mitigating inter-user interference in a broad range of interference regimes. In this article, we first present the theoretical foundation of RSMA. Subsequently, we put forth four key benefits of RSMA: spectral efficiency, robustness, scalability, and flexibility. Upon this, we describe how RSMA can enable ten promising scenarios and applications along with future research directions to pave the way for 6G.|
|**2023-06-22**|**Sum-Rate Maximization of RSMA-based Aerial Communications with Energy Harvesting: A Reinforcement Learning Approach**|Jaehyup Seong et.al.|[2306.12977v1](http://arxiv.org/abs/2306.12977v1)|null|In this letter, we investigate a joint power and beamforming design problem for rate-splitting multiple access (RSMA)-based aerial communications with energy harvesting, where a self-sustainable aerial base station serves multiple users by utilizing the harvested energy. Considering maximizing the sum-rate from the long-term perspective, we utilize a deep reinforcement learning (DRL) approach, namely the soft actor-critic algorithm, to restrict the maximum transmission power at each time based on the stochastic property of the channel environment, harvested energy, and battery power information. Moreover, for designing precoders and power allocation among all the private/common streams of the RSMA, we employ sequential least squares programming (SLSQP) using the Han-Powell quasi-Newton method to maximize the sum-rate for the given transmission power via DRL. Numerical results show the superiority of the proposed scheme over several baseline methods in terms of the average sum-rate performance.|
|**2023-06-22**|**Whitham modulation theory for the Zakharov-Kuznetsov equation and transverse instability of its periodic traveling wave solutions**|Gino Biondini et.al.|[2306.12966v1](http://arxiv.org/abs/2306.12966v1)|null|We derive the Whitham modulation equations for the Zakharov-Kuznetsov equation via a multiple scales expansion and averaging two conservation laws over one oscillation period of its periodic traveling wave solutions. We then use the Whitham modulation equations to study the transverse stability of the periodic traveling wave solutions. We find that all such solutions are linearly unstable, and we obtain an explicit expression for the growth rate of the most unstable wave numbers. We validate these predictions by linearizing the equation around its periodic solutions and solving the resulting eigenvalue problem numerically. Finally, we calculate the growth rate of the solitary waves analytically. The predictions of Whitham modulation theory are in excellent agreement with both of these approaches.|
|**2023-06-22**|**Star cluster formation and feedback in different environments of a Milky Way-like galaxy**|Ahmad A. Ali et.al.|[2306.12945v1](http://arxiv.org/abs/2306.12945v1)|null|It remains unclear how galactic environment affects star formation and stellar cluster properties. This is difficult to address in Milky Way-mass galaxy simulations because of limited resolution and less accurate feedback compared to cloud-scale models. We carry out zoom-in simulations to re-simulate 100-300 pc regions of a Milky Way-like galaxy using smoothed particle hydrodynamics, including finer resolution (0.4 Msun per particle), cluster-sink particles, ray-traced photoionization from O stars, H$_2$/CO chemistry, and ISM heating/cooling. We select $10^6$ Msun cloud complexes from a galactic bar, inner spiral arm, outer arm, and inter-arm region (in order of galactocentric radius), retaining the original galactic potentials. The surface densities of star formation rate and neutral gas follow $\Sigma_{SFR} \propto \Sigma_{gas}^{1.3}$, with the bar lying higher up the relation than the other regions. However, the inter-arm region forms stars 2-3x less efficiently than the arm models at the same $\Sigma_{gas}$. The bar produces the most massive cluster, the inner arm the second, and the inter-arm the third. Almost all clusters in the bar and inner arm are small (radii < 5 pc), while 30-50 per cent of clusters in the outer arm and inter-arm have larger radii more like associations. Bar and inner arm clusters rotate at least twice as fast, on average, than clusters in the outer arm and inter-arm regions. The degree of spatial clustering also decreases from bar to inter-arm. Our results indicate that young massive clusters, potentially progenitors of globular clusters, may preferentially form near the bar/inner arm compared to outer arm/inter-arm regions.|
|**2023-06-22**|**The source of electrons at comet 67P**|P. Stephenson et.al.|[2306.12942v1](http://arxiv.org/abs/2306.12942v1)|null|We examine the origin of electrons in a weakly outgassing comet, using Rosetta mission data and a 3D collisional model of electrons at a comet. We have calculated a new dataset of electron-impact ionization (EII) frequency throughout the Rosetta escort phase, with measurements of the Rosetta Plasma Consortium's Ion and Electron Sensor (RPC/IES). The EII frequency is evaluated in 15-minute intervals and compared to other Rosetta datasets.   Electron-impact ionization is the dominant source of electrons at 67P away from perihelion and is highly variable (by up to three orders of magnitude). Around perihelion, EII is much less variable and less efficient than photoionization at Rosetta. Several drivers of the EII frequency are identified, including magnetic field strength and the outgassing rate. Energetic electrons are correlated to the Rosetta-upstream solar wind potential difference, confirming that the ionizing electrons are solar wind electrons accelerated by an ambipolar field.   The collisional test particle model incorporates a spherically symmetric, pure water coma and all the relevant electron-neutral collision processes. Electric and magnetic fields are stationary model inputs, and are computed using a fully-kinetic, collisionless Particle-in-Cell simulation. Collisional electrons are modelled at outgassing rates of $Q=10^{26}$ s$^{-1}$ and $Q=1.5\times10^{27}$ s$^{-1}$. Secondary electrons are the dominant population within a weakly outgassing comet. These are produced by collisions of solar wind electrons with the neutral coma.   The implications of large ion flow speed estimates at Rosetta, away from perihelion, are discussed in relation to multi-instrument studies and the new results of the EII frequency obtained in the present study.|
|**2023-06-22**|**Implicit spoken language diarization**|Jagabandhu Mishra et.al.|[2306.12913v1](http://arxiv.org/abs/2306.12913v1)|null|Spoken language diarization (LD) and related tasks are mostly explored using the phonotactic approach. Phonotactic approaches mostly use explicit way of language modeling, hence requiring intermediate phoneme modeling and transcribed data. Alternatively, the ability of deep learning approaches to model temporal dynamics may help for the implicit modeling of language information through deep embedding vectors. Hence this work initially explores the available speaker diarization frameworks that capture speaker information implicitly to perform LD tasks. The performance of the LD system on synthetic code-switch data using the end-to-end x-vector approach is 6.78% and 7.06%, and for practical data is 22.50% and 60.38%, in terms of diarization error rate and Jaccard error rate (JER), respectively. The performance degradation is due to the data imbalance and resolved to some extent by using pre-trained wave2vec embeddings that provide a relative improvement of 30.74% in terms of JER.|
|**2023-06-22**|**The limit of macroscopic homogeneous ice nucleation at the nanoscale**|John A. Hayton et.al.|[2306.12903v1](http://arxiv.org/abs/2306.12903v1)|null|Nucleation in small volumes of water has garnered renewed interest due to the relevance of pore condensation and freezing under conditions of low partial pressures of water, such as in the upper troposphere. Molecular simulations can in principle provide insight on this process at the molecular scale that is challenging to achieve experimentally. However, there are discrepancies in the literature as to whether the rate in confined systems is enhanced or suppressed relative to bulk water at the same temperature and pressure. In this study, we investigate the extent to which the size of the critical nucleus and the rate at which it grows in thin films of water are affected by the thickness of the film. Our results suggest that nucleation remains bulk-like in films that are barely large enough accommodate a critical nucleus. This conclusion seems robust to the presence of physical confining boundaries. We also discuss the difficulties in unambiguously determining homogeneous nucleation rates in nanoscale systems, owing to the challenges in defining the volume. Our results suggest any impact on a film's thickness on the rate is largely inconsequential for present day experiments.|
|**2023-06-22**|**Collective modes of a collisional anisotropic quark-gluon plasma**|Ruizhe Zhao et.al.|[2306.12851v1](http://arxiv.org/abs/2306.12851v1)|null|In this paper we consider the collective modes of a momentum-space anisotropic quark-gluon plasma taking into account the effect of collisions between the plasma constituents. Our analysis is carried out using a collisional kernel of Bhatnagar-Gross-Krook form and extends prior analyses in the literature by considering all possible angles of propagation of the gluonic modes relative to the momentum-anisotropy axis. We extract both the stable and unstable modes as a function of the collision rate and confirm prior findings that gluonic unstable modes can be eliminated from the spectrum if the collision rate is sufficiently large. In addition, we discuss the conditions necessary for the existence of unstable modes and present evidence that unstable mode growth rates are maximal for modes with momentum along the anisotropy direction. Finally, we demonstrate that when there is a finite collisional rate, gluonic unstable modes are absent from the spectrum at both small and large momentum anisotropy. These results pave the way for understanding the impact of collisions on a variety of non-equilibrium quark-gluon plasma observables.|
|**2023-06-22**|**Detailed study of the astrophysical direct capture reaction $^{6}{\rm Li}(p, γ)^{7}{\rm Be}$ in a potential model approach**|E. M. Tursunov et.al.|[2306.12838v1](http://arxiv.org/abs/2306.12838v1)|null|The astrophysical $S$ factor and reaction rates of the direct capture process $^{6}$Li(p,$\gamma)^{7}$Be are estimated within a two-body single-channel potential model approach. Central potentials of the Gaussian-form in the $^2P_{3/2}$ and $^2P_{1/2}$ waves are adjusted to reproduce the binding energies and the empirical values of the asymptotic normalization coefficients (ANC) for the $^7$Be(3/2$^-$) ground and $^7$Be(1/2$^-$) excited bound states, respectively. The parameters of the potential in the most important $^2S_{1/2}$ scattering channel were fitted to reproduce the empirical phase shifts from the literature and the low-energy astrophysical $S$ factor of the LUNA collaboration. The obtained results for the astrophysical $S$ factor and the reaction rates are in a very good agreement with available experimental data sets. The numerical estimates reproduce not only the absolute values, but also the energy and temperature dependence of the $S$ factor and reaction rates of the LUNA collaboration, respectively. The estimated $^{7}{\rm Li/H}$ primordial abundance ratio $(4.67\pm 0.04 )\times 10^{-10}$ is well consistent with recent BBN result of $(4.72\pm 0.72) \times 10^{-10}$ after the Planck observation.|
|**2023-06-22**|**MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge**|Sokratis Nikolaidis et.al.|[2306.12830v1](http://arxiv.org/abs/2306.12830v1)|null|Cascade systems comprise a two-model sequence, with a lightweight model processing all samples and a heavier, higher-accuracy model conditionally refining harder samples to improve accuracy. By placing the light model on the device side and the heavy model on a server, model cascades constitute a widely used distributed inference approach. With the rapid expansion of intelligent indoor environments, such as smart homes, the new setting of Multi-Device Cascade is emerging where multiple and diverse devices are to simultaneously use a shared heavy model on the same server, typically located within or close to the consumer environment. This work presents MultiTASC, a multi-tenancy-aware scheduler that adaptively controls the forwarding decision functions of the devices in order to maximize the system throughput, while sustaining high accuracy and low latency. By explicitly considering device heterogeneity, our scheduler improves the latency service-level objective (SLO) satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade methods in highly heterogeneous setups, while serving over 40 devices, showcasing its scalability.|
|**2023-06-22**|**Global dynamics of a predator-prey model with alarm-taxis**|Songzhi Li et.al.|[2306.12828v1](http://arxiv.org/abs/2306.12828v1)|null|This paper concerns with the global dynamics of classical solutions to an important alarm-taxis ecosystem, which demonstrates the behaviors of prey that attract secondary predator when threatened by primary predator. And the secondary predator pursues the signal generated by the interaction of the prey and primary predator. However, it seems that the necessary gradient estimates for global existence cannot be obtained in critical case due to strong coupled structure. Thereby, we develop a new approach to estimate the gradient of prey and primary predator which takes advantage of slightly higher damping power. Then the boundedness of classical solutions in two dimension with Neumann boundary conditions can be established by energy estimates and semigroup theory. Moreover, by constructing Lyapunov functional, it is proved that the coexistence homogeneous steady states is asymptotically stability and the convergence rate is exponential under certain assumptions on the system coefficients.|
|**2023-06-22**|**Harnessing the Potential of Optical Communications for the Metaverse**|Baha Eddine Youcef Belmekki et.al.|[2306.12822v1](http://arxiv.org/abs/2306.12822v1)|null|The Metaverse is a digital world that offers an immersive virtual experience. However, the Metaverse applications are bandwidth-hungry and delay-sensitive that require ultrahigh data rates, ultra-low latency, and hyper-intensive computation. To cater for these requirements, optical communication arises as a key pillar in bringing this paradigm into reality. We highlight in this paper the potential of optical communications in the Metaverse. First, we set forth Metaverse requirements in terms of capacity and latency; then, we introduce ultra-high data rates requirements for various Metaverse experiences. Then, we put forward the potential of optical communications to achieve these data rate requirements in backbone, backhaul, fronthaul, and access segments. Both optical fiber and optical wireless communication (OWC) technologies, as well as their current and future expected data rates, are detailed. In addition, we propose a comprehensive set of configurations, connectivity, and equipment necessary for an immersive Metaverse experience. Finally, we identify a set of key enablers and research directions such as analog neuromorphic optical computing, optical intelligent reflective surfaces (IRS), hollow core fiber (HCF), and terahertz (THz).|
|**2023-06-22**|**Searching for supermassive charged gravitinos in underground experiments**|Krzysztof A. Meissner et.al.|[2306.12797v1](http://arxiv.org/abs/2306.12797v1)|null|We examine possible experimental signatures that may be exploited to search for stable supermassive particles with electric charges of $O(1)$ in future underground experiments, and the upcoming JUNO experiment in particular. The telltale signal would be a correlated sequence of three or more nuclear recoils along a straight line, corresponding to the motion of a non-relativistic ($\beta <10^{-2}$) particle that could enter the detector from any direction. We provide some preliminary estimates for the expected event rates.|
|**2023-06-22**|**DiffWA: Diffusion Models for Watermark Attack**|Xinyu Li et.al.|[2306.12790v1](http://arxiv.org/abs/2306.12790v1)|null|With the rapid development of deep neural networks(DNNs), many robust blind watermarking algorithms and frameworks have been proposed and achieved good results. At present, the watermark attack algorithm can not compete with the watermark addition algorithm. And many watermark attack algorithms only care about interfering with the normal extraction of the watermark, and the watermark attack will cause great visual loss to the image. To this end, we propose DiffWA, a conditional diffusion model with distance guidance for watermark attack, which can restore the image while removing the embedded watermark. The core of our method is training an image-to-image conditional diffusion model on unwatermarked images and guiding the conditional model using a distance guidance when sampling so that the model will generate unwatermarked images which is similar to original images. We conducted experiments on CIFAR-10 using our proposed models. The results shows that the model can remove the watermark with good effect and make the bit error rate of watermark extraction higher than 0.4. At the same time, the attacked image will maintain good visual effect with PSNR more than 31 and SSIM more than 0.97 compared with the original image.|
|**2023-06-22**|**Similar levels of deuteration in the pre-stellar core L1544 and the protostellar core HH211**|K. Giers et.al.|[2306.12775v1](http://arxiv.org/abs/2306.12775v1)|null|In the centre of pre-stellar cores, deuterium fractionation is enhanced due to the low temperatures and high densities. Therefore, the chemistry of deuterated molecules can be used to study the earliest stages of star formation. We analyse the deuterium fractionation of simple molecules, comparing the level of deuteration in the envelopes of the pre-stellar core L1544 in Taurus and the protostellar core HH211 in Perseus. We used single-dish observations of CCH, HCN, HNC, HCO$^+$, and their $^{13}$C-, $^{18}$O- and D-bearing isotopologues, detected with the Onsala 20m telescope. We derived the column densities and the deuterium fractions of the molecules. Additionally, we used radiative transfer simulations and results from chemical modelling to reproduce the observed molecular lines. We used new collisional rate coefficients for HNC, HN$^{13}$C, DNC, and DCN that consider the hyperfine structure of these molecules. We find high levels of deuteration for CCH (10%) in both sources, consistent with other carbon chains, and moderate levels for HCN (5-7%) and HNC (8%). The deuterium fraction of HCO$^+$ is enhanced towards HH211, most likely caused by isotope-selective photodissociation of C$^{18}$O. Similar levels of deuteration show that the process is likely equally efficient towards both cores, suggesting that the protostellar envelope still retains the chemical composition of the original pre-stellar core. The fact that the two cores are embedded in different molecular clouds also suggests that environmental conditions do not have a significant effect on the deuteration within dense cores. Radiative transfer modelling shows that it is necessary to include the outer layers of the cores to consider the effects of extended structures. Besides HCO$^+$ observations, HCN observations towards L1544 also require the presence of an outer diffuse layer where the molecules are relatively abundant.|
|**2023-06-22**|**On the rate of convergence of Yosida approximation for rhe nonlocal Cahn-Hilliard equation**|Piotr Gwiazda et.al.|[2306.12772v1](http://arxiv.org/abs/2306.12772v1)|null|It is well-known that one can construct solutions to the nonlocal Cahn-Hilliard equation with singular potentials via Yosida approximation with parameter $\lambda \to 0$. The usual method is based on compactness arguments and does not provide any rate of convergence. Here, we fill the gap and we obtain an explicit convergence rate $\sqrt{\lambda}$. The proof is based on the theory of maximal monotone operators and an observation that the nonlocal operator is of Hilbert-Schmidt type. Our estimate can provide convergence result for the Galerkin methods where the parameter $\lambda$ could be linked to the discretization parameters, yielding appropriate error estimates.|
|**2023-06-22**|**Restoration of the JPEG Maximum Lossy Compressed Face Images with Hourglass Block based on Early Stopping Discriminator**|Jongwook Si et.al.|[2306.12757v1](http://arxiv.org/abs/2306.12757v1)|null|When a JPEG image is compressed using the loss compression method with a high compression rate, a blocking phenomenon can occur in the image, making it necessary to restore the image to its original quality. In particular, restoring compressed images that are unrecognizable presents an innovative challenge. Therefore, this paper aims to address the restoration of JPEG images that have suffered significant loss due to maximum compression using a GAN-based net-work method. The generator in this network is based on the U-Net architecture and features a newly presented hourglass structure that can preserve the charac-teristics of deep layers. Additionally, the network incorporates two loss functions, LF Loss and HF Loss, to generate natural and high-performance images. HF Loss uses a pretrained VGG-16 network and is configured using a specific layer that best represents features, which can enhance performance for the high-frequency region. LF Loss, on the other hand, is used to handle the low-frequency region. These two loss functions facilitate the generation of images by the generator that can deceive the discriminator while accurately generating both high and low-frequency regions. The results show that the blocking phe-nomenon in lost compressed images was removed, and recognizable identities were generated. This study represents a significant improvement over previous research in terms of image restoration performance.|
|**2023-06-22**|**ViCTORIA project: MeerKAT HI observations of the ram pressure stripped galaxy NGC 4523**|A. Boselli et.al.|[2306.12751v1](http://arxiv.org/abs/2306.12751v1)|null|We present the first results of a 21 cm HI line pilot observation carried out with MeerKAT in preparation for the ViCTORIA project, an untargeted survey of the Virgo galaxy cluster. The extraordinary quality of the data in terms of sensitivity and angular resolution (rms~0.65 mJy beam^-1 at ~27"x39" and 11 km/s resolution) allowed us to detect an extended (~10 kpc projected length) low column density (N(HI) < 2.5x10^20 cm^-2) HI gas tail associated with the dwarf irregular galaxy NGC4523 at the northern edge of the cluster. The morphology of the tail and of the stellar disc suggest that the galaxy is suffering a hydrodynamic interaction with the surrounding hot intracluster medium (ICM; ram pressure stripping). The orientation of the trailing tail, the gradient in the HI gas column density at the interface between the cold ISM and the hot ICM, the velocity of the galaxy with respect to that of the cluster, and its position indicate that NGC4523 is infalling for the first time into Virgo from the NNW background of the cluster. Using a grid of hydrodynamic simulations we derive the impact parameters with the surrounding ICM, and estimate that the galaxy will be at pericentre (D~500-600 kpc) in ~1 Gyr, where ram pressure stripping will be able to remove most, if not all, of its gas. The galaxy is located on the star formation main sequence when its star formation rate is derived using Halpha images obtained during the VESTIGE survey, suggesting that NGC4523 is only at the beginning of its interaction with the surrounding environment. A few HII regions are detected in the Halpha images within the HI gas tail outside the stellar disc. Their ages, derived by comparing their Halpha, FUV, NUV, and optical colours with the predictions of SED fitting models, are <30 Myr, and suggest that these HII regions have formed within the stripped gas.|
|**2023-06-22**|**Don't be so Monotone: Relaxing Stochastic Line Search in Over-Parameterized Models**|Leonardo Galli et.al.|[2306.12747v1](http://arxiv.org/abs/2306.12747v1)|[link](https://github.com/leonardogalli91/ponos)|Recent works have shown that line search methods can speed up Stochastic Gradient Descent (SGD) and Adam in modern over-parameterized settings. However, existing line searches may take steps that are smaller than necessary since they require a monotone decrease of the (mini-)batch objective function. We explore nonmonotone line search methods to relax this condition and possibly accept larger step sizes. Despite the lack of a monotonic decrease, we prove the same fast rates of convergence as in the monotone case. Our experiments show that nonmonotone methods improve the speed of convergence and generalization properties of SGD/Adam even beyond the previous monotone line searches. We propose a POlyak NOnmonotone Stochastic (PoNoS) method, obtained by combining a nonmonotone line search with a Polyak initial step size. Furthermore, we develop a new resetting technique that in the majority of the iterations reduces the amount of backtracks to zero while still maintaining a large initial step size. To the best of our knowledge, a first runtime comparison shows that the epoch-wise advantage of line-search-based methods gets reflected in the overall computational time.|
|**2023-06-22**|**Rotation Group Synchronization via Quotient Manifold**|Linglingzhi Zhu et.al.|[2306.12730v1](http://arxiv.org/abs/2306.12730v1)|null|Rotation group $\mathcal{SO}(d)$ synchronization is an important inverse problem and has attracted intense attention from numerous application fields such as graph realization, computer vision, and robotics. In this paper, we focus on the least-squares estimator of rotation group synchronization with general additive noise models, which is a nonconvex optimization problem with manifold constraints. Unlike the phase/orthogonal group synchronization, there are limited provable approaches for solving rotation group synchronization. First, we derive improved estimation results of the least-squares/spectral estimator, illustrating the tightness and validating the existing relaxation methods of solving rotation group synchronization through the optimum of relaxed orthogonal group version under near-optimal noise level for exact recovery. Moreover, departing from the standard approach of utilizing the geometry of the ambient Euclidean space, we adopt an intrinsic Riemannian approach to study orthogonal/rotation group synchronization. Benefiting from a quotient geometric view, we prove the positive definite condition of quotient Riemannian Hessian around the optimum of orthogonal group synchronization problem, and consequently the Riemannian local error bound property is established to analyze the convergence rate properties of various Riemannian algorithms. As a simple and feasible method, the sequential convergence guarantee of the (quotient) Riemannian gradient method for solving orthogonal/rotation group synchronization problem is studied, and we derive its global linear convergence rate to the optimum with the spectral initialization. All results are deterministic without any probabilistic model.|
|**2023-06-22**|**Analysis of divergence-preserving unfitted finite element methods for the mixed Poisson problem**|Christoph Lehrenfeld et.al.|[2306.12722v1](http://arxiv.org/abs/2306.12722v1)|null|In this paper we present a new H(div)-conforming unfitted finite element method for the mixed Poisson problem which is robust in the cut configuration and preserves conservation properties of body-fitted finite element methods. The key is to formulate the divergence-constraint on the active mesh, instead of the physical domain, in order to obtain robustness with respect to cut configurations without the need for a stabilization that pollutes the mass balance. This change in the formulation results in a slight inconsistency, but does not affect the accuracy of the flux variable. By applying post-processings for the scalar variable, in virtue of classical local post-processings in body-fitted methods, we retain optimal convergence rates for both variables and even the superconvergence after post-processing of the scalar variable. We present the method and perform a rigorous a-priori error analysis of the method and discuss several variants and extensions. Numerical experiments confirm the theoretical results.|

## actigraphy

### actigraphy
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-03-14**|**Transfer Learning for Real-time Deployment of a Screening Tool for Depression Detection Using Actigraphy**|Rajanikant Ghate et.al.|[2303.07847v1](http://arxiv.org/abs/2303.07847v1)|null|Automated depression screening and diagnosis is a highly relevant problem today. There are a number of limitations of the traditional depression detection methods, namely, high dependence on clinicians and biased self-reporting. In recent years, research has suggested strong potential in machine learning (ML) based methods that make use of the user's passive data collected via wearable devices. However, ML is data hungry. Especially in the healthcare domain primary data collection is challenging. In this work, we present an approach based on transfer learning, from a model trained on a secondary dataset, for the real time deployment of the depression screening tool based on the actigraphy data of users. This approach enables machine learning modelling even with limited primary data samples. A modified version of leave one out cross validation approach performed on the primary set resulted in mean accuracy of 0.96, where in each iteration one subject's data from the primary set was set aside for testing.|
|**2023-01-04**|**KIDS: kinematics-based (in)activity detection and segmentation in a sleep case study**|Omar Elnaggar et.al.|[2301.03469v1](http://arxiv.org/abs/2301.03469v1)|null|Sleep behaviour and in-bed movements contain rich information on the neurophysiological health of people, and have a direct link to the general well-being and quality of life. Standard clinical practices rely on polysomnography for sleep assessment; however, it is intrusive, performed in unfamiliar environments and requires trained personnel. Progress has been made on less invasive sensor technologies, such as actigraphy, but clinical validation raises concerns over their reliability and precision. Additionally, the field lacks a widely acceptable algorithm, with proposed approaches ranging from raw signal or feature thresholding to data-hungry classification models, many of which are unfamiliar to medical staff. This paper proposes an online Bayesian probabilistic framework for objective (in)activity detection and segmentation based on clinically meaningful joint kinematics, measured by a custom-made wearable sensor. Intuitive three-dimensional visualisations of kinematic timeseries were accomplished through dimension reduction based preprocessing, offering out-of-the-box framework explainability potentially useful for clinical monitoring and diagnosis. The proposed framework attained up to 99.2\% $F_1$-score and 0.96 Pearson's correlation coefficient in, respectively, the posture change detection and inactivity segmentation tasks. The work paves the way for a reliable home-based analysis of movements during sleep which would serve patient-centred longitudinal care plans.|
|**2022-12-31**|**Definition and clinical validation of Pain Patient States from high-dimensional mobile data: application to a chronic pain cohort**|Jenna M. Reinen et.al.|[2301.00299v1](http://arxiv.org/abs/2301.00299v1)|null|The technical capacity to monitor patients with a mobile device has drastically expanded, but data produced from this approach are often difficult to interpret. We present a solution to produce a meaningful representation of patient status from large, complex data streams, leveraging both a data-driven approach, and use clinical knowledge to validate results. Data were collected from a clinical trial enrolling chronic pain patients, and included questionnaires, voice recordings, actigraphy, and standard health assessments. The data were reduced using a clustering analysis. In an initial exploratory analysis with only questionnaire data, we found up to 3 stable cluster solutions that grouped symptoms on a positive to negative spectrum. Objective features (actigraphy, speech) expanded the cluster solution granularity. Using a 5 state solution with questionnaire and actigraphy data, we found significant correlations between cluster properties and assessments of disability and quality-of-life. The correlation coefficient values showed an ordinal distinction, confirming the cluster ranking on a negative to positive spectrum. This suggests we captured novel, distinct Pain Patient States with this approach, even when multiple clusters were equated on pain magnitude. Relative to using complex time courses of many variables, Pain Patient States holds promise as an interpretable, useful, and actionable metric for a clinician or caregiver to simplify and provide timely delivery of care.|
|**2022-12-21**|**A hidden Markov modeling approach combining objective measure of activity and subjective measure of self-reported sleep to estimate the sleep-wake cycle**|Semhar B. Ogbagaber et.al.|[2212.11224v1](http://arxiv.org/abs/2212.11224v1)|null|Characterizing the sleep-wake cycle in adolescents is an important prerequisite to better understand the association of abnormal sleep patterns with subsequent clinical and behavioral outcomes. The aim of this research was to develop hidden Markov models (HMM) that incorporate both objective (actigraphy) and subjective (sleep log) measures to estimate the sleep-wake cycle using data from the NEXT longitudinal study, a large population-based cohort study. The model was estimated with a negative binomial distribution for the activity counts (1-minute epochs) to account for overdispersion relative to a Poisson process. Furthermore, self-reported measures were dichotomized (for each one-minute interval) and subject to misclassification. We assumed that the unobserved sleep-wake cycle follows a two-state Markov chain with transitional probabilities varying according to a circadian rhythm. Maximum-likelihood estimation using a backward-forward algorithm was applied to fit the longitudinal data on a subject by subject basis. The algorithm was used to reconstruct the sleep-wake cycle from sequences of self-reported sleep and activity data. Furthermore, we conduct simulations to examine the properties of this approach under different observational patterns including both complete and partially observed measurements on each individual.|
|**2022-08-30**|**Mediation analysis with densities as mediators with an application to iCOMPARE trial**|Jingru Zhang et.al.|[2208.13939v1](http://arxiv.org/abs/2208.13939v1)|null|Physical activity has long been shown to be associated with biological and physiological performance and risk of diseases. It is of great interest to assess whether the effect of an exposure or intervention on an outcome is mediated through physical activity measured by modern wearable devices such as actigraphy. However, existing methods for mediation analysis focus almost exclusively on mediation variable that is in the Euclidean space, which cannot be applied directly to the actigraphy data of physical activity. Such data is best summarized in the form of an histogram or density. In this paper, we extend the structural equation models (SEMs) to the settings where a density is treated as the mediator to study the indirect mediation effect of physical activity on an outcome. We provide sufficient conditions for identifying the average causal effects of density mediator and present methods for estimating the direct and mediating effects of density on an outcome. We apply our method to the data set from the iCOMPARE trial that compares flexible duty-hour policies and standard duty-hour policies on interns' sleep related outcomes to explore the mediation effect of physical activity on the causal path between flexible duty-hour policies and sleep related outcomes.|
|**2021-11-29**|**Validating CircaCP: a Generic Sleep-Wake Cycle Detection Algorithm**|Shanshan Chen et.al.|[2111.14960v1](http://arxiv.org/abs/2111.14960v1)|[link](https://github.com/shanshanchen-biostat/circacp)|Sleep-wake cycle detection is a key step when extrapolating sleep patterns from actigraphy data. Numerous supervised detection algorithms have been developed with parameters estimated from and optimized for a particular dataset, yet their generalizability from sensor to sensor or study to study is unknown. In this paper, we propose and validate an unsupervised algorithm -- CircaCP -- to detect sleep-wake cycles from minute-by-minute actigraphy data. It first uses a robust cosinor model to estimate circadian rhythm, then searches for a single change point (CP) within each cycle. We used CircaCP to estimate sleep/wake onset times (S/WOTs) from 2125 indviduals' data in the MESA Sleep study and compared the estimated S/WOTs against self-reported S/WOT event markers. Lastly, we quantified the biases between estimated and self-reported S/WOTs, as well as variation in S/WOTs contributed by the two methods, using linear mixed-effects models and variance component analysis.   On average, SOTs estimated by CircaCP were five minutes behind those reported by event markers, and WOTs estimated by CircaCP were less than one minute behind those reported by markers. These differences accounted for less than 0.2% variability in SOTs and in WOTs, taking into account other sources of between-subject variations. By focusing on the commonality in human circadian rhythms captured by actigraphy, our algorithm transferred seamlessly from hip-worn ActiGraph data collected from children in our previous study to wrist-worn Actiwatch data collected from adults. The large between- and within-subject variability highlights the need for estimating individual-level S/WOTs when conducting actigraphy research. The generalizability of our algorithm also suggests that it could be widely applied to actigraphy data collected by other wearable sensors.|
|**2021-07-08**|**Circadian Rhythms are Not Captured Equal: Exploring Circadian Metrics Extracted by Different Computational Methods from Smartphone Accelerometer and GPS Sensors in Daily Life Tracking**|Congyu Wu et.al.|[2107.04135v1](http://arxiv.org/abs/2107.04135v1)|null|Circadian rhythm is the natural biological cycle manifested in human daily routines. A regular and stable rhythm is found to be correlated with good physical and mental health. With the wide adoption of mobile and wearable technology, many types of sensor data, such as GPS and actigraphy, provide evidence for researchers to objectively quantify the circadian rhythm of a user and further use these quantified metrics of circadian rhythm to infer the user's health status. Researchers in computer science and psychology have investigated circadian rhythm using various mobile and wearable sensors in ecologically valid human sensing studies, but questions remain whether and how different data types produce different circadian rhythm results when simultaneously used to monitor a user. We hypothesize that different sensor data reveal different aspects of the user's daily behavior, thus producing different circadian rhythm patterns. In this paper we focus on two data types: GPS and accelerometer data from smartphones. We used smartphone data from 225 college student participants and applied four circadian rhythm characterization methods. We found significant and interesting discrepancies in the rhythmic patterns discovered among sensors, which suggests circadian rhythms discovered from different personal tracking sensors have different levels of sensitivity to device usage and aspects of daily behavior.|
|**2021-07-01**|**Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors**|Ulysse Côté-Allard et.al.|[2107.00710v3](http://arxiv.org/abs/2107.00710v3)|[link](https://github.com/UlysseCoteAllard/LongShortNetworkBipolar)|Manic episodes of bipolar disorder can lead to uncritical behaviour and delusional psychosis, often with destructive consequences for those affected and their surroundings. Early detection and intervention of a manic episode are crucial to prevent escalation, hospital admission and premature death. However, people with bipolar disorder may not recognize that they are experiencing a manic episode and symptoms such as euphoria and increased productivity can also deter affected individuals from seeking help. This work proposes to perform user-independent, automatic mood-state detection based on actigraphy and electrodermal activity acquired from a wrist-worn device during mania and after recovery (euthymia). This paper proposes a new deep learning-based ensemble method leveraging long (20h) and short (5 minutes) time-intervals to discriminate between the mood-states. When tested on 47 bipolar patients, the proposed classification scheme achieves an average accuracy of 91.59% in euthymic/manic mood-state recognition.|
|**2021-05-05**|**Activity-Aware Deep Cognitive Fatigue Assessment using Wearables**|Mohammad Arif Ul Alam et.al.|[2105.02824v1](http://arxiv.org/abs/2105.02824v1)|null|Cognitive fatigue has been a common problem among workers which has become an increasing global problem since the emergence of COVID-19 as a global pandemic. While existing multi-modal wearable sensors-aided automatic cognitive fatigue monitoring tools have focused on physical and physiological sensors (ECG, PPG, Actigraphy) analytic on specific group of people (say gamers, athletes, construction workers), activity-awareness is utmost importance due to its different responses on physiology in different person. In this paper, we propose a novel framework, Activity-Aware Recurrent Neural Network (\emph{AcRoNN}), that can generalize individual activity recognition and improve cognitive fatigue estimation significantly. We evaluate and compare our proposed method with state-of-art methods using one real-time collected dataset from 5 individuals and another publicly available dataset from 27 individuals achieving max. 19% improvement.|
|**2021-04-28**|**Optimizing Rescoring Rules with Interpretable Representations of Long-Term Information**|Aaron Fisher et.al.|[2104.14291v1](http://arxiv.org/abs/2104.14291v1)|null|Analyzing temporal data (e.g., wearable device data) requires a decision about how to combine information from the recent and distant past. In the context of classifying sleep status from actigraphy, Webster's rescoring rules offer one popular solution based on the long-term patterns in the output of a moving-window model. Unfortunately, the question of how to optimize rescoring rules for any given setting has remained unsolved. To address this problem and expand the possible use cases of rescoring rules, we propose rephrasing these rules in terms of epoch-specific features. Our features take two general forms: (1) the time lag between now and the most recent [or closest upcoming] bout of time spent in a given state, and (2) the length of the most recent [or closest upcoming] bout of time spent in a given state. Given any initial moving window model, these features can be defined recursively, allowing for straightforward optimization of rescoring rules. Joint optimization of the moving window model and the subsequent rescoring rules can also be implemented using gradient-based optimization software, such as Tensorflow. Beyond binary classification problems (e.g., sleep-wake), the same approach can be applied to summarize long-term patterns for multi-state classification problems (e.g., sitting, walking, or stair climbing). We find that optimized rescoring rules improve the performance of sleep-wake classifiers, achieving accuracy comparable to that of certain neural network architectures.|
|**2021-01-05**|**Bayesian Hierarchical Modeling and Analysis for Actigraph Data from Wearable Devices**|Pierfrancesco Alaimo Di Loro et.al.|[2101.01624v4](http://arxiv.org/abs/2101.01624v4)|[link](https://github.com/minmar94/EfficientTNNGPforActigraph)|The majority of Americans fail to achieve recommended levels of physical activity, which leads to numerous preventable health problems such as diabetes, hypertension, and heart diseases. This has generated substantial interest in monitoring human activity to gear interventions toward environmental features that may relate to higher physical activity. Wearable devices, such as wrist-worn sensors that monitor gross motor activity (actigraph units) continuously record the activity levels of a subject, producing massive amounts of high-resolution measurements. Analyzing actigraph data needs to account for spatial and temporal information on trajectories or paths traversed by subjects wearing such devices. Inferential objectives include estimating a subject's physical activity levels along a given trajectory; identifying trajectories that are more likely to produce higher levels of physical activity for a given subject; and predicting expected levels of physical activity in any proposed new trajectory for a given set of health attributes. Here, we devise a Bayesian hierarchical modeling framework for spatial-temporal actigraphy data to deliver fully model-based inference on trajectories while accounting for subject-level health attributes and spatial-temporal dependencies. We undertake a comprehensive analysis of an original dataset from the Physical Activity through Sustainable Transport Approaches in Los Angeles (PASTA-LA) study to ascertain spatial zones and trajectories exhibiting significantly higher levels of physical activity while accounting for various sources of heterogeneity.|
|**2020-11-14**|**Using Convolutional Variational Autoencoders to Predict Post-Trauma Health Outcomes from Actigraphy Data**|Ayse S. Cakmak et.al.|[2011.07406v2](http://arxiv.org/abs/2011.07406v2)|null|Depression and post-traumatic stress disorder (PTSD) are psychiatric conditions commonly associated with experiencing a traumatic event. Estimating mental health status through non-invasive techniques such as activity-based algorithms can help to identify successful early interventions. In this work, we used locomotor activity captured from 1113 individuals who wore a research grade smartwatch post-trauma. A convolutional variational autoencoder (VAE) architecture was used for unsupervised feature extraction from four weeks of actigraphy data. By using VAE latent variables and the participant's pre-trauma physical health status as features, a logistic regression classifier achieved an area under the receiver operating characteristic curve (AUC) of 0.64 to estimate mental health outcomes. The results indicate that the VAE model is a promising approach for actigraphy data analysis for mental health outcomes in long-term studies.|
|**2020-08-06**|**Fatigue Assessment using ECG and Actigraphy Sensors**|Yang Bai et.al.|[2008.02871v2](http://arxiv.org/abs/2008.02871v2)|[link](https://github.com/baiyang4/Sjogrens_questionnaire)|Fatigue is one of the key factors in the loss of work efficiency and health-related quality of life, and most fatigue assessment methods were based on self-reporting, which may suffer from many factors such as recall bias. To address this issue, we developed an automated system using wearable sensing and machine learning techniques for objective fatigue assessment. ECG/Actigraphy data were collected from subjects in free-living environments. Preprocessing and feature engineering methods were applied, before interpretable solution and deep learning solution were introduced. Specifically, for interpretable solution, we proposed a feature selection approach which can select less correlated and high informative features for better understanding system's decision-making process. For deep learning solution, we used state-of-the-art self-attention model, based on which we further proposed a consistency self-attention (CSA) mechanism for fatigue assessment. Extensive experiments were conducted, and very promising results were achieved.|
|**2019-06-03**|**Deep learning from wristband sensor data: towards wearable, non-invasive seizure forecasting**|Christian Meisel et.al.|[1906.00511v2](http://arxiv.org/abs/1906.00511v2)|null|Seizure forecasting may provide patients with timely warnings to adapt their daily activities and help clinicians deliver more objective, personalized treatments. While recent work has convincingly demonstrated that seizure risk assessment is possible, these early approaches relied largely on complex, often invasive setups including intracranial electrocorticography, implanted devices and multi-channel EEG, which limits translation of these methods to broad clinical application. To facilitate broader adaptation of seizure forecasting in clinical practice, non-invasive, easily applicable techniques that reliably assess seizure risk, in combination with clinical information, are crucial. Wristbands that continuously record physiological parameters, including electrodermal activity, body temperature, blood volume pressure and actigraphy, may afford monitoring of autonomous nervous system function and movement relevant for such a task, hence minimizing potential complications associated with invasive monitoring, and avoiding stigma associated with bulky external monitoring devices on the head. Here, we use deep learning to analyze long-term, multi-modal wristband sensor data from 50 patients with epilepsy (total duration $>$1400 hours) to assess its capability to distinguish preictal from interictal states. Prediction performance is assessed using area under the receiver operating charateristic (AUC) and improvement over chance (IoC) based on F1 scores. Using one- and two-dimensional convolutional neural networks, we identified better-than-chance predictability in out-of-sample test data in 60\% of the patients in leave-one-out and 43\% of patients in pseudo-prospective approaches. These results provide a step towards developing easier to apply, non-invasive methods for seizure risk assessments in patients with epilepsy.|
|**2019-03-28**|**A Generic Algorithm for Sleep-Wake Cycle Detection using Unlabeled Actigraphy Data**|Shanshan Chen et.al.|[1904.05313v1](http://arxiv.org/abs/1904.05313v1)|null|One key component when analyzing actigraphy data for sleep studies is sleep-wake cycle detection. Most detection algorithms rely on accurate sleep diary labels to generate supervised classifiers, with parameters optimized for a particular dataset. However, once the actigraphy trackers are deployed in the field, labels for training models and validating detection accuracy are often not available.   In this paper, we propose a generic, training-free algorithm to detect sleep-wake cycles from minute-by-minute actigraphy. Leveraging a robust nonlinear parametric model, our proposed method refines the detection region by searching for a single change point within bounded regions defined by the parametric model. Challenged by the absence of ground truth labels, we also propose an evaluation metric dedicated to this problem. Tested on week-long actigraphy from 112 children, the results show that the proposed algorithm improves on the baseline model consistently and significantly (p<3e-15). Moreover, focusing on the commonality in human circadian rhythm captured by actigraphy, the proposed method is generic to data collected by various actigraphy trackers, circumventing the laborious label collection step in developing customized classifiers for sleep detection.|
|**2019-02-10**|**Classifying attention deficit hyperactivity disorder in children with non-linearities in actigraphy**|Jeremi K. Ochab et.al.|[1902.03530v1](http://arxiv.org/abs/1902.03530v1)|null|Objective This study provides an objective measure based on actigraphy for Attention Deficit Hyperactivity Disorder (ADHD) diagnosis in children. We search for motor activity features that could allow further investigation into their association with other neurophysiological disordered traits.   Method The study involved $n=29$ (48 eligible) male participants aged $9.89\pm0.92$ years (8 controls, and 7 in each group: ADHD combined subtype, ADHD hyperactive-impulsive subtype, and autism spectrum disorder, ASD) wearing a wristwatch actigraph continuously for a week ($9\%$ losses in daily records) in two acquisition modes. We analyzed 47 quantities: from sleep duration or movement intensity to theory-driven scaling exponents or non-linear prediction errors of both diurnal and nocturnal activity. We used them in supervised classification to obtain cross-validated diagnostic performance.   Results We report the best performing measures, including a nearest neighbors 4-feature classifier providing $69.4\pm1.6\%$ accuracy, $78.0\pm2.2\%$ sensitivity and $60.8\pm2.6\%$ specificity in a binary ADHD vs control classification and $46.5\pm1.1\%$ accuracy (against $25\%$ baseline), $61.8\pm1.4\%$ sensitivity and $79.30 \pm0.43\%$ specificity in 4-class task (two ADHD subtypes, ASD, and control). The most informative feature is skewness of the shape of Zero Crossing Mode (ZCM) activity. Mean and standard deviation of nocturnal activity are among the least informative.   Conclusion Actigraphy causes only minor discomfort to the subjects and is inexpensive. The range of existing mathematical and machine learning tools also allow it to be a useful add-on test for ADHD or differential diagnosis between ADHD subtypes. The study was limited to a small, male sample without the inattentive ADHD subtype.|
|**2018-12-03**|**A Hidden Markov Model Based Unsupervised Algorithm for Sleep/Wake Identification Using Actigraphy**|Xinyue Li et.al.|[1812.00553v2](http://arxiv.org/abs/1812.00553v2)|null|Actigraphy is widely used in sleep studies but lacks a universal unsupervised algorithm for sleep/wake identification. In this study, we proposed a Hidden Markov Model (HMM) based unsupervised algorithm that can automatically and effectively infer sleep/wake states. It is an individualized data-driven approach that analyzes actigraphy from each individual respectively to learn activity characteristics and further separate sleep and wake states. We used Actiwatch and polysomnography (PSG) data from 43 individuals in the Multi-Ethnic Study of Atherosclerosis to evaluate the performance of our method. Epoch-by-epoch comparisons were made between our HMM algorithm and that embedded in the Actiwatch software (AS). The percent agreement between HMM and PSG was 85.7%, and that between AS and PSG was 84.7%. Positive predictive values for sleep epochs were 85.6% and 84.6% for HMM and AS, respectively, and 95.5% and 85.6% for wake epochs. Both methods have similar performance and tend to overestimate sleep and underestimate wake compared to PSG. Our HMM approach is able to quantify the variability in activity counts that allow us to differentiate relatively active and sedentary individuals: individuals with higher estimated variabilities tend to show more frequent sedentary behaviors. In conclusion, our unsupervised data-driven HMM algorithm achieves slightly better performance compared to the commonly used algorithm in the Actiwatch software. HMM can help expand the application of actigraphy in large-scale studies and in cases where intrusive PSG is hard to acquire or unavailable. In addition, the estimated HMM parameters can characterize individual activity patterns that can be utilized for further analysis.|
|**2018-08-20**|**Bayesian Function-on-Scalars Regression for High Dimensional Data**|Daniel R. Kowal et.al.|[1808.06689v2](http://arxiv.org/abs/1808.06689v2)|null|We develop a fully Bayesian framework for function-on-scalars regression with many predictors. The functional data response is modeled nonparametrically using unknown basis functions, which produces a flexible and data-adaptive functional basis. We incorporate shrinkage priors that effectively remove unimportant scalar covariates from the model and reduce sensitivity to the number of (unknown) basis functions. For variable selection in functional regression, we propose a decision theoretic posterior summarization technique, which identifies a subset of covariates that retains nearly the predictive accuracy of the full model. Our approach is broadly applicable for Bayesian functional regression models, and unlike existing methods provides joint rather than marginal selection of important predictor variables. Computationally scalable posterior inference is achieved using a Gibbs sampler with linear time complexity in the number of predictors. The resulting algorithm is empirically faster than existing frequentist and Bayesian techniques, and provides joint estimation of model parameters, prediction and imputation of functional trajectories, and uncertainty quantification via the posterior distribution. A simulation study demonstrates improvements in estimation accuracy, uncertainty quantification, and variable selection relative to existing alternatives. The methodology is applied to actigraphy data to investigate the association between intraday physical activity and responses to a sleep questionnaire.|
|**2018-04-25**|**The Intelligent ICU Pilot Study: Using Artificial Intelligence Technology for Autonomous Patient Monitoring**|Anis Davoudi et.al.|[1804.10201v2](http://arxiv.org/abs/1804.10201v2)|null|Currently, many critical care indices are repetitively assessed and recorded by overburdened nurses, e.g. physical function or facial pain expressions of nonverbal patients. In addition, many essential information on patients and their environment are not captured at all, or are captured in a non-granular manner, e.g. sleep disturbance factors such as bright light, loud background noise, or excessive visitations. In this pilot study, we examined the feasibility of using pervasive sensing technology and artificial intelligence for autonomous and granular monitoring of critically ill patients and their environment in the Intensive Care Unit (ICU). As an exemplar prevalent condition, we also characterized delirious and non-delirious patients and their environment. We used wearable sensors, light and sound sensors, and a high-resolution camera to collected data on patients and their environment. We analyzed collected data using deep learning and statistical analysis. Our system performed face detection, face recognition, facial action unit detection, head pose detection, facial expression recognition, posture recognition, actigraphy analysis, sound pressure and light level detection, and visitation frequency detection. We were able to detect patient's face (Mean average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their postures (F1=0.94). We also found that all facial expressions, 11 activity features, visitation frequency during the day, visitation frequency during the night, light levels, and sound pressure levels during the night were significantly different between delirious and non-delirious patients (p-value<0.05). In summary, we showed that granular and autonomous monitoring of critically ill patients and their environment is feasible and can be used for characterizing critical care conditions and related environment factors.|
|**2018-03-31**|**Continuous Circadian Phase Estimation Using Adaptive Notch Filter**|Wei Qiao et.al.|[1804.00115v1](http://arxiv.org/abs/1804.00115v1)|null|Actigraphy has been widely used for the analysis of circadian rhythm. Current practice applies regression analysis to data from multiple days to estimate the circadian phase. This paper presents a filtering method for online processing of biometric data to estimate the circadian phase. We apply the proposed method on actigraphy data of fruit flies (Drosophila melanogaster).|
|**2018-02-22**|**Actigraphy-based Sleep/Wake Pattern Detection using Convolutional Neural Networks**|Lena Granovsky et.al.|[1802.07945v1](http://arxiv.org/abs/1802.07945v1)|null|Common medical conditions are often associated with sleep abnormalities. Patients with medical disorders often suffer from poor sleep quality compared to healthy individuals, which in turn may worsen the symptoms of the disorder. Accurate detection of sleep/wake patterns is important in developing personalized digital markers, which can be used for objective measurements and efficient disease management. Big Data technologies and advanced analytics methods hold the promise to revolutionize clinical research processes, enabling the effective blending of digital data into clinical trials. Actigraphy, a non-invasive activity monitoring method is heavily used to detect and evaluate activities and movement disorders, and assess sleep/wake behavior. In order to study the connection between sleep/wake patterns and a cluster headache disorder, activity data was collected using a wearable device in the course of a clinical trial. This study presents two novel modeling schemes that utilize Deep Convolutional Neural Networks (CNN) to identify sleep/wake states. The proposed methods are a sequential CNN, reminiscent of the bi-directional CNN for slot filling, and a Multi-Task Learning (MTL) based model. Furthermore, we expand standard "Sleep" and "Wake" activity states space by adding the "Falling asleep" and "Siesta" states. We show that the proposed methods provide promising results in accurate detection of the expanded sleep/wake states. Finally, we explore the relations between the detected sleep/wake patterns and onset of cluster headache attacks, and present preliminary observations.|
|**2017-12-27**|**Co-Morbidity Exploration on Wearables Activity Data Using Unsupervised Pre-training and Multi-Task Learning**|Karan Aggarwal et.al.|[1712.09527v1](http://arxiv.org/abs/1712.09527v1)|null|Physical activity and sleep play a major role in the prevention and management of many chronic conditions. It is not a trivial task to understand their impact on chronic conditions. Currently, data from electronic health records (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid increase in the popularity of wearable health devices provides a significant new data source, making it possible to track the user's lifestyle real-time through web interfaces, both to consumer as well as their healthcare provider, potentially. However, at present there is a gap between lifestyle data (e.g., sleep, physical activity) and clinical outcomes normally captured in EHRs. This is a critical barrier for the use of this new source of signal for healthcare decision making. Applying deep learning to wearables data provides a new opportunity to overcome this barrier.   To address the problem of the unavailability of clinical data from a major fraction of subjects and unrepresentative subject populations, we propose a novel unsupervised (task-agnostic) time-series representation learning technique called act2vec. act2vec learns useful features by taking into account the co-occurrence of activity levels along with periodicity of human activity patterns. The learned representations are then exploited to boost the performance of disorder-specific supervised learning models. Furthermore, since many disorders are often related to each other, a phenomenon referred to as co-morbidity, we use a multi-task learning framework for exploiting the shared structure of disorder inducing life-style choices partially captured in the wearables data. Empirical evaluation using actigraphy data from 4,124 subjects shows that our proposed method performs and generalizes substantially better than the conventional time-series symbolic representational methods and task-specific deep learning models.|
|**2017-12-18**|**Activity and Circadian Rhythm of Sepsis Patients in the Intensive Care Unit**|Anis Davoudi et.al.|[1712.06631v1](http://arxiv.org/abs/1712.06631v1)|null|Early mobilization of critically ill patients in the Intensive Care Unit (ICU) can prevent adverse outcomes such as delirium and post-discharge physical impairment. To date, no studies have characterized activity of sepsis patients in the ICU using granular actigraphy data. This study characterizes the activity of sepsis patients in the ICU to aid in future mobility interventions. We have compared the actigraphy features of 24 patients in four groups: Chronic Critical Illness (CCI) sepsis patients in the ICU, Rapid Recovery (RR) sepsis patients in the ICU, non-sepsis ICU patients (control-ICU), and healthy subjects. We used several statistical and circadian rhythm features extracted from the patients' actigraphy data collected over a five-day period. Our results show that the four groups are significantly different in terms of activity features. In addition, we observed that the CCI and control-ICU patients show less regularity in their circadian rhythm compared to the RR patients. These results show the potential of using actigraphy data for guiding mobilization practices, classifying sepsis recovery subtype, as well as for tracking patients' recovery.|
|**2017-11-02**|**Sleep Stage Classification Based on Multi-level Feature Learning and Recurrent Neural Networks via Wearable Device**|Xin Zhang et.al.|[1711.00629v1](http://arxiv.org/abs/1711.00629v1)|null|This paper proposes a practical approach for automatic sleep stage classification based on a multi-level feature learning framework and Recurrent Neural Network (RNN) classifier using heart rate and wrist actigraphy derived from a wearable device. The feature learning framework is designed to extract low- and mid-level features. Low-level features capture temporal and frequency domain properties and mid-level features learn compositions and structural information of signals. Since sleep staging is a sequential problem with long-term dependencies, we take advantage of RNNs with Bidirectional Long Short-Term Memory (BLSTM) architectures for sequence data learning. To simulate the actual situation of daily sleep, experiments are conducted with a resting group in which sleep is recorded in resting state, and a comprehensive group in which both resting sleep and non-resting sleep are included.We evaluate the algorithm based on an eight-fold cross validation to classify five sleep stages (W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision, recall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%, 61.1%, and 58.5% in the comprehensive group, respectively. Various comparison experiments demonstrate the effectiveness of feature learning and BLSTM. We further explore the influence of depth and width of RNNs on performance. Our method is specially proposed for wearable devices and is expected to be applicable for long-term sleep monitoring at home. Without using too much prior domain knowledge, our method has the potential to generalize sleep disorder detection.|
|**2017-05-10**|**Visualization of Wearable Data and Biometrics for Analysis and Recommendations in Childhood Obesity**|Michael Aupetit et.al.|[1705.03691v1](http://arxiv.org/abs/1705.03691v1)|null|Obesity is one of the major health risk factors be- hind the rise of non-communicable conditions. Understanding the factors influencing obesity is very complex since there are many variables that can affect the health behaviors leading to it. Nowadays, multiple data sources can be used to study health behaviors, such as wearable sensors for physical activity and sleep, social media, mobile and health data. In this paper we describe the design of a dashboard for the visualization of actigraphy and biometric data from a childhood obesity camp in Qatar. This dashboard allows quantitative discoveries that can be used to guide patient behavior and orient qualitative research.|
|**2017-02-13**|**On multifractals: a non-linear study of actigraphy data**|Lucas Gabriel Souza França et.al.|[1702.03912v2](http://arxiv.org/abs/1702.03912v2)|[link](https://github.com/lucasfr/actiMF)|This work aimed, to determine the characteristics of activity series from fractal geometry concepts application, in addition to evaluate the possibility of identifying individuals with fibromyalgia. Activity level data were collected from 27 healthy subjects and 27 fibromyalgia patients, with the use of clock-like devices equipped with accelerometers, for about four weeks, all day long. The activity series were evaluated through fractal and multifractal methods. Hurst exponent analysis exhibited values according to other studies ($H>0.5$) for both groups ($H=0.98\pm0.04$ for healthy subjects and $H=0.97\pm0.03$ for fibromyalgia patients), however, it is not possible to distinguish between the two groups by such analysis. Activity time series also exhibited a multifractal pattern. A paired analysis of the spectra indices for the sleep and awake states revealed differences between healthy subjects and fibromyalgia patients. The individuals feature differences between awake and sleep states, having statistically significant differences for $\alpha_{q-} - \alpha_{0}$ in healthy subjects ($p = 0.014$) and $D_{0}$ for patients with fibromyalgia ($p = 0.013$). The approach has proven to be an option on the characterisation of such kind of signals and was able to differ between both healthy and fibromyalgia groups. This outcome suggests changes in the physiologic mechanisms of movement control.|
|**2016-09-12**|**Hearables: Multimodal physiological in-ear sensing**|Valentin Goverdovsky et.al.|[1609.03330v2](http://arxiv.org/abs/1609.03330v2)|null|Future health systems require the means to assess and track the neural and physiological function of a user over long periods of time and in the community. Human body responses are manifested through multiple modalities, such as the mechanical, electrical and chemical; yet current physiological monitors (actigraphy, heart rate) largely lack in both the desired cross-modal and non-stigmatizing aspects. We address these challenges through an inconspicuous and comfortable earpiece, equipped with miniature multimodal sensors, which benefits from the relatively stable position of the ear canal with respect to vital organs to robustly measure the brain, cardiac and respiratory functions. Comprehensive experiments validate each modality within the proposed earpiece, while its potential in health monitoring is illustrated through case studies. We further demonstrate how combining data from multiple sensors within such an integrated wearable device improves both the accuracy of measurements and the ability to deal with artifacts in real-life scenarios.|
|**2016-07-30**|**Learning Tree-Structured Detection Cascades for Heterogeneous Networks of Embedded Devices**|Hamid Dadkhahi et.al.|[1608.00159v4](http://arxiv.org/abs/1608.00159v4)|null|In this paper, we present a new approach to learning cascaded classifiers for use in computing environments that involve networks of heterogeneous and resource-constrained, low-power embedded compute and sensing nodes. We present a generalization of the classical linear detection cascade to the case of tree-structured cascades where different branches of the tree execute on different physical compute nodes in the network. Different nodes have access to different features, as well as access to potentially different computation and energy resources. We concentrate on the problem of jointly learning the parameters for all of the classifiers in the cascade given a fixed cascade architecture and a known set of costs required to carry out the computation at each node.To accomplish the objective of joint learning of all detectors, we propose a novel approach to combining classifier outputs during training that better matches the hard cascade setting in which the learned system will be deployed. This work is motivated by research in the area of mobile health where energy efficient real time detectors integrating information from multiple wireless on-body sensors and a smart phone are needed for real-time monitoring and delivering just- in-time adaptive interventions. We apply our framework to two activity recognition datasets as well as the problem of cigarette smoking detection from a combination of wrist-worn actigraphy data and respiration chest band data.|
|**2016-07-24**|**Impact of Physical Activity on Sleep:A Deep Learning Based Exploration**|Aarti Sathyanarayana et.al.|[1607.07034v1](http://arxiv.org/abs/1607.07034v1)|null|The importance of sleep is paramount for maintaining physical, emotional and mental wellbeing. Though the relationship between sleep and physical activity is known to be important, it is not yet fully understood. The explosion in popularity of actigraphy and wearable devices, provides a unique opportunity to understand this relationship. Leveraging this information source requires new tools to be developed to facilitate data-driven research for sleep and activity patient-recommendations.   In this paper we explore the use of deep learning to build sleep quality prediction models based on actigraphy data. We first use deep learning as a pure model building device by performing human activity recognition (HAR) on raw sensor data, and using deep learning to build sleep prediction models. We compare the deep learning models with those build using classical approaches, i.e. logistic regression, support vector machines, random forest and adaboost. Secondly, we employ the advantage of deep learning with its ability to handle high dimensional datasets. We explore several deep learning models on the raw wearable sensor output without performing HAR or any other feature extraction.   Our results show that using a convolutional neural network on the raw wearables output improves the predictive value of sleep quality from physical activity, by an additional 8% compared to state-of-the-art non-deep learning approaches, which itself shows a 15% improvement over current practice. Moreover, utilizing deep learning on raw data eliminates the need for data pre-processing and simplifies the overall workflow to analyze actigraphy data for sleep and physical activity research.|
|**2016-07-13**|**Learning Shallow Detection Cascades for Wearable Sensor-Based Mobile Health Applications**|Hamid Dadkhahi et.al.|[1607.03730v1](http://arxiv.org/abs/1607.03730v1)|null|The field of mobile health aims to leverage recent advances in wearable on-body sensing technology and smart phone computing capabilities to develop systems that can monitor health states and deliver just-in-time adaptive interventions. However, existing work has largely focused on analyzing collected data in the off-line setting. In this paper, we propose a novel approach to learning shallow detection cascades developed explicitly for use in a real-time wearable-phone or wearable-phone-cloud systems. We apply our approach to the problem of cigarette smoking detection from a combination of wrist-worn actigraphy data and respiration chest band data using two and three stage cascades.|

## huawei

### huawei watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-20**|**MRFI: An Open Source Multi-Resolution Fault Injection Framework for Neural Network Processing**|Haitong Huang et.al.|[2306.11758v1](http://arxiv.org/abs/2306.11758v1)|[link](https://github.com/fffasttime/mrfi)|To ensure resilient neural network processing on even unreliable hardware, comprehensive reliability analysis against various hardware faults is generally required before the deep neural network models are deployed, and efficient error injection tools are highly demanded. However, most existing fault injection tools remain rather limited to basic fault injection to neurons and fail to provide fine-grained vulnerability analysis capability. In addition, many of the fault injection tools still need to change the neural network models and make the fault injection closely coupled with normal neural network processing, which further complicates the use of the fault injection tools and slows down the fault simulation. In this work, we propose MRFI, a highly configurable multi-resolution fault injection tool for deep neural networks. It enables users to modify an independent fault configuration file rather than neural network models for the fault injection and vulnerability analysis. Particularly, it integrates extensive fault analysis functionalities from different perspectives and enables multi-resolution investigation of the vulnerability of neural networks. In addition, it does not modify the major neural network computing framework of PyTorch. Hence, it allows parallel processing on GPUs naturally and exhibits fast fault simulation according to our experiments.|
|**2023-06-19**|**SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces**|Ziqiao Peng et.al.|[2306.10799v1](http://arxiv.org/abs/2306.10799v1)|null|Speech-driven 3D face animation technique, extending its applications to various multimedia fields. Previous research has generated promising realistic lip movements and facial expressions from audio signals. However, traditional regression models solely driven by data face several essential problems, such as difficulties in accessing precise labels and domain gaps between different modalities, leading to unsatisfactory results lacking precision and coherence. To enhance the visual accuracy of generated lip movement while reducing the dependence on labeled data, we propose a novel framework SelfTalk, by involving self-supervision in a cross-modals network system to learn 3D talking faces. The framework constructs a network system consisting of three modules: facial animator, speech recognizer, and lip-reading interpreter. The core of SelfTalk is a commutative training diagram that facilitates compatible features exchange among audio, text, and lip shape, enabling our models to learn the intricate connection between these factors. The proposed framework leverages the knowledge learned from the lip-reading interpreter to generate more plausible lip shapes. Extensive experiments and user studies demonstrate that our proposed approach achieves state-of-the-art performance both qualitatively and quantitatively. We recommend watching the supplementary video.|
|**2023-06-17**|**Enhancing the Prediction of Emotional Experience in Movies using Deep Neural Networks: The Significance of Audio and Language**|Sogand Mehrpour Mohammadi et.al.|[2306.10397v1](http://arxiv.org/abs/2306.10397v1)|null|Our paper focuses on making use of deep neural network models to accurately predict the range of human emotions experienced during watching movies. In this certain setup, there exist three clear-cut input modalities that considerably influence the experienced emotions: visual cues derived from RGB video frames, auditory components encompassing sounds, speech, and music, and linguistic elements encompassing actors' dialogues. Emotions are commonly described using a two-factor model including valence (ranging from happy to sad) and arousal (indicating the intensity of the emotion). In this regard, a Plethora of works have presented a multitude of models aiming to predict valence and arousal from video content. However, non of these models contain all three modalities, with language being consistently eliminated across all of them. In this study, we comprehensively combine all modalities and conduct an analysis to ascertain the importance of each in predicting valence and arousal. Making use of pre-trained neural networks, we represent each input modality in our study. In order to process visual input, we employ pre-trained convolutional neural networks to recognize scenes[1], objects[2], and actions[3,4]. For audio processing, we utilize a specialized neural network designed for handling sound-related tasks, namely SoundNet[5]. Finally, Bidirectional Encoder Representations from Transformers (BERT) models are used to extract linguistic features[6] in our analysis. We report results on the COGNIMUSE dataset[7], where our proposed model outperforms the current state-of-the-art approaches. Surprisingly, our findings reveal that language significantly influences the experienced arousal, while sound emerges as the primary determinant for predicting valence. In contrast, the visual modality exhibits the least impact among all modalities in predicting emotions.|
|**2023-06-16**|**Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian Optimization**|Kamil Dreczkowski et.al.|[2306.09803v1](http://arxiv.org/abs/2306.09803v1)|[link](https://github.com/huawei-noah/hebo)|This paper introduces a modular framework for Mixed-variable and Combinatorial Bayesian Optimization (MCBO) to address the lack of systematic benchmarking and standardized evaluation in the field. Current MCBO papers often introduce non-diverse or non-standard benchmarks to evaluate their methods, impeding the proper assessment of different MCBO primitives and their combinations. Additionally, papers introducing a solution for a single MCBO primitive often omit benchmarking against baselines that utilize the same methods for the remaining primitives. This omission is primarily due to the significant implementation overhead involved, resulting in a lack of controlled assessments and an inability to showcase the merits of a contribution effectively. To overcome these challenges, our proposed framework enables an effortless combination of Bayesian Optimization components, and provides a diverse set of synthetic and real-world benchmarking tasks. Leveraging this flexibility, we implement 47 novel MCBO algorithms and benchmark them against seven existing MCBO solvers and five standard black-box optimization algorithms on ten tasks, conducting over 4000 experiments. Our findings reveal a superior combination of MCBO primitives outperforming existing approaches and illustrate the significance of model fit and the use of a trust region. We make our MCBO library available under the MIT license at \url{https://github.com/huawei-noah/HEBO/tree/master/MCBO}.|
|**2023-06-14**|**A pose and shear-based tactile robotic system for object tracking, surface following and object pushing**|John Lloyd et.al.|[2306.08560v1](http://arxiv.org/abs/2306.08560v1)|null|Tactile perception is a crucial sensing modality in robotics, particularly in scenarios that require precise manipulation and safe interaction with other objects. Previous research in this area has focused extensively on tactile perception of contact poses as this is an important capability needed for tasks such as traversing an object's surface or edge, manipulating an object, or pushing an object along a predetermined path. Another important capability needed for tasks such as object tracking and manipulation is estimation of post-contact shear but this has received much less attention. Indeed, post-contact shear has often been considered a "nuisance variable" and is removed if possible because it can have an adverse effect on other types of tactile perception such as contact pose estimation. This paper proposes a tactile robotic system that can simultaneously estimate both the contact pose and post-contact shear, and use this information to control its interaction with other objects. Moreover, our new system is capable of interacting with other objects in a smooth and continuous manner, unlike the stepwise, position-controlled systems we have used in the past. We demonstrate the capabilities of our new system using several different controller configurations, on tasks including object tracking, surface following, single-arm object pushing, and dual-arm object pushing.|
|**2023-06-11**|**Characterizing the effect of retractions on scientific careers**|Shahan Ali Memon et.al.|[2306.06710v1](http://arxiv.org/abs/2306.06710v1)|[link](https://github.com/samemon/retraction_effects_on_academic_careers)|Retracting academic papers is a fundamental tool of quality control when the validity of papers or the integrity of authors is questioned post-publication. While retractions do not completely eliminate papers from the record, they have far-reaching consequences for retracted authors and their careers, serving as a visible and permanent signal of potential transgressions. Previous studies have highlighted the adverse effects of retractions on citation counts and co-authors' citations; however, the underlying mechanisms driving these effects and the broader impacts beyond these traditional metrics have not been fully explored. We address this gap leveraging Retraction Watch, the most extensive data set on retractions and link it to Microsoft Academic Graph, a comprehensive data set of scientific publications and their citation networks, and Altmetric that monitors online attention to scientific output. Our investigation focuses on: 1) the likelihood of authors exiting scientific publishing following retraction, and 2) the evolution of collaboration networks among authors who continue publishing after retraction. Our empirical analysis reveals that retracted authors, particularly those with less experience, tend to leave scientific publishing in the aftermath of retraction, particularly if their retractions attract widespread attention. Furthermore, we uncover a pattern whereby retracted authors who remain active in publishing tend to maintain and establish more collaborations compared to their similar non-retracted counterparts. Taken together, notwithstanding the indispensable role of retractions in upholding the integrity of the academic community, our findings shed light on the disproportionate impact that retractions impose on early-career researchers as opposed to those with more established careers.|
|**2023-06-10**|**The Weight Distributions of Two Classes of Linear Codes From Perfect Nonlinear Functions**|Huawei Wu et.al.|[2306.06422v1](http://arxiv.org/abs/2306.06422v1)|null|In this paper, all the possibilities for the value distribution of a perfect nonlinear function from $\mathbb{F}_{p^m}$ to $\mathbb{F}_p$ are determined, where $p$ is an odd prime number and $m\in\mathbb{N}_+$. As an application, we determine the weight distributions of two classes of linear codes over $\mathbb{F}_p$ constructed from perfect nonlinear functions.|
|**2023-06-09**|**Digital Twin-Assisted Resource Demand Prediction for Multicast Short Video Streaming**|Xinyu Huang et.al.|[2306.05946v1](http://arxiv.org/abs/2306.05946v1)|null|In this paper, we propose a digital twin (DT)-assisted resource demand prediction scheme to enhance prediction accuracy for multicast short video streaming. Particularly, we construct user DTs (UDTs) for collecting real-time user status, including channel condition, location, watching duration, and preference. A reinforcement learning-empowered K-means++ algorithm is developed to cluster users based on the collected user status in UDTs, which can effectively employ the mined users' intrinsic correlation to improve the accuracy of user clustering. We then analyze users' video watching duration and preferences in each multicast group to obtain the swiping probability distribution and recommended videos, respectively. The obtained information is utilized to predict radio and computing resource demand of each multicast group. Initial results demonstrate that the proposed scheme can effectively abstract multicast groups' swiping probability distributions for accurate resource demand prediction.|
|**2023-06-09**|**Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots**|Jiange Yang et.al.|[2306.05716v1](http://arxiv.org/abs/2306.05716v1)|null|Improving the generalization capabilities of general-purpose robotic agents has long been a significant challenge actively pursued by research communities. Existing approaches often rely on collecting large-scale real-world robotic data, such as the RT-1 dataset. However, these approaches typically suffer from low efficiency, limiting their capability in open-domain scenarios with new objects, and diverse backgrounds. In this paper, we propose a novel paradigm that effectively leverages language-grounded segmentation masks generated by state-of-the-art foundation models, to address a wide range of pick-and-place robot manipulation tasks in everyday scenarios. By integrating precise semantics and geometries conveyed from masks into our multi-view policy model, our approach can perceive accurate object poses and enable sample-efficient learning. Besides, such design facilitates effective generalization for grasping new objects with similar shapes observed during training. Our approach consists of two distinct steps. First, we introduce a series of foundation models to accurately ground natural language demands across multiple tasks. Second, we develop a Multi-modal Multi-view Policy Model that incorporates inputs such as RGB images, semantic masks, and robot proprioception states to jointly predict precise and executable robot actions. Extensive real-world experiments conducted on a Franka Emika robot arm validate the effectiveness of our proposed paradigm. Real-world demos are shown in YouTube (https://www.youtube.com/watch?v=1m9wNzfp_4E ) and Bilibili (https://www.bilibili.com/video/BV178411Z7H2/ ).|
|**2023-06-06**|**Minimizing Hitting Time between Disparate Groups with Shortcut Edges**|Florian Adriaens et.al.|[2306.03571v2](http://arxiv.org/abs/2306.03571v2)|null|Structural bias or segregation of networks refers to situations where two or more disparate groups are present in the network, so that the groups are highly connected internally, but loosely connected to each other. In many cases it is of interest to increase the connectivity of disparate groups so as to, e.g., minimize social friction, or expose individuals to diverse viewpoints. A commonly-used mechanism for increasing the network connectivity is to add edge shortcuts between pairs of nodes. In many applications of interest, edge shortcuts typically translate to recommendations, e.g., what video to watch, or what news article to read next. The problem of reducing structural bias or segregation via edge shortcuts has recently been studied in the literature, and random walks have been an essential tool for modeling navigation and connectivity in the underlying networks. Existing methods, however, either do not offer approximation guarantees, or engineer the objective so that it satisfies certain desirable properties that simplify the optimization~task. In this paper we address the problem of adding a given number of shortcut edges in the network so as to directly minimize the average hitting time and the maximum hitting time between two disparate groups. Our algorithm for minimizing average hitting time is a greedy bicriteria that relies on supermodularity. In contrast, maximum hitting time is not supermodular. Despite, we develop an approximation algorithm for that objective as well, by leveraging connections with average hitting time and the asymmetric k-center problem.|
|**2023-06-06**|**Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation**|Xiao Lin et.al.|[2306.03392v1](http://arxiv.org/abs/2306.03392v1)|null|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|
|**2023-06-01**|**GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception Tasks?**|Ning Ding et.al.|[2306.00693v2](http://arxiv.org/abs/2306.00693v2)|[link](https://github.com/huawei-noah/Efficient-Computing)|The recent upsurge in pre-trained large models (e.g. GPT-4) has swept across the entire deep learning community. Such powerful large language models (LLMs) demonstrate advanced generative ability and multimodal understanding capability, which quickly achieve new state-of-the-art performances on a variety of benchmarks. The pre-trained LLM usually plays the role as a universal AI model that can conduct various tasks, including context reasoning, article analysis and image content comprehension. However, considering the prohibitively high memory and computational cost for implementing such a large model, the conventional models (such as CNN and ViT), are still essential for many visual perception tasks. In this paper, we propose to enhance the representation ability of ordinary vision models for perception tasks (e.g. image classification) by taking advantage of large pre-trained models. We present a new learning paradigm in which the knowledge extracted from large pre-trained models are utilized to help models like CNN and ViT learn enhanced representations and achieve better performance. Firstly, we curate a high quality description set by prompting a multimodal LLM to generate descriptive text for all training images. Furthermore, we feed these detailed descriptions into a pre-trained encoder to extract text embeddings with rich semantic information that encodes the content of images. During training, text embeddings will serve as extra supervising signals and be aligned with image representations learned by vision models. The alignment process helps vision models learn better and achieve higher accuracy with the assistance of pre-trained LLMs. We conduct extensive experiments to verify that the proposed algorithm consistently improves the performance for various vision models with heterogeneous architectures.|
|**2023-06-01**|**MindBigData 2023 MNIST-8B The 8 billion datapoints Multimodal Dataset of Brain Signals**|David Vivancos et.al.|[2306.00455v1](http://arxiv.org/abs/2306.00455v1)|null|MindBigData 2023 MNIST-8B is the largest, to date (June 1st 2023), brain signals open dataset created for Machine Learning, based on EEG signals from a single subject captured using a custom 128 channels device, replicating the full 70,000 digits from Yaan LeCun et all MNIST dataset. The brain signals were captured while the subject was watching the pixels of the original digits one by one on a screen and listening at the same time to the spoken number 0 to 9 from the real label. The data, collection procedures, hardware and software created are described in detail, background extra information and other related datasets can be found at our previous paper MindBigData 2022: A Large Dataset of Brain Signals.|
|**2023-06-01**|**BiSync: A Bilingual Editor for Synchronized Monolingual Texts**|Josep Crego et.al.|[2306.00400v1](http://arxiv.org/abs/2306.00400v1)|[link](https://github.com/jmcrego/bisync)|In our globalized world, a growing number of situations arise where people are required to communicate in one or several foreign languages. In the case of written communication, users with a good command of a foreign language may find assistance from computer-aided translation (CAT) technologies. These technologies often allow users to access external resources, such as dictionaries, terminologies or bilingual concordancers, thereby interrupting and considerably hindering the writing process. In addition, CAT systems assume that the source sentence is fixed and also restrict the possible changes on the target side. In order to make the writing process smoother, we present BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. We also include additional functionalities, such as the display of alternative prefix translations and paraphrases, which are intended to facilitate the authoring of texts. We detail the model architecture used for synchronization and evaluate the resulting tool, showing that high accuracy can be attained with limited computational resources. The interface and models are publicly available at https://github.com/jmcrego/BiSync and a demonstration video can be watched on YouTube at https://youtu.be/_l-ugDHfNgU .|
|**2023-06-01**|**Example-based Motion Synthesis via Generative Motion Matching**|Weiyu Li et.al.|[2306.00378v1](http://arxiv.org/abs/2306.00378v1)|null|We present GenMM, a generative model that "mines" as many diverse motions as possible from a single or few example sequences. In stark contrast to existing data-driven methods, which typically require long offline training time, are prone to visual artifacts, and tend to fail on large and complex skeletons, GenMM inherits the training-free nature and the superior quality of the well-known Motion Matching method. GenMM can synthesize a high-quality motion within a fraction of a second, even with highly complex and large skeletal structures. At the heart of our generative framework lies the generative motion matching module, which utilizes the bidirectional visual similarity as a generative cost function to motion matching, and operates in a multi-stage framework to progressively refine a random guess using exemplar motion matches. In addition to diverse motion generation, we show the versatility of our generative framework by extending it to a number of scenarios that are not possible with motion matching alone, including motion completion, key frame-guided generation, infinite looping, and motion reassembly. Code and data for this paper are at https://wyysf-98.github.io/GenMM/|
|**2023-05-31**|**ReDSEa: Automated Acceleration of Triangular Solver on Supercloud Heterogeneous Systems**|Georgios Zacharopoulos et.al.|[2305.19917v1](http://arxiv.org/abs/2305.19917v1)|null|When utilized effectively, Supercloud heterogeneous systems have the potential to significantly enhance performance. Our ReDSEa tool-chain automates the mapping, load balancing, scheduling, parallelism, and overlapping processes for the Triangular System Solver (TS) on a heterogeneous system consisting of a Huawei Kunpeng ARM multi-core CPU and an Ascend 910 AI HW accelerator. We propose an LLVM compiler tool-chain that a) leverages compiler analysis and b) utilizes novel performance models exploring recursive, iterative, and blocked computation models. Our tool-chain facilitates a speedup of up to 16x compared to an optimized 48-core CPU-only implementation.|
|**2023-05-31**|**Few-Shot Speaker Identification Using Lightweight Prototypical Network with Feature Grouping and Interaction**|Yanxiong Li et.al.|[2305.19541v1](http://arxiv.org/abs/2305.19541v1)|null|Existing methods for few-shot speaker identification (FSSI) obtain high accuracy, but their computational complexities and model sizes need to be reduced for lightweight applications. In this work, we propose a FSSI method using a lightweight prototypical network with the final goal to implement the FSSI on intelligent terminals with limited resources, such as smart watches and smart speakers. In the proposed prototypical network, an embedding module is designed to perform feature grouping for reducing the memory requirement and computational complexity, and feature interaction for enhancing the representational ability of the learned speaker embedding. In the proposed embedding module, audio feature of each speech sample is split into several low-dimensional feature subsets that are transformed by a recurrent convolutional block in parallel. Then, the operations of averaging, addition, concatenation, element-wise summation and statistics pooling are sequentially executed to learn a speaker embedding for each speech sample. The recurrent convolutional block consists of a block of bidirectional long short-term memory, and a block of de-redundancy convolution in which feature grouping and interaction are conducted too. Our method is compared to baseline methods on three datasets that are selected from three public speech corpora (VoxCeleb1, VoxCeleb2, and LibriSpeech). The results show that our method obtains higher accuracy under several conditions, and has advantages over all baseline methods in computational complexity and model size.|
|**2023-05-30**|**AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation**|Chuhao Jin et.al.|[2305.18898v1](http://arxiv.org/abs/2305.18898v1)|null|We propose a novel framework for learning high-level cognitive capabilities in robot manipulation tasks, such as making a smiley face using building blocks. These tasks often involve complex multi-step reasoning, presenting significant challenges due to the limited paired data connecting human instructions (e.g., making a smiley face) and robot actions (e.g., end-effector movement). Existing approaches relieve this challenge by adopting an open-loop paradigm decomposing high-level instructions into simple sub-task plans, and executing them step-by-step using low-level control models. However, these approaches are short of instant observations in multi-step reasoning, leading to sub-optimal results. To address this issue, we propose to automatically collect a cognitive robot dataset by Large Language Models (LLMs). The resulting dataset AlphaBlock consists of 35 comprehensive high-level tasks of multi-step text plans and paired observation sequences. To enable efficient data acquisition, we employ elaborated multi-round prompt designs that effectively reduce the burden of extensive human involvement. We further propose a closed-loop multi-modal embodied planning model that autoregressively generates plans by taking image observations as input. To facilitate effective learning, we leverage MiniGPT-4 with a frozen visual encoder and LLM, and finetune additional vision adapter and Q-former to enable fine-grained spatial perception for manipulation tasks. We conduct experiments to verify the superiority over existing open and closed-loop methods, and achieve a significant increase in success rate by 21.4% and 14.5% over ChatGPT and GPT-4 based robot tasks. Real-world demos are shown in https://www.youtube.com/watch?v=ayAzID1_qQk .|
|**2023-05-29**|**minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts, Transitivities, and Lattices**|Animesh Chaturvedi et.al.|[2305.17984v1](http://arxiv.org/abs/2305.17984v1)|null|Hate speech classification has become an important problem due to the spread of hate speech on social media platforms. For a given set of Hate Terms lists (HTs-lists) and Hate Speech data (HS-data), it is challenging to understand which hate term contributes the most for hate speech classification. This paper contributes two approaches to quantitatively measure and qualitatively visualise the relationship between co-occurring Hate Terms (HTs). Firstly, we propose an approach for the classification of hate-speech by producing a Severe Hate Terms list (Severe HTs-list) from existing HTs-lists. To achieve our goal, we proposed three metrics (Hatefulness, Relativeness, and Offensiveness) to measure the severity of HTs. These metrics assist to create an Inter-agreement HTs-list, which explains the contribution of an individual hate term toward hate speech classification. Then, we used the Offensiveness metric values of HTs above a proposed threshold minimum Offense (minOffense) to generate a new Severe HTs-list. To evaluate our approach, we used three hate speech datasets and six hate terms lists. Our approach shown an improvement from 0.845 to 0.923 (best) as compared to the baseline. Secondly, we also proposed Stable Hate Rule (SHR) mining to provide ordered co-occurrence of various HTs with minimum Stability (minStab). The SHR mining detects frequently co-occurring HTs to form Stable Hate Rules and Concepts. These rules and concepts are used to visualise the graphs of Transitivities and Lattices formed by HTs.|
|**2023-05-29**|**Bayesian feedback in the framework of ecological sciences**|Mario Figueira-Pereira et.al.|[2305.17922v1](http://arxiv.org/abs/2305.17922v1)|null|In ecology we may find scenarios where the same phenomenon (species occurrence, species abundance, etc.) is observed using two different types of samplers. For instance, species data can be collected from scientific surveys with a completely random sample pattern, but also from opportunistic sampling (e.g., whale or bird watching fishery commercial vessels), in which observers tend to look for a specific species in areas where they expect to find it.   Species Distribution Models (SDMs) are a widely used tool for analyzing this kind of ecological data. Specifically, we have two models available for the above data: an independent model (IM) for the data coming from a complete random sampler and a dependent model (DM) for data from opportunistic sampling.   In this work, we propose a sequential Bayesian procedure to connect these two models through the update of prior distributions. Implementation of the Bayesian paradigm is done through the integrated nested Laplace approximation (INLA) methodology, a good option to make inference and prediction in spatial models with high performance and low computational costs. This sequential approach has been evaluated by simulating several scenarios and comparing the results of sharing information from one model to another using different criteria.   Our main results imply that, in general, it is better to share information from the independent (completely random) to the dependent model than the alternative way. However, it depends on different factors such as the spatial range or the spatial arrangement of sampling locations.|
|**2023-05-26**|**DES Y3 + KiDS-1000: Consistent cosmology combining cosmic shear surveys**|Dark Energy Survey et.al.|[2305.17173v1](http://arxiv.org/abs/2305.17173v1)|null|We present a joint cosmic shear analysis of the Dark Energy Survey (DES Y3) and the Kilo-Degree Survey (KiDS-1000) in a collaborative effort between the two survey teams. We find consistent cosmological parameter constraints between DES Y3 and KiDS-1000 which, when combined in a joint-survey analysis, constrain the parameter $S_8 = \sigma_8 \sqrt{\Omega_{\rm m}/0.3}$ with a mean value of $0.790^{+0.018}_{-0.014}$. The mean marginal is lower than the maximum a posteriori estimate, $S_8=0.801$, owing to skewness in the marginal distribution and projection effects in the multi-dimensional parameter space. Our results are consistent with $S_8$ constraints from observations of the cosmic microwave background by Planck, with agreement at the $1.7\sigma$ level. We use a Hybrid analysis pipeline, defined from a mock survey study quantifying the impact of the different analysis choices originally adopted by each survey team. We review intrinsic alignment models, baryon feedback mitigation strategies, priors, samplers and models of the non-linear matter power spectrum.|
|**2023-05-26**|**Regular access to constantly renewed online content favors radicalization of opinions**|Guillaume Deffuant et.al.|[2305.16855v1](http://arxiv.org/abs/2305.16855v1)|null|Worry over polarization has grown alongside the digital information consumption revolution. Where most scientific work considered user-generated and user-disseminated (i.e.,~Web 2.0) content as the culprit, the potential of purely increased access to information (or Web 1.0) has been largely overlooked. Here, we suggest that the shift to Web 1.0 alone could include a powerful mechanism of belief extremization. We study an empirically calibrated persuasive argument model with confirmation bias. We compare an offline setting -- in which a limited number of arguments is broadcast by traditional media -- with an online setting -- in which the agent can choose to watch contents within a very wide set of possibilities. In both cases, we assume that positive and negative arguments are balanced. The simulations show that the online setting leads to significantly more extreme opinions and amplifies initial prejudice.|
|**2023-05-25**|**Break-A-Scene: Extracting Multiple Concepts from a Single Image**|Omri Avrahami et.al.|[2305.16311v1](http://arxiv.org/abs/2305.16311v1)|null|Text-to-image model personalization aims to introduce a user-provided concept to the model, allowing its synthesis in diverse contexts. However, current methods primarily focus on the case of learning a single concept from multiple images with variations in backgrounds and poses, and struggle when adapted to a different scenario. In this work, we introduce the task of textual scene decomposition: given a single image of a scene that may contain several concepts, we aim to extract a distinct text token for each concept, enabling fine-grained control over the generated scenes. To this end, we propose augmenting the input image with masks that indicate the presence of target concepts. These masks can be provided by the user or generated automatically by a pre-trained segmentation model. We then present a novel two-phase customization process that optimizes a set of dedicated textual embeddings (handles), as well as the model weights, striking a delicate balance between accurately capturing the concepts and avoiding overfitting. We employ a masked diffusion loss to enable handles to generate their assigned concepts, complemented by a novel loss on cross-attention maps to prevent entanglement. We also introduce union-sampling, a training strategy aimed to improve the ability of combining multiple concepts in generated images. We use several automatic metrics to quantitatively compare our method against several baselines, and further affirm the results using a user study. Finally, we showcase several applications of our method. Project page is available at: https://omriavrahami.com/break-a-scene/|
|**2023-05-25**|**PDE+: Enhancing Generalization via PDE with Adaptive Distributional Diffusion**|Yige Yuan et.al.|[2305.15835v1](http://arxiv.org/abs/2305.15835v1)|null|The generalization of neural networks is a central challenge in machine learning, especially concerning the performance under distributions that differ from training ones. Current methods, mainly based on the data-driven paradigm such as data augmentation, adversarial training, and noise injection, may encounter limited generalization due to model non-smoothness. In this paper, we propose to investigate generalization from a Partial Differential Equation (PDE) perspective, aiming to enhance it directly through the underlying function of neural networks, rather than focusing on adjusting input data. Specifically, we first establish the connection between neural network generalization and the smoothness of the solution to a specific PDE, namely ``transport equation''. Building upon this, we propose a general framework that introduces adaptive distributional diffusion into transport equation to enhance the smoothness of its solution, thereby improving generalization. In the context of neural networks, we put this theoretical framework into practice as PDE+ (\textbf{PDE} with \textbf{A}daptive \textbf{D}istributional \textbf{D}iffusion) which diffuses each sample into a distribution covering semantically similar inputs. This enables better coverage of potentially unobserved distributions in training, thus improving generalization beyond merely data-driven methods. The effectiveness of PDE+ is validated in extensive settings, including clean samples and various corruptions, demonstrating its superior performance compared to SOTA methods.|
|**2023-05-25**|**IDEA: Invariant Causal Defense for Graph Adversarial Robustness**|Shuchang Tao et.al.|[2305.15792v1](http://arxiv.org/abs/2305.15792v1)|null|Graph neural networks (GNNs) have achieved remarkable success in various tasks, however, their vulnerability to adversarial attacks raises concerns for the real-world applications. Existing defense methods can resist some attacks, but suffer unbearable performance degradation under other unknown attacks. This is due to their reliance on either limited observed adversarial examples to optimize (adversarial training) or specific heuristics to alter graph or model structures (graph purification or robust aggregation). In this paper, we propose an Invariant causal DEfense method against adversarial Attacks (IDEA), providing a new perspective to address this issue. The method aims to learn causal features that possess strong predictability for labels and invariant predictability across attacks, to achieve graph adversarial robustness. Through modeling and analyzing the causal relationships in graph adversarial attacks, we design two invariance objectives to learn the causal features. Extensive experiments demonstrate that our IDEA significantly outperforms all the baselines under both poisoning and evasion attacks on five benchmark datasets, highlighting the strong and invariant predictability of IDEA. The implementation of IDEA is available at https://anonymous.4open.science/r/IDEA_repo-666B.|
|**2023-05-24**|**Large Language Models for User Interest Journeys**|Konstantina Christakopoulou et.al.|[2305.15498v1](http://arxiv.org/abs/2305.15498v1)|null|Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation. Their potential for deeper user understanding and improved personalized user experience on recommendation platforms is, however, largely untapped. This paper aims to address this gap. Recommender systems today capture users' interests through encoding their historical activities on the platforms. The generated user representations are hard to examine or interpret. On the other hand, if we were to ask people about interests they pursue in their life, they might talk about their hobbies, like I just started learning the ukulele, or their relaxation routines, e.g., I like to watch Saturday Night Live, or I want to plant a vertical garden. We argue, and demonstrate through extensive experiments, that LLMs as foundation models can reason through user activities, and describe their interests in nuanced and interesting ways, similar to how a human would.   We define interest journeys as the persistent and overarching user interests, in other words, the non-transient ones. These are the interests that we believe will benefit most from the nuanced and personalized descriptions. We introduce a framework in which we first perform personalized extraction of interest journeys, and then summarize the extracted journeys via LLMs, using techniques like few-shot prompting, prompt-tuning and fine-tuning. Together, our results in prompting LLMs to name extracted user journeys in a large-scale industrial platform demonstrate great potential of these models in providing deeper, more interpretable, and controllable user understanding. We believe LLM powered user understanding can be a stepping stone to entirely new user experiences on recommendation platforms that are journey-aware, assistive, and enabling frictionless conversation down the line.|
|**2023-05-24**|**LLMDet: A Large Language Models Detection Tool**|Kangxi Wu et.al.|[2305.15004v1](http://arxiv.org/abs/2305.15004v1)|[link](https://github.com/trustedllm/llmdet)|With the advancement of generative language models, the generated text has come remarkably close to high-quality human-authored text in terms of fluency and diversity. This calls for a highly practical detection tool that can identify the source of text, preferably pinpointing the language model it originates from. However, existing detection tools typically require access to language models and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of rapid detection and text tracing. Therefore, in this paper, we propose an efficient, secure, and scalable detection tool called LLMDet, which calculates the proxy perplexity of text by utilizing the prior information of the model's next-token probabilities, obtained through pre-training. Subsequently, we use the self-watermarking information of the model, as measured by proxy perplexity, to detect the source of the text. We found that our method demonstrates impressive detection performance while ensuring speed and security, particularly achieving a recognition accuracy of 97.97\% for human-authored text. Furthermore, our detection tool also shows promising results in identifying the large language model (e.g., GPT-2, OPT, LLaMA, Vicuna...) responsible for the text. We release the code and processed data at \url{https://github.com/TrustedLLM/LLMDet}.|
|**2023-05-24**|**Constraints on black hole charges in M87* and Sgr A* with the EHT observations**|Alexander F. Zakharov et.al.|[2305.15446v1](http://arxiv.org/abs/2305.15446v1)|null|In May 2022 ICRANet organized the Workshop dedicated to the 80th anniversary of Professor Ruffini. This paper is based on the talk delivered at the meeting.   Professor Ruffini was well known for Soviet scientific community not only due to his publications in leading journals but also due Russian translations of his books where he was an author or a contributor in collection of articles.   But only in 1988 I had an opportunity to watch and listen professor R. Ruffini at the Conference dedicated to the century since the birthday of Alexander Alexandrovich Friedmann. This conference was organized in Leningrad (Soviet Union) in June during a short magic period when there are white nights there. In June 2023 we celebrate the 135th anniversary of Friedmann's birth. Friedmann and his closed friend V. K. Frederics were the founders of Soviet school of general relativity and George Gamow was one of the brilliant representative of the school and he was the author of the hot Universe model which is the most popular now. In the USSR a development of general relativity and relativistic cosmology was not smooth and only in sixties of the last century these branches of science freed from the total control of representatives of the ideology of Marxism -- Leninism. I also discussed a Soviet contribution in a discovery of cosmic microwave background radiation done by T. Shmaonov in 1957 and reasons why his supervisors did not connect these results with the hot Universe models discussed by G. Gamow. Author's results about observational features of supemassive black holes (including the black hole in our Galactic Center) are also briefly discussed, it was considered   an opportunity to evaluate a (tidal) charge of Reissner -- Nordstr\"om black hole from observational estimates of shadow size in the Galactic Center and M87* done by the EHT Collaboration based its observations in April 2017.|
|**2023-05-23**|**ChipGPT: How far are we from natural language hardware design**|Kaiyan Chang et.al.|[2305.14019v3](http://arxiv.org/abs/2305.14019v3)|null|As large language models (LLMs) like ChatGPT exhibited unprecedented machine intelligence, it also shows great performance in assisting hardware engineers to realize higher-efficiency logic design via natural language interaction. To estimate the potential of the hardware design process assisted by LLMs, this work attempts to demonstrate an automated design environment that explores LLMs to generate hardware logic designs from natural language specifications. To realize a more accessible and efficient chip development flow, we present a scalable four-stage zero-code logic design framework based on LLMs without retraining or finetuning. At first, the demo, ChipGPT, begins by generating prompts for the LLM, which then produces initial Verilog programs. Second, an output manager corrects and optimizes these programs before collecting them into the final design space. Eventually, ChipGPT will search through this space to select the optimal design under the target metrics. The evaluation sheds some light on whether LLMs can generate correct and complete hardware logic designs described by natural language for some specifications. It is shown that ChipGPT improves programmability, and controllability, and shows broader design optimization space compared to prior work and native LLMs alone.|
|**2023-05-22**|**pytest-inline: An Inline Testing Tool for Python**|Yu Liu et.al.|[2305.13486v1](http://arxiv.org/abs/2305.13486v1)|[link](https://github.com/pytest-dev/pytest-inline)|We present pytest-inline, the first inline testing framework for Python. We recently proposed inline tests to make it easier to test individual program statements. But, there is no framework-level support for developers to write inline tests in Python. To fill this gap, we design and implement pytest-inline as a plugin for pytest, the most popular Python testing framework. Using pytest-inline, a developer can write an inline test by assigning test inputs to variables in a target statement and specifying the expected test output. Then, pytest-inline runs each inline test and fails if the target statement's output does not match the expected output. In this paper, we describe our design of pytest-inline, the testing features that it provides, and the intended use cases. Our evaluation on inline tests that we wrote for 80 target statements from 31 open-source Python projects shows that using pytest-inline incurs negligible overhead, at 0.012x. pytest-inline is integrated into the pytest-dev organization, and a video demo is at https://www.youtube.com/watch?v=pZgiAxR_uJg.|

### huawei band
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Disorder-induced topological quantum phase transitions in Euler semimetals**|Wojciech J. Jankowski et.al.|[2306.13084v1](http://arxiv.org/abs/2306.13084v1)|null|We study the effect of disorder in systems having a non-trivial Euler class. As these recently proposed multi-gap topological phases come about by braiding non-Abelian charged band nodes residing between different bands to induce stable pairs within isolated band subspaces, novel properties that include a finite critical phase under the debraiding to a metal rather than a transition point and a modified stability may be expected when the disorder preserves the underlying $C_2\cal{T}$ or $\cal{P}\cal{T}$ symmetry on average. Employing elaborate numerical computations, we verify the robustness of associated topology by evaluating the changes in the average densities of states and conductivities for different types of disorders. Upon performing a scaling analysis around the corresponding quantum critical points we retrieve a universality for the localization length exponent of $\nu = 1.4 \pm 0.1$ for Euler-protected phases, relating to 2D percolation models. We generically find that quenched disorder drives Euler semimetals into critical metallic phases. Finally, we show that magnetic disorder can also induce topological transitions to quantum anomalous Hall plaquettes with local Chern numbers determined by the initial value of the Euler invariant.|
|**2023-06-22**|**Gain-loss induced non-Abelian Bloch braids**|B. Midya et.al.|[2306.13056v1](http://arxiv.org/abs/2306.13056v1)|null|Onsite gain-loss induced topological braiding principles of non-Hermitian energy bands is theoretically formulated in multiband lattice models with Hermitian hopping amplitudes. Braid phase transition occurs when the gain-loss parameter is tuned across exceptional point degeneracies. Laboratory realizable effective-Hamiltonians are proposed to realize braid groups $\mathbb{B}_2$ and $\mathbb{B}_3$ of two and three bands respectively. While $\mathbb{B}_2$ is trivially Abelian, the group $\mathbb{B}_3$ features non-Abelian braiding and energy permutation. Phase diagrams with respect to lattice parameters to realize braid group generators and their non-commutativity are shown. The proposed theory is conducive to synthesize exceptional materials for applications in topological quantum photonic computation and information processing.|
|**2023-06-22**|**Magnetic Dirac semimetal state of (Mn,Ge)Bi$_2$Te$_4$**|Alexander S. Frolov et.al.|[2306.13024v1](http://arxiv.org/abs/2306.13024v1)|null|For quantum electronics, the possibility to finely tune the properties of magnetic topological insulators (TIs) is a key issue. We studied solid solutions between two isostructural Z$_2$ TIs, magnetic MnBi$_2$Te$_4$ and nonmagnetic GeBi$_2$Te$_4$, with Z$_2$ invariants of 1;000 and 1;001, respectively. For high-quality, large mixed crystals of Ge$_x$Mn$_{1-x}$Bi$_2$Te$_4$, we observed linear x-dependent magnetic properties, composition-independent pairwise exchange interactions along with an easy magnetization axis. The bulk band gap gradually decreases to zero for $x$ from 0 to 0.4, before reopening for $x>0.6$, evidencing topological phase transitions (TPTs) between topologically nontrivial phases and the semimetal state. The TPTs are driven purely by the variation of orbital contributions. By tracing the x-dependent $6p$ contribution to the states near the fundamental gap, the effective spin-orbit coupling variation is extracted. As $x$ varies, the maximum of this contribution switches from the valence to the conduction band, thereby driving two TPTs. The gapless state observed at $x=0.42$ closely resembles a Dirac semimetal above the Neel temperature and shows a magnetic gap below, which is clearly visible in raw photoemission data. The observed behavior of the Ge$_x$Mn$_{1-x}$Bi$_2$Te$_4$ system thereby demonstrates an ability to precisely control topological and magnetic properties of TIs.|
|**2023-06-22**|**Deficit of Hot Dust in Low-redshift Active Galactic Nuclei**|Suyeon Son et.al.|[2306.12927v1](http://arxiv.org/abs/2306.12927v1)|null|We assemble a broad-band spectral energy distribution (SED) ranging from optical to mid-infrared of nearby active galactic nuclei at $z < 0.4$. SED fitting analysis is performed using semi-empirical templates derived from Palomar-Green quasars to classify the sample into normal, warm-dust-deficient (WDD), and hot-dust-deficient (HDD) AGNs. Kolmogorov-Smirnov tests reveal that HDD AGNs exhibit, on average higher AGN luminosity than normal and WDD AGNs. HDD fraction, on the other hand, is only weakly correlated with black hole mass and inversely correlated with Eddington ratio. By fixing the other parameters, we conclude that the HDD fraction is primarily connected with the AGN luminosity. It implies that there is a causal connection between the covering factor of the hot dust component and AGN luminosity, possibly due to the sublimation of the innermost dust or the thickening of the intervening gas in the broad-line region. Analysis of the outflow properties traced by the wing of [O III]$\lambda5007$ suggests that outflows may be related to the formation and maintenance of the hot dust component. Finally, we demonstrate through comparison with previous studies that the classification of HDD AGNs requires careful subtraction of the host galaxy light.|
|**2023-06-22**|**Superconducting stripes in the hole-doped three-band Hubbard model**|Boris Ponsioen et.al.|[2306.12910v1](http://arxiv.org/abs/2306.12910v1)|null|We study the ground state properties of the hole-doped three-band Hubbard (Emery) model, describing the copper-oxygen planes of the cuprates, using large-scale 2D tensor network calculations. Our simulations reveal a period 4 stripe state with spin and weak charge order over an extended doping range beyond $\delta\sim0.12$ and stripes with larger periods at smaller doping. The period 4 stripe exhibits coexisting $d$-wave superconductivity in the doping range $0.15 \lesssim \delta < 0.25$, while at smaller doping around $\delta \sim 1/8$ we find a strong competition between superconducting and non-superconducting stripes, including also pair density-wave states with alternating sign structure on neighboring stripes, suggesting that the fate of superconductivity around 1/8 doping may be sensitive on the model parameters.|
|**2023-06-22**|**Momentum matching and band-alignment type in van der Waals heterostructures: Interfacial effects and materials screening**|Yue-Jiao Zhang et.al.|[2306.12821v1](http://arxiv.org/abs/2306.12821v1)|null|Momentum-matched type II van der Waals heterostructures (vdWHs) have been designed by assembling layered two-dimensional semiconductors (2DSs) with special band-structure combinations - that is, the valence band edge at the Gamma point (the Brillouin-zone center) for one 2DS and the conduction band edge at the Gamma point for the other [Ubrig et al., Nat. Mater. 19, 299 (2020)]. However, the band offset sizes, band-alignment types, and whether momentum matched or not, all are affected by the interfacial effects between the component 2DSs, such as the quasichemical-bonding (QB) interaction between layers and the electrical dipole moment formed around the vdW interface. Here, based on density-functional theory calculations, first we probe the interfacial effects (including different QBs for valence and conduction bands, interface dipole, and, the synergistic effects of these two aspects) on band-edge evolution in energy and valley (location in the Brillouin zone) and the resulting changes in band alignment and momentum matching for a typical vdWH of monolayer InSe and bilayer WS2, in which the band edges of subsystems satisfy the special band-structure combination for a momentum-matched type II vdWH. Then, based on the conclusions of the studied interfacial effects, we propose a practical screening method for robust momentum-matched type II vdWHs. This practical screening method can also be applied to other band alignment types. Our current study opens a way for practical screening and designing of vdWHs with robust momentum-matching and band alignment type.|
|**2023-06-22**|**A prior regularized full waveform inversion using generative diffusion models**|Fu Wang et.al.|[2306.12776v1](http://arxiv.org/abs/2306.12776v1)|null|Full waveform inversion (FWI) has the potential to provide high-resolution subsurface model estimations. However, due to limitations in observation, e.g., regional noise, limited shots or receivers, and band-limited data, it is hard to obtain the desired high-resolution model with FWI. To address this challenge, we propose a new paradigm for FWI regularized by generative diffusion models. Specifically, we pre-train a diffusion model in a fully unsupervised manner on a prior velocity model distribution that represents our expectations of the subsurface and then adapt it to the seismic observations by incorporating the FWI into the sampling process of the generative diffusion models. What makes diffusion models uniquely appropriate for such an implementation is that the generative process retains the form and dimensions of the velocity model. Numerical examples demonstrate that our method can outperform the conventional FWI with only negligible additional computational cost. Even in cases of very sparse observations or observations with strong noise, the proposed method could still reconstruct a high-quality subsurface model. Thus, we can incorporate our prior expectations of the solutions in an efficient manner. We further test this approach on field data, which demonstrates the effectiveness of the proposed method.|
|**2023-06-22**|**Fermi surface reconstruction due to the orthorhombic distortion in Dirac semimetal YbMnSb$_2$**|Dilip Bhoi et.al.|[2306.12732v1](http://arxiv.org/abs/2306.12732v1)|null|Dirac semi-metal with magnetic atoms as constituents delivers an interesting platform to investigate the interplay of Fermi surface (FS) topology, electron correlation, and magnetism. One such family of semi-metal is YbMn$Pn_2$ ($Pn$ = Sb, Bi), which is being actively studied due to the intertwined spin and charge degrees of freedom. In this Letter, we investigate the relationship between the magnetic/crystal structures and FS topology of YbMnSb$_2$ using single crystal x-ray diffraction, neutron scattering, magnetic susceptibility, magnetotransport measurement and complimentary DFT calculation. Contrary to previous reports, the x-ray and neutron diffraction reveal that YbMnSb$_2$ crystallizes in an orthorhombic $Pnma$ structure with notable anti-phase displacement of the magnetic Mn ions that increases in magnitude upon cooling. First principles DFT calculation reveals a reduced Brillouin zone and more anisotropic FS of YbMnSb$_2$ compared to YbMnBi$_2$ as a result of the orthorhombicity. Moreover, the hole type carrier density drops by two orders of magnitude as YbMnSb$_2$ orders antiferromagnetically indicating band folding in magnetic ordered state. In addition, the Landau level fan diagram yields a non-trivial nature of the SdH quantum oscillation frequency arising from the Dirac-like Fermi pocket. These results imply that YbMnSb$_2$ is an ideal platform to explore the interplay of subtle lattice distortion, magnetic order, and topological transport arising from relativistic quasiparticles.|
|**2023-06-22**|**Time Domain Superoscillation Enables Super-contrast Spectroscopy**|Peisong Peng et.al.|[2306.12665v1](http://arxiv.org/abs/2306.12665v1)|null|In the field of optical imaging, resolution has been historically hard bounded by the observed system's diffraction limit. Superoscillation, a phenomenon where a band-limited wave may oscillate faster than it's fastest Fourier component, can break this limit and confer a sort of super-resolution. Superoscillations in the spatial domain have been demonstrated and successfully employed for this purpose. We demonstrate that similarly powerful enhancements in imaging may also be obtained with superoscillations in the time domain. We define the parameter of discriminability, $J$, which characterizes a light wave's ability to discriminate between two samples with similar optical properties. We demonstrate that time domain superoscillations increase $J$ by two orders of magnitude, as compared to probing samples using only fundamental harmonics. Quite counterintuitively, we also find that $J$ is increased as the observation window is made $\textit{shorter}$. As such, we propose that for many biomedical imaging applications where intense light inputs are unnecessary (or even detrimental to a sample system), time domain superoscillation can be adopted to massively increase imaging contrast.|
|**2023-06-22**|**Extragalactic Star Cluster Science with the Nancy Grace Roman Space Telescope's High Latitude Wide Area Survey and the Vera C. Rubin Observatory**|Kristen C. Dage et.al.|[2306.12620v1](http://arxiv.org/abs/2306.12620v1)|null|The Nancy Grace Roman Telescope's High Latitude Wide Area Survey will have a number of synergies with the Vera Rubin Observatory's Legacy Survey of Space and Time (LSST), particularly for extragalactic star clusters. Understanding the nature of star clusters and star cluster systems are key topics in many areas of astronomy, chief among them stellar evolution, high energy astrophysics, galaxy assembly/dark matter, the extragalactic distance scale, and cosmology. One of the challenges will be disentangling the age/metallicity degeneracy because young ($\sim$Myr) metal-rich clusters have similar SEDs to old ($\sim$Gyr) metal-poor clusters. Rubin will provide homogeneous, $ugrizy$ photometric coverage, and measurements in the red Roman filters will help break the age-metallicity and age-extinction degeneracies, providing the first globular cluster samples that cover wide areas while essentially free of contamination from Milky Way stars. Roman's excellent spatial resolution will also allow measurements of cluster sizes. We advocate for observations of a large sample of galaxies with a range of properties and morphologies in the Rubin/LSST footprint matching the depth of the LSST Wide-Fast-Deep field $i$ band limit (26.3 mag), and recommend adding the F213 filter to the survey.|
|**2023-06-21**|**Neural Spectro-polarimetric Fields**|Youngchan Kim et.al.|[2306.12562v1](http://arxiv.org/abs/2306.12562v1)|null|Modeling the spatial radiance distribution of light rays in a scene has been extensively explored for applications, including view synthesis. Spectrum and polarization, the wave properties of light, are often neglected due to their integration into three RGB spectral bands and their non-perceptibility to human vision. Despite this, these properties encompass substantial material and geometric information about a scene. In this work, we propose to model spectro-polarimetric fields, the spatial Stokes-vector distribution of any light ray at an arbitrary wavelength. We present Neural Spectro-polarimetric Fields (NeSpoF), a neural representation that models the physically-valid Stokes vector at given continuous variables of position, direction, and wavelength. NeSpoF manages inherently noisy raw measurements, showcases memory efficiency, and preserves physically vital signals, factors that are crucial for representing the high-dimensional signal of a spectro-polarimetric field. To validate NeSpoF, we introduce the first multi-view hyperspectral-polarimetric image dataset, comprised of both synthetic and real-world scenes. These were captured using our compact hyperspectral-polarimetric imaging system, which has been calibrated for robustness against system imperfections. We demonstrate the capabilities of NeSpoF on diverse scenes.|
|**2023-06-21**|**Wurtzite/Zincblende Crystal Phase GaAs Heterostructures in the Tight Binding Approximation**|Joseph Sink et.al.|[2306.12537v1](http://arxiv.org/abs/2306.12537v1)|null|Crystal phase semiconductor heterostructures allow for electron confinement without uncertainties caused by chemical intermixing found in material heterostructures and are candidates for next generation optoelectronics devices ranging from single-photon emitters to high efficiency LEDs. While there has been a great deal of experimental work developing fabrication processes for these structures, theoretical calculations have been limited due to a lack of atomistic models that are able to incorporate the zincblende and wurtzite within the same structure. Here, we present calculations of the electronic energies in GaAs nanowires containing various thicknesses of zincblende and wurtzite layers using a recently developed tight-binding model for wurtzite III-V semiconductors that is compatible with a zincblende model. By comparing results in the flat-band and the unscreened limits, we explain the sensitivity of experimentally observed band gaps on zincblende and wurtzite well widths. Our calculations suggest that experiments on devices are likely near the flat-band limit under typical operating conditions.|
|**2023-06-21**|**Ionization clamping in ultrafast optical breakdown of transparent solids**|Anton Rudenko et.al.|[2306.12524v1](http://arxiv.org/abs/2306.12524v1)|null|We formulate a multi-physics model to describe the nonlinear propagation of a femtosecond, near-infrared, tightly focused laser pulse in a transparent dielectric. The application of our model to the case of bulk sapphire shows that even under extreme excitation conditions, ionization is universally clamped at about one tenth of the electron density in the upper valence band. The earlier estimate of ~10 TPa pressure that could be attainable through the internal excitation of transparent dielectrics by tightly focused ultrafast laser beams is shown to be off by two orders of magnitude.|
|**2023-06-21**|**Self-doped flat band and spin-triplet superconductivity in monolayer 1T-TaSe$_{2-x}$Te$_{x}$**|Jan Phillips et.al.|[2306.12493v1](http://arxiv.org/abs/2306.12493v1)|null|Two-dimensional van der Waals materials have become an established platform to engineer flat bands which can lead to strongly-correlated emergent phenomena. In particular, the family of Ta dichalcogenides in the 1\textit{T} phase presents a star-of-David charge density wave that creates a flat band at the Fermi level. For TaS$_2$ and TaSe$_2$ this flat band is at half filling leading to a magnetic insulating phase. In this work, we theoretically demonstrate that ligand substitution in the TaSe$_{2-x}$Te$_x$ system produces a transition from the magnetic insulator to a non-magnetic metal in which the flat band gets doped away from half-filling. For $x\in[{0.846},{1.231}]$ the spin-polarized flat band is self-doped and the system becomes a magnetic metal. In this regime, we show that attractive interactions promote three different spin-triplet superconducting phases as a function of $x$, corresponding to a nodal f-wave and two topologically-different chiral p-wave superconducting phases. Our results establish monolayer TaSe$_{2-x}$Te$_{x}$ as a promising platform for correlated flat band physics leading to unconventional superconducting states.|
|**2023-06-21**|**Quantitative polarimetry for the transition disk in RX J1604.3-213010**|Jie Ma et.al.|[2306.12329v1](http://arxiv.org/abs/2306.12329v1)|null|The bright disk of RX J1604 has a very simple axisymmetric structure and is well suited as a benchmark object for accurate photo-polarimetric measurements. We used archival data of RX J1604 from the ESO archive and carefully corrected the polarization signal for instrumental effects, also taking the interstellar polarization into account. We derive accurate radial disk profiles for the intrinsic polarized intensity, ${\hat{Q}}_{\varphi}(r)/I_{\star}$, and measure different profile peak radii for different bands because of the wavelength dependence of the dust opacity. The disk-integrated polarization is $\hat{Q}_{\varphi}/I_{\star} = 0.92 \pm 0.04\%$ for the R band and $1.51 \pm 0.11\%$ for the J band, indicating a red color for the polarized reflectivity of the disk. The intensity of the disk is $I_{\rm disk}/I_{\star} = 3.9 \pm 0.5 \%$ in the J band, and the fractional polarization is $\hat{p}_{\varphi} = 38 \pm 4\%$ for the J band and $42 \pm 2\%$ for the H band. The comparison with the IR excess for RX J1604 yields an apparent disk albedo of about $\Lambda_{I} \approx 0.16 \pm 0.08$. We also find that previously described shadows seen in the R band data are likely affected by calibration errors. Using dust scattering models for transition disks, We derive approximate J band values for the scattering albedo $\omega \approx 0.5$, scattering asymmetry $g \approx 0.5$, and scattering polarization $p_{\rm max} \approx 0.7$ for the dust. The positive R to J band color for the polarized reflectivity is mainly a result of the wavelength dependence of dust parameters because the scattering geometry is expected to be very similar for different colors. This work demonstrates the potential of accurate photo-polarimetric measurements of the circumstellar disk RX J1604 for the determination of dust scattering parameters that strongly constrain the physical properties of the dust.|
|**2023-06-21**|**DFT insights into MAX phase borides Hf2AB [A = S, Se, Te] in comparison with MAX phase carbides Hf2AC [A = S, Se, Te]**|J. Islam et.al.|[2306.12270v1](http://arxiv.org/abs/2306.12270v1)|null|In this work, density functional theory (DFT) based calculations were performed to compute the physical properties (structural stability, mechanical behavior, electronic, thermodynamic, and optical properties) of synthesized MAX phases Hf2SB, Hf2SC, Hf2SeB, Hf2SeC, Hf2TeB, and the as-yet-undiscovered MAX carbide phase Hf2TeC. Calculations of formation energy, phonon dispersion curves, and elastic constants confirmed the stability of the aforementioned compounds. The obtained values of lattice parameters, elastic constants, and elastic moduli of Hf2SB, Hf2SC, Hf2SeB, Hf2SeC, and Hf2TeB showed fair agreement with earlier studies, whereas the values of the mentioned parameters for the predicted Hf2TeC exhibit a good consequence of B replacement by C. The anisotropic mechanical properties are exhibited by the considered MAX phases. The metallic nature and its anisotropic behavior were revealed by the electronic band structure and density of states. The analysis of the thermal properties Debye temperature, melting temperature, minimum thermal conductivity, and Gruneisen parameter confirmed that the carbide phases were more suited than the boride phases considered herein. The MAX phase response to incoming photons further demonstrated that they were metallic. Their suitability for use as coating materials to prevent solar heating was demonstrated by the reflectivity spectra. Additionally, this study demonstrated the impact of B replacing C in the MAX phases.|
|**2023-06-21**|**Unexpected antagonism between ferroelectricity and Rashba effects in epitaxially strained SrTiO$_3$**|Julien Varignon et.al.|[2306.12267v1](http://arxiv.org/abs/2306.12267v1)|null|The Rashba interaction appearing in materials characterized by polar displacements is at the core of spin-orbitronic applications enabling spin-charge currents interconversion. The efficiency of the conversion is related to the Rashba parameter, usually assumed to depend directly on the spin-orbit interaction (SOI) and polar displacements amplitude. Here I show, on the basis of first-principles simulations, that ferroelectric phases of SrTiO$_3$ reached under epitaxial compressive strain are characterized by an unexpected suppression of Rashba effects at the bottom of the conduction band when polar displacements amplitude increases. By carefully inspecting the role of individual lattice distortions on electronic states, this peculiar behavior is ascribed to the suppression of Ti t$_{2g}$ orbital degeneracies induced by polar displacements thereby weakening the SOI and hence Rashba effects. This antagonism observed in SrTiO$_3$ thus highlights that large polar displacements are not necessarily a prerequisite for reaching a sizable Rashba parameter and that the latter quantity might be bounded to a upper value.|
|**2023-06-21**|**Near infrared view on the photodissociation regions S255, S257, NGC7538 and S140**|M. S. Kirsanova et.al.|[2306.12264v1](http://arxiv.org/abs/2306.12264v1)|null|We performed photometric observations of the S255, S257, S140, NGC7358 and the Orion~Bar photo-dissociation regions (PDRs) at 2 micron using narrow-band filters centered on the Br-gamma, H2 and [FeII] lines, as well as the narrow-band Kcont and the broad-band H filters for continuum subtraction. The observations were done with the 2.5-m telescope of the SAI Caucasian Mountain Observatory and the near-infrared camera and spectrograph ASTRONIRCAM. We find several high-density arc-like structures in the Br-gamma and [FeII] images of the ionized gas in NGC7538 and extended shells and arcs visible through the H2 emission. The H ionization front and H2 dissociation front are merged in NGC7538. In S255 and S257 we detected only Br-gamma emission from the HII regions and bright H2 emission from the PDRs. The projected distance between the H ionization and H2 dissociation fronts are approx. 0.3-0.4 pc, which cannot be explained using models of a uniform medium. Most probably, the ionized and neutral gas in these PDRs is clumpy. The H-to-H2 transitions in the NGC7538, S255, S257 and S140 PDRs are gradual with no sharp borders. This conclusion also confirms the suggestion of a clumpy medium.|
|**2023-06-21**|**An efficient mass lumping scheme for isogeometric analysis based on approximate dual basis functions**|Susanne Held et.al.|[2306.12257v1](http://arxiv.org/abs/2306.12257v1)|null|In this contribution, we provide a new mass lumping scheme for explicit dynamics in isogeometric analysis (IGA). To this end, an element formulation based on the idea of dual functionals is developed. Non-Uniform Rational B-splines (NURBS) are applied as shape functions and their corresponding dual basis functions are applied as test functions in the variational form, where two kinds of dual basis functions are compared. The first type are approximate dual basis functions (AD) with varying degree of reproduction, resulting in banded mass matrices. Dual basis functions derived from the inversion of the Gram matrix (IG) are the second type and already yield diagonal mass matrices. We will show that it is possible to apply the dual scheme as a transformation of the resulting system of equations based on NURBS as shape and test functions. Hence, it can be easily implemented into existing IGA routines. Treating the application of dual test functions as preconditioner reduces the additional computational effort, but it cannot entirely erase it and the density of the stiffness matrix still remains higher than in standard Bubnov-Galerkin formulations. In return applying additional row-sum lumping to the mass matrices is either not necessary for IG or the caused loss of accuracy is lowered to a reasonable magnitude in the case of AD. Numerical examples show a significantly better approximation of the dynamic behavior for the dual lumping scheme compared to standard NURBS approaches making use of row-sum lumping. Applying IG yields accurate numerical results without additional lumping. But as result of the global support of the IG dual basis functions, fully populated stiffness matrices occur, which are entirely unsuitable for explicit dynamic simulations. Combining AD and row-sum lumping leads to an efficient computation regarding effort and accuracy.|
|**2023-06-21**|**The effect of singularities and damping on the spectra of photonic crystals**|Konstantinos Alexopoulos et.al.|[2306.12254v1](http://arxiv.org/abs/2306.12254v1)|null|Understanding the dispersive properties of photonic crystals is a fundamental and well-studied problem. However, the introduction of singular permittivities and damping complicates the otherwise straightforward theory. In this paper, we study photonic crystals with a Drude-Lorentz model for the permittivity, motivated by halide perovskites. We demonstrate how the introduction of singularities and damping affects the spectral band structure and show how to interpret the notion of a "band gap" in this setting. We present explicit solutions for a one-dimensional model and show how integral operators can be used to handle multi-dimensional systems.|
|**2023-06-21**|**Noble gas functional defect with unusual relaxation pattern in solids**|Lovelesh et.al.|[2306.12252v1](http://arxiv.org/abs/2306.12252v1)|null|The conventional understanding has always been that noble gases are chemically inert and do not affect materials properties. This belief has led to their use as a standard reference in various experimental applications through noble gas implantation. However, in our research, using first-principles calculations, we delve into the effects of noble gas defects on the properties of several functional oxides, thereby questioning this long-held assumption. We provide evidence that noble gases can indeed serve as functional defects. They have the potential to decentralize the localized defect states and prompt a shift of electrons from a localized state to the main conduction band. Our investigation unveils that noble gas defects can indeed significantly alter material properties. Thus, we underscore the importance of factoring in such defects when assessing material properties.|
|**2023-06-21**|**Optical frequency comb Fourier transform spectroscopy of formaldehyde in the 1250 to 1390 cm$^{-1}$ range: experimental line list and improved MARVEL analysis**|Matthias Germann et.al.|[2306.12246v1](http://arxiv.org/abs/2306.12246v1)|null|We use optical frequency comb Fourier transform spectroscopy to record high-resolution, low-pressure, room-temperature spectra of formaldehyde (H$_2$$^{12}$C$^{16}$O) in the range of 1250 to 1390 cm$^{-1}$. Through line-by-line fitting, we retrieve line positions and intensities of 747 rovibrational transitions: 558 from the ${\nu}_6$ band, 129 from the ${\nu}_4$ band, and 14 from the ${\nu}_3$ band, as well as 46 from four different hot bands. We incorporate the accurate and precise line positions (0.4 MHz median uncertainty) into the MARVEL (measured active vibration-rotation energy levels) analysis of the H$_2$CO spectrum. This increases the number of MARVEL-predicted energy levels by 82 and of rovibrational transitions by 5382, and substantially reduces uncertainties of MARVEL-derived H$_2$CO energy levels over a large range: from pure rotational levels below 200 cm$^{-1}$ up to multiply excited vibrational levels at 6000 cm$^{-1}$. This work is an important step toward filling the gaps in formaldehyde data in the HITRAN database.|
|**2023-06-21**|**Superconductivity and magnetism in the surface states of ABC-stacked multilayer graphene**|Oladunjoye A. Awoga et.al.|[2306.12220v1](http://arxiv.org/abs/2306.12220v1)|null|ABC-stacked multilayer graphene (ABC-MLG) exhibits topological surface flat bands with a divergent density of states, leading to many-body instabilities at charge neutrality. Here, we explore electronic ordering within a mean-field approach with full generic treatment of all spin-isotropic, two-site charge density and spin interactions up to next-nearest neighbor (NNN) sites. We find that surface superconductivity and magnetism are significantly enhanced over bulk values. We find spin-singlet $s$-wave and unconventional NNN bond spin-triplet $f$-wave to be the dominant superconducting pairing symmetries, both with a full energy gap. By establishing the existence of ferromagnetic intra-sublattice interaction, ($J_2<0$) we conclude that the $f$-wave state is favored in ABC-MLG, in sharp contrast to bulk ABC-graphite where chiral d- or p-wave states, together with s-wave states, display stronger ordering tendencies albeit not achievable at charge neutrality. We trace this distinctive surface behavior to the strong sublattice polarization of the surface flat bands. We also find competing ferrimagnetic order, fully consistent with density functional theory (DFT) calculations. The magnetic order interpolates between sublattice ferromagnetism and antiferromagnetism, but only with the ratio of the sublattice magnetic moments ($R$) being insensitive to the DFT exchange correlation functional. We finally establish the full phase diagram by constraining the interactions to the $R$-value identified by DFT. We find $f$-wave superconductivity being favored for all weak to moderately strong couplings $J_2$ and as long as $J_2$ is a sufficiently large part of the full interaction mix. Gating ABC-MLG away from charge neutrality further enhances the $f$-wave state over the ferrimagnetic state, establishing ABC-MLG as a strong candidate for $f$-wave superconductivity.|
|**2023-06-21**|**Cloud Behaviour on Tidally Locked Rocky Planets from Global High-resolution Modeling**|Jun Yang et.al.|[2306.12186v1](http://arxiv.org/abs/2306.12186v1)|null|Determining the behaviour of convection and clouds is one of the biggest challenges in our understanding of exoplanetary climates. Given the lack of in situ observations, one of the most preferable approaches is to use cloud-resolving or cloud-permitting models (CPM). Here we present CPM simulations in a quasi-global domain with high spatial resolution (4$\times$4 km grid) and explicit convection to study the cloud regime of 1 to 1 tidally locked rocky planets orbiting around low-mass stars. We show that the substellar region is covered by deep convective clouds and cloud albedo increases with increasing stellar flux. The CPM produces relatively less cloud liquid water concentration, smaller cloud coverage, lower cloud albedo, and deeper H2O spectral features than previous general circulation model (GCM) simulations employing empirical convection and cloud parameterizations. Furthermore, cloud streets--long bands of low-level clouds oriented nearly parallel to the direction of the mean boundary-layer winds--appear in the CPM and substantially affect energy balance and surface precipitation at a local level.|
|**2023-06-21**|**Optical study of three-dimensional Weyl semimetal Mn$_3$Sn**|L. Y. Cao et.al.|[2306.12180v1](http://arxiv.org/abs/2306.12180v1)|null|Three-dimensional (3D) Weyl semimetal Mn$_3$Sn has attracted tremendous attention due to its great application potential. However, the complex magnetic structures at different temperature intervals make it extremely difficult to unravel the underlying electronic structures of Mn$_3$Sn. Here, we perform temperature-dependent optical spectroscopy measurements on single crystalline Mn$_3$Sn to investigate its charge dynamics. We find that both of the optical reflectivity $R(\omega)$ and conductivity $\sigma_1(\omega)$ evolve very smoothly across the magnetic phase transition at $T_M$ = 285 K, where the giant anomalous Hall effect (AHE) at room temperature drops significantly. Furthermore, two linearly increasing segments of $\sigma_1(\omega)$ are observed in the whole temperature range from 300 K to 10 K, indicating that the existence of Weyl fermions is very robust against the magnetic phase transition. In addition, the Weyl points closest to the Fermi level $E_F$ are identified to be located about 101 meV away from $E_F$ at 10 K, and the associated Fermi velocity is about 2.55 $\times 10^7$ cm/s. Our results reveal that the phase transition at $T_M$ only generates subtle modification to the band structure, which helps to further uncover the mechanism of the dramatic change of AHE in Mn$_3$Sn.|
|**2023-06-21**|**Extended NYUSIM-based MmWave Channel Model and Simulator for RIS-Assisted Systems**|Aline Habib et.al.|[2306.12164v1](http://arxiv.org/abs/2306.12164v1)|null|Spectrum scarcity has motivated the exploration of the millimeter-wave (mmWave) band as a key technology to cope with the ever-increasing data traffic. However, in this band, radiofrequency waves are highly susceptible to transmission loss and blockage. Recently, reconfigurable intelligent surfaces (RIS) have been proposed to transform the random nature of the propagation channel into a programmable and controllable radio environment. This innovative technique can improve mmWave coverage. However, most works consider theoretical channel models. In order to fill the gap towards a realistic RIS channel simulator, we extend the 3D statistical channel simulator NYUSIM based on extensive measurements to help model RIS-assisted mmWave systems. We validate the extended simulator analytically and via simulations. In addition, we study the received power in different configurations. Finally, we highlight the effectiveness of using RIS when the direct link is partially blocked or non-existent.|
|**2023-06-21**|**Electron-phonon coupling from GW perturbation theory: Practical workflow combining BerkeleyGW, ABINIT, and EPW**|Zhenglu Li et.al.|[2306.12075v1](http://arxiv.org/abs/2306.12075v1)|null|We present a workflow of practical calculations of electron-phonon (e-ph) coupling with many-electron correlation effects included using the GW perturbation theory (GWPT). This workflow combines BerkeleyGW, ABINIT, and EPW software packages to enable accurate e-ph calculations at the GW self-energy level, going beyond standard calculations based on density functional theory (DFT) and density-functional perturbation theory (DFPT). This workflow begins with DFT and DFPT calculations (ABINIT) as starting point, followed by GW and GWPT calculations (BerkeleyGW) for the quasiparticle band structures and e-ph matrix elements on coarse electron k- and phonon q-grids, which are then interpolated to finer grids through Wannier interpolation (EPW) for computations of various e-ph coupling determined physical quantities such as the electron self-energies or solutions of anisotropic Eliashberg equations, among others. A gauge-recovering symmetry unfolding technique is developed to reduce the computational cost of GWPT (as well as DFPT) while fulfilling the gauge consistency requirement for Wannier interpolation.|
|**2023-06-21**|**Non-Hermitian band theory in all dimensions: uniform spectra and skin effect**|Haiping Hu et.al.|[2306.12022v1](http://arxiv.org/abs/2306.12022v1)|null|The non-Hermitian skin effect is an iconic phenomenon, characterized by the aggregation of eigenstates near the system boundaries in non-Hermitian systems. While extensively studied in one dimension, understanding the skin effect and extending the non-Bloch band theory to higher dimensions poses a formidable challenge, primarily due to infinite lattice geometries or open boundary conditions. This work adopts a point-gap perspective and presents a unified non-Hermitian band theory that governs skin effects across all spatial dimensions. We introduce the concept of uniform spectra and reveal that regardless of lattice geometry, their energy spectra are uniformly given by the uniform spectra, even though their manifestations of skin modes may differ. Building on the uniform spectra, we demonstrate how to account for the skin effect in generic lattice cuts and establish the connections of skin modes across different geometric shapes via momentum-basis transformations. Our findings highlight the pivotal roles played by point gaps, offering a unified understanding of the non-Hermitian skin effect in all dimensions.|
|**2023-06-20**|**Raman Study of Layered Breathing Kagome Lattice Semiconductor Nb3Cl8**|Dylan A. Jeff et.al.|[2306.11905v1](http://arxiv.org/abs/2306.11905v1)|null|Niobium chloride (Nb3Cl8) is a layered 2D semiconducting material with many exotic properties including a breathing kagome lattice, a topological flat band in its band structure, and a crystal structure that undergoes a structural and magnetic phase transition at temperatures below 90 K. Despite being a remarkable material with fascinating new physics, the understanding of its phononic properties is at its infancy. In this study, we investigate the phonon dynamics of Nb3Cl8 in bulk and few layer flakes using polarized Raman spectroscopy and density-functional theory (DFT) analysis to determine the material's vibrational modes, as well as their symmetrical representations and atomic displacements. We experimentally resolved 12 phonon modes, 5 of which are A1g modes the remaining 7 are Eg modes, which is in strong agreement with our DFT calculation. Layer-dependent results suggest that the Raman peak positions are mostly insensitive to changes in layer thickness, while peak intensity and FWHM are affected. Raman measurements as a function of excitation wavelength (473, 532, 633, 785 nm) show a significant increase of the peak intensities when using a 473 nm excitation source, suggesting a near resonant condition. Low-temperature Raman measurements carried out at 7.6 K did not show any changes in the phonon modes and their symmetries, suggesting that the observed Raman modes may not be sensitive to the structural phase transition. Magneto-Raman measurements carried out at 140 and 2 K between -2 to 2 T show that Raman modes are not magnetically coupled. Overall, the study presented here significantly advances the fundamental understanding of the layered material Nb3Cl8 which can be further exploited for future applications.|
|**2023-06-20**|**A DFT Study on the Mechanical, Electronic, Thermodynamic, and Optical Properties of GaN and AlN Counterparts of Biphenylene Network**|Kleuton Antunes Lopes Lima et.al.|[2306.11881v1](http://arxiv.org/abs/2306.11881v1)|null|The biphenylene network (BPN) is a notable achievement in recent fabrication endeavors for conceiving new 2D materials. The stability of its boron nitride counterpart, BN-BPN, has been confirmed through numerical investigations. In this study, we conducted a density functional theory (DFT) analysis to examine the mechanical, electronic, thermodynamic, and optical properties of two other group-III counterparts of BPN: gallium nitride (BPN-GaN) and aluminum nitride (BPN-AlN). Our findings reveal that the band gap values for BPN-GaN and BPN-AlN are 2.3 eV and 3.2 eV, respectively, at the HSE06 level. At the GGA/PBE level, we found band gap values of 1.8 eV and 2.3 eV for BPN-GaN and BPN-AlN, respectively. Phonon calculations and ab initio molecular dynamics (AIMD) simulations suggest that BPN-AlN has good structural and dynamic stabilities. On the other hand, BPN-GaN displayed negative phonon frequencies, suggesting potential instability. Nevertheless, results from AIMD simulations point to its structural integrity with no bond reconstructions at 1000 K. These materials exhibit noteworthy UV activity, presenting promising prospects as UV collectors. The thermodynamic properties reveal that the heat capacity of both BPN-AlN and BPN-GaN increases with temperature, eventually reaching the Dulong-Petit limit at around 800 K. We also performed calculations to determine the elastic stiffness constants, Young's modulus, and Poisson ratio for both BPN-GaN and BPN-AlN, providing valuable insights into their mechanical properties.|

## Electromyography

### Electromyography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Influence of Force-Length Relationship and Task-Specific Constraints on Finger Force-Generating Capacities**|Benjamin Goislard de Monsabert et.al.|[2306.12842v1](http://arxiv.org/abs/2306.12842v1)|null|Grip strength loss in extended and flexed wrist postures has been explained by reduced force-generating capacities of extrinsic finger flexor resulting from non-optimal length, owing to the force-length relationship. Recent works suggested that other muscles, especially wrist extensors, participate in this grip strength loss. The objective of this study was to clarify the role of the force-length relationship in finger force production. 18 participants performed maximal isometric finger force production during pinch grip (Pinch) and four-finger pressing (Press) tasks in four different wrist postures (extended, flexed, neutral, spontaneous). The maximum finger force (MFF), finger and wrist joint angles, as well as activation of four muscles were determined using dynamometry, motion capture, and electromyography. The force and length of the four muscles were estimated from joint angles and muscle activation using a musculoskeletal model. MFF decreased for flexed wrist during Pinch but remained stable across wrist postures during Press. The results suggested that the loss of pinch grip force in deviated wrist posture is partially related to force-length relationship of finger extensors. In opposition, MFF during Press was not influenced by the modulation of muscle capacities but was probably first limited by mechanical and neural factors related to finger interdependence|
|**2023-05-28**|**Multi-Modal Wireless Flexible Gel-Free Sensors with Edge Deep Learning for Detecting and Alerting Freezing of Gait in Parkinson's Patients**|Yuhan Hou et.al.|[2305.17629v1](http://arxiv.org/abs/2305.17629v1)|null|Freezing of gait (FoG) is a debilitating symptom of Parkinson's disease (PD). This work develops flexible wearable sensors that can detect FoG and alert patients and companions to help prevent falls. FoG is detected on the sensors using a deep learning (DL) model with multi-modal sensory inputs collected from distributed wireless sensors. Two types of wireless sensors are developed, including: (1) a C-shape central node placed around the patient's ears, which collects electroencephalogram (EEG), detects FoG using an on-device DL model, and generates auditory alerts when FoG is detected; (2) a stretchable patch-type sensor attached to the patient's legs, which collects electromyography (EMG) and movement information from accelerometers. The patch-type sensors wirelessly send collected data to the central node through low-power ultra-wideband (UWB) transceivers. All sensors are fabricated on flexible printed circuit boards. Adhesive gel-free acetylene carbon black and polydimethylsiloxane electrodes are fabricated on the flexible substrate to allow conformal wear over the long term. Custom integrated circuits (IC) are developed in 180 nm CMOS technology and used in both types of sensors for signal acquisition, digitization, and wireless communication. A novel lightweight DL model is trained using multi-modal sensory data. The inference of the DL model is performed on a low-power microcontroller in the central node. The DL model achieves a high detection sensitivity of 0.81 and a specificity of 0.88. The developed wearable sensors are ready for clinical experiments and hold great promise in improving the quality of life of patients with PD. The proposed design methodologies can be used in wearable medical devices for the monitoring and treatment of a wide range of neurodegenerative diseases.|
|**2023-05-26**|**A Multi-Resolution Physics-Informed Recurrent Neural Network: Formulation and Application to Musculoskeletal Systems**|Karan Taneja et.al.|[2305.16593v1](http://arxiv.org/abs/2305.16593v1)|null|This work presents a multi-resolution physics-informed recurrent neural network (MR PI-RNN), for simultaneous prediction of musculoskeletal (MSK) motion and parameter identification of the MSK systems. The MSK application was selected as the model problem due to its challenging nature in mapping the high-frequency surface electromyography (sEMG) signals to the low-frequency body joint motion controlled by the MSK and muscle contraction dynamics. The proposed method utilizes the fast wavelet transform to decompose the mixed frequency input sEMG and output joint motion signals into nested multi-resolution signals. The prediction model is subsequently trained on coarser-scale input-output signals using a gated recurrent unit (GRU), and then the trained parameters are transferred to the next level of training with finer-scale signals. These training processes are repeated recursively under a transfer-learning fashion until the full-scale training (i.e., with unfiltered signals) is achieved, while satisfying the underlying dynamic equilibrium. Numerical examples on recorded subject data demonstrate the effectiveness of the proposed framework in generating a physics-informed forward-dynamics surrogate, which yields higher accuracy in motion predictions of elbow flexion-extension of an MSK system compared to the case with single-scale training. The framework is also capable of identifying muscle parameters that are physiologically consistent with the subject's kinematics data.|
|**2023-05-18**|**Adaptive Learning based Upper-Limb Rehabilitation Training System with Collaborative Robot**|Jun Hong Lim et.al.|[2305.10642v1](http://arxiv.org/abs/2305.10642v1)|null|Rehabilitation training for patients with motor disabilities usually requires specialized devices in rehabilitation centers. Home-based multi-purpose training would significantly increase treatment accessibility and reduce medical costs. While it is unlikely to equip a set of rehabilitation robots at home, we investigate the feasibility to use the general-purpose collaborative robot for rehabilitation therapies. In this work, we developed a new system for multi-purpose upper-limb rehabilitation training using a generic robot arm with human motor feedback and preference. We integrated surface electromyography, force/torque sensors, RGB-D cameras, and robot controllers with the Robot Operating System to enable sensing, communication, and control of the system. Imitation learning methods were adopted to imitate expert-provided training trajectories which could adapt to subject capabilities to facilitate in-home training. Our rehabilitation system is able to perform gross motor function and fine motor skill training with a gripper-based end-effector. We simulated system control in Gazebo and training effects (muscle activation level) in OpenSim and evaluated its real performance with human subjects. For all the subjects enrolled, our system achieved better training outcomes compared to specialist-assisted rehabilitation under the same conditions. Our work demonstrates the potential of utilizing collaborative robots for in-home motor rehabilitation training.|
|**2023-05-06**|**Electromyography Signal Classification Using Deep Learning**|Mekia Shigute Gaso et.al.|[2305.04006v1](http://arxiv.org/abs/2305.04006v1)|null|We have implemented a deep learning model with L2 regularization and trained it on Electromyography (EMG) data. The data comprises of EMG signals collected from control group, myopathy and ALS patients. Our proposed deep neural network consists of eight layers; five fully connected, two batch normalization and one dropout layers. The data is divided into training and testing sections by subsequently dividing the training data into sub-training and validation sections. Having implemented this model, an accuracy of 99 percent is achieved on the test data set. The model was able to distinguishes the normal cases (control group) from the others at a precision of 100 percent and classify the myopathy and ALS with high accuracy of 97.4 and 98.2 percents, respectively. Thus we believe that, this highly improved classification accuracies will be beneficial for their use in the clinical diagnosis of neuromuscular disorders.|
|**2023-04-08**|**Overview of processing techniques for surface electromyography signals**|Alejandra Manjarres-Triana et.al.|[2304.04098v1](http://arxiv.org/abs/2304.04098v1)|null|Surface electromyography (sEMG) is a technology to assess muscle activation, which is an important component in applications related to diagnosis, treatment, progression assessment, and rehabilitation of specific individuals' conditions. Recently, sEMG potential has been shown, since it can be used in a non-invasive manner; nevertheless, it requires careful signal analysis to support health professionals reliably. This paper briefly described the basic concepts involved in the sEMG, such as the physiology of the muscles, the data acquisition, the signal processing techniques, and classification methods that may be used to identify disorders or signs of abnormalities according to muscular patterns. Specifically, classification methods encompass digital signal processing techniques and machine learning with high potential in the field. We hope that this work serves as an introduction to researchers interested in this field.|
|**2023-04-02**|**A Framework and Call to Action for the Future Development of EMG-Based Input in HCI**|Ethan Eddy et.al.|[2304.00582v1](http://arxiv.org/abs/2304.00582v1)|null|Electromyography (EMG) has been explored as an HCI input modality following a long history of success for prosthesis control. While EMG has the potential to address a range of hands-free interaction needs, it has yet to be widely accepted outside of prosthetics due to a perceived lack of robustness and intuitiveness. To understand how EMG input systems can be better designed, we sampled the ACM digital library to identify limitations in the approaches taken. Leveraging these works in combination with our research group's extensive interdisciplinary experience in this field, four themes emerged (1) interaction design, (2) model design, (3) system evaluation, and (4) reproducibility. Using these themes, we provide a step-by-step framework for designing EMG-based input systems to strengthen the foundation on which EMG-based interactions are built. Additionally, we provide a call-to-action for researchers to unlock the hidden potential of EMG as a widely applicable and highly usable input modality.|
|**2023-03-13**|**Discriminative sEMG-based features to assess damping ability and interpret activation patterns in lower-limb muscles of ACLR athletes**|Mehran Hatamzadeh et.al.|[2303.06954v1](http://arxiv.org/abs/2303.06954v1)|null|Objective: The main goal of the athletes who undergo anterior cruciate ligament reconstruction (ACLR) surgery is a successful return-to-sport. At this stage, identifying muscular deficits becomes important. Hence, in this study, three discriminative features based on surface electromyographic signals (sEMG) acquired in a dynamic protocol are introduced to assess the damping ability and interpret activation patterns in lower-limb muscles of ACLR athletes. Methods: The features include the median frequency of the power spectrum density (PSD), the relative percentage of the equivalent damping or equivalent stiffness derived from the median frequency, and the energy of the signals in the time-frequency plane of the pseudo-Wigner-Ville distribution (PWVD). To evaluate the features, 11 healthy and 11 ACLR athletes (6 months post-reconstruction surgery) were recruited to acquire the sEMG signals from the medial and the lateral parts of the hamstrings, quadriceps, and gastrocnemius muscles in pre- and post-fatigue single-leg landings. Results: A significant damping deficiency is observed in the hamstring muscles of ACLR athletes by evaluating the proposed features. This deficiency indicates that more attention should be paid to this muscle of ACLR athletes in pre-return-to-sport rehabilitations. Conclusion: The quality of electromyography-based pre-return-to-sport assessments on ACLR subjects depends on the sEMG acquisition protocol, as well as the type and nature of the extracted features. Hence, combinatorial application of both energy-based features (derived from the PWVD) and power-based features (derived from the PSD) could facilitate the assessment process by providing additional biomechanical information regarding the behavior of the muscles surrounding the knee.|
|**2023-03-11**|**AI-Enhanced Intensive Care Unit: Revolutionizing Patient Care with Pervasive Sensing**|Subhash Nerella et.al.|[2303.06252v1](http://arxiv.org/abs/2303.06252v1)|null|The intensive care unit (ICU) is a specialized hospital space where critically ill patients receive intensive care and monitoring. Comprehensive monitoring is imperative in assessing patients conditions, in particular acuity, and ultimately the quality of care. However, the extent of patient monitoring in the ICU is limited due to time constraints and the workload on healthcare providers. Currently, visual assessments for acuity, including fine details such as facial expressions, posture, and mobility, are sporadically captured, or not captured at all. These manual observations are subjective to the individual, prone to documentation errors, and overburden care providers with the additional workload. Artificial Intelligence (AI) enabled systems has the potential to augment the patient visual monitoring and assessment due to their exceptional learning capabilities. Such systems require robust annotated data to train. To this end, we have developed pervasive sensing and data processing system which collects data from multiple modalities depth images, color RGB images, accelerometry, electromyography, sound pressure, and light levels in ICU for developing intelligent monitoring systems for continuous and granular acuity, delirium risk, pain, and mobility assessment. This paper presents the Intelligent Intensive Care Unit (I2CU) system architecture we developed for real-time patient monitoring and visual assessment.|
|**2023-02-19**|**Estimation and Early Prediction of Grip Force Based on sEMG Signals and Deep Recurrent Neural Networks**|Atusa Ghorbani et.al.|[2302.09555v1](http://arxiv.org/abs/2302.09555v1)|null|Hands are used for communicating with the surrounding environment and have a complex structure that enables them to perform various tasks with their multiple degrees of freedom. Hand amputation can prevent a person from performing their daily activities. In that event, finding a suitable, fast, and reliable alternative for the missing limb can affect the lives of people who suffer from such conditions. As the most important use of the hands is to grasp objects, the purpose of this study is to accurately predict gripping force from surface electromyography (sEMG) signals during a pinch-type grip. In that regard, gripping force and sEMG signals are derived from 10 healthy subjects. Results show that for this task, recurrent networks outperform nonrecurrent ones, such as a fully connected multilayer perceptron (MLP) network. Gated recurrent unit (GRU) and long short-term memory (LSTM) networks can predict the gripping force with R-squared values of 0.994 and 0.992, respectively, and a prediction rate of over 1300 predictions per second. The predominant advantage of using such frameworks is that the gripping force can be predicted straight from preprocessed sEMG signals without any form of feature extraction, not to mention the ability to predict future force values using larger prediction horizons adequately. The methods presented in this study can be used in the myoelectric control of prosthetic hands or robotic grippers.|
|**2023-02-17**|**Sleep Model -- A Sequence Model for Predicting the Next Sleep Stage**|Iksoo Choi et.al.|[2302.12709v1](http://arxiv.org/abs/2302.12709v1)|null|As sleep disorders are becoming more prevalent there is an urgent need to classify sleep stages in a less disturbing way.In particular, sleep-stage classification using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical $n$-gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the $n$-gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.|
|**2023-02-15**|**Automated Movement Detection with Dirichlet Process Mixture Models and Electromyography**|Navin Cooray et.al.|[2302.07509v1](http://arxiv.org/abs/2302.07509v1)|null|Numerous sleep disorders are characterised by movement during sleep, these include rapid-eye movement sleep behaviour disorder (RBD) and periodic limb movement disorder. The process of diagnosing movement related sleep disorders requires laborious and time-consuming visual analysis of sleep recordings. This process involves sleep clinicians visually inspecting electromyogram (EMG) signals to identify abnormal movements. The distribution of characteristics that represent movement can be diverse and varied, ranging from brief moments of tensing to violent outbursts. This study proposes a framework for automated limb-movement detection by fusing data from two EMG sensors (from the left and right limb) through a Dirichlet process mixture model. Several features are extracted from 10 second mini-epochs, where each mini-epoch has been classified as 'leg-movement' or 'no leg-movement' based on annotations of movement from sleep clinicians. The distributions of the features from each category can be estimated accurately using Gaussian mixture models with the Dirichlet process as a prior. The available dataset includes 36 participants that have all been diagnosed with RBD. The performance of this framework was evaluated by a 10-fold cross validation scheme (participant independent). The study was compared to a random forest model and outperformed it with a mean accuracy, sensitivity, and specificity of 94\%, 48\%, and 95\%, respectively. These results demonstrate the ability of this framework to automate the detection of limb movement for the potential application of assisting clinical diagnosis and decision-making.|
|**2023-02-08**|**Simplified markerless stride detection pipeline (sMaSDP) for surface EMG segmentation**|Rafael Castro Aguiar et.al.|[2302.04243v1](http://arxiv.org/abs/2302.04243v1)|null|People with mobility impairments are often recommended for gait assessment studies to diagnose their condition and to select appropriate physiotherapy to improve their mobility. These studies are often conducted in clinical or lab settings, where subjects are assessed in a foreign environment, which may influence their motivation, coordination and overall mobility. Alternatively, if the subject's gait could be assessed in their daily-lives, in unconstrained settings, a more naturalistic gait assessment could be performed. Kinematic analysis of a gait pattern on its own may not be sufficient to characterise a subject's mobility. To better diagnose gait deficiencies, analysis of the patient's muscle activity should be conducted as well. To do so, gait studies should collect, synchronously, Electromyography (EMG) and kinematic data. This method introduces a simplified markerless gait event detection pipeline for the segmentation of EMG signals, via synchronously recorded Inertial Measurement Unit (IMU) data. In an unconstrained walking experiment, healthy subjects walk through a designed course with their kinematic and EMG data recorded. This course comprises 5 different walking modalities (level walking, ramp up/down, staircase up/down), mimicking everyday walking. Through timepoint matching, segmentation and filtering, we generate an algorithm that detects heel-strike (HS) events using a single IMU, and isolates EMG activity of gait cycles, in the different walking modalities. This gait event detection algorithm can be adapted to different datasets, and was tested in both healthy and Parkinson's Disease (PD) gait. Results demonstrate the extracted muscle activity levels in a healthy subject's level ground walking, and the extracted HS events of a PD patient. Adjustments to algorithm parameters are possible (e.g., expected velocity, cadence) and can further increase the detection accuracy.|
|**2023-02-01**|**Upper-limb Geometric MyoPassivity Map for Physical Human-Robot Interaction**|Xingyuan Zhou et.al.|[2302.00495v1](http://arxiv.org/abs/2302.00495v1)|null|The intrinsic biomechanical characteristic of the human upper limb plays a central role in absorbing the interactive energy during physical human-robot interaction (pHRI). We have recently shown that based on the concept of ``Excess of Passivity (EoP)," from nonlinear control theory, it is possible to decode such energetic behavior for both upper and lower limbs. The extracted knowledge can be used in the design of controllers for optimizing the transparency and fidelity of force fields in human-robot interaction and in haptic systems. In this paper, for the first time, we investigate the frequency behavior of the passivity map for the upper limb when the muscle co-activation was controlled in real-time through visual electromyographic feedback. Five healthy subjects (age: 27 +/- 5) were included in this study. The energetic behavior was evaluated at two stimulation frequencies at eight interaction directions over two controlled muscle co-activation levels. Electromyography (EMG) was captured using the Delsys Wireless Trigno system. Results showed a correlation between EMG and EoP, which was further altered by increasing the frequency. The proposed energetic behavior is named the Geometric MyoPassivity (GMP) map. The findings indicate that the GMP map has the potential to be used in real-time to quantify the absorbable energy, thus passivity margin of stability for upper limb interaction during pHRI.|
|**2023-01-31**|**A Prototype System for High Frame Rate Ultrasound Imaging based Prosthetic Arm Control**|Ayush Singh et.al.|[2301.13809v3](http://arxiv.org/abs/2301.13809v3)|null|The creation of unique control methods for a hand prosthesis is still a problem that has to be addressed. The best choice of a human-machine interface (HMI) that should be used to enable natural control is still a challenge. Surface electromyography (sEMG), the most popular option, has a variety of difficult-to-fix issues (electrode displacement, sweat, fatigue). The ultrasound imaging-based methodology offers a means of recognising complex muscle activity and configuration with a greater SNR and less hardware requirements as compared to sEMG. In this study, a prototype system for high frame rate ultrasound imaging for prosthetic arm control is proposed. Using the proposed framework, a virtual robotic hand simulation is developed that can mimic a human hand as illustrated in the link [10]. The proposed classification model simulating four hand gestures has a classification accuracy of more than 90%.|
|**2023-01-23**|**Long-term stable Electromyography classification using Canonical Correlation Analysis**|Elisa Donati et.al.|[2301.09729v1](http://arxiv.org/abs/2301.09729v1)|null|Discrimination of hand gestures based on the decoding of surface electromyography (sEMG) signals is a well-establish approach for controlling prosthetic devices and for Human-Machine Interfaces (HMI). However, despite the promising results achieved by this approach in well-controlled experimental conditions, its deployment in long-term real-world application scenarios is still hindered by several challenges. One of the most critical challenges is maintaining high EMG data classification performance across multiple days without retraining the decoding system. The drop in performance is mostly due to the high EMG variability caused by electrodes shift, muscle artifacts, fatigue, user adaptation, or skin-electrode interfacing issues. Here we propose a novel statistical method based on canonical correlation analysis (CCA) that stabilizes EMG classification performance across multiple days for long-term control of prosthetic devices. We show how CCA can dramatically decrease the performance drop of standard classifiers observed across days, by maximizing the correlation among multiple-day acquisition data sets. Our results show how the performance of a classifier trained on EMG data acquired only of the first day of the experiment maintains 90% relative accuracy across multiple days, compensating for the EMG data variability that occurs over long-term periods, using the CCA transformation on data obtained from a small number of gestures. This approach eliminates the need for large data sets and multiple or periodic training sessions, which currently hamper the usability of conventional pattern recognition based approaches|
|**2023-01-23**|**High-density magnetomyography is superior over surface electromyography for the decomposition of motor units: a simulation study**|Thomas Klotz et.al.|[2301.09494v1](http://arxiv.org/abs/2301.09494v1)|null|Studying motor units (MUs) is essential for understanding motor control, the detection of neuromuscular disorders and the control of human-machine interfaces. Individual motor unit firings are currently identified in vivo by decomposing electromyographic (EMG) signals. Due to our body's electric properties, individual motor units can only be separated to a limited extent with surface EMG. Unlike electrical signals, magnetic fields pass through biological tissues without distortion. This physical property and emerging technology of quantum sensors make magnetomyography (MMG) a highly promising methodology. However, the full potential of MMG to study neuromuscular physiology has not yet been explored. In this work, we perform in silico trials that combine a biophysical model of EMG and MMG with state-of-the-art algorithms for the decomposition of motor units. This allows the prediction of an upper-bound for the motor unit decomposition accuracy. It is shown that non-invasive MMG is superior over surface EMG for the robust identification of the discharge patterns of individual motor units. Decomposing MMG instead of EMG increased the number of identifiable motor units by 71%. Notably, MMG exhibits a less pronounced bias to detect superficial motor units. The presented simulations provide insights into methods to study the neuromuscular system non-invasively and in vivo that would not be easily feasible by other means. Hence, this study provides guidance for the development of novel biomedical technologies.|
|**2023-01-13**|**Analysis of LGM Model for sEMG Signals related to Weight Training**|Durgesh Kusuru et.al.|[2301.05417v1](http://arxiv.org/abs/2301.05417v1)|null|Statistical models of Surface electromyography (sEMG) signals have several applications such as better understanding of sEMG signal generation, improved pattern recognition based control of wearable exoskeletons and prostheses, improving training strategies in sports activities, and EMG simulation studies. Most of the existing studies analysed the statistical model of sEMG signals acquired under isometric contractions. However, there is no study that addresses the statistical model under isotonic contractions. In this work, a new dataset, electromyography analysis of human activities - database 2 (EMAHA-DB2) is developed. It consists of two experiments based on both isometric and isotonic activities during weight training. Previously, a novel Laplacian-Gaussian Mixture (LGM) model was demonstrated for a few benchmark datasets consisting of basic movements and gestures. In this work, the model suitability analysis is extended to the EMAHA-DB2 dataset. Further, the LGM model is compared with three existing statistical models including the recent scale-mixture model. According to qualitative and quantitative analyses, the LGM model has a better fit to the empirical pdf of the recorded sEMG signals compared with the scale mixture model and the other standard models. The variance and mixing weight of the Laplacian component of the signal are analyzed with respect to the type of muscle, type of muscle contraction, dumb-bell weight and training experience of the subjects. The sEMG variance (the Laplacian component) increases with respect to the weights, is greater for isotonic activity especially for the biceps. For isotonic activity, the signal variance increases with training experience. Importantly, the ratio of the variances from the two muscle sites is observed to be nearly independent of the lifted weight and consistently increases with the training experience.|
|**2023-01-09**|**EMAHA-DB1: A New Upper Limb sEMG Dataset for Classification of Activities of Daily Living**|Naveen Kumar Karnam et.al.|[2301.03325v1](http://arxiv.org/abs/2301.03325v1)|null|In this paper, we present electromyography analysis of human activity - database 1 (EMAHA-DB1), a novel dataset of multi-channel surface electromyography (sEMG) signals to evaluate the activities of daily living (ADL). The dataset is acquired from 25 able-bodied subjects while performing 22 activities categorised according to functional arm activity behavioral system (FAABOS) (3 - full hand gestures, 6 - open/close office draw, 8 - grasping and holding of small office objects, 2 - flexion and extension of finger movements, 2 - writing and 1 - rest). The sEMG data is measured by a set of five Noraxon Ultium wireless sEMG sensors with Ag/Agcl electrodes placed on a human hand. The dataset is analyzed for hand activity recognition classification performance. The classification is performed using four state-ofthe-art machine learning classifiers, including Random Forest (RF), Fine K-Nearest Neighbour (KNN), Ensemble KNN (sKNN) and Support Vector Machine (SVM) with seven combinations of time domain and frequency domain feature sets. The state-of-theart classification accuracy on five FAABOS categories is 83:21% by using the SVM classifier with the third order polynomial kernel using energy feature and auto regressive feature set ensemble. The classification accuracy on 22 class hand activities is 75:39% by the same SVM classifier with the log moments in frequency domain (LMF) feature, modified LMF, time domain statistical (TDS) feature, spectral band powers (SBP), channel cross correlation and local binary patterns (LBP) set ensemble. The analysis depicts the technical challenges addressed by the dataset. The developed dataset can be used as a benchmark for various classification methods as well as for sEMG signal analysis corresponding to ADL and for the development of prosthetics and other wearable robotics.|
|**2023-01-04**|**A Novel Power-optimized CMOS sEMG Device with Ultra Low-noise integrated with ConvNet (VGG16) for Biomedical Applications**|Ahmed Ayman - Mohamed Sabry et.al.|[2301.09570v2](http://arxiv.org/abs/2301.09570v2)|null|The needle bio-potential sensors for measuring muscle and brain activity need invasive surgical targeted muscle reinnervation (TMR) and a demanding process to maintain, but surface bio-potential sensors lack clear bio-signal reading (Signal-Interference). In this research, a novel power-optimized complementary metal-oxide-semiconductor (CMOS) Surface Electromyography (sEMG) is developed to improve the efficiency and quality of captured bio-signal for biomedical application: The early diagnosis of neurological disorders (Dystonia) and a novel compatible mind-controlled prosthetic leg with human daily activities. A novel sEMG composed of CMOS Op-Amp based PIC16F877A 8-bit CMOS Flash-based Microcontroller is utilized to minimize power consumption and data processing time. sEMG Circuit is implemented with developed analog filter along with infinite impulse response (IIR) digital filter via Fast Fourier Transform (FFT), Z-transform, and difference equations. The analysis shows a significant improvement of 169.2% noise-reduction in recorded EMG signal using developed digital filter compared to analog one according to numerical root mean square error (RMSE). Moreover, digital IIR was tested in two stages: algorithmic and real-world. As a result, IIR's algorithmic (MATLAB) and real-world RMSEs were 0.03616 and 0.05224, respectively. A notable advancement of 20.8% in data processing duration in EMG signal analysis. Optimizing VGG, AlexNet, and ResNet ConvNet as trained and tested on 15 public EEG (62-electrode) and 18 subjects' observed EMG data. The results indicate that VGG16-1D is 98.43% higher. During real testing, the accuracy was 95.8 +/- 4.6% for 16 subjects (6 Amputees-10 Dystonia). This study demonstrates the potential for sEMG, paving the way for biomedical applications.|
|**2023-01-03**|**A Laplacian Gaussian Mixture Model for Surface EMG Signals of Human Arm Activity**|Durgesh Kusuru et.al.|[2301.01080v1](http://arxiv.org/abs/2301.01080v1)|null|The probability density function (pdf) of surface Electromyography (sEMG) signals follows any one of the standalone standard distributions: the Gaussian or the Laplacian. Further, the choice of the model is dependent on muscle contraction force (MCF) levels. Hence, a unified model is proposed which explains the statistical nature of sEMG signals at different MCF levels. In this paper, we propose the Laplacian Gaussian Mixture (LGM) model for the signals recorded from upper limbs. This model is able to explain the sEMG signals from different activities corresponding to different MCF levels. The model is tested on different bench-mark sEMG data sets and is validated using both the qualitative and quantitative perspectives. It is determined that for low and medium contraction force levels the proposed mixture model is more accurate than both the Laplacian and the Gaussian models. Whereas for high contraction force level, the LGM model behaves as a Gaussian model. The mixing weights of the LGM model are analyzed and it is observed that for low and medium MCF levels both the mixing weights of LGM model do contribute. Whereas for high contraction force levels the Laplacian weight becomes weaker. The proposed LGM model for sEMG signals from upper limbs explains sEMG signals at different MCF levels. The proposed model helps in improved understanding of statistical nature of sEMG signals and better feature representation in the classification problems.|
|**2022-12-28**|**Joint Action is a Framework for Understanding Partnerships Between Humans and Upper Limb Prostheses**|Michael R. Dawson et.al.|[2212.14124v1](http://arxiv.org/abs/2212.14124v1)|null|Recent advances in upper limb prostheses have led to significant improvements in the number of movements provided by the robotic limb. However, the method for controlling multiple degrees of freedom via user-generated signals remains challenging. To address this issue, various machine learning controllers have been developed to better predict movement intent. As these controllers become more intelligent and take on more autonomy in the system, the traditional approach of representing the human-machine interface as a human controlling a tool becomes limiting. One possible approach to improve the understanding of these interfaces is to model them as collaborative, multi-agent systems through the lens of joint action. The field of joint action has been commonly applied to two human partners who are trying to work jointly together to achieve a task, such as singing or moving a table together, by effecting coordinated change in their shared environment. In this work, we compare different prosthesis controllers (proportional electromyography with sequential switching, pattern recognition, and adaptive switching) in terms of how they present the hallmarks of joint action. The results of the comparison lead to a new perspective for understanding how existing myoelectric systems relate to each other, along with recommendations for how to improve these systems by increasing the collaborative communication between each partner.|
|**2022-12-24**|**Agent-based Modeling and Simulation of Human Muscle For Development of Software to Analyze the Human Gait**|Sina Saadati et.al.|[2212.12760v1](http://arxiv.org/abs/2212.12760v1)|null|In this research, we are about to present an agentbased model of human muscle which can be used in analysis of human movement. As the model is designed based on the physiological structure of the muscle, The simulation calculations would be natural, and also, It can be possible to analyze human movement using reverse engineering methods. The model is also a suitable choice to be used in modern prostheses, because the calculation of the model is less than other machine learning models such as artificial neural network algorithms and It makes our algorithm battery-friendly. We will also devise a method that can calculate the intensity of human muscle during gait cycle using a reverse engineering solution. The algorithm called Boots is different from some optimization methods, so It would be able to compute the activities of both agonist and antagonist muscles in a joint. As a consequence, By having an agent-based model of human muscle and Boots algorithm, We would be capable to develop software that can calculate the nervous stimulation of human's lower body muscle based on the angular displacement during gait cycle without using painful methods like electromyography. By developing the application as open-source software, We are hopeful to help researchers and physicians who are studying in medical and biomechanical fields.|
|**2022-12-20**|**Pain level and pain-related behaviour classification using GRU-based sparsely-connected RNNs**|Mohammad Mahdi Dehshibi et.al.|[2212.14806v1](http://arxiv.org/abs/2212.14806v1)|null|There is a growing body of studies on applying deep learning to biometrics analysis. Certain circumstances, however, could impair the objective measures and accuracy of the proposed biometric data analysis methods. For instance, people with chronic pain (CP) unconsciously adapt specific body movements to protect themselves from injury or additional pain. Because there is no dedicated benchmark database to analyse this correlation, we considered one of the specific circumstances that potentially influence a person's biometrics during daily activities in this study and classified pain level and pain-related behaviour in the EmoPain database. To achieve this, we proposed a sparsely-connected recurrent neural networks (s-RNNs) ensemble with the gated recurrent unit (GRU) that incorporates multiple autoencoders using a shared training framework. This architecture is fed by multidimensional data collected from inertial measurement unit (IMU) and surface electromyography (sEMG) sensors. Furthermore, to compensate for variations in the temporal dimension that may not be perfectly represented in the latent space of s-RNNs, we fused hand-crafted features derived from information-theoretic approaches with represented features in the shared hidden state. We conducted several experiments which indicate that the proposed method outperforms the state-of-the-art approaches in classifying both pain level and pain-related behaviour.|
|**2022-12-06**|**TripCEAiR: A Multi-Loss minimization approach for surface EMG based Airwriting Recognition**|Ayush Tripathi et.al.|[2212.02870v3](http://arxiv.org/abs/2212.02870v3)|null|Airwriting Recognition refers to the problem of identification of letters written in space with movement of the finger. It can be seen as a special case of dynamic gesture recognition wherein the set of gestures are letters in a particular language. Surface Electromyography (sEMG) is a non-invasive approach used to capture electrical signals generated as a result of contraction and relaxation of the muscles. sEMG has been widely adopted for gesture recognition applications. Unlike static gestures, dynamic gestures are user-friendly and can be used as a method for input with applications in Human Computer Interaction. There has been limited work in recognition of dynamic gestures such as airwriting, using sEMG signals and forms the core of the current work. In this work, a multi-loss minimization framework for sEMG based airwriting recognition is proposed. The proposed framework aims at learning a feature embedding vector that minimizes the triplet loss, while simultaneously learning the parameters of a classifier head to recognize corresponding alphabets. The proposed method is validated on a dataset recorded in the lab comprising of sEMG signals from 50 participants writing English uppercase alphabets. The effect of different variations of triplet loss, triplet mining strategies and feature embedding dimension is also presented. The best-achieved accuracy was 81.26% and 65.62% in user-dependent and independent scenarios respectively by using semihard positive and hard negative triplet mining. The code for our implementation will be made available at https://github.com/ayushayt/TripCEAiR.|
|**2022-12-05**|**Muscles in Action**|Mia Chiquier et.al.|[2212.02978v3](http://arxiv.org/abs/2212.02978v3)|null|Human motion is created by, and constrained by, our muscles. We take a first step at building computer vision methods that represent the internal muscle activity that causes motion. We present a new dataset, Muscles in Action (MIA), to learn to incorporate muscle activity into human motion representations. The dataset consists of 12.5 hours of synchronized video and surface electromyography (sEMG) data of 10 subjects performing various exercises. Using this dataset, we learn a bidirectional representation that predicts muscle activation from video, and conversely, reconstructs motion from muscle activation. We evaluate our model on in-distribution subjects and exercises, as well as on out-of-distribution subjects and exercises. We demonstrate how advances in modeling both modalities jointly can serve as conditioning for muscularly consistent motion generation. Putting muscles into computer vision systems will enable richer models of virtual humans, with applications in sports, fitness, and AR/VR.|
|**2022-11-13**|**Review of medical data analysis based on spiking neural networks**|X. Li et.al.|[2212.02234v1](http://arxiv.org/abs/2212.02234v1)|null|Medical data mainly includes various biomedical signals and medical images, and doctors can make judgments on the physical condition of patients through medical data. However, the interpretation of medical data requires a lot of labor costs and may be misjudged, so many scholars use neural networks and deep learning to classify and study medical data, thereby improving doctors' work efficiency and accuracy, achieving early detection of diseases and early diagnosis, so it has a wide range of application prospects. However, traditional neural networks have disadvantages such as high energy consumption and high latency (slow calculation speed). This paper introduces the research on signal classification and disease diagnosis based on the third-generation neural network - pulse neural network in recent years, using medical data, such as electroencephalogram (EEG), electrocardiogram (ECG), electromyography (EMG), magnetic resonance imaging (MRI), etc., summarizes the advantages and disadvantages of pulse neural networks compared with traditional networks, and looks forward to the future development direction.|
|**2022-11-07**|**Novel Muscle Monitoring by Radiomyography(RMG) and Application to Hand Gesture Recognition**|Zijing Zhang et.al.|[2211.03767v1](http://arxiv.org/abs/2211.03767v1)|null|Conventional electromyography (EMG) measures the continuous neural activity during muscle contraction, but lacks explicit quantification of the actual contraction. Mechanomyography (MMG) and accelerometers only measure body surface motion, while ultrasound, CT-scan and MRI are restricted to in-clinic snapshots. Here we propose a novel radiomyography (RMG) for continuous muscle actuation sensing that can be wearable and touchless, capturing both superficial and deep muscle groups. We verified RMG experimentally by a forearm wearable sensor for detailed hand gesture recognition. We first converted the radio sensing outputs to the time-frequency spectrogram, and then employed the vision transformer (ViT) deep learning network as the classification model, which can recognize 23 gestures with an average accuracy up to 99% on 8 subjects. By transfer learning, high adaptivity to user difference and sensor variation were achieved at an average accuracy up to 97%. We further demonstrated RMG to monitor eye and leg muscles and achieved high accuracy for eye movement and body postures tracking. RMG can be used with synchronous EMG to derive stimulation-actuation waveforms for many future applications in kinesiology, physiotherapy, rehabilitation, and human-machine interface.|
|**2022-10-31**|**SurfMyoAiR: A surface Electromyography based framework for Airwriting Recognition**|Ayush Tripathi et.al.|[2210.17185v1](http://arxiv.org/abs/2210.17185v1)|null|Airwriting Recognition is the task of identifying letters written in free space with finger movement. Electromyography (EMG) is a technique used to record electrical activity during muscle contraction and relaxation as a result of movement and is widely used for gesture recognition. Most of the current research in gesture recognition is focused on identifying static gestures. However, dynamic gestures are natural and user-friendly for being used as alternate input methods in Human-Computer Interaction applications. Airwriting recognition using EMG signals recorded from forearm muscles is therefore a viable solution. Since the user does not need to learn any new gestures and a large range of words can be formed by concatenating these letters, it is generalizable to a wider population. There has been limited work in recognition of airwriting using EMG signals and forms the core idea of the current work. The SurfMyoAiR dataset comprising of EMG signals recorded during writing English uppercase alphabets is constructed. Several different time-domain features to construct EMG envelope and two different time-frequency image representations: Short-Time Fourier Transform and Continuous Wavelet Transform were explored to form the input to a deep learning model for airwriting recognition. Several different deep learning architectures were exploited for this task. Additionally, the effect of various parameters such as signal length, window length and interpolation techniques on the recognition performance is comprehensively explored. The best-achieved accuracy was 78.50% and 62.19% in user-dependent and independent scenarios respectively by using Short-Time Fourier Transform in conjunction with a 2D Convolutional Neural Network based classifier. Airwriting has great potential as a user-friendly modality to be used as an alternate input method in Human-Computer Interaction applications.|
|**2022-10-27**|**Light-weighted CNN-Attention based architecture for Hand Gesture Recognition via ElectroMyography**|Soheil Zabihi et.al.|[2210.15119v1](http://arxiv.org/abs/2210.15119v1)|null|Advancements in Biological Signal Processing (BSP) and Machine-Learning (ML) models have paved the path for development of novel immersive Human-Machine Interfaces (HMI). In this context, there has been a surge of significant interest in Hand Gesture Recognition (HGR) utilizing Surface-Electromyogram (sEMG) signals. This is due to its unique potential for decoding wearable data to interpret human intent for immersion in Mixed Reality (MR) environments. To achieve the highest possible accuracy, complicated and heavy-weighted Deep Neural Networks (DNNs) are typically developed, which restricts their practical application in low-power and resource-constrained wearable systems. In this work, we propose a light-weighted hybrid architecture (HDCAM) based on Convolutional Neural Network (CNN) and attention mechanism to effectively extract local and global representations of the input. The proposed HDCAM model with 58,441 parameters reached a new state-of-the-art (SOTA) performance with 82.91% and 81.28% accuracy on window sizes of 300 ms and 200 ms for classifying 17 hand gestures. The number of parameters to train the proposed HDCAM architecture is 18.87 times less than its previous SOTA counterpart.|

## all search terms

### all search terms
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Affine Correspondences between Multi-Camera Systems for Relative Pose Estimation**|Banglei Guan et.al.|[2306.12996v1](http://arxiv.org/abs/2306.12996v1)|[link](https://github.com/jizhaox/relpose-mcs-depth)|We present a novel method to compute the relative pose of multi-camera systems using two affine correspondences (ACs). Existing solutions to the multi-camera relative pose estimation are either restricted to special cases of motion, have too high computational complexity, or require too many point correspondences (PCs). Thus, these solvers impede an efficient or accurate relative pose estimation when applying RANSAC as a robust estimator. This paper shows that the 6DOF relative pose estimation problem using ACs permits a feasible minimal solution, when exploiting the geometric constraints between ACs and multi-camera systems using a special parameterization. We present a problem formulation based on two ACs that encompass two common types of ACs across two views, i.e., inter-camera and intra-camera. Moreover, the framework for generating the minimal solvers can be extended to solve various relative pose estimation problems, e.g., 5DOF relative pose estimation with known rotation angle prior. Experiments on both virtual and real multi-camera systems prove that the proposed solvers are more efficient than the state-of-the-art algorithms, while resulting in a better relative pose accuracy. Source code is available at https://github.com/jizhaox/relpose-mcs-depth.|
|**2023-06-22**|**Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers**|Qi Jiang et.al.|[2306.12992v1](http://arxiv.org/abs/2306.12992v1)|[link](https://github.com/zju-jiangqi/pcie-part)|High-quality panoramic images with a Field of View (FoV) of 360-degree are essential for contemporary panoramic computer vision tasks. However, conventional imaging systems come with sophisticated lens designs and heavy optical components. This disqualifies their usage in many mobile and wearable applications where thin and portable, minimalist imaging systems are desired. In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to address minimalist and high-quality panoramic imaging. With less than three spherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is constructed based on the design of the Panoramic Annular Lens (PAL), but with low-quality imaging results due to aberrations and small image plane size. We propose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and Aberration Correction (SR&AC), to solve the image quality problems of MPIP, with imaging sensors of small and large pixel size, respectively. To provide a universal network for the two pipelines, we leverage the information from the Point Spread Function (PSF) of the optical system and design a PSF-aware Aberration-image Recovery Transformer (PART), in which the self-attention calculation and feature extraction are guided via PSF-aware mechanisms. We train PART on synthetic image pairs from simulation and put forward the PALHQ dataset to fill the gap of real-world high-quality PAL images for low-level vision. A comprehensive variety of experiments on synthetic and real-world benchmarks demonstrates the impressive imaging results of PCIE and the effectiveness of plug-and-play PSF-aware mechanisms. We further deliver heuristic experimental findings for minimalist and high-quality panoramic imaging. Our dataset and code will be available at https://github.com/zju-jiangqi/PCIE-PART.|
|**2023-06-22**|**Relevance-Based Compression of Cataract Surgery Videos**|Natalia Mathá et.al.|[2306.12829v1](http://arxiv.org/abs/2306.12829v1)|null|In the last decade, the need for storing videos from cataract surgery has increased significantly. Hospitals continue to improve their imaging and recording devices (e.g., microscopes and cameras used in microscopic surgery, such as ophthalmology) to enhance their post-surgical processing efficiency. The video recordings enable a lot of user-cases after the actual surgery, for example, teaching, documentation, and forensics. However, videos recorded from operations are typically stored in the internal archive without any domain-specific compression, leading to a massive storage space consumption. In this work, we propose a relevance-based compression scheme for videos from cataract surgery, which is based on content specifics of particular cataract surgery phases. We evaluate our compression scheme with three state-of-the-art video codecs, namely H.264/AVC, H.265/HEVC, and AV1, and ask medical experts to evaluate the visual quality of encoded videos. Our results show significant savings, in particular up to 95.94% when using H.264/AVC, up to 98.71% when using H.265/HEVC, and up to 98.82% when using AV1.|
|**2023-06-22**|**3D Reconstruction of Spherical Images based on Incremental Structure from Motion**|San Jiang et.al.|[2306.12770v1](http://arxiv.org/abs/2306.12770v1)|null|3D reconstruction plays an increasingly important role in modern photogrammetric systems. Conventional satellite or aerial-based remote sensing (RS) platforms can provide the necessary data sources for the 3D reconstruction of large-scale landforms and cities. Even with low-altitude UAVs (Unmanned Aerial Vehicles), 3D reconstruction in complicated situations, such as urban canyons and indoor scenes, is challenging due to the frequent tracking failures between camera frames and high data collection costs. Recently, spherical images have been extensively exploited due to the capability of recording surrounding environments from one camera exposure. Classical 3D reconstruction pipelines, however, cannot be used for spherical images. Besides, there exist few software packages for 3D reconstruction of spherical images. Based on the imaging geometry of spherical cameras, this study investigates the algorithms for the relative orientation using spherical correspondences, absolute orientation using 3D correspondences between scene and spherical points, and the cost functions for BA (bundle adjustment) optimization. In addition, an incremental SfM (Structure from Motion) workflow has been proposed for spherical images using the above-mentioned algorithms. The proposed solution is finally verified by using three spherical datasets captured by both consumer-grade and professional spherical cameras. The results demonstrate that the proposed SfM workflow can achieve the successful 3D reconstruction of complex scenes and provide useful clues for the implementation in open-source software packages. The source code of the designed SfM workflow would be made publicly available.|
|**2023-06-22**|**PEBO-SLAM: Observer design for visual inertial SLAM with convergence guarantees**|Bowen Yi et.al.|[2306.12723v1](http://arxiv.org/abs/2306.12723v1)|null|This paper introduces a new linear parameterization to the problem of visual inertial simultaneous localization and mapping (VI-SLAM) -- without any approximation -- for the case only using information from a single monocular camera and an inertial measurement unit. In this problem set, the system state evolves on the nonlinear manifold $SE(3)\times \mathbb{R}^{3n}$, on which we design dynamic extensions carefully to generate invariant foliations, such that the problem can be reformulated into online \emph{constant parameter} identification, then interestingly with linear regression models obtained. It demonstrates that VI-SLAM can be translated into a linear least squares problem, in the deterministic sense, \emph{globally} and \emph{exactly}. Based on this observation, we propose a novel SLAM observer, following the recently established parameter estimation-based observer (PEBO) methodology. A notable merit is that the proposed observer enjoys almost global asymptotic stability, requiring neither persistency of excitation nor uniform complete observability, which, however, are widely adopted in most existing works with provable stability but can hardly be assured in many practical scenarios.|
|**2023-06-22**|**One at A Time: Multi-step Volumetric Probability Distribution Diffusion for Depth Estimation**|Bohan Li et.al.|[2306.12681v1](http://arxiv.org/abs/2306.12681v1)|null|Recent works have explored the fundamental role of depth estimation in multi-view stereo (MVS) and semantic scene completion (SSC). They generally construct 3D cost volumes to explore geometric correspondence in depth, and estimate such volumes in a single step relying directly on the ground truth approximation. However, such problem cannot be thoroughly handled in one step due to complex empirical distributions, especially in challenging regions like occlusions, reflections, etc. In this paper, we formulate the depth estimation task as a multi-step distribution approximation process, and introduce a new paradigm of modeling the Volumetric Probability Distribution progressively (step-by-step) following a Markov chain with Diffusion models (VPDD). Specifically, to constrain the multi-step generation of volume in VPDD, we construct a meta volume guidance and a confidence-aware contextual guidance as conditional geometry priors to facilitate the distribution approximation. For the sampling process, we further investigate an online filtering strategy to maintain consistency in volume representations for stable training. Experiments demonstrate that our plug-and-play VPDD outperforms the state-of-the-arts for tasks of MVS and SSC, and can also be easily extended to different baselines to get improvement. It is worth mentioning that we are the first camera-based work that surpasses LiDAR-based methods on the SemanticKITTI dataset.|
|**2023-06-22**|**RXFOOD: Plug-in RGB-X Fusion for Object of Interest Detection**|Jin Ma et.al.|[2306.12621v1](http://arxiv.org/abs/2306.12621v1)|null|The emergence of different sensors (Near-Infrared, Depth, etc.) is a remedy for the limited application scenarios of traditional RGB camera. The RGB-X tasks, which rely on RGB input and another type of data input to resolve specific problems, have become a popular research topic in multimedia. A crucial part in two-branch RGB-X deep neural networks is how to fuse information across modalities. Given the tremendous information inside RGB-X networks, previous works typically apply naive fusion (e.g., average or max fusion) or only focus on the feature fusion at the same scale(s). While in this paper, we propose a novel method called RXFOOD for the fusion of features across different scales within the same modality branch and from different modality branches simultaneously in a unified attention mechanism. An Energy Exchange Module is designed for the interaction of each feature map's energy matrix, who reflects the inter-relationship of different positions and different channels inside a feature map. The RXFOOD method can be easily incorporated to any dual-branch encoder-decoder network as a plug-in module, and help the original backbone network better focus on important positions and channels for object of interest detection. Experimental results on RGB-NIR salient object detection, RGB-D salient object detection, and RGBFrequency image manipulation detection demonstrate the clear effectiveness of the proposed RXFOOD.|
|**2023-06-21**|**Arc-to-line frame registration method for ultrasound and photoacoustic image-guided intraoperative robot-assisted laparoscopic prostatectomy**|Hyunwoo Song et.al.|[2306.12590v1](http://arxiv.org/abs/2306.12590v1)|null|Purpose: To achieve effective robot-assisted laparoscopic prostatectomy, the integration of transrectal ultrasound (TRUS) imaging system which is the most widely used imaging modelity in prostate imaging is essential. However, manual manipulation of the ultrasound transducer during the procedure will significantly interfere with the surgery. Therefore, we propose an image co-registration algorithm based on a photoacoustic marker method, where the ultrasound / photoacoustic (US/PA) images can be registered to the endoscopic camera images to ultimately enable the TRUS transducer to automatically track the surgical instrument Methods: An optimization-based algorithm is proposed to co-register the images from the two different imaging modalities. The principles of light propagation and an uncertainty in PM detection were assumed in this algorithm to improve the stability and accuracy of the algorithm. The algorithm is validated using the previously developed US/PA image-guided system with a da Vinci surgical robot. Results: The target-registration-error (TRE) is measured to evaluate the proposed algorithm. In both simulation and experimental demonstration, the proposed algorithm achieved a sub-centimeter accuracy which is acceptable in practical clinics. The result is also comparable with our previous approach, and the proposed method can be implemented with a normal white light stereo camera and doesn't require highly accurate localization of the PM. Conclusion: The proposed frame registration algorithm enabled a simple yet efficient integration of commercial US/PA imaging system into laparoscopic surgical setting by leveraging the characteristic properties of acoustic wave propagation and laser excitation, contributing to automated US/PA image-guided surgical intervention applications.|
|**2023-06-21**|**Varstrometry for Off-nucleus and Dual sub-Kpc AGN (VODKA). SDSS J1608+2716: A Sub-arcsec Quadruply Lensed Quasar at $z=2.575$**|Junyao Li et.al.|[2306.12502v1](http://arxiv.org/abs/2306.12502v1)|null|We report Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3) deep IR (F160W) imaging of SDSS J1608+2716. This system, located at a redshift of $z=2.575$, was recently reported as a triple quasar candidate with subarcsecond separations ($\sim0.25''$) based on selection from Gaia astrometry and follow-up Keck adaptive optics-assisted integral field unit spectroscopy. Our new HST deep IR imaging reveals the presence of a fourth point-like component located $\sim0.9''$ away from the triple system. Additionally, we detect an edge-on disk galaxy located in between the four point sources, which appears to be in the process of merging with a fainter companion galaxy. The entire system exhibits a characteristic cusp structure in the context of strong gravitational lensing, and the observed image configuration can be successfully reproduced using a lens model based on a singular isothermal ellipsoid mass profile. These findings indicate that this system is a quadruply lensed quasar. Our results highlight the challenges associated with identifying dual/multiple quasars on $\sim$kpc scales at high redshifts, and emphasize the crucial role of deep, high-resolution IR imaging in robustly confirming such systems.|
|**2023-06-21**|**Benchmarking and Analyzing 3D-aware Image Synthesis with a Modularized Codebase**|Qiuyu Wang et.al.|[2306.12423v1](http://arxiv.org/abs/2306.12423v1)|[link](https://github.com/qiuyu96/carver)|Despite the rapid advance of 3D-aware image synthesis, existing studies usually adopt a mixture of techniques and tricks, leaving it unclear how each part contributes to the final performance in terms of generality. Following the most popular and effective paradigm in this field, which incorporates a neural radiance field (NeRF) into the generator of a generative adversarial network (GAN), we build a well-structured codebase, dubbed Carver, through modularizing the generation process. Such a design allows researchers to develop and replace each module independently, and hence offers an opportunity to fairly compare various approaches and recognize their contributions from the module perspective. The reproduction of a range of cutting-edge algorithms demonstrates the availability of our modularized codebase. We also perform a variety of in-depth analyses, such as the comparison across different types of point feature, the necessity of the tailing upsampler in the generator, the reliance on the camera pose prior, etc., which deepen our understanding of existing methods and point out some further directions of the research work. We release code and models at https://github.com/qiuyu96/Carver to facilitate the development and evaluation of this field.|
|**2023-06-21**|**Spectroscopy of the Supernova H0pe Host Galaxy at Redshift 1.78**|M. Polletta et.al.|[2306.12385v1](http://arxiv.org/abs/2306.12385v1)|null|Supernova (SN) H0pe was discovered as a new transient in James Webb Space Telescope (JWST) NIRCam images of the galaxy cluster PLCK G165.7+67.0 taken as part of the "Prime Extragalactic Areas for Reionization and Lensing Science" (PEARLS) JWST GTO program (# 1176) on 2023 March 30 (AstroNote 2023-96; Frye et al. 2023). The transient is a compact source associated with a background galaxy that is stretched and triply-imaged by the cluster's strong gravitational lensing. This paper reports spectra in the 950-1370 nm observer frame of two of the galaxy's images obtained with Large Binocular Telescope (LBT) Utility Camera in the Infrared (LUCI) in longslit mode two weeks after the \JWST\ observations. The individual average spectra show the [OII] doublet and the Balmer and 4000 Angstrom breaks at redshift z=1.783+/-0.002. The CIGALE best-fit model of the spectral energy distribution indicates that SN H0pe's host galaxy is massive (Mstar~6x10^10 Msun after correcting for a magnification factor ~7) with a predominant intermediate age (~2 Gyr) stellar population, moderate extinction, and a magnification-corrected star formation rate ~13 Msun/yr, consistent with being below the main sequence of star formation. These properties suggest that H0pe might be a type Ia SN. Additional observations of SN H0pe and its host recently carried out with JWST (JWST-DD-4446; PI: B. Frye) will be able to both determine the SN classification and confirm its association with the galaxy analyzed in this work.|
|**2023-06-21**|**Euclid: Constraining linearly scale-independent modifications of gravity with the spectroscopic and photometric primary probes**|N. Frusciante et.al.|[2306.12368v1](http://arxiv.org/abs/2306.12368v1)|null|The future Euclid space satellite mission will offer an invaluable opportunity to constrain modifications to general relativity at cosmic scales. We focus on modified gravity models characterised, at linear scales, by a scale-independent growth of perturbations while featuring different testable types of derivative screening mechanisms at smaller nonlinear scales. We consider 3 specific models, namely Jordan-Brans-Dicke (JBD), the normal branch of Dvali-Gabadadze-Porrati (nDGP) gravity and $k$-mouflage (KM) gravity. We provide forecasts from spectroscopic and photometric primary probes by Euclid on the cosmological parameters and the extra parameters of the models, respectively, $\omega_{\rm BD}$, $\Omega_{\rm rc}$ and $\epsilon_{2,0}$, which quantify the deviations from general relativity. This analysis will improve our knowledge of the cosmology of these modified gravity models. The forecasts analysis employs the Fisher matrix method applied to weak lensing (WL); photometric galaxy clustering (GC$_{ph}$); spectroscopic galaxy clustering (GC$_{sp}$) and the cross-correlation (XC) between GC$_{ph}$ and WL. For the Euclid survey specifications we define three scenarios, characterised by different cuts in $\ell$ and $k$, to assess the constraining power of nonlinear scales. For each model we consider two fiducial values for the corresponding model parameter. In an optimistic setting at 68.3\% confidence interval, with Euclid alone we find the following percentage relative errors: for $\log_{10}{\omega_{\rm BD}}$, with a fiducial value of $\omega_{\rm BD}=800$, 35% using GC$_{sp}$ alone, 3.6% using GC$_{ph}$+WL+XC and 3.3% using GC$_{ph}$+WL+XC+GC$_{sp}$; for $\log_{10}{\Omega_{\rm rc}}$, with a fiducial value of $\Omega_{\rm rc}=0.25$, we find respectively 90%, 20% and 17%; finally, for $\epsilon_{2,0}=-0.04$ respectively 5%, 0.15% and 0.14%. (abridged)|
|**2023-06-21**|**Wildfire Detection Via Transfer Learning: A Survey**|Ziliang Hong et.al.|[2306.12276v1](http://arxiv.org/abs/2306.12276v1)|null|This paper surveys different publicly available neural network models used for detecting wildfires using regular visible-range cameras which are placed on hilltops or forest lookout towers. The neural network models are pre-trained on ImageNet-1K and fine-tuned on a custom wildfire dataset. The performance of these models is evaluated on a diverse set of wildfire images, and the survey provides useful information for those interested in using transfer learning for wildfire detection. Swin Transformer-tiny has the highest AUC value but ConvNext-tiny detects all the wildfire events and has the lowest false alarm rate in our dataset.|
|**2023-06-21**|**Near infrared view on the photodissociation regions S255, S257, NGC7538 and S140**|M. S. Kirsanova et.al.|[2306.12264v1](http://arxiv.org/abs/2306.12264v1)|null|We performed photometric observations of the S255, S257, S140, NGC7358 and the Orion~Bar photo-dissociation regions (PDRs) at 2 micron using narrow-band filters centered on the Br-gamma, H2 and [FeII] lines, as well as the narrow-band Kcont and the broad-band H filters for continuum subtraction. The observations were done with the 2.5-m telescope of the SAI Caucasian Mountain Observatory and the near-infrared camera and spectrograph ASTRONIRCAM. We find several high-density arc-like structures in the Br-gamma and [FeII] images of the ionized gas in NGC7538 and extended shells and arcs visible through the H2 emission. The H ionization front and H2 dissociation front are merged in NGC7538. In S255 and S257 we detected only Br-gamma emission from the HII regions and bright H2 emission from the PDRs. The projected distance between the H ionization and H2 dissociation fronts are approx. 0.3-0.4 pc, which cannot be explained using models of a uniform medium. Most probably, the ionized and neutral gas in these PDRs is clumpy. The H-to-H2 transitions in the NGC7538, S255, S257 and S140 PDRs are gradual with no sharp borders. This conclusion also confirms the suggestion of a clumpy medium.|
|**2023-06-21**|**MimiC: Combating Client Dropouts in Federated Learning by Mimicking Central Updates**|Yuchang Sun et.al.|[2306.12212v1](http://arxiv.org/abs/2306.12212v1)|null|Federated learning (FL) is a promising framework for privacy-preserving collaborative learning. In FL, the model training tasks are distributed to clients and only the model updates need to be collected at a central server. However, when being deployed at the mobile edge network, clients (e.g., smartphones and wearables) may have unpredictable availability and randomly drop out of any training iteration, which hinders FL from achieving the convergence. This paper tackles such a critical challenge of FL. In particular, we first investigate the convergence of the classical FedAvg algorithm with arbitrary client dropouts. We find that with the common choice of a decaying learning rate, FedAvg can only oscillate within the neighborhood of a stationary point of the global loss function, which is caused by the divergence between the aggregated update and the desired central update. Motivated by this new observation, we then design a novel training algorithm named MimiC, where the server modifies each received model update based on the previous ones. The proposed modification of the received model updates is able to mimic the imaginary central update irrespective of the dropout clients. The theoretical analysis of MimiC shows that the divergence between the aggregated update and the central update diminishes with a proper choice of the learning rates, leading to its convergence. Simulation results further demonstrate that MimiC maintains stable convergence performance in the presence of client dropouts and learns better models than the baseline methods.|
|**2023-06-20**|**NILUT: Conditional Neural Implicit 3D Lookup Tables for Image Enhancement**|Marcos V. Conde et.al.|[2306.11920v1](http://arxiv.org/abs/2306.11920v1)|[link](https://github.com/mv-lab/nilut)|3D lookup tables (3D LUTs) are a key component for image enhancement. Modern image signal processors (ISPs) have dedicated support for these as part of the camera rendering pipeline. Cameras typically provide multiple options for picture styles, where each style is usually obtained by applying a unique handcrafted 3D LUT. Current approaches for learning and applying 3D LUTs are notably fast, yet not so memory-efficient, as storing multiple 3D LUTs is required. For this reason and other implementation limitations, their use on mobile devices is less popular. In this work, we propose a Neural Implicit LUT (NILUT), an implicitly defined continuous 3D color transformation parameterized by a neural network. We show that NILUTs are capable of accurately emulating real 3D LUTs. Moreover, a NILUT can be extended to incorporate multiple styles into a single network with the ability to blend styles implicitly. Our novel approach is memory-efficient, controllable and can complement previous methods, including learned ISPs. Code, models and dataset available at: https://github.com/mv-lab/nilut|
|**2023-06-20**|**Self-supervised Multi-task Learning Framework for Safety and Health-Oriented Connected Driving Environment Perception using Onboard Camera**|Shaocheng Jia et.al.|[2306.11822v1](http://arxiv.org/abs/2306.11822v1)|null|Cutting-edge connected vehicle (CV) technologies have drawn much attention in recent years. The real-time traffic data captured by a CV can be shared with other CVs and data centers so as to open new possibilities for solving diverse transportation problems. However, imagery captured by onboard cameras in a connected environment, are not sufficiently investigated, especially for safety and health-oriented visual perception. In this paper, a bidirectional process of image synthesis and decomposition (BPISD) approach is proposed, and thus a novel self-supervised multi-task learning framework, to simultaneously estimate depth map, atmospheric visibility, airlight, and PM2.5 mass concentration, in which depth map and visibility are considered highly associated with traffic safety, while airlight and PM2.5 mass concentration are directly correlated with human health. Both the training and testing phases of the proposed system solely require a single image as input. Due to the innovative training pipeline, the depth estimation network can manage various levels of visibility conditions and overcome inherent problems in current image-synthesis-based depth estimation, thereby generating high-quality depth maps even in low-visibility situations and further benefiting accurate estimations of visibility, airlight, and PM2.5 mass concentration. Extensive experiments on the synthesized data from the KITTI and real-world data collected in Beijing demonstrate that the proposed method can (1) achieve performance competitive in depth estimation as compared with state-of-the-art methods when taking clear images as input; (2) predict vivid depth map for images contaminated by various levels of haze; and (3) accurately estimate visibility, airlight, and PM2.5 mass concentrations. Beneficial applications can be developed based on the presented work to improve traffic safety, air quality, and public health.|
|**2023-06-20**|**BEVScope: Enhancing Self-Supervised Depth Estimation Leveraging Bird's-Eye-View in Dynamic Scenarios**|Yucheng Mao et.al.|[2306.11598v1](http://arxiv.org/abs/2306.11598v1)|null|Depth estimation is a cornerstone of perception in autonomous driving and robotic systems. The considerable cost and relatively sparse data acquisition of LiDAR systems have led to the exploration of cost-effective alternatives, notably, self-supervised depth estimation. Nevertheless, current self-supervised depth estimation methods grapple with several limitations: (1) the failure to adequately leverage informative multi-camera views. (2) the limited capacity to handle dynamic objects effectively. To address these challenges, we present BEVScope, an innovative approach to self-supervised depth estimation that harnesses Bird's-Eye-View (BEV) features. Concurrently, we propose an adaptive loss function, specifically designed to mitigate the complexities associated with moving objects. Empirical evaluations conducted on the Nuscenes dataset validate our approach, demonstrating competitive performance. Code will be released at https://github.com/myc634/BEVScope.|
|**2023-06-20**|**The Ecological Fallacy in Annotation: Modelling Human Label Variation goes beyond Sociodemographics**|Matthias Orlikowski et.al.|[2306.11559v1](http://arxiv.org/abs/2306.11559v1)|[link](https://github.com/morlikowski/ecological-fallacy)|Many NLP tasks exhibit human label variation, where different annotators give different labels to the same texts. This variation is known to depend, at least in part, on the sociodemographics of annotators. Recent research aims to model individual annotator behaviour rather than predicting aggregated labels, and we would expect that sociodemographic information is useful for these models. On the other hand, the ecological fallacy states that aggregate group behaviour, such as the behaviour of the average female annotator, does not necessarily explain individual behaviour. To account for sociodemographics in models of individual annotator behaviour, we introduce group-specific layers to multi-annotator models. In a series of experiments for toxic content detection, we find that explicitly accounting for sociodemographic attributes in this way does not significantly improve model performance. This result shows that individual annotation behaviour depends on much more than just sociodemographics.|
|**2023-06-20**|**Bullying10K: A Neuromorphic Dataset towards Privacy-Preserving Bullying Recognition**|Yiting Dong et.al.|[2306.11546v1](http://arxiv.org/abs/2306.11546v1)|null|The prevalence of violence in daily life poses significant threats to individuals' physical and mental well-being. Using surveillance cameras in public spaces has proven effective in proactively deterring and preventing such incidents. However, concerns regarding privacy invasion have emerged due to their widespread deployment. To address the problem, we leverage Dynamic Vision Sensors (DVS) cameras to detect violent incidents and preserve privacy since it captures pixel brightness variations instead of static imagery. We introduce the Bullying10K dataset, encompassing various actions, complex movements, and occlusions from real-life scenarios. It provides three benchmarks for evaluating different tasks: action recognition, temporal action localization, and pose estimation. With 10,000 event segments, totaling 12 billion events and 255 GB of data, Bullying10K contributes significantly by balancing violence detection and personal privacy persevering. And it also poses a challenge to the neuromorphic dataset. It will serve as a valuable resource for training and developing privacy-protecting video systems. The Bullying10K opens new possibilities for innovative approaches in these domains.|
|**2023-06-20**|**End-to-end 2D-3D Registration between Image and LiDAR Point Cloud for Vehicle Localization**|Guangming Wang et.al.|[2306.11346v1](http://arxiv.org/abs/2306.11346v1)|null|Robot localization using a previously built map is essential for a variety of tasks including highly accurate navigation and mobile manipulation. A popular approach to robot localization is based on image-to-point cloud registration, which combines illumination-invariant LiDAR-based mapping with economical image-based localization. However, the recent works for image-to-point cloud registration either divide the registration into separate modules or project the point cloud to the depth image to register the RGB and depth images. In this paper, we present I2PNet, a novel end-to-end 2D-3D registration network. I2PNet directly registers the raw 3D point cloud with the 2D RGB image using differential modules with a unique target. The 2D-3D cost volume module for differential 2D-3D association is proposed to bridge feature extraction and pose regression. 2D-3D cost volume module implicitly constructs the soft point-to-pixel correspondence on the intrinsic-independent normalized plane of the pinhole camera model. Moreover, we introduce an outlier mask prediction module to filter the outliers in the 2D-3D association before pose regression. Furthermore, we propose the coarse-to-fine 2D-3D registration architecture to increase localization accuracy. We conduct extensive localization experiments on the KITTI Odometry and nuScenes datasets. The results demonstrate that I2PNet outperforms the state-of-the-art by a large margin. In addition, I2PNet has a higher efficiency than the previous works and can perform the localization in real-time. Moreover, we extend the application of I2PNet to the camera-LiDAR online calibration and demonstrate that I2PNet outperforms recent approaches on the online calibration task.|
|**2023-06-20**|**Meerkat Behaviour Recognition Dataset**|Mitchell Rogers et.al.|[2306.11326v1](http://arxiv.org/abs/2306.11326v1)|null|Recording animal behaviour is an important step in evaluating the well-being of animals and further understanding the natural world. Current methods for documenting animal behaviour within a zoo setting, such as scan sampling, require excessive human effort, are unfit for around-the-clock monitoring, and may produce human-biased results. Several animal datasets already exist that focus predominantly on wildlife interactions, with some extending to action or behaviour recognition. However, there is limited data in a zoo setting or data focusing on the group behaviours of social animals. We introduce a large meerkat (Suricata Suricatta) behaviour recognition video dataset with diverse annotated behaviours, including group social interactions, tracking of individuals within the camera view, skewed class distribution, and varying illumination conditions. This dataset includes videos from two positions within the meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with 848,400 annotated frames across 20 videos and 15 unannotated videos.|
|**2023-06-20**|**Spatiotemporal Pyramidal CNN with Depth-Wise Separable Convolution for Eye Blinking Detection in the Wild**|Lan Anh Thi Nguy et.al.|[2306.11287v1](http://arxiv.org/abs/2306.11287v1)|null|Eye blinking detection in the wild plays an essential role in deception detection, driving fatigue detection, etc. Despite the fact that numerous attempts have already been made, the majority of them have encountered difficulties, such as the derived eye images having different resolutions as the distance between the face and the camera changes; or the requirement of a lightweight detection model to obtain a short inference time in order to perform in real-time. In this research, two problems are addressed: how the eye blinking detection model can learn efficiently from different resolutions of eye pictures in diverse conditions; and how to reduce the size of the detection model for faster inference time. We propose to utilize upsampling and downsampling the input eye images to the same resolution as one potential solution for the first problem, then find out which interpolation method can result in the highest performance of the detection model. For the second problem, although a recent spatiotemporal convolutional neural network used for eye blinking detection has a strong capacity to extract both spatial and temporal characteristics, it remains having a high number of network parameters, leading to high inference time. Therefore, using Depth-wise Separable Convolution rather than conventional convolution layers inside each branch is considered in this paper as a feasible solution.|
|**2023-06-20**|**GUMSum: Multi-Genre Data and Evaluation for English Abstractive Summarization**|Yang Janet Liu et.al.|[2306.11256v1](http://arxiv.org/abs/2306.11256v1)|null|Automatic summarization with pre-trained language models has led to impressively fluent results, but is prone to 'hallucinations', low performance on non-news genres, and outputs which are not exactly summaries. Targeting ACL 2023's 'Reality Check' theme, we present GUMSum, a small but carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. Summaries are highly constrained, focusing on substitutive potential, factuality, and faithfulness. We present guidelines and evaluate human agreement as well as subjective judgments on recent system outputs, comparing general-domain untuned approaches, a fine-tuned one, and a prompt-based approach, to human performance. Results show that while GPT3 achieves impressive scores, it still underperforms humans, with varying quality across genres. Human judgments reveal different types of errors in supervised, prompted, and human-generated summaries, shedding light on the challenges of producing a good summary.|
|**2023-06-19**|**Thickness Dependent Sensitivity of GAGG:Ce Scintillation detectors for Thermal Neutrons: GEANT4 Simulations and Experimental Measurements**|Annesha Karmakar et.al.|[2306.11191v1](http://arxiv.org/abs/2306.11191v1)|null|In the present work, we report extensive GEANT4 simulations in order to study the dependence of sensitivity of GAGG:Ce scintillation crystal based detector on thickness of the crystal. All the simulations are made considering a thermalised Am-Be neutron source. The simulations are validated, qualitatively and quantitatively, by comparing the simulated energy spectra and sensitivity values with those obtained from experimental measurements carried out using two different thicknesses of the crystal from our own experiment (0.5mm and 3mm) and validated with three other thicknesses (0.01mm, 0.1 mm and 1 mm) from literature. In this study, we define sensitivity of GAGG:Ce as the ratio of area under 77 keV sum peak to 45 keV peak. The present studies clearly confirm that, while it requires about 0.1 mm thickness for the GAGG:Ce crystal to fully absorb thermal neutrons, it requires about 3 mm to fully absorb the thermal neutron induced events. Further, we propose an equation, that can be used to estimate the thickness of the GAGG:Ce crystal directly from the observed sensitivity of the GAGG:Ce crystal. This equation could be very useful for the neutron imaging community for medical and space applications, as well as for manufactures of cameras meant for nuclear security purposes.|
|**2023-06-19**|**Euclid: Constraints on f(R) cosmologies from the spectroscopic and photometric primary probes**|S. Casas et.al.|[2306.11053v1](http://arxiv.org/abs/2306.11053v1)|null|$\textit{Euclid}$ will provide a powerful compilation of data including spectroscopic redshifts, the angular clustering of galaxies, weak lensing cosmic shear, and the cross-correlation of these last two photometric observables. In this study we extend recently presented $\textit{Euclid}$ forecasts into the Hu-Sawicki $f(R)$ cosmological model, a popular extension of the Hilbert-Einstein action that introduces an universal modified gravity force in a scale-dependent way. Our aim is to estimate how well future $\textit{Euclid}$ data will be able to constrain the extra parameter of the theory, $f_{R0}$, for the range in which this parameter is still allowed by current observations. For the spectroscopic probe, we use a phenomenological approach for the scale dependence of the growth of perturbations in the terms related to baryon acoustic oscillations and redshift-space distortions. For the photometric observables, we use a fitting formula that captures the modifications in the non-linear matter power spectrum caused by the $f(R)$ model. We show that, in an optimistic setting, and for a fiducial value of $f_{R0} = 5 \times 10^{-6}$, $\textit{Euclid}$ alone will be able to constrain the additional parameter $\log f_{R0}$ at the $3\%$ level, using spectroscopic galaxy clustering alone; at the $1.4\%$ level, using the combination of photometric probes on their own; and at the $1\%$ level, using the combination of spectroscopic and photometric observations. This last constraint corresponds to an error of the order of $6 \times 10^{-7}$ at the $1\sigma$ level on the model parameter $f_{R0} = 5 \times 10^{-6}$. We report also forecasted constraints for $f_{R0} = 5 \times 10^{-5}$ and $f_{R0} = 5 \times 10^{-7}$ and show that in the optimistic scenario, $\textit{Euclid}$ will be able to distinguish these models from $\Lambda\mathrm{CDM}$ at more than 3$\sigma$. (abridged)|
|**2023-06-19**|**Scaling of Class-wise Training Losses for Post-hoc Calibration**|Seungjin Jung et.al.|[2306.10989v1](http://arxiv.org/abs/2306.10989v1)|[link](https://github.com/seungjinjung/sctl)|The class-wise training losses often diverge as a result of the various levels of intra-class and inter-class appearance variation, and we find that the diverging class-wise training losses cause the uncalibrated prediction with its reliability. To resolve the issue, we propose a new calibration method to synchronize the class-wise training losses. We design a new training loss to alleviate the variance of class-wise training losses by using multiple class-wise scaling factors. Since our framework can compensate the training losses of overfitted classes with those of under-fitted classes, the integrated training loss is preserved, preventing the performance drop even after the model calibration. Furthermore, our method can be easily employed in the post-hoc calibration methods, allowing us to use the pre-trained model as an initial model and reduce the additional computation for model calibration. We validate the proposed framework by employing it in the various post-hoc calibration methods, which generally improves calibration performance while preserving accuracy, and discover through the investigation that our approach performs well with unbalanced datasets and untuned hyperparameters.|
|**2023-06-19**|**Tame a Wild Camera: In-the-Wild Monocular Camera Calibration**|Shengjie Zhu et.al.|[2306.10988v1](http://arxiv.org/abs/2306.10988v1)|[link](https://github.com/shngjz/wildcamera)|3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D object detection, has become increasingly important. However, the unknown intrinsic parameter hinders their development and deployment. Previous methods for the monocular camera calibration rely on specific 3D objects or strong geometry prior, such as using a checkerboard or imposing a Manhattan World assumption. This work solves the problem from the other perspective by exploiting the monocular 3D prior. Our method is assumption-free and calibrates the complete $4$ Degree-of-Freedom (DoF) intrinsic parameters. First, we demonstrate intrinsic is solved from two well-studied monocular priors, i.e., monocular depthmap, and surface normal map. However, this solution imposes a low-bias and low-variance requirement for depth estimation. Alternatively, we introduce a novel monocular 3D prior, the incidence field, defined as the incidence rays between points in 3D space and pixels in the 2D imaging plane. The incidence field is a pixel-wise parametrization of the intrinsic invariant to image cropping and resizing. With the estimated incidence field, a robust RANSAC algorithm recovers intrinsic. We demonstrate the effectiveness of our method by showing superior performance on synthetic and zero-shot testing datasets. Beyond calibration, we demonstrate downstream applications in image manipulation detection & restoration, uncalibrated two-view pose estimation, and 3D sensing. Codes, models, and data will be held in https://github.com/ShngJZ/WildCamera.|
|**2023-06-19**|**PowerBEV: A Powerful Yet Lightweight Framework for Instance Prediction in Bird's-Eye View**|Peizheng Li et.al.|[2306.10761v1](http://arxiv.org/abs/2306.10761v1)|[link](https://github.com/edwardleelpz/powerbev)|Accurately perceiving instances and predicting their future motion are key tasks for autonomous vehicles, enabling them to navigate safely in complex urban traffic. While bird's-eye view (BEV) representations are commonplace in perception for autonomous driving, their potential in a motion prediction setting is less explored. Existing approaches for BEV instance prediction from surround cameras rely on a multi-task auto-regressive setup coupled with complex post-processing to predict future instances in a spatio-temporally consistent manner. In this paper, we depart from this paradigm and propose an efficient novel end-to-end framework named POWERBEV, which differs in several design choices aimed at reducing the inherent redundancy in previous methods. First, rather than predicting the future in an auto-regressive fashion, POWERBEV uses a parallel, multi-scale module built from lightweight 2D convolutional networks. Second, we show that segmentation and centripetal backward flow are sufficient for prediction, simplifying previous multi-task objectives by eliminating redundant output modalities. Building on this output representation, we propose a simple, flow warping-based post-processing approach which produces more stable instance associations across time. Through this lightweight yet powerful design, POWERBEV outperforms state-of-the-art baselines on the NuScenes Dataset and poses an alternative paradigm for BEV instance prediction. We made our code publicly available at: https://github.com/EdwardLeeLPZ/PowerBEV.|
|**2023-06-18**|**STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced Audio-Visual Diarization**|Kyle Min et.al.|[2306.10608v1](http://arxiv.org/abs/2306.10608v1)|null|This report introduces our novel method named STHG for the Audio-Visual Diarization task of the Ego4D Challenge 2023. Our key innovation is that we model all the speakers in a video using a single, unified heterogeneous graph learning framework. Unlike previous approaches that require a separate component solely for the camera wearer, STHG can jointly detect the speech activities of all people including the camera wearer. Our final method obtains 61.1% DER on the test set of Ego4D, which significantly outperforms all the baselines as well as last year's winner. Our submission achieved 1st place in the Ego4D Challenge 2023. We additionally demonstrate that applying the off-the-shelf speech recognition system to the diarized speech segments by STHG produces a competitive performance on the Speech Transcription task of this challenge.|

## smart ring

### smart ring
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Automorphisms of extensions of Lie-Yamaguti algebras and Inducibility problem**|Saikat Goswami et.al.|[2306.12937v1](http://arxiv.org/abs/2306.12937v1)|null|Lie-Yamaguti algebras generalize both the notions of Lie algebras and Lie triple systems. In this paper, we consider the inducibility problem for automorphisms of Lie-Yamaguti algebra extensions. More precisely, given an abelian extension $$0 \to V \xrightarrow[]{i} \widetilde{L} \xrightarrow[]{p} L \to 0$$ of Lie-Yamaguti algebra $L$, we are interested in finding the pairs $(\phi, \psi)\in \mathrm{Aut}(V)\times \mathrm{Aut}(L)$, which are inducible by an automorphism in $\mathrm{Aut}(\widetilde{L})$. We connect the inducibility problem to the $(2,3)$ cohomology of Lie-Yamaguti algebra. In particular, we show that the obstruction for a pair of automorphisms in $\mathrm{Aut}(V)\times \mathrm{Aut}(L)$ to be inducible lies in a cohomology class of the $(2,3)$ cohomology group $\mathrm{H}^{(2,3)}(L,V)$. We develop the Wells exact sequence for Lie-Yamaguti algebra extensions, which relates the space of derivations, automorphism groups, and $(2,3)$-cohomology groups of Lie-Yamaguti algebras. Finally, we consider nilpotent Lie-Yamaguti algebras of index $2$ with a one-dimensional center. We give two infinite families of such nilpotent Lie-Yamaguti algebras and characterize the inducible pairs for extensions arising from these examples. Finally, We give an algorithm to characterize inducible pairs of automorphisms for extensions arising from nilpotent Lie-Yamaguti algebras (index $2$) with a one-dimensional center.|
|**2023-06-22**|**Toric differential forms and periods of complete intersections**|Roberto Villaflor Loyola et.al.|[2306.12931v1](http://arxiv.org/abs/2306.12931v1)|null|Let $n$ be an even natural number. We compute the periods of any $\frac{n}{2}$-dimensional complete intersection algebraic cycle inside an $n$-dimensional non-degenerated intersection of a projective simplicial toric variety. Using this information we determine the cycle class of such algebraic cycles. As part of the proof we develop a toric generalization of a classical theorem of Macaulay about complete intersection Artin Gorenstein rings, and we generalize an algebraic cup formula for residue forms due to Carlson and Griffiths to the toric setting.|
|**2023-06-22**|**Mapping non-axisymmetric velocity fields of external galaxies**|Francesco Sylos Labini et.al.|[2306.12902v1](http://arxiv.org/abs/2306.12902v1)|null|Disk galaxies are typically in a stable configuration where matter moves in almost closed circular orbits. However, non-circular motions caused by distortions, warps, lopsidedness, or satellite interactions are common and leave distinct signatures on galaxy velocity maps. We develop an algorithm that uses an ordinary least square method for fitting a non-axisymmetric model to the observed two-dimensional line-of-sight velocity map of an external galaxy, which allows for anisotropic non-circular motions. The method approximates a galaxy as a flat disk, which is an appropriate assumption for spiral galaxies within the optical radius where warps are rare. In the outer parts of HI distributions, which may extend well into the warp region, we use this method in combination with a standard rotating tilted ring model to constrain the range of radii where the flat disk assumption can be conservatively considered valid. Within this range, the transversal and radial velocity profiles, averaged in rings, can be directly reconstructed from the velocity map. The novelty of the algorithm consists in using arc segments in addition to rings: in this way spatial velocity anisotropies can be measured in both components, allowing for the reconstruction of angularly resolved coarse-grained two-dimensional velocity maps. We applied this algorithm to 25 disk galaxies from the THINGS sample for which we can provide 2D maps of both velocity components.|
|**2023-06-22**|**Applications of reduced and coreduced modules II**|David Ssevviiri et.al.|[2306.12871v1](http://arxiv.org/abs/2306.12871v1)|null|This is the second in a series of papers highlighting the applications of reduced and coreduced modules. Let $R$ be a commutative unital ring and $I$ be an ideal of $R$. We give the necessary and sufficient conditions in terms of $I$-reduced and $I$-coreduced $R$-modules for the functors $\text{Hom}_R(R/I, -)$ and $\Gamma_I$, the $I$-torsion functor, on the abelian full subcategories of the category of all $R$-modules to be radicals. These conditions: 1) subsume and unify many results which were proved on a case-by-case basis, 2) provide a setting for the generalisation of Jans' correspondence of an idempotent ideal of a ring with a torsion-torsionfree class, 3) provide answers to open questions that were posed by Rohrer, and 4) lead to a new radical class of rings.|
|**2023-06-22**|**MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge**|Sokratis Nikolaidis et.al.|[2306.12830v1](http://arxiv.org/abs/2306.12830v1)|null|Cascade systems comprise a two-model sequence, with a lightweight model processing all samples and a heavier, higher-accuracy model conditionally refining harder samples to improve accuracy. By placing the light model on the device side and the heavy model on a server, model cascades constitute a widely used distributed inference approach. With the rapid expansion of intelligent indoor environments, such as smart homes, the new setting of Multi-Device Cascade is emerging where multiple and diverse devices are to simultaneously use a shared heavy model on the same server, typically located within or close to the consumer environment. This work presents MultiTASC, a multi-tenancy-aware scheduler that adaptively controls the forwarding decision functions of the devices in order to maximize the system throughput, while sustaining high accuracy and low latency. By explicitly considering device heterogeneity, our scheduler improves the latency service-level objective (SLO) satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade methods in highly heterogeneous setups, while serving over 40 devices, showcasing its scalability.|
|**2023-06-22**|**Josephson diode effect in monolithic dc-SQUIDs based on 3D Dayem nanobridges**|Angelo Greco et.al.|[2306.12765v1](http://arxiv.org/abs/2306.12765v1)|null|It was recently experimentally proved that the superconducting counterpart of a diode, i.e., a device that realizes nonreciprocal Cooper pairs transport, can be realized by breaking the spatial and time-reversal symmetry of a system simultaneously. Here we report the theory, fabrication, and operation of a monolithic dc superconducting quantum interference device (dc-SQUID) that embedding three-dimensional (3D) Dayem nanobridges as weak links realizes an efficient and magnetic flux-tunable supercurrent diode. The device is entirely realized in Al and achieves a maximum rectification efficiency of $\sim 20\%$, which stems from the high harmonic content of its current-to-phase relation only without the need of any sizable screening current caused by a finite loop inductance. Our interferometer can be easily integrated with state-of-the-art superconducting electronics, and since it does not require a finite loop inductance to provide large rectification its downsizing is not limited by the geometrical constraints of the superconducting ring.|
|**2023-06-22**|**Wedge product matrices and orbits of principal congruence subgroups**|Yao Ming Chan et.al.|[2306.12615v1](http://arxiv.org/abs/2306.12615v1)|null|The orbits in $\Gamma_{\infty}(3) \backslash \Gamma(3)$ are in bijection with sets of invariants satisfying certain relations. We explain how wedge product matrices give an alternative definition of the invariants of matrix orbits. This new method provides the possibility of performing similar computations with other congruence subgroups and arbitrary $n \times n$ matrices. Using Steinberg's refined version of the Bruhat decomposition, we construct an explicit choice of coset representative for each orbit in the orbit space $\Gamma_{\infty}(3) \backslash \Gamma(3)$ of $3 \times 3$ matrices over the PID of Eisenstein integers.|
|**2023-06-21**|**Non-Perturbative Explorations of Chiral Rings in 4d $\mathcal{N}=2$ SCFTs**|Anindya Banerjee et.al.|[2306.12521v1](http://arxiv.org/abs/2306.12521v1)|null|We study the conditions under which 4d $\mathcal{N}=2$ superconformal field theories (SCFTs) have multiplets housing operators that are chiral with respect to an $\mathcal{N}=1$ subalgebra. Our main focus is on the set of often-ignored and relatively poorly understood $\overline{\mathcal{B}}$ representations. These multiplets typically evade direct detection by the most popular non-perturbative 4d $\mathcal{N}=2$ tools and correspondences. In spite of this fact, we demonstrate the ubiquity of $\overline{\mathcal{B}}$ multiplets and show they are associated with interesting phenomena. For example, we give a purely algebraic proof that they are present in all local unitary $\mathcal{N}>2$ SCFTs. We also show that $\overline{\mathcal{B}}$ multiplets exist in $\mathcal{N}=2$ theories with rank greater than one and a conformal manifold or a freely generated Coulomb branch. Using recent topological quantum field theory results, we argue that certain $\overline{\mathcal{B}}$ multiplets exist in broad classes of theories with the $\mathbb{Z}_2$-valued 't Hooft anomaly for $Sp(N)$ global symmetry. Motivated by these statements, we then study the question of whether $\overline{\mathcal{B}}$ multiplets exist in rank-one SCFTs with exactly $\mathcal{N}=2$ SUSY. We conclude with various open questions.|
|**2023-06-21**|**NTT-Based Polynomial Modular Multiplication for Homomorphic Encryption: A Tutorial**|Sin-Wei Chiu et.al.|[2306.12519v1](http://arxiv.org/abs/2306.12519v1)|null|Homomorphic Encryption (HE) allows any third party to operate on the encrypted data without decrypting it in advance. For the majority of HE schemes, the multiplicative depth of circuits is the main practical limitation in performing computations over encrypted data. Hence, Homomorphic multiplication is one of the most important components of homomorphic encryption. Since most of the HE schemes are constructed from the ring-learning with errors (R-LWE) problem. Efficient polynomial modular multiplication implementation becomes critical. This work consists of describing various approaches to implementing polynomial modular multiplication based on number theoretic transform.|
|**2023-06-21**|**Involutions of the second kind on finitary incidence algebras**|Érica Zancanella Fornaroli et.al.|[2306.12512v1](http://arxiv.org/abs/2306.12512v1)|null|Let $K$ be a field and $X$ a connected partially ordered set. In the first part of this paper, we show that the finitary incidence algebra $FI(X,K)$ of $X$ over $K$ has an involution of the second kind if and only if $X$ has an involution and $K$ has an automorphism of order $2$. We also give a characterization of the involutions of the second kind on $FI(X,K)$. In the second part, we give necessary and sufficient conditions for two involutions of the second kind on $FI(X,K)$ to be equivalent in the case where $char K\neq 2$ and every multiplicative automorphism of $FI(X,K)$ is inner.|
|**2023-06-21**|**Derived equivalences of upper-triangular ring spectra via reflection functors**|Gustavo Jasso et.al.|[2306.12396v2](http://arxiv.org/abs/2306.12396v2)|null|We use the generalised Bernstein-Gelfand-Ponomarev reflection functors constructed in joint work with Dyckerhoff and Walde to extend a theorem of Ladkani concerning derived equivalences between upper-triangular matrix rings from ordinary rings to ring spectra. Our result also extends an analogous theorem of Maycock for differential graded algebras.|
|**2023-06-21**|**Boundedness in $L_p$ spaces for the Hartley-Fourier convolutions operator and their applications**|Trinh Tuan et.al.|[2306.12378v2](http://arxiv.org/abs/2306.12378v2)|null|The paper deals with $L_p$-boundedness of the Hartley-Fourier convolutions operator and their applied aspects. We establish various new Young-type inequalities and obtain the structure of a normed ring in Banach space when equipping it with such convolutional multiplication. Weighted $L_p$-norm inequalities of these convolutions are also considered. As applications, we investigate the solvability and the bounded $L_1$-solution of a class of Fredholm-type integral equations and linear Barbashin's equations with the help of factorization identities of such convolutions. Several examples are provided to illustrate the obtained results to ensure their validity and applicability.|
|**2023-06-21**|**Do you still need a manual smart contract audit?**|Isaac David et.al.|[2306.12338v2](http://arxiv.org/abs/2306.12338v2)|null|We investigate the feasibility of employing large language models (LLMs) for conducting the security audit of smart contracts, a traditionally time-consuming and costly process. Our research focuses on the optimization of prompt engineering for enhanced security analysis, and we evaluate the performance and accuracy of LLMs using a benchmark dataset comprising 52 Decentralized Finance (DeFi) smart contracts that have previously been compromised.   Our findings reveal that, when applied to vulnerable contracts, both GPT-4 and Claude models correctly identify the vulnerability type in 40% of the cases. However, these models also demonstrate a high false positive rate, necessitating continued involvement from manual auditors. The LLMs tested outperform a random model by 20% in terms of F1-score.   To ensure the integrity of our study, we conduct mutation testing on five newly developed and ostensibly secure smart contracts, into which we manually insert two and 15 vulnerabilities each. This testing yielded a remarkable best-case 78.7% true positive rate for the GPT-4-32k model. We tested both, asking the models to perform a binary classification on whether a contract is vulnerable, and a non-binary prompt. We also examined the influence of model temperature variations and context length on the LLM's performance.   Despite the potential for many further enhancements, this work lays the groundwork for a more efficient and economical approach to smart contract security audits.|
|**2023-06-21**|**Frieze patterns over algebraic numbers**|Michael Cuntz et.al.|[2306.12148v1](http://arxiv.org/abs/2306.12148v1)|null|Conway and Coxeter have shown that frieze patterns over positive rational integers are in bijection with triangulations of polygons. An investigation of frieze patterns over other subsets of the complex numbers has recently been initiated by Jorgensen and the authors. In this note we determine rings of algebraic numbers such that there are finitely many non-zero frieze patterns for any given height. We show that this is only the case for subrings of quadratic number fields $\mathbb{Q}(\sqrt{d})$ where $d<0$. We then concentrate on the imaginary quadratic case and show as a second main result that apart from the cases $d\in \{-1,-2,-3,-7,-11\}$ all non-zero frieze patterns over the rings of integers $\mathcal{O}_d$ for $d<0$ have only integral entries and hence are known as (twisted) Conway-Coxeter frieze patterns.|
|**2023-06-21**|**Chili Pepper Disease Diagnosis via Image Reconstruction Using GrabCut and Generative Adversarial Serial Autoencoder**|Jongwook Si et.al.|[2306.12057v1](http://arxiv.org/abs/2306.12057v1)|null|With the recent development of smart farms, researchers are very interested in such fields. In particular, the field of disease diagnosis is the most important factor. Disease diagnosis belongs to the field of anomaly detection and aims to distinguish whether plants or fruits are normal or abnormal. The problem can be solved by binary or multi-classification based on CNN, but it can also be solved by image reconstruction. However, due to the limitation of the performance of image generation, SOTA's methods propose a score calculation method using a latent vector error. In this paper, we propose a network that focuses on chili peppers and proceeds with background removal through Grabcut. It shows high performance through image-based score calculation method. Due to the difficulty of reconstructing the input image, the difference between the input and output images is large. However, the serial autoencoder proposed in this paper uses the difference between the two fake images except for the actual input as a score. We propose a method of generating meaningful images using the GAN structure and classifying three results simultaneously by one discriminator. The proposed method showed higher performance than previous researches, and image-based scores showed the best performanc|
|**2023-06-21**|**Some invariants of $U(1,1;\mathbb{H})$ and diagonalization**|Cailing Yao et.al.|[2306.12052v1](http://arxiv.org/abs/2306.12052v1)|null|Denote by $\mathbb{H}$ the set of all quaternions. We are interested in the group $U(1,1;\mathbb{H})$, which is a subgroup of $2\times 2$ quaternionic matrix group and is sometimes called $Sp(1,1)$. As well known, $U(1,1;\mathbb{H})$ corresponds to the quaternionic M\"{o}bius transformations on the unit ball in $\mathbb{H}$. In this article, some similar invariants on $U(1,1;\mathbb{H})$ are discussed. Our main result shows that each matrix $T\in U(1,1;\mathbb{H})$, which corresponds to an elliptic quaternionic M\"{o}bius transformation $g_T(z)$, could be $U(1,1;\mathbb{H})$-similar to a diagonal matrix.|
|**2023-06-21**|**Learning When to Trust Which Teacher for Weakly Supervised ASR**|Aakriti Agrawal et.al.|[2306.12012v1](http://arxiv.org/abs/2306.12012v1)|null|Automatic speech recognition (ASR) training can utilize multiple experts as teacher models, each trained on a specific domain or accent. Teacher models may be opaque in nature since their architecture may be not be known or their training cadence is different from that of the student ASR model. Still, the student models are updated incrementally using the pseudo-labels generated independently by the expert teachers. In this paper, we exploit supervision from multiple domain experts in training student ASR models. This training strategy is especially useful in scenarios where few or no human transcriptions are available. To that end, we propose a Smart-Weighter mechanism that selects an appropriate expert based on the input audio, and then trains the student model in an unsupervised setting. We show the efficacy of our approach using LibriSpeech and LibriLight benchmarks and find an improvement of 4 to 25\% over baselines that uniformly weight all the experts, use a single expert model, or combine experts using ROVER.|
|**2023-06-21**|**A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code**|Qing Huang et.al.|[2306.11981v1](http://arxiv.org/abs/2306.11981v1)|null|API documentation, technical blogs and programming Q&A sites contain numerous partial code that can be reused in programming tasks, but often these code are uncompilable due to unresolved names and syntax errors. To facilitate partial code reuse, we propose the Partial Code Reuse Chain (PCR-Chain) for resolving fully-qualified names (FQNs) and fixing last-mile syntax errors in partial code based on a giant large language model (LLM) like ChatGPT. Methodologically, PCR-Chain is backed up by the underlying global-level prompt architecture (which combines three design ideas: hierarchical task breakdown, prompt composition, and a mix of prompt-based AI and non-AI units) and the local-level prompt design. Technically, we propose PCR-Chain, which employs in-context learning rather than symbolic, costly training methods. Experimental results demonstrate that in dynamically-typed languages (Python), PCR-Chain outperforms current state-of-the-art (SOTA) 5% accuracy like RING. For statically-type languages (Java), our approach achieves high accuracy of 80.5% in resolving both non-FQNs and last-mile syntax errors, surpassing SOTA methods (RING) that can only address last-mile syntax errors. The correct execution of the unit, module, and PCR-Chain demonstrates the effectiveness of the prompt design, composition, and architecture and opens up possibilities for building software engineering tools based on LLMs, replacing traditional program analysis methods.|
|**2023-06-21**|**LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System (ACM)(Draft) LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System**|Ashish Bastola et.al.|[2306.11980v1](http://arxiv.org/abs/2306.11980v1)|null|CSCW studies have increasingly explored AI's role in enhancing communication efficiency and productivity in collaborative tasks. AI tools such as chatbots, smart replies, and language models aim to optimize conversation management and improve team performance. Early AI assistants, such as Gmail smart reply, were limited by predefined knowledge bases and decision trees. However, the advent of large language models (LLMs) such as ChatGPT has revolutionized AI assistants, employing advanced deep learning architecture to generate context-aware, coherent, and personalized responses. Consequently, ChatGPT-based AI assistants provide a more natural and efficient user experience across various tasks and domains. In this paper, we formalize the concept of AI Collaborative Tools (ACT) as AI technologies in human collaborative work and discuss how the emergence of ChatGPT has transformed the AI landscape and increased focus on ACT for improving team performance. Meanwhile, we present an LLM-based Smart Reply (LSR) system utilizing the ChatGPT API to generate personalized responses in daily collaborative scenarios, considering context, tone, and communication style. Our two-step process involves generating a preliminary response type (e.g., Agree, Disagree) to provide a generalized direction for message generation, thus reducing response drafting time. We conducted an experiment in which participants completed simulated work tasks, involving Google Calendar manipulation and a double-back N-back test, while interacting with researchers posing as teammates requesting scheduling changes. Our findings indicate that the AI teammate increases perceived performance and reduces mental demand, as measured by the NASA TLX, and improves performance in the N-back task. We also provide qualitative feedback on participants' experiences working with the AI teammate.|
|**2023-06-21**|**Multimodality Fusion for Smart Healthcare: a Journey from Data, Information, Knowledge to Wisdom**|Thanveer Shaik et.al.|[2306.11963v1](http://arxiv.org/abs/2306.11963v1)|null|Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data, information, and knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. A comprehensive review of multimodal medical data fusion focuses on the integration of various data modalities are presented. It explores different approaches such as Feature selection, Rule-based systems, Machine learning, Deep learning, and Natural Language Processing for fusing and analyzing multimodal data. The paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and insights, a generic framework for multimodal medical data fusion is proposed while aligning with the DIKW mechanism. Moreover, it discusses future directions aligned with the four pillars of healthcare: Predictive, Preventive, Personalized, and Participatory approaches based on the DIKW and the generic framework. The components from this comprehensive survey form the foundation for the successful implementation of multimodal fusion in smart healthcare. The findings of this survey can guide researchers and practitioners in leveraging the power of multimodal fusion with the approaches to revolutionize healthcare and improve patient outcomes.|
|**2023-06-20**|**Protecting the Decentralized Future: An Exploration of Common Blockchain Attacks and their Countermeasures**|Bilash Saha et.al.|[2306.11884v1](http://arxiv.org/abs/2306.11884v1)|null|Blockchain technology transformed the digital sphere by providing a transparent, secure, and decentralized platform for data security across a range of industries, including cryptocurrencies and supply chain management. Blockchain's integrity and dependability have been jeopardized by the rising number of security threats, which have attracted cybercriminals as a target. By summarizing suggested fixes, this research aims to offer a thorough analysis of mitigating blockchain attacks. The objectives of the paper include identifying weak blockchain attacks, evaluating various solutions, and determining how effective and effective they are at preventing these attacks. The study also highlights how crucial it is to take into account the particular needs of every blockchain application. This study provides beneficial perspectives and insights for blockchain researchers and practitioners, making it essential reading for those interested in current and future trends in blockchain security research.|
|**2023-06-20**|**Predicting Strategic Energy Storage Behaviors**|Yuexin Bian et.al.|[2306.11872v1](http://arxiv.org/abs/2306.11872v1)|[link](https://github.com/alwaysbyx/predicting-strategic-energy-storage-behaviors)|Energy storage are strategic participants in electricity markets to arbitrage price differences. Future power system operators must understand and predict strategic storage arbitrage behaviors for market power monitoring and capacity adequacy planning. This paper proposes a novel data-driven approach that incorporates prior model knowledge for predicting the strategic behaviors of price-taker energy storage systems. We propose a gradient-descent method to find the storage model parameters given the historical price signals and observations. We prove that the identified model parameters will converge to the true user parameters under a class of quadratic objective and linear equality-constrained storage models. We demonstrate the effectiveness of our approach through numerical experiments with synthetic and real-world storage behavior data. The proposed approach significantly improves the accuracy of storage model identification and behavior forecasting compared to previous blackbox data-driven approaches.|
|**2023-06-20**|**Cup-one algebras and 1-minimal models**|Richard D. Porter et.al.|[2306.11849v1](http://arxiv.org/abs/2306.11849v1)|null|In previous work, we introduced the notion of binomial cup-one algebras, which are differential graded algebras endowed with Steenrod $\cup_1$-products and compatible binomial operations. Given such an $R$-dga, $(A,d_A)$, defined over the ring $R=\mathbb{Z}$ or $\mathbb{Z}_p$ (for $p$ a prime), with $H^0(A)=R$ and with $H^1(A)$ a finitely generated, free $R$-module, we show that $A$ admits a functorially defined 1-minimal model, $\rho\colon (\mathcal{M}(A),d)\to (A,d_A)$, which is unique up to isomorphism. Furthermore, we associate to this model a pronilpotent group, $G(A)$, which only depends on the 1-quasi-isomorphism type of $A$. These constructions, which refine classical notions from rational homotopy theory, allow us to distinguish spaces with isomorphic (torsion-free) cohomology rings that share the same rational 1-minimal model, yet whose integral 1-minimal models are not isomorphic.|
|**2023-06-20**|**SkyGPT: Probabilistic Short-term Solar Forecasting Using Synthetic Sky Videos from Physics-constrained VideoGPT**|Yuhao Nie et.al.|[2306.11682v1](http://arxiv.org/abs/2306.11682v1)|null|In recent years, deep learning-based solar forecasting using all-sky images has emerged as a promising approach for alleviating uncertainty in PV power generation. However, the stochastic nature of cloud movement remains a major challenge for accurate and reliable solar forecasting. With the recent advances in generative artificial intelligence, the synthesis of visually plausible yet diversified sky videos has potential for aiding in forecasts. In this study, we introduce \emph{SkyGPT}, a physics-informed stochastic video prediction model that is able to generate multiple possible future images of the sky with diverse cloud motion patterns, by using past sky image sequences as input. Extensive experiments and comparison with benchmark video prediction models demonstrate the effectiveness of the proposed model in capturing cloud dynamics and generating future sky images with high realism and diversity. Furthermore, we feed the generated future sky images from the video prediction models for 15-minute-ahead probabilistic solar forecasting for a 30-kW roof-top PV system, and compare it with an end-to-end deep learning baseline model SUNSET and a smart persistence model. Better PV output prediction reliability and sharpness is observed by using the predicted sky images generated with SkyGPT compared with other benchmark models, achieving a continuous ranked probability score (CRPS) of 2.81 (13\% better than SUNSET and 23\% better than smart persistence) and a Winkler score of 26.70 for the test set. Although an arbitrary number of futures can be generated from a historical sky image sequence, the results suggest that 10 future scenarios is a good choice that balances probabilistic solar forecasting performance and computational cost.|
|**2023-06-20**|**Superfluid Rivers in Spinning-down Neutron Stars**|Yuri Levin et.al.|[2306.11775v1](http://arxiv.org/abs/2306.11775v1)|null|We study the motion of neutron superfluid vortices in a spinning-down neutron star, assuming axisymmetry of the flow and ignoring motion of vortices about the rotation axis. We find that the vortex array, if initially rectilinear, is soon substantially deformed as the star spins down; vortices are swept outward by the Magnus force, accumulating in regions of the inner crust where they pin, accompanied by significant bending of the vortex array. As the star spins down to below a spin rate of ~20 Hz (twice the spin rate of the Vela pulsar), the Magnus and pinning forces gradually compress the vortex array into dense sheets that follow spherical shells. In some cases, the vortex array bends on itself and reconnects, forming one or more tori of vortex rings that contain superfluid ``rivers" with significant angular momentum. Vortex sheets are likely to form near the base of the inner crust, in the regime of nuclear pasta.|
|**2023-06-20**|**Decay of persistent currents in annular atomic superfluids**|Klejdja Xhani et.al.|[2306.11645v1](http://arxiv.org/abs/2306.11645v1)|null|We investigate the role of vortices in the decay of persistent current states of annular atomic superfluids by solving numerically the Gross-Pitaevskii equation, and we directly compare our results with experimental data from Ref. [1]. We theoretically model the optical phase-imprinting technique employed to experimentally excite finite-circulation states in Ref. [1] in the Bose-Einstein condensation regime, accounting for imperfections of the optical gradient imprinting profile. By comparing simulations of this realistic protocol to an ideal imprinting, we show that the introduced density excitations arising from imperfect imprinting are mainly responsible for limiting the maximum reachable winding number $w_\mathrm{max}$ in the superfluid ring. We also investigate the effect of a point-like obstacle with variable potential height $V_0$ onto the decay of circulating supercurrents. For a given obstacle height, a critical circulation $w_c$ exists, such that for an initial circulation $w_0$ larger than $w_c$ the supercurrent decays through the emission of vortices, which cross the superflow and thus induce phase slippage. Higher values of the obstacle height $V_0$ further favour the entrance of vortices, thus leading to lower values of $w_c$. Furthermore, the stronger vortex-defect interaction at higher $V_0$ leads to vortices that propagate closer to the center of the ring condensate. The combination of both these effects leads to an increase of the supercurrent decay rate for increasing $w_0$, in agreement with experimental observations.   [1]: G. Del Pace, et al., Phys. Rev. X 12, 041037 (2022)|
|**2023-06-20**|**Mid-Infrared Ring Interband Cascade Laser: Operation at the Standard Quantum Limit**|Georg Marschick et.al.|[2306.11628v1](http://arxiv.org/abs/2306.11628v1)|null|Many precision applications in the mid-infrared spectral range have strong constraints based on quantum effects that are expressed in particular noise characteristics. They limit, e.g., sensitivity and resolution of mid-infrared imaging and spectroscopic systems as well as the bit-error rate in optical free-space communication. Interband cascade lasers (ICLs) are a class of mid-infrared laser exploiting interband transitions in type-II band alignment geometry. They are currently gaining significant importance for mid-infrared applications from <3 {\mu}m to >6 {\mu}m wavelength, enabled by novel types of high-performance ICLs such as ring-cavity devices. Their noise-behavior is an important feature that still needs to be thoroughly analyzed, including its potential reduction with respect to the shot noise limit. In this work, we provide a comprehensive characterization of {\lambda} = 3.8 {\mu}m-emitting, continuous-wave ring-ICLs operating at room temperature. It is based on an in-depth study of their main physical intensity noise features, such as their bias-dependent intensity noise power spectral density (INPSD) and relative intensity noise (RIN). We obtain shot-noise-limited statistics for Fourier frequencies above 100 kHz. This is an important result for precision applications, e.g. interferometry or advanced spectroscopy, which benefit from exploiting the advantage of using such a shot-noise limited source, enhancing the setup sensitivity. Moreover, it is an important feature for novel quantum optics schemes including testing specific light states below the shot noise level, such as squeezed states.|
|**2023-06-20**|**Role of coupling delay in oscillatory activity in autonomous networks of excitable neurons with dissipation**|A. V. Bukh et.al.|[2306.11573v1](http://arxiv.org/abs/2306.11573v1)|null|We study numerically the effects of time delay in networks of delay-coupled excitable FitzHugh Nagumo systems with dissipation. The generation of periodic self-sustained oscillations and its threshold are analyzed depending on the dissipation of a single neuron, the delay time, and random initial conditions. The peculiarities of spatiotemporal dynamics of time-delayed bidirectional ring-structured FitzHugh-Nagumo neuronal systems are investigated in cases of local and nonlocal coupling topology between the nodes, and a first-order nonequilibrium phase transition to synchrony is established. It is shown that the emergence of oscillatory activity in delay-coupled FitzHugh-Nagumo neurons is observed for smaller values of the coupling strength as the dissipation parameter decreases. This can provide the possibility of controlling the spatiotemporal behavior of the considered neuronal networks. The observed effects are quantified by plotting distributions of the maximal Lyapunov exponent and the global order parameter in terms of delay and coupling strength.|
|**2023-06-20**|**Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes**|Mathilde Leuridan et.al.|[2306.11553v1](http://arxiv.org/abs/2306.11553v1)|[link](https://github.com/ecmwf/polytope)|Data extraction algorithms on data hypercubes, or datacubes, are traditionally only capable of cutting boxes of data along the datacube axes. For many use cases however, this is not a sufficient approach and returns more data than users might actually need. This not only forces users to apply post-processing after extraction, but more importantly this consumes more I/O resources than is necessary. When considering very large datacubes from which users only want to extract small non-rectangular subsets, the box approach does not scale well. Indeed, with this traditional approach, I/O systems quickly reach capacity, trying to read and return unwanted data to users. In this paper, we propose a novel technique, based on computational geometry concepts, which instead carefully pre-selects the precise bytes of data which the user needs in order to then only read those from the datacube. As we discuss later on, this novel extraction method will considerably help scale access to large petabyte size data hypercubes in a variety of scientific fields.|
|**2023-06-20**|**AGN and Star Formation feedback in the evolution of galaxy outflows**|William E. Clavijo-Bohórquez et.al.|[2306.11494v1](http://arxiv.org/abs/2306.11494v1)|null|We conducted 3D-MHD simulations to investigate the feedback processes in the central 1kpc scale of galaxies hosting both active star formation (SF) and an AGN wind. Our simulations naturally generated a turbulent and clumpy interstellar medium driven by SF evolution. We found that the AGN wind duty cycle plays a crucial role in shaping the evolution of the outflows. This cycle consists of an active, a remnant and an inactive phase, lasting up to 1.5 Myr. The duration of the cycle increases with larger star formation rate (SFR) and smaller AGN wind power (tested for luminosities log L = 42-44 ergs per second and SFR=1-1000 solar masses per year. The feedback on SF, whether positive or negative, depends on various factors, including the AGN outflow opening angle, power, and phase of activity, as well as the initial SFR. The passage of the AGN wind enhances SF in a ring around it, resembling the structures observed in ULIRGs, and is stronger for larger AGN power or SFR. Also, a higher SFR enhances the mixing of interstellar matter with the AGN wind, resulting in a greater number of colder, denser structures with volume filling factors ~ 0.02 to 0.12 and velocities comparable to those observed in Seyferts and LINERs, but smaller than those observed in ULIRGs. The efficiency of the AGN wind in transporting mass to kiloparsec distances diminishes with increasing SFR. The mass loss rates range from 50 to 250 solar masses per year within the initial 2 Myr of evolution, which aligns with observed rates in nearby Seyferts and ULIRGs.|

## PPG

### Photoplethysmography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-19**|**ApSense: Data-driven Algorithm in PPG-based Sleep Apnea Sensing**|Tanut Choksatchawathi et.al.|[2306.10863v1](http://arxiv.org/abs/2306.10863v1)|null|In this paper, we utilized obstructive sleep apnea and cardiovascular disease-related photoplethysmography (PPG) features in constructing the input to deep learning (DL). The features are pulse wave amplitude (PWA), beat-to-beat or RR interval, a derivative of PWA, a derivative of RR interval, systolic phase duration, diastolic phase duration, and pulse area. Then, we develop DL architectures to evaluate the proposed features' usefulness. Eventually, we demonstrate that in human-machine settings where the medical staff only needs to label 20% of the PPG recording length, our proposed features with the developed DL architectures achieve 79.95% and 73.81% recognition accuracy in MESA and HeartBEAT datasets. This simplifies the labelling task of the medical staff during the sleep test yet provides accurate apnea event recognition.|
|**2023-06-16**|**Camera PPG waveforms at the forehead**|A. C. den Brinker et.al.|[2306.09879v1](http://arxiv.org/abs/2306.09879v1)|null|In order to obtain insights into the feasibility of replacing ECG-guided triggering in magnetic resonance imaging (MRI) by a system based on video photoplethysmography (PPG), PPG and ECG data were collected from volunteers in an MRI scanner. PPG waveforms obtained using remote camera PPG directed at the forehead are studied in qualitative and quantitative sense over a number of volunteers. The data analysis considers variations in PPG waveforms across volunteers, modelling of the waveforms in Fourier series, dependencies of waveforms and features on the interbeat interval (IBI) and breath-holding, and models for ECG-blind estimation of R-peak position. The main findings are that the PPG waveform depends on the volunteer and that its shape changes with IBI and does not depend on breath-holding in the given scenario. Low-order harmonic models provide accurate approximations to the PPG waveform, where for higher IBI the waveform shows more temporal details. Accurate predictions (20 ms std) of the delays between markers in ECG and PPG appear feasible from a single PPG feature.|
|**2023-06-13**|**BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation**|Valentin Bieri et.al.|[2306.07730v2](http://arxiv.org/abs/2306.07730v2)|null|We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three different cross-validation experiments.|
|**2023-06-04**|**rPPG-MAE: Self-supervised Pre-training with Masked Autoencoders for Remote Physiological Measurement**|Xin Liu et.al.|[2306.02301v1](http://arxiv.org/abs/2306.02301v1)|null|Remote photoplethysmography (rPPG) is an important technique for perceiving human vital signs, which has received extensive attention. For a long time, researchers have focused on supervised methods that rely on large amounts of labeled data. These methods are limited by the requirement for large amounts of data and the difficulty of acquiring ground truth physiological signals. To address these issues, several self-supervised methods based on contrastive learning have been proposed. However, they focus on the contrastive learning between samples, which neglect the inherent self-similar prior in physiological signals and seem to have a limited ability to cope with noisy. In this paper, a linear self-supervised reconstruction task was designed for extracting the inherent self-similar prior in physiological signals. Besides, a specific noise-insensitive strategy was explored for reducing the interference of motion and illumination. The proposed framework in this paper, namely rPPG-MAE, demonstrates excellent performance even on the challenging VIPL-HR dataset. We also evaluate the proposed method on two public datasets, namely PURE and UBFC-rPPG. The results show that our method not only outperforms existing self-supervised methods but also exceeds the state-of-the-art (SOTA) supervised methods. One important observation is that the quality of the dataset seems more important than the size in self-supervised pre-training of rPPG. The source code is released at https://github.com/linuxsino/rPPG-MAE.|
|**2023-06-01**|**Privacy-Preserving Remote Heart Rate Estimation from Facial Videos**|Divij Gupta et.al.|[2306.01141v1](http://arxiv.org/abs/2306.01141v1)|null|Remote Photoplethysmography (rPPG) is the process of estimating PPG from facial videos. While this approach benefits from contactless interaction, it is reliant on videos of faces, which often constitutes an important privacy concern. Recent research has revealed that deep learning techniques are vulnerable to attacks, which can result in significant data breaches making deep rPPG estimation even more sensitive. To address this issue, we propose a data perturbation method that involves extraction of certain areas of the face with less identity-related information, followed by pixel shuffling and blurring. Our experiments on two rPPG datasets (PURE and UBFC) show that our approach reduces the accuracy of facial recognition algorithms by over 60%, with minimal impact on rPPG extraction. We also test our method on three facial recognition datasets (LFW, CALFW, and AgeDB), where our approach reduced performance by nearly 50%. Our findings demonstrate the potential of our approach as an effective privacy-preserving solution for rPPG estimation.|
|**2023-05-25**|**Mask Attack Detection Using Vascular-weighted Motion-robust rPPG Signals**|Chenglin Yao et.al.|[2305.15940v1](http://arxiv.org/abs/2305.15940v1)|null|Detecting 3D mask attacks to a face recognition system is challenging. Although genuine faces and 3D face masks show significantly different remote photoplethysmography (rPPG) signals, rPPG-based face anti-spoofing methods often suffer from performance degradation due to unstable face alignment in the video sequence and weak rPPG signals. To enhance the rPPG signal in a motion-robust way, a landmark-anchored face stitching method is proposed to align the faces robustly and precisely at the pixel-wise level by using both SIFT keypoints and facial landmarks. To better encode the rPPG signal, a weighted spatial-temporal representation is proposed, which emphasizes the face regions with rich blood vessels. In addition, characteristics of rPPG signals in different color spaces are jointly utilized. To improve the generalization capability, a lightweight EfficientNet with a Gated Recurrent Unit (GRU) is designed to extract both spatial and temporal features from the rPPG spatial-temporal representation for classification. The proposed method is compared with the state-of-the-art methods on five benchmark datasets under both intra-dataset and cross-dataset evaluations. The proposed method shows a significant and consistent improvement in performance over other state-of-the-art rPPG-based methods for face spoofing detection.|
|**2023-05-24**|**Promoting Generalization in Cross-Dataset Remote Photoplethysmography**|Nathan Vance et.al.|[2305.15199v1](http://arxiv.org/abs/2305.15199v1)|null|Remote Photoplethysmography (rPPG), or the remote monitoring of a subject's heart rate using a camera, has seen a shift from handcrafted techniques to deep learning models. While current solutions offer substantial performance gains, we show that these models tend to learn a bias to pulse wave features inherent to the training dataset. We develop augmentations to mitigate this learned bias by expanding both the range and variability of heart rates that the model sees while training, resulting in improved model convergence when training and cross-dataset generalization at test time. Through a 3-way cross dataset analysis we demonstrate a reduction in mean absolute error from over 13 beats per minute to below 3 beats per minute. We compare our method with other recent rPPG systems, finding similar performance under a variety of evaluation parameters.|
|**2023-05-23**|**Amplitude-Independent Machine Learning for PPG through Visibility Graphs and Transfer Learning**|Yuyang Miao et.al.|[2305.14062v1](http://arxiv.org/abs/2305.14062v1)|null|Photoplethysmography (PPG) signals are omnipresent in wearable devices, as they measure blood volume variations using LED technology. These signals provide insight into the body's circulatory system and can be employed to extract various bio-features, such as heart rate and vascular ageing. Although several algorithms have been proposed for this purpose, many exhibit limitations, including heavy reliance on human calibration, high signal quality requirements, and a lack of generalization. In this paper, we introduce a PPG signal processing framework that integrates graph theory and computer vision algorithms, which is invariant to affine transformations, offers rapid computation speed, and exhibits robust generalization across tasks and datasets.|
|**2023-05-21**|**Your smartphone could act as a pulse-oximeter and as a single-lead ECG**|Ahsan Mehmood et.al.|[2305.12583v1](http://arxiv.org/abs/2305.12583v1)|null|In the post-covid19 era, every new wave of the pandemic causes an increased concern among the masses to learn more about their state of well-being. Therefore, it is the need of the hour to come up with ubiquitous, low-cost, non-invasive tools for rapid and continuous monitoring of body vitals that reflect the status of one's overall health. In this backdrop, this work proposes a deep learning approach to turn a smartphone-the popular hand-held personal gadget-into a diagnostic tool to measure/monitor the three most important body vitals, i.e., pulse rate (PR), blood oxygen saturation level (aka SpO2), and respiratory rate (RR). Furthermore, we propose another method that could extract a single-lead electrocardiograph (ECG) of the subject. The proposed methods include the following core steps: subject records a small video of his/her fingertip by placing his/her finger on the rear camera of the smartphone, and the recorded video is pre-processed to extract the filtered and/or detrended video-photoplethysmography (vPPG) signal, which is then fed to custom-built convolutional neural networks (CNN), which eventually spit-out the vitals (PR, SpO2, and RR) as well as a single-lead ECG of the subject. To be precise, the contribution of this paper is two-fold: 1) estimation of the three body vitals (PR, SpO2, RR) from the vPPG data using custom-built CNNs, vision transformer, and most importantly by CLIP model; 2) a novel discrete cosine transform+feedforward neural network-based method that translates the recorded video- PPG signal to a single-lead ECG signal. The proposed method is anticipated to find its application in several use-case scenarios, e.g., remote healthcare, mobile health, fitness, sports, etc.|
|**2023-05-09**|**Predicting Cardiovascular Disease Risk using Photoplethysmography and Deep Learning**|Wei-Hung Weng et.al.|[2305.05648v1](http://arxiv.org/abs/2305.05648v1)|null|Cardiovascular diseases (CVDs) are responsible for a large proportion of premature deaths in low- and middle-income countries. Early CVD detection and intervention is critical in these populations, yet many existing CVD risk scores require a physical examination or lab measurements, which can be challenging in such health systems due to limited accessibility. Here we investigated the potential to use photoplethysmography (PPG), a sensing technology available on most smartphones that can potentially enable large-scale screening at low cost, for CVD risk prediction. We developed a deep learning PPG-based CVD risk score (DLS) to predict the probability of having major adverse cardiovascular events (MACE: non-fatal myocardial infarction, stroke, and cardiovascular death) within ten years, given only age, sex, smoking status and PPG as predictors. We compared the DLS with the office-based refit-WHO score, which adopts the shared predictors from WHO and Globorisk scores (age, sex, smoking status, height, weight and systolic blood pressure) but refitted on the UK Biobank (UKB) cohort. In UKB cohort, DLS's C-statistic (71.1%, 95% CI 69.9-72.4) was non-inferior to office-based refit-WHO score (70.9%, 95% CI 69.7-72.2; non-inferiority margin of 2.5%, p<0.01). The calibration of the DLS was satisfactory, with a 1.8% mean absolute calibration error. Adding DLS features to the office-based score increased the C-statistic by 1.0% (95% CI 0.6-1.4). DLS predicts ten-year MACE risk comparable with the office-based refit-WHO score. It provides a proof-of-concept and suggests the potential of a PPG-based approach strategies for community-based primary prevention in resource-limited regions.|
|**2023-04-28**|**Non-Contact Heart Rate Measurement from Deteriorated Videos**|Nhi Nguyen et.al.|[2304.14789v1](http://arxiv.org/abs/2304.14789v1)|null|Remote photoplethysmography (rPPG) offers a state-of-the-art, non-contact methodology for estimating human pulse by analyzing facial videos. Despite its potential, rPPG methods can be susceptible to various artifacts, such as noise, occlusions, and other obstructions caused by sunglasses, masks, or even involuntary facial contact, such as individuals inadvertently touching their faces. In this study, we apply image processing transformations to intentionally degrade video quality, mimicking these challenging conditions, and subsequently evaluate the performance of both non-learning and learning-based rPPG methods on the deteriorated data. Our results reveal a significant decrease in accuracy in the presence of these artifacts, prompting us to propose the application of restoration techniques, such as denoising and inpainting, to improve heart-rate estimation outcomes. By addressing these challenging conditions and occlusion artifacts, our approach aims to make rPPG methods more robust and adaptable to real-world situations. To assess the effectiveness of our proposed methods, we undertake comprehensive experiments on three publicly available datasets, encompassing a wide range of scenarios and artifact types. Our findings underscore the potential to construct a robust rPPG system by employing an optimal combination of restoration algorithms and rPPG techniques. Moreover, our study contributes to the advancement of privacy-conscious rPPG methodologies, thereby bolstering the overall utility and impact of this innovative technology in the field of remote heart-rate estimation under realistic and diverse conditions.|
|**2023-04-21**|**Heart Rate Extraction from Abdominal Audio Signals**|Jake Stuchbury-Wass et.al.|[2304.11020v1](http://arxiv.org/abs/2304.11020v1)|null|Abdominal sounds (ABS) have been traditionally used for assessing gastrointestinal (GI) disorders. However, the assessment requires a trained medical professional to perform multiple abdominal auscultation sessions, which is resource-intense and may fail to provide an accurate picture of patients' continuous GI wellbeing. This has generated a technological interest in developing wearables for continuous capture of ABS, which enables a fuller picture of patient's GI status to be obtained at reduced cost. This paper seeks to evaluate the feasibility of extracting heart rate (HR) from such ABS monitoring devices. The collection of HR directly from these devices would enable gathering vital signs alongside GI data without the need for additional wearable devices, providing further cost benefits and improving general usability. We utilised a dataset containing 104 hours of ABS audio, collected from the abdomen using an e-stethoscope, and electrocardiogram as ground truth. Our evaluation shows for the first time that we can successfully extract HR from audio collected from a wearable on the abdomen. As heart sounds collected from the abdomen suffer from significant noise from GI and respiratory tracts, we leverage wavelet denoising for improved heart beat detection. The mean absolute error of the algorithm for average HR is 3.4 BPM with mean directional error of -1.2 BPM over the whole dataset. A comparison to photoplethysmography-based wearable HR sensors shows that our approach exhibits comparable accuracy to consumer wrist-worn wearables for average and instantaneous heart rate.|
|**2023-04-21**|**IoT-Based Solution for Paraplegic Sufferer to Send Signals to Physician via Internet**|L. Srinivasan et.al.|[2304.10840v1](http://arxiv.org/abs/2304.10840v1)|null|We come across hospitals and non-profit organizations that care for people with paralysis who have experienced all or portion of their physique being incapacitated by the paralyzing attack. Due to a lack of motor coordination by their mind, these persons are typically unable to communicate their requirements because they can speak clearly or use sign language. In such a case, we suggest a system that enables a disabled person to move any area of his body capable of moving to broadcast a text on the LCD. This method also addresses the circumstance in which the patient cannot be attended to in person and instead sends an SMS message using GSM. By detecting the user part's tilt direction, our suggested system operates. As a result, patients can communicate with physicians, therapists, or their loved ones at home or work over the web. Case-specific data, such as heart rate, must be continuously reported in health centers. The suggested method tracks the body of the case's pulse rate and other comparable data. For instance, photoplethysmography is used to assess heart rate. The decoded periodic data is transmitted continually via a Microcontroller coupled to a transmitting module. The croaker's cabin contains a receiver device that obtains and deciphers data as well as constantly exhibits it on Graphical interfaces viewable on the laptop. As a result, the croaker can monitor and handle multiple situations at once.|
|**2023-04-14**|**PPG Signals for Hypertension Diagnosis: A Novel Method using Deep Learning Models**|Graham Frederick et.al.|[2304.06952v1](http://arxiv.org/abs/2304.06952v1)|null|Hypertension is a medical condition characterized by high blood pressure, and classifying it into its various stages is crucial to managing the disease. In this project, a novel method is proposed for classifying stages of hypertension using Photoplethysmography (PPG) signals and deep learning models, namely AvgPool_VGG-16. The PPG signal is a non-invasive method of measuring blood pressure through the use of light sensors that measure the changes in blood volume in the microvasculature of tissues. PPG images from the publicly available blood pressure classification dataset were used to train the model. Multiclass classification for various PPG stages were done. The results show the proposed method achieves high accuracy in classifying hypertension stages, demonstrating the potential of PPG signals and deep learning models in hypertension diagnosis and management.|
|**2023-04-05**|**Deep Learning Systems for Advanced Driving Assistance**|Francesco Rundo et.al.|[2304.06041v1](http://arxiv.org/abs/2304.06041v1)|null|Next generation cars embed intelligent assessment of car driving safety through innovative solutions often based on usage of artificial intelligence. The safety driving monitoring can be carried out using several methodologies widely treated in scientific literature. In this context, the author proposes an innovative approach that uses ad-hoc bio-sensing system suitable to reconstruct the physio-based attentional status of the car driver. To reconstruct the car driver physiological status, the author proposed the use of a bio-sensing probe consisting of a coupled LEDs at Near infrared (NiR) spectrum with a photodetector. This probe placed over the monitored subject allows to detect a physiological signal called PhotoPlethysmoGraphy (PPG). The PPG signal formation is regulated by the change in oxygenated and non-oxygenated hemoglobin concentration in the monitored subject bloodstream which will be directly connected to cardiac activity in turn regulated by the Autonomic Nervous System (ANS) that characterizes the subject's attention level. This so designed car driver drowsiness monitoring will be combined with further driving safety assessment based on correlated intelligent driving scenario understanding.|
|**2023-03-23**|**Efficient and Direct Inference of Heart Rate Variability using Both Signal Processing and Machine Learning**|Yuntong Zhang et.al.|[2303.13637v1](http://arxiv.org/abs/2303.13637v1)|null|Heart Rate Variability (HRV) measures the variation of the time between consecutive heartbeats and is a major indicator of physical and mental health. Recent research has demonstrated that photoplethysmography (PPG) sensors can be used to infer HRV. However, many prior studies had high errors because they only employed signal processing or machine learning (ML), or because they indirectly inferred HRV, or because there lacks large training datasets. Many prior studies may also require large ML models. The low accuracy and large model sizes limit their applications to small embedded devices and potential future use in healthcare. To address the above issues, we first collected a large dataset of PPG signals and HRV ground truth. With this dataset, we developed HRV models that combine signal processing and ML to directly infer HRV. Evaluation results show that our method had errors between 3.5% to 25.7% and outperformed signal-processing-only and ML-only methods. We also explored different ML models, which showed that Decision Trees and Multi-level Perceptrons have 13.0% and 9.1% errors on average with models at most hundreds of KB and inference time less than 1ms. Hence, they are more suitable for small embedded devices and potentially enable the future use of PPG-based HRV monitoring in healthcare.|
|**2023-03-23**|**PPG-based Heart Rate Estimation with Efficient Sensor Sampling and Learning Models**|Yuntong Zhang et.al.|[2303.13636v1](http://arxiv.org/abs/2303.13636v1)|null|Recent studies showed that Photoplethysmography (PPG) sensors embedded in wearable devices can estimate heart rate (HR) with high accuracy. However, despite of prior research efforts, applying PPG sensor based HR estimation to embedded devices still faces challenges due to the energy-intensive high-frequency PPG sampling and the resource-intensive machine-learning models. In this work, we aim to explore HR estimation techniques that are more suitable for lower-power and resource-constrained embedded devices. More specifically, we seek to design techniques that could provide high-accuracy HR estimation with low-frequency PPG sampling, small model size, and fast inference time. First, we show that by combining signal processing and ML, it is possible to reduce the PPG sampling frequency from 125 Hz to only 25 Hz while providing higher HR estimation accuracy. This combination also helps to reduce the ML model feature size, leading to smaller models. Additionally, we present a comprehensive analysis on different ML models and feature sizes to compare their accuracy, model size, and inference time. The models explored include Decision Tree (DT), Random Forest (RF), K-nearest neighbor (KNN), Support vector machines (SVM), and Multi-layer perceptron (MLP). Experiments were conducted using both a widely-utilized dataset and our self-collected dataset. The experimental results show that our method by combining signal processing and ML had only 5% error for HR estimation using low-frequency PPG data. Moreover, our analysis showed that DT models with 10 to 20 input features usually have good accuracy, while are several magnitude smaller in model sizes and faster in inference time.|
|**2023-03-21**|**Motion Matters: Neural Motion Transfer for Better Camera Physiological Sensing**|Akshay Paruchuri et.al.|[2303.12059v2](http://arxiv.org/abs/2303.12059v2)|[link](https://github.com/Roni-Lab/MA-rPPG-Video-Toolbox)|Machine learning models for camera-based physiological measurement can have weak generalization due to a lack of representative training data. Body motion is one of the most significant sources of noise when attempting to recover the subtle cardiac pulse from a video. We explore motion transfer as a form of data augmentation to introduce motion variation while preserving physiological changes. We adapt a neural video synthesis approach to augment videos for the task of remote photoplethysmography (PPG) and study the effects of motion augmentation with respect to 1) the magnitude and 2) the type of motion. After training on motion-augmented versions of publicly available datasets, the presented inter-dataset results on five benchmark datasets show improvements of up to 75% over existing state-of-the-art results. Our findings illustrate the utility of motion transfer as a data augmentation technique for improving the generalization of models for camera-based physiological sensing. We release our code and pre-trained models for using motion transfer as a data augmentation technique on our project page: https://motion-matters.github.io/|
|**2023-03-17**|**HDformer: A Higher Dimensional Transformer for Diabetes Detection Utilizing Long Range Vascular Signals**|Ella Lan et.al.|[2303.11340v1](http://arxiv.org/abs/2303.11340v1)|null|Diabetes mellitus is a worldwide concern, and early detection can help to prevent serious complications. Low-cost, non-invasive detection methods, which take cardiovascular signals into deep learning models, have emerged. However, limited accuracy constrains their clinical usage. In this paper, we present a new Transformer-based architecture, Higher Dimensional Transformer (HDformer), which takes long-range photoplethysmography (PPG) signals to detect diabetes. The long-range PPG contains broader and deeper signal contextual information compared to the less-than-one-minute PPG signals commonly utilized in existing research. To increase the capability and efficiency of processing the long range data, we propose a new attention module Time Square Attention (TSA), reducing the volume of the tokens by more than 10x, while retaining the local/global dependencies. It converts the 1-dimensional inputs into 2-dimensional representations and groups adjacent points into a single 2D token, using the 2D Transformer models as the backbone of the encoder. It generates the dynamic patch sizes into a gated mixture-of-experts (MoE) network as decoder, which optimizes the learning on different attention areas. Extensive experimentations show that HDformer results in the state-of-the-art performance (sensitivity 98.4, accuracy 97.3, specificity 92.8, and AUC 0.929) on the standard MIMIC-III dataset, surpassing existing studies. This work is the first time to take long-range, non-invasive PPG signals via Transformer for diabetes detection, achieving a more scalable and convenient solution compared to traditional invasive approaches. The proposed HDformer can also be scaled to analyze general long-range biomedical waveforms. A wearable prototype finger-ring is designed as a proof of concept.|
|**2023-03-16**|**Full-Body Cardiovascular Sensing with Remote Photoplethysmography**|Lu Niu et.al.|[2303.09638v1](http://arxiv.org/abs/2303.09638v1)|null|Remote photoplethysmography (rPPG) allows for noncontact monitoring of blood volume changes from a camera by detecting minor fluctuations in reflected light. Prior applications of rPPG focused on face videos. In this paper we explored the feasibility of rPPG from non-face body regions such as the arms, legs, and hands. We collected a new dataset titled Multi-Site Physiological Monitoring (MSPM), which will be released with this paper. The dataset consists of 90 frames per second video of exposed arms, legs, and face, along with 10 synchronized PPG recordings. We performed baseline heart rate estimation experiments from non-face regions with several state-of-the-art rPPG approaches, including chrominance-based (CHROM), plane-orthogonal-to-skin (POS) and RemotePulseNet (RPNet). To our knowledge, this is the first evaluation of the fidelity of rPPG signals simultaneously obtained from multiple regions of a human body. Our experiments showed that skin pixels from arms, legs, and hands are all potential sources of the blood volume pulse. The best-performing approach, POS, achieved a mean absolute error peaking at 7.11 beats per minute from non-facial body parts compared to 1.38 beats per minute from the face. Additionally, we performed experiments on pulse transit time (PTT) from both the contact PPG and rPPG signals. We found that remote PTT is possible with moderately high frame rate video when distal locations on the body are visible. These findings and the supporting dataset should facilitate new research on non-face rPPG and monitoring blood flow dynamics over the whole body with a camera.|
|**2023-03-16**|**Image Enhancement for Remote Photoplethysmography in a Low-Light Environment**|Lin Xi et.al.|[2303.09336v1](http://arxiv.org/abs/2303.09336v1)|[link](https://github.com/xilin1991/Large-scale-Multi-illumination-HR-Database)|With the improvement of sensor technology and significant algorithmic advances, the accuracy of remote heart rate monitoring technology has been significantly improved. Despite of the significant algorithmic advances, the performance of rPPG algorithm can degrade in the long-term, high-intensity continuous work occurred in evenings or insufficient light environments. One of the main challenges is that the lost facial details and low contrast cause the failure of detection and tracking. Also, insufficient lighting in video capturing hurts the quality of physiological signal. In this paper, we collect a large-scale dataset that was designed for remote heart rate estimation recorded with various illumination variations to evaluate the performance of the rPPG algorithm (Green, ICA, and POS). We also propose a low-light enhancement solution (technical solution) for remote heart rate estimation under the low-light condition. Using collected dataset, we found 1) face detection algorithm cannot detect faces in video captured in low light conditions; 2) A decrease in the amplitude of the pulsatile signal will lead to the noise signal to be in the dominant position; and 3) the chrominance-based method suffers from the limitation in the assumption about skin-tone will not hold, and Green and ICA method receive less influence than POS in dark illuminance environment. The proposed solution for rPPG process is effective to detect and improve the signal-to-noise ratio and precision of the pulsatile signal.|
|**2023-03-14**|**Non-Contrastive Unsupervised Learning of Physiological Signals from Video**|Jeremy Speth et.al.|[2303.07944v1](http://arxiv.org/abs/2303.07944v1)|[link](https://github.com/cvrl/sinc-rppg)|Subtle periodic signals such as blood volume pulse and respiration can be extracted from RGB video, enabling remote health monitoring at low cost. Advancements in remote pulse estimation -- or remote photoplethysmography (rPPG) -- are currently driven by deep learning solutions. However, modern approaches are trained and evaluated on benchmark datasets with associated ground truth from contact-PPG sensors. We present the first non-contrastive unsupervised learning framework for signal regression to break free from the constraints of labelled video data. With minimal assumptions of periodicity and finite bandwidth, our approach is capable of discovering the blood volume pulse directly from unlabelled videos. We find that encouraging sparse power spectra within normal physiological bandlimits and variance over batches of power spectra is sufficient for learning visual features of periodic signals. We perform the first experiments utilizing unlabelled video data not specifically created for rPPG to train robust pulse rate estimators. Given the limited inductive biases and impressive empirical results, the approach is theoretically capable of discovering other periodic signals from video, enabling multiple physiological measurements without the need for ground truth signals. Codes to fully reproduce the experiments are made available along with the paper.|
|**2023-03-14**|**ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario**|Alexander Heimerl et.al.|[2303.07742v1](http://arxiv.org/abs/2303.07742v1)|null|We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.|
|**2023-03-11**|**Hallucinated Heartbeats: Anomaly-Aware Remote Pulse Estimation**|Jeremy Speth et.al.|[2303.06452v1](http://arxiv.org/abs/2303.06452v1)|null|Camera-based physiological monitoring, especially remote photoplethysmography (rPPG), is a promising tool for health diagnostics, and state-of-the-art pulse estimators have shown impressive performance on benchmark datasets. We argue that evaluations of modern solutions may be incomplete, as we uncover failure cases for videos without a live person, or in the presence of severe noise. We demonstrate that spatiotemporal deep learning models trained only with live samples "hallucinate" a genuine-shaped pulse on anomalous and noisy videos, which may have negative consequences when rPPG models are used by medical personnel. To address this, we offer: (a) An anomaly detection model, built on top of the predicted waveforms. We compare models trained in open-set (unknown abnormal predictions) and closed-set (abnormal predictions known when training) settings; (b) An anomaly-aware training regime that penalizes the model for predicting periodic signals from anomalous videos. Extensive experimentation with eight research datasets (rPPG-specific: DDPM, CDDPM, PURE, UBFC, ARPM; deep fakes: DFDC; face presentation attack detection: HKBU-MARs; rPPG outlier: KITTI) show better accuracy of anomaly detection for deep learning models incorporating the proposed training (75.8%), compared to models trained regularly (73.7%) and to hand-crafted rPPG methods (52-62%).|
|**2023-03-10**|**Neuron Structure Modeling for Generalizable Remote Physiological Measurement**|Hao Lu et.al.|[2303.05955v1](http://arxiv.org/abs/2303.05955v1)|[link](https://github.com/lupaopao/nest)|Remote photoplethysmography (rPPG) technology has drawn increasing attention in recent years. It can extract Blood Volume Pulse (BVP) from facial videos, making many applications like health monitoring and emotional analysis more accessible. However, as the BVP signal is easily affected by environmental changes, existing methods struggle to generalize well for unseen domains. In this paper, we systematically address the domain shift problem in the rPPG measurement task. We show that most domain generalization methods do not work well in this problem, as domain labels are ambiguous in complicated environmental changes. In light of this, we propose a domain-label-free approach called NEuron STructure modeling (NEST). NEST improves the generalization capacity by maximizing the coverage of feature space during training, which reduces the chance for under-optimized feature activation during inference. Besides, NEST can also enrich and enhance domain invariant features across multi-domain. We create and benchmark a large-scale domain generalization protocol for the rPPG measurement task. Extensive experiments show that our approach outperforms the state-of-the-art methods on both cross-dataset and intra-dataset settings.|
|**2023-02-08**|**MMPD: Multi-Domain Mobile Video Physiology Dataset**|Jiankai Tang et.al.|[2302.03840v2](http://arxiv.org/abs/2302.03840v2)|[link](https://github.com/thu-cs-pi/mmpd_rppg_dataset)|Remote photoplethysmography (rPPG) is an attractive method for noninvasive, convenient and concomitant measurement of physiological vital signals. Public benchmark datasets have served a valuable role in the development of this technology and improvements in accuracy over recent years.However, there remain gaps in the public datasets.First, despite the ubiquity of cameras on mobile devices, there are few datasets recorded specifically with mobile phone cameras. Second, most datasets are relatively small and therefore are limited in diversity, both in appearance (e.g., skin tone), behaviors (e.g., motion) and environment (e.g., lighting conditions). In an effort to help the field advance, we present the Multi-domain Mobile Video Physiology Dataset (MMPD), comprising 11 hours of recordings from mobile phones of 33 subjects. The dataset is designed to capture videos with greater representation across skin tone, body motion, and lighting conditions. MMPD is comprehensive with eight descriptive labels and can be used in conjunction with the rPPG-toolbox. The reliability of the dataset is verified by mainstream unsupervised methods and neural methods. The GitHub repository of our dataset: https://github.com/THU-CS-PI/MMPD_rPPG_dataset.|
|**2023-02-07**|**Can gamification reduce the burden of self-reporting in mHealth applications? A feasibility study using machine learning from smartwatch data to estimate cognitive load**|Michal K. Grzeszczyk et.al.|[2302.03616v2](http://arxiv.org/abs/2302.03616v2)|null|The effectiveness of digital treatments can be measured by requiring patients to self-report their state through applications, however, it can be overwhelming and causes disengagement. We conduct a study to explore the impact of gamification on self-reporting. Our approach involves the creation of a system to assess cognitive load (CL) through the analysis of photoplethysmography (PPG) signals. The data from 11 participants is utilized to train a machine learning model to detect CL. Subsequently, we create two versions of surveys: a gamified and a traditional one. We estimate the CL experienced by other participants (13) while completing surveys. We find that CL detector performance can be enhanced via pre-training on stress detection tasks. For 10 out of 13 participants, a personalized CL detector can achieve an F1 score above 0.7. We find no difference between the gamified and non-gamified surveys in terms of CL but participants prefer the gamified version.|
|**2023-02-07**|**PhysFormer++: Facial Video-based Physiological Measurement with SlowFast Temporal Difference Transformer**|Zitong Yu et.al.|[2302.03548v1](http://arxiv.org/abs/2302.03548v1)|null|Remote photoplethysmography (rPPG), which aims at measuring heart activities and physiological signals from facial video without any contact, has great potential in many applications (e.g., remote healthcare and affective computing). Recent deep learning approaches focus on mining subtle rPPG clues using convolutional neural networks with limited spatio-temporal receptive fields, which neglect the long-range spatio-temporal perception and interaction for rPPG modeling. In this paper, we propose two end-to-end video transformer based architectures, namely PhysFormer and PhysFormer++, to adaptively aggregate both local and global spatio-temporal features for rPPG representation enhancement. As key modules in PhysFormer, the temporal difference transformers first enhance the quasi-periodic rPPG features with temporal difference guided global attention, and then refine the local spatio-temporal representation against interference. To better exploit the temporal contextual and periodic rPPG clues, we also extend the PhysFormer to the two-pathway SlowFast based PhysFormer++ with temporal difference periodic and cross-attention transformers. Furthermore, we propose the label distribution learning and a curriculum learning inspired dynamic constraint in frequency domain, which provide elaborate supervisions for PhysFormer and PhysFormer++ and alleviate overfitting. Comprehensive experiments are performed on four benchmark datasets to show our superior performance on both intra- and cross-dataset testings. Unlike most transformer networks needed pretraining from large-scale datasets, the proposed PhysFormer family can be easily trained from scratch on rPPG datasets, which makes it promising as a novel transformer baseline for the rPPG community.|
|**2023-01-16**|**A Deep Learning & Fast Wavelet Transform-based Hybrid Approach for Denoising of PPG Signals**|Rabia Ahmed et.al.|[2301.06549v1](http://arxiv.org/abs/2301.06549v1)|null|This letter presents a novel hybrid method that leverages deep learning to exploit the multi-resolution analysis capability of the wavelets, in order to denoise a photoplethysmography (PPG) signal. Under the proposed method, a noisy PPG sequence of length N is first decomposed into L detailed coefficients using the fast wavelet transform (FWT). Then, the clean PPG sequence is reconstructed as follows. A custom feedforward neural network (FFNN) provides the binary weights for each of the wavelet sub-signals outputted by the inverse-FWT block. This way, all those sub-signals which correspond to noise or artefacts are discarded during reconstruction. The FFNN is trained on the Beth Israel Deaconess Medical Center (BIDMC) dataset under the supervised learning framework, whereby we compute the mean squared-error (MSE) between the denoised sequence and the reference clean PPG signal, and compute the gradient of the MSE for the back-propagation. Numerical results show that the proposed method effectively denoises the corrupted PPG and video-PPG signal.|
|**2023-01-07**|**A Greedy-optimized Framework for Heart Rate Variability Monitoring during Daily Activities using Wearable Photoplethysmography**|Luffina C. Huang et.al.|[2301.02906v1](http://arxiv.org/abs/2301.02906v1)|null|Continuous monitoring of inter-beat-interval (IBI) and heart rate variability (HRV) provides insights in cardiovascular, neurological, and mental health. Photoplethysmography (PPG) from wearables assures convenient measurement of IBI. However, PPG is susceptible to motion artifacts, considerably deteriorating the accuracy of IBIs estimation. Although a multi-channel model in previous study improves accuracy, prevailing compact commercial wearables would favor single-channel sensors, causing benefits of multi-channel applications to have restrictions. In this paper, a greedy-optimized framework is proposed for measurement of IBI and HRV featuring single-channel and multi-channel PPG signals collected during daily activities. Utilizing the fact of continuity in heartbeats, the IBI estimation problem is converted into the shortest path problem in a directed acyclic graph, where candidate heartbeats from the noisy PPG are regarded as vertices. The framework exploits a convex penalty function to optimize weight assignment in the shortest path calculation and a greedy-optimized fusion method to mitigate overly fluctuating patterns in estimated IBIs. The results achieve correlation of 0.96 with percentage error of 3.2% for IBI estimation using single-channel PPG signals from the 2015 IEEE Signal Processing Cup dataset, where percentage error is reduced by 58.4% and correlation is improved by 11.6% in comparison to those without greedy-optimized fusion. In the multi-channel model, it achieves correlation of 0.98 with percentage error of 2.2%. Estimated and true HRV parameters are also highly correlated with low percentage errors. This paper further validates these techniques on the PPG-DaLiA dataset, indicating the robustness of the proposed framework.|

## camera

### wearable camera
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-22**|**Affine Correspondences between Multi-Camera Systems for Relative Pose Estimation**|Banglei Guan et.al.|[2306.12996v1](http://arxiv.org/abs/2306.12996v1)|[link](https://github.com/jizhaox/relpose-mcs-depth)|We present a novel method to compute the relative pose of multi-camera systems using two affine correspondences (ACs). Existing solutions to the multi-camera relative pose estimation are either restricted to special cases of motion, have too high computational complexity, or require too many point correspondences (PCs). Thus, these solvers impede an efficient or accurate relative pose estimation when applying RANSAC as a robust estimator. This paper shows that the 6DOF relative pose estimation problem using ACs permits a feasible minimal solution, when exploiting the geometric constraints between ACs and multi-camera systems using a special parameterization. We present a problem formulation based on two ACs that encompass two common types of ACs across two views, i.e., inter-camera and intra-camera. Moreover, the framework for generating the minimal solvers can be extended to solve various relative pose estimation problems, e.g., 5DOF relative pose estimation with known rotation angle prior. Experiments on both virtual and real multi-camera systems prove that the proposed solvers are more efficient than the state-of-the-art algorithms, while resulting in a better relative pose accuracy. Source code is available at https://github.com/jizhaox/relpose-mcs-depth.|
|**2023-06-22**|**Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers**|Qi Jiang et.al.|[2306.12992v1](http://arxiv.org/abs/2306.12992v1)|[link](https://github.com/zju-jiangqi/pcie-part)|High-quality panoramic images with a Field of View (FoV) of 360-degree are essential for contemporary panoramic computer vision tasks. However, conventional imaging systems come with sophisticated lens designs and heavy optical components. This disqualifies their usage in many mobile and wearable applications where thin and portable, minimalist imaging systems are desired. In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to address minimalist and high-quality panoramic imaging. With less than three spherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is constructed based on the design of the Panoramic Annular Lens (PAL), but with low-quality imaging results due to aberrations and small image plane size. We propose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and Aberration Correction (SR&AC), to solve the image quality problems of MPIP, with imaging sensors of small and large pixel size, respectively. To provide a universal network for the two pipelines, we leverage the information from the Point Spread Function (PSF) of the optical system and design a PSF-aware Aberration-image Recovery Transformer (PART), in which the self-attention calculation and feature extraction are guided via PSF-aware mechanisms. We train PART on synthetic image pairs from simulation and put forward the PALHQ dataset to fill the gap of real-world high-quality PAL images for low-level vision. A comprehensive variety of experiments on synthetic and real-world benchmarks demonstrates the impressive imaging results of PCIE and the effectiveness of plug-and-play PSF-aware mechanisms. We further deliver heuristic experimental findings for minimalist and high-quality panoramic imaging. Our dataset and code will be available at https://github.com/zju-jiangqi/PCIE-PART.|
|**2023-06-22**|**Relevance-Based Compression of Cataract Surgery Videos**|Natalia Mathá et.al.|[2306.12829v1](http://arxiv.org/abs/2306.12829v1)|null|In the last decade, the need for storing videos from cataract surgery has increased significantly. Hospitals continue to improve their imaging and recording devices (e.g., microscopes and cameras used in microscopic surgery, such as ophthalmology) to enhance their post-surgical processing efficiency. The video recordings enable a lot of user-cases after the actual surgery, for example, teaching, documentation, and forensics. However, videos recorded from operations are typically stored in the internal archive without any domain-specific compression, leading to a massive storage space consumption. In this work, we propose a relevance-based compression scheme for videos from cataract surgery, which is based on content specifics of particular cataract surgery phases. We evaluate our compression scheme with three state-of-the-art video codecs, namely H.264/AVC, H.265/HEVC, and AV1, and ask medical experts to evaluate the visual quality of encoded videos. Our results show significant savings, in particular up to 95.94% when using H.264/AVC, up to 98.71% when using H.265/HEVC, and up to 98.82% when using AV1.|
|**2023-06-22**|**3D Reconstruction of Spherical Images based on Incremental Structure from Motion**|San Jiang et.al.|[2306.12770v1](http://arxiv.org/abs/2306.12770v1)|null|3D reconstruction plays an increasingly important role in modern photogrammetric systems. Conventional satellite or aerial-based remote sensing (RS) platforms can provide the necessary data sources for the 3D reconstruction of large-scale landforms and cities. Even with low-altitude UAVs (Unmanned Aerial Vehicles), 3D reconstruction in complicated situations, such as urban canyons and indoor scenes, is challenging due to the frequent tracking failures between camera frames and high data collection costs. Recently, spherical images have been extensively exploited due to the capability of recording surrounding environments from one camera exposure. Classical 3D reconstruction pipelines, however, cannot be used for spherical images. Besides, there exist few software packages for 3D reconstruction of spherical images. Based on the imaging geometry of spherical cameras, this study investigates the algorithms for the relative orientation using spherical correspondences, absolute orientation using 3D correspondences between scene and spherical points, and the cost functions for BA (bundle adjustment) optimization. In addition, an incremental SfM (Structure from Motion) workflow has been proposed for spherical images using the above-mentioned algorithms. The proposed solution is finally verified by using three spherical datasets captured by both consumer-grade and professional spherical cameras. The results demonstrate that the proposed SfM workflow can achieve the successful 3D reconstruction of complex scenes and provide useful clues for the implementation in open-source software packages. The source code of the designed SfM workflow would be made publicly available.|
|**2023-06-22**|**PEBO-SLAM: Observer design for visual inertial SLAM with convergence guarantees**|Bowen Yi et.al.|[2306.12723v1](http://arxiv.org/abs/2306.12723v1)|null|This paper introduces a new linear parameterization to the problem of visual inertial simultaneous localization and mapping (VI-SLAM) -- without any approximation -- for the case only using information from a single monocular camera and an inertial measurement unit. In this problem set, the system state evolves on the nonlinear manifold $SE(3)\times \mathbb{R}^{3n}$, on which we design dynamic extensions carefully to generate invariant foliations, such that the problem can be reformulated into online \emph{constant parameter} identification, then interestingly with linear regression models obtained. It demonstrates that VI-SLAM can be translated into a linear least squares problem, in the deterministic sense, \emph{globally} and \emph{exactly}. Based on this observation, we propose a novel SLAM observer, following the recently established parameter estimation-based observer (PEBO) methodology. A notable merit is that the proposed observer enjoys almost global asymptotic stability, requiring neither persistency of excitation nor uniform complete observability, which, however, are widely adopted in most existing works with provable stability but can hardly be assured in many practical scenarios.|
|**2023-06-22**|**One at A Time: Multi-step Volumetric Probability Distribution Diffusion for Depth Estimation**|Bohan Li et.al.|[2306.12681v1](http://arxiv.org/abs/2306.12681v1)|null|Recent works have explored the fundamental role of depth estimation in multi-view stereo (MVS) and semantic scene completion (SSC). They generally construct 3D cost volumes to explore geometric correspondence in depth, and estimate such volumes in a single step relying directly on the ground truth approximation. However, such problem cannot be thoroughly handled in one step due to complex empirical distributions, especially in challenging regions like occlusions, reflections, etc. In this paper, we formulate the depth estimation task as a multi-step distribution approximation process, and introduce a new paradigm of modeling the Volumetric Probability Distribution progressively (step-by-step) following a Markov chain with Diffusion models (VPDD). Specifically, to constrain the multi-step generation of volume in VPDD, we construct a meta volume guidance and a confidence-aware contextual guidance as conditional geometry priors to facilitate the distribution approximation. For the sampling process, we further investigate an online filtering strategy to maintain consistency in volume representations for stable training. Experiments demonstrate that our plug-and-play VPDD outperforms the state-of-the-arts for tasks of MVS and SSC, and can also be easily extended to different baselines to get improvement. It is worth mentioning that we are the first camera-based work that surpasses LiDAR-based methods on the SemanticKITTI dataset.|
|**2023-06-22**|**RXFOOD: Plug-in RGB-X Fusion for Object of Interest Detection**|Jin Ma et.al.|[2306.12621v1](http://arxiv.org/abs/2306.12621v1)|null|The emergence of different sensors (Near-Infrared, Depth, etc.) is a remedy for the limited application scenarios of traditional RGB camera. The RGB-X tasks, which rely on RGB input and another type of data input to resolve specific problems, have become a popular research topic in multimedia. A crucial part in two-branch RGB-X deep neural networks is how to fuse information across modalities. Given the tremendous information inside RGB-X networks, previous works typically apply naive fusion (e.g., average or max fusion) or only focus on the feature fusion at the same scale(s). While in this paper, we propose a novel method called RXFOOD for the fusion of features across different scales within the same modality branch and from different modality branches simultaneously in a unified attention mechanism. An Energy Exchange Module is designed for the interaction of each feature map's energy matrix, who reflects the inter-relationship of different positions and different channels inside a feature map. The RXFOOD method can be easily incorporated to any dual-branch encoder-decoder network as a plug-in module, and help the original backbone network better focus on important positions and channels for object of interest detection. Experimental results on RGB-NIR salient object detection, RGB-D salient object detection, and RGBFrequency image manipulation detection demonstrate the clear effectiveness of the proposed RXFOOD.|
|**2023-06-21**|**Arc-to-line frame registration method for ultrasound and photoacoustic image-guided intraoperative robot-assisted laparoscopic prostatectomy**|Hyunwoo Song et.al.|[2306.12590v1](http://arxiv.org/abs/2306.12590v1)|null|Purpose: To achieve effective robot-assisted laparoscopic prostatectomy, the integration of transrectal ultrasound (TRUS) imaging system which is the most widely used imaging modelity in prostate imaging is essential. However, manual manipulation of the ultrasound transducer during the procedure will significantly interfere with the surgery. Therefore, we propose an image co-registration algorithm based on a photoacoustic marker method, where the ultrasound / photoacoustic (US/PA) images can be registered to the endoscopic camera images to ultimately enable the TRUS transducer to automatically track the surgical instrument Methods: An optimization-based algorithm is proposed to co-register the images from the two different imaging modalities. The principles of light propagation and an uncertainty in PM detection were assumed in this algorithm to improve the stability and accuracy of the algorithm. The algorithm is validated using the previously developed US/PA image-guided system with a da Vinci surgical robot. Results: The target-registration-error (TRE) is measured to evaluate the proposed algorithm. In both simulation and experimental demonstration, the proposed algorithm achieved a sub-centimeter accuracy which is acceptable in practical clinics. The result is also comparable with our previous approach, and the proposed method can be implemented with a normal white light stereo camera and doesn't require highly accurate localization of the PM. Conclusion: The proposed frame registration algorithm enabled a simple yet efficient integration of commercial US/PA imaging system into laparoscopic surgical setting by leveraging the characteristic properties of acoustic wave propagation and laser excitation, contributing to automated US/PA image-guided surgical intervention applications.|
|**2023-06-21**|**Varstrometry for Off-nucleus and Dual sub-Kpc AGN (VODKA). SDSS J1608+2716: A Sub-arcsec Quadruply Lensed Quasar at $z=2.575$**|Junyao Li et.al.|[2306.12502v1](http://arxiv.org/abs/2306.12502v1)|null|We report Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3) deep IR (F160W) imaging of SDSS J1608+2716. This system, located at a redshift of $z=2.575$, was recently reported as a triple quasar candidate with subarcsecond separations ($\sim0.25''$) based on selection from Gaia astrometry and follow-up Keck adaptive optics-assisted integral field unit spectroscopy. Our new HST deep IR imaging reveals the presence of a fourth point-like component located $\sim0.9''$ away from the triple system. Additionally, we detect an edge-on disk galaxy located in between the four point sources, which appears to be in the process of merging with a fainter companion galaxy. The entire system exhibits a characteristic cusp structure in the context of strong gravitational lensing, and the observed image configuration can be successfully reproduced using a lens model based on a singular isothermal ellipsoid mass profile. These findings indicate that this system is a quadruply lensed quasar. Our results highlight the challenges associated with identifying dual/multiple quasars on $\sim$kpc scales at high redshifts, and emphasize the crucial role of deep, high-resolution IR imaging in robustly confirming such systems.|
|**2023-06-21**|**Benchmarking and Analyzing 3D-aware Image Synthesis with a Modularized Codebase**|Qiuyu Wang et.al.|[2306.12423v1](http://arxiv.org/abs/2306.12423v1)|[link](https://github.com/qiuyu96/carver)|Despite the rapid advance of 3D-aware image synthesis, existing studies usually adopt a mixture of techniques and tricks, leaving it unclear how each part contributes to the final performance in terms of generality. Following the most popular and effective paradigm in this field, which incorporates a neural radiance field (NeRF) into the generator of a generative adversarial network (GAN), we build a well-structured codebase, dubbed Carver, through modularizing the generation process. Such a design allows researchers to develop and replace each module independently, and hence offers an opportunity to fairly compare various approaches and recognize their contributions from the module perspective. The reproduction of a range of cutting-edge algorithms demonstrates the availability of our modularized codebase. We also perform a variety of in-depth analyses, such as the comparison across different types of point feature, the necessity of the tailing upsampler in the generator, the reliance on the camera pose prior, etc., which deepen our understanding of existing methods and point out some further directions of the research work. We release code and models at https://github.com/qiuyu96/Carver to facilitate the development and evaluation of this field.|
|**2023-06-21**|**Spectroscopy of the Supernova H0pe Host Galaxy at Redshift 1.78**|M. Polletta et.al.|[2306.12385v1](http://arxiv.org/abs/2306.12385v1)|null|Supernova (SN) H0pe was discovered as a new transient in James Webb Space Telescope (JWST) NIRCam images of the galaxy cluster PLCK G165.7+67.0 taken as part of the "Prime Extragalactic Areas for Reionization and Lensing Science" (PEARLS) JWST GTO program (# 1176) on 2023 March 30 (AstroNote 2023-96; Frye et al. 2023). The transient is a compact source associated with a background galaxy that is stretched and triply-imaged by the cluster's strong gravitational lensing. This paper reports spectra in the 950-1370 nm observer frame of two of the galaxy's images obtained with Large Binocular Telescope (LBT) Utility Camera in the Infrared (LUCI) in longslit mode two weeks after the \JWST\ observations. The individual average spectra show the [OII] doublet and the Balmer and 4000 Angstrom breaks at redshift z=1.783+/-0.002. The CIGALE best-fit model of the spectral energy distribution indicates that SN H0pe's host galaxy is massive (Mstar~6x10^10 Msun after correcting for a magnification factor ~7) with a predominant intermediate age (~2 Gyr) stellar population, moderate extinction, and a magnification-corrected star formation rate ~13 Msun/yr, consistent with being below the main sequence of star formation. These properties suggest that H0pe might be a type Ia SN. Additional observations of SN H0pe and its host recently carried out with JWST (JWST-DD-4446; PI: B. Frye) will be able to both determine the SN classification and confirm its association with the galaxy analyzed in this work.|
|**2023-06-21**|**Euclid: Constraining linearly scale-independent modifications of gravity with the spectroscopic and photometric primary probes**|N. Frusciante et.al.|[2306.12368v1](http://arxiv.org/abs/2306.12368v1)|null|The future Euclid space satellite mission will offer an invaluable opportunity to constrain modifications to general relativity at cosmic scales. We focus on modified gravity models characterised, at linear scales, by a scale-independent growth of perturbations while featuring different testable types of derivative screening mechanisms at smaller nonlinear scales. We consider 3 specific models, namely Jordan-Brans-Dicke (JBD), the normal branch of Dvali-Gabadadze-Porrati (nDGP) gravity and $k$-mouflage (KM) gravity. We provide forecasts from spectroscopic and photometric primary probes by Euclid on the cosmological parameters and the extra parameters of the models, respectively, $\omega_{\rm BD}$, $\Omega_{\rm rc}$ and $\epsilon_{2,0}$, which quantify the deviations from general relativity. This analysis will improve our knowledge of the cosmology of these modified gravity models. The forecasts analysis employs the Fisher matrix method applied to weak lensing (WL); photometric galaxy clustering (GC$_{ph}$); spectroscopic galaxy clustering (GC$_{sp}$) and the cross-correlation (XC) between GC$_{ph}$ and WL. For the Euclid survey specifications we define three scenarios, characterised by different cuts in $\ell$ and $k$, to assess the constraining power of nonlinear scales. For each model we consider two fiducial values for the corresponding model parameter. In an optimistic setting at 68.3\% confidence interval, with Euclid alone we find the following percentage relative errors: for $\log_{10}{\omega_{\rm BD}}$, with a fiducial value of $\omega_{\rm BD}=800$, 35% using GC$_{sp}$ alone, 3.6% using GC$_{ph}$+WL+XC and 3.3% using GC$_{ph}$+WL+XC+GC$_{sp}$; for $\log_{10}{\Omega_{\rm rc}}$, with a fiducial value of $\Omega_{\rm rc}=0.25$, we find respectively 90%, 20% and 17%; finally, for $\epsilon_{2,0}=-0.04$ respectively 5%, 0.15% and 0.14%. (abridged)|
|**2023-06-21**|**Wildfire Detection Via Transfer Learning: A Survey**|Ziliang Hong et.al.|[2306.12276v1](http://arxiv.org/abs/2306.12276v1)|null|This paper surveys different publicly available neural network models used for detecting wildfires using regular visible-range cameras which are placed on hilltops or forest lookout towers. The neural network models are pre-trained on ImageNet-1K and fine-tuned on a custom wildfire dataset. The performance of these models is evaluated on a diverse set of wildfire images, and the survey provides useful information for those interested in using transfer learning for wildfire detection. Swin Transformer-tiny has the highest AUC value but ConvNext-tiny detects all the wildfire events and has the lowest false alarm rate in our dataset.|
|**2023-06-21**|**Near infrared view on the photodissociation regions S255, S257, NGC7538 and S140**|M. S. Kirsanova et.al.|[2306.12264v1](http://arxiv.org/abs/2306.12264v1)|null|We performed photometric observations of the S255, S257, S140, NGC7358 and the Orion~Bar photo-dissociation regions (PDRs) at 2 micron using narrow-band filters centered on the Br-gamma, H2 and [FeII] lines, as well as the narrow-band Kcont and the broad-band H filters for continuum subtraction. The observations were done with the 2.5-m telescope of the SAI Caucasian Mountain Observatory and the near-infrared camera and spectrograph ASTRONIRCAM. We find several high-density arc-like structures in the Br-gamma and [FeII] images of the ionized gas in NGC7538 and extended shells and arcs visible through the H2 emission. The H ionization front and H2 dissociation front are merged in NGC7538. In S255 and S257 we detected only Br-gamma emission from the HII regions and bright H2 emission from the PDRs. The projected distance between the H ionization and H2 dissociation fronts are approx. 0.3-0.4 pc, which cannot be explained using models of a uniform medium. Most probably, the ionized and neutral gas in these PDRs is clumpy. The H-to-H2 transitions in the NGC7538, S255, S257 and S140 PDRs are gradual with no sharp borders. This conclusion also confirms the suggestion of a clumpy medium.|
|**2023-06-21**|**MimiC: Combating Client Dropouts in Federated Learning by Mimicking Central Updates**|Yuchang Sun et.al.|[2306.12212v1](http://arxiv.org/abs/2306.12212v1)|null|Federated learning (FL) is a promising framework for privacy-preserving collaborative learning. In FL, the model training tasks are distributed to clients and only the model updates need to be collected at a central server. However, when being deployed at the mobile edge network, clients (e.g., smartphones and wearables) may have unpredictable availability and randomly drop out of any training iteration, which hinders FL from achieving the convergence. This paper tackles such a critical challenge of FL. In particular, we first investigate the convergence of the classical FedAvg algorithm with arbitrary client dropouts. We find that with the common choice of a decaying learning rate, FedAvg can only oscillate within the neighborhood of a stationary point of the global loss function, which is caused by the divergence between the aggregated update and the desired central update. Motivated by this new observation, we then design a novel training algorithm named MimiC, where the server modifies each received model update based on the previous ones. The proposed modification of the received model updates is able to mimic the imaginary central update irrespective of the dropout clients. The theoretical analysis of MimiC shows that the divergence between the aggregated update and the central update diminishes with a proper choice of the learning rates, leading to its convergence. Simulation results further demonstrate that MimiC maintains stable convergence performance in the presence of client dropouts and learns better models than the baseline methods.|
|**2023-06-20**|**NILUT: Conditional Neural Implicit 3D Lookup Tables for Image Enhancement**|Marcos V. Conde et.al.|[2306.11920v1](http://arxiv.org/abs/2306.11920v1)|[link](https://github.com/mv-lab/nilut)|3D lookup tables (3D LUTs) are a key component for image enhancement. Modern image signal processors (ISPs) have dedicated support for these as part of the camera rendering pipeline. Cameras typically provide multiple options for picture styles, where each style is usually obtained by applying a unique handcrafted 3D LUT. Current approaches for learning and applying 3D LUTs are notably fast, yet not so memory-efficient, as storing multiple 3D LUTs is required. For this reason and other implementation limitations, their use on mobile devices is less popular. In this work, we propose a Neural Implicit LUT (NILUT), an implicitly defined continuous 3D color transformation parameterized by a neural network. We show that NILUTs are capable of accurately emulating real 3D LUTs. Moreover, a NILUT can be extended to incorporate multiple styles into a single network with the ability to blend styles implicitly. Our novel approach is memory-efficient, controllable and can complement previous methods, including learned ISPs. Code, models and dataset available at: https://github.com/mv-lab/nilut|
|**2023-06-20**|**Self-supervised Multi-task Learning Framework for Safety and Health-Oriented Connected Driving Environment Perception using Onboard Camera**|Shaocheng Jia et.al.|[2306.11822v1](http://arxiv.org/abs/2306.11822v1)|null|Cutting-edge connected vehicle (CV) technologies have drawn much attention in recent years. The real-time traffic data captured by a CV can be shared with other CVs and data centers so as to open new possibilities for solving diverse transportation problems. However, imagery captured by onboard cameras in a connected environment, are not sufficiently investigated, especially for safety and health-oriented visual perception. In this paper, a bidirectional process of image synthesis and decomposition (BPISD) approach is proposed, and thus a novel self-supervised multi-task learning framework, to simultaneously estimate depth map, atmospheric visibility, airlight, and PM2.5 mass concentration, in which depth map and visibility are considered highly associated with traffic safety, while airlight and PM2.5 mass concentration are directly correlated with human health. Both the training and testing phases of the proposed system solely require a single image as input. Due to the innovative training pipeline, the depth estimation network can manage various levels of visibility conditions and overcome inherent problems in current image-synthesis-based depth estimation, thereby generating high-quality depth maps even in low-visibility situations and further benefiting accurate estimations of visibility, airlight, and PM2.5 mass concentration. Extensive experiments on the synthesized data from the KITTI and real-world data collected in Beijing demonstrate that the proposed method can (1) achieve performance competitive in depth estimation as compared with state-of-the-art methods when taking clear images as input; (2) predict vivid depth map for images contaminated by various levels of haze; and (3) accurately estimate visibility, airlight, and PM2.5 mass concentrations. Beneficial applications can be developed based on the presented work to improve traffic safety, air quality, and public health.|
|**2023-06-20**|**BEVScope: Enhancing Self-Supervised Depth Estimation Leveraging Bird's-Eye-View in Dynamic Scenarios**|Yucheng Mao et.al.|[2306.11598v1](http://arxiv.org/abs/2306.11598v1)|null|Depth estimation is a cornerstone of perception in autonomous driving and robotic systems. The considerable cost and relatively sparse data acquisition of LiDAR systems have led to the exploration of cost-effective alternatives, notably, self-supervised depth estimation. Nevertheless, current self-supervised depth estimation methods grapple with several limitations: (1) the failure to adequately leverage informative multi-camera views. (2) the limited capacity to handle dynamic objects effectively. To address these challenges, we present BEVScope, an innovative approach to self-supervised depth estimation that harnesses Bird's-Eye-View (BEV) features. Concurrently, we propose an adaptive loss function, specifically designed to mitigate the complexities associated with moving objects. Empirical evaluations conducted on the Nuscenes dataset validate our approach, demonstrating competitive performance. Code will be released at https://github.com/myc634/BEVScope.|
|**2023-06-20**|**The Ecological Fallacy in Annotation: Modelling Human Label Variation goes beyond Sociodemographics**|Matthias Orlikowski et.al.|[2306.11559v1](http://arxiv.org/abs/2306.11559v1)|[link](https://github.com/morlikowski/ecological-fallacy)|Many NLP tasks exhibit human label variation, where different annotators give different labels to the same texts. This variation is known to depend, at least in part, on the sociodemographics of annotators. Recent research aims to model individual annotator behaviour rather than predicting aggregated labels, and we would expect that sociodemographic information is useful for these models. On the other hand, the ecological fallacy states that aggregate group behaviour, such as the behaviour of the average female annotator, does not necessarily explain individual behaviour. To account for sociodemographics in models of individual annotator behaviour, we introduce group-specific layers to multi-annotator models. In a series of experiments for toxic content detection, we find that explicitly accounting for sociodemographic attributes in this way does not significantly improve model performance. This result shows that individual annotation behaviour depends on much more than just sociodemographics.|
|**2023-06-20**|**Bullying10K: A Neuromorphic Dataset towards Privacy-Preserving Bullying Recognition**|Yiting Dong et.al.|[2306.11546v1](http://arxiv.org/abs/2306.11546v1)|null|The prevalence of violence in daily life poses significant threats to individuals' physical and mental well-being. Using surveillance cameras in public spaces has proven effective in proactively deterring and preventing such incidents. However, concerns regarding privacy invasion have emerged due to their widespread deployment. To address the problem, we leverage Dynamic Vision Sensors (DVS) cameras to detect violent incidents and preserve privacy since it captures pixel brightness variations instead of static imagery. We introduce the Bullying10K dataset, encompassing various actions, complex movements, and occlusions from real-life scenarios. It provides three benchmarks for evaluating different tasks: action recognition, temporal action localization, and pose estimation. With 10,000 event segments, totaling 12 billion events and 255 GB of data, Bullying10K contributes significantly by balancing violence detection and personal privacy persevering. And it also poses a challenge to the neuromorphic dataset. It will serve as a valuable resource for training and developing privacy-protecting video systems. The Bullying10K opens new possibilities for innovative approaches in these domains.|
|**2023-06-20**|**End-to-end 2D-3D Registration between Image and LiDAR Point Cloud for Vehicle Localization**|Guangming Wang et.al.|[2306.11346v1](http://arxiv.org/abs/2306.11346v1)|null|Robot localization using a previously built map is essential for a variety of tasks including highly accurate navigation and mobile manipulation. A popular approach to robot localization is based on image-to-point cloud registration, which combines illumination-invariant LiDAR-based mapping with economical image-based localization. However, the recent works for image-to-point cloud registration either divide the registration into separate modules or project the point cloud to the depth image to register the RGB and depth images. In this paper, we present I2PNet, a novel end-to-end 2D-3D registration network. I2PNet directly registers the raw 3D point cloud with the 2D RGB image using differential modules with a unique target. The 2D-3D cost volume module for differential 2D-3D association is proposed to bridge feature extraction and pose regression. 2D-3D cost volume module implicitly constructs the soft point-to-pixel correspondence on the intrinsic-independent normalized plane of the pinhole camera model. Moreover, we introduce an outlier mask prediction module to filter the outliers in the 2D-3D association before pose regression. Furthermore, we propose the coarse-to-fine 2D-3D registration architecture to increase localization accuracy. We conduct extensive localization experiments on the KITTI Odometry and nuScenes datasets. The results demonstrate that I2PNet outperforms the state-of-the-art by a large margin. In addition, I2PNet has a higher efficiency than the previous works and can perform the localization in real-time. Moreover, we extend the application of I2PNet to the camera-LiDAR online calibration and demonstrate that I2PNet outperforms recent approaches on the online calibration task.|
|**2023-06-20**|**Meerkat Behaviour Recognition Dataset**|Mitchell Rogers et.al.|[2306.11326v1](http://arxiv.org/abs/2306.11326v1)|null|Recording animal behaviour is an important step in evaluating the well-being of animals and further understanding the natural world. Current methods for documenting animal behaviour within a zoo setting, such as scan sampling, require excessive human effort, are unfit for around-the-clock monitoring, and may produce human-biased results. Several animal datasets already exist that focus predominantly on wildlife interactions, with some extending to action or behaviour recognition. However, there is limited data in a zoo setting or data focusing on the group behaviours of social animals. We introduce a large meerkat (Suricata Suricatta) behaviour recognition video dataset with diverse annotated behaviours, including group social interactions, tracking of individuals within the camera view, skewed class distribution, and varying illumination conditions. This dataset includes videos from two positions within the meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with 848,400 annotated frames across 20 videos and 15 unannotated videos.|
|**2023-06-20**|**Spatiotemporal Pyramidal CNN with Depth-Wise Separable Convolution for Eye Blinking Detection in the Wild**|Lan Anh Thi Nguy et.al.|[2306.11287v1](http://arxiv.org/abs/2306.11287v1)|null|Eye blinking detection in the wild plays an essential role in deception detection, driving fatigue detection, etc. Despite the fact that numerous attempts have already been made, the majority of them have encountered difficulties, such as the derived eye images having different resolutions as the distance between the face and the camera changes; or the requirement of a lightweight detection model to obtain a short inference time in order to perform in real-time. In this research, two problems are addressed: how the eye blinking detection model can learn efficiently from different resolutions of eye pictures in diverse conditions; and how to reduce the size of the detection model for faster inference time. We propose to utilize upsampling and downsampling the input eye images to the same resolution as one potential solution for the first problem, then find out which interpolation method can result in the highest performance of the detection model. For the second problem, although a recent spatiotemporal convolutional neural network used for eye blinking detection has a strong capacity to extract both spatial and temporal characteristics, it remains having a high number of network parameters, leading to high inference time. Therefore, using Depth-wise Separable Convolution rather than conventional convolution layers inside each branch is considered in this paper as a feasible solution.|
|**2023-06-20**|**GUMSum: Multi-Genre Data and Evaluation for English Abstractive Summarization**|Yang Janet Liu et.al.|[2306.11256v1](http://arxiv.org/abs/2306.11256v1)|null|Automatic summarization with pre-trained language models has led to impressively fluent results, but is prone to 'hallucinations', low performance on non-news genres, and outputs which are not exactly summaries. Targeting ACL 2023's 'Reality Check' theme, we present GUMSum, a small but carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. Summaries are highly constrained, focusing on substitutive potential, factuality, and faithfulness. We present guidelines and evaluate human agreement as well as subjective judgments on recent system outputs, comparing general-domain untuned approaches, a fine-tuned one, and a prompt-based approach, to human performance. Results show that while GPT3 achieves impressive scores, it still underperforms humans, with varying quality across genres. Human judgments reveal different types of errors in supervised, prompted, and human-generated summaries, shedding light on the challenges of producing a good summary.|
|**2023-06-19**|**Thickness Dependent Sensitivity of GAGG:Ce Scintillation detectors for Thermal Neutrons: GEANT4 Simulations and Experimental Measurements**|Annesha Karmakar et.al.|[2306.11191v1](http://arxiv.org/abs/2306.11191v1)|null|In the present work, we report extensive GEANT4 simulations in order to study the dependence of sensitivity of GAGG:Ce scintillation crystal based detector on thickness of the crystal. All the simulations are made considering a thermalised Am-Be neutron source. The simulations are validated, qualitatively and quantitatively, by comparing the simulated energy spectra and sensitivity values with those obtained from experimental measurements carried out using two different thicknesses of the crystal from our own experiment (0.5mm and 3mm) and validated with three other thicknesses (0.01mm, 0.1 mm and 1 mm) from literature. In this study, we define sensitivity of GAGG:Ce as the ratio of area under 77 keV sum peak to 45 keV peak. The present studies clearly confirm that, while it requires about 0.1 mm thickness for the GAGG:Ce crystal to fully absorb thermal neutrons, it requires about 3 mm to fully absorb the thermal neutron induced events. Further, we propose an equation, that can be used to estimate the thickness of the GAGG:Ce crystal directly from the observed sensitivity of the GAGG:Ce crystal. This equation could be very useful for the neutron imaging community for medical and space applications, as well as for manufactures of cameras meant for nuclear security purposes.|
|**2023-06-19**|**Euclid: Constraints on f(R) cosmologies from the spectroscopic and photometric primary probes**|S. Casas et.al.|[2306.11053v1](http://arxiv.org/abs/2306.11053v1)|null|$\textit{Euclid}$ will provide a powerful compilation of data including spectroscopic redshifts, the angular clustering of galaxies, weak lensing cosmic shear, and the cross-correlation of these last two photometric observables. In this study we extend recently presented $\textit{Euclid}$ forecasts into the Hu-Sawicki $f(R)$ cosmological model, a popular extension of the Hilbert-Einstein action that introduces an universal modified gravity force in a scale-dependent way. Our aim is to estimate how well future $\textit{Euclid}$ data will be able to constrain the extra parameter of the theory, $f_{R0}$, for the range in which this parameter is still allowed by current observations. For the spectroscopic probe, we use a phenomenological approach for the scale dependence of the growth of perturbations in the terms related to baryon acoustic oscillations and redshift-space distortions. For the photometric observables, we use a fitting formula that captures the modifications in the non-linear matter power spectrum caused by the $f(R)$ model. We show that, in an optimistic setting, and for a fiducial value of $f_{R0} = 5 \times 10^{-6}$, $\textit{Euclid}$ alone will be able to constrain the additional parameter $\log f_{R0}$ at the $3\%$ level, using spectroscopic galaxy clustering alone; at the $1.4\%$ level, using the combination of photometric probes on their own; and at the $1\%$ level, using the combination of spectroscopic and photometric observations. This last constraint corresponds to an error of the order of $6 \times 10^{-7}$ at the $1\sigma$ level on the model parameter $f_{R0} = 5 \times 10^{-6}$. We report also forecasted constraints for $f_{R0} = 5 \times 10^{-5}$ and $f_{R0} = 5 \times 10^{-7}$ and show that in the optimistic scenario, $\textit{Euclid}$ will be able to distinguish these models from $\Lambda\mathrm{CDM}$ at more than 3$\sigma$. (abridged)|
|**2023-06-19**|**Scaling of Class-wise Training Losses for Post-hoc Calibration**|Seungjin Jung et.al.|[2306.10989v1](http://arxiv.org/abs/2306.10989v1)|[link](https://github.com/seungjinjung/sctl)|The class-wise training losses often diverge as a result of the various levels of intra-class and inter-class appearance variation, and we find that the diverging class-wise training losses cause the uncalibrated prediction with its reliability. To resolve the issue, we propose a new calibration method to synchronize the class-wise training losses. We design a new training loss to alleviate the variance of class-wise training losses by using multiple class-wise scaling factors. Since our framework can compensate the training losses of overfitted classes with those of under-fitted classes, the integrated training loss is preserved, preventing the performance drop even after the model calibration. Furthermore, our method can be easily employed in the post-hoc calibration methods, allowing us to use the pre-trained model as an initial model and reduce the additional computation for model calibration. We validate the proposed framework by employing it in the various post-hoc calibration methods, which generally improves calibration performance while preserving accuracy, and discover through the investigation that our approach performs well with unbalanced datasets and untuned hyperparameters.|
|**2023-06-19**|**Tame a Wild Camera: In-the-Wild Monocular Camera Calibration**|Shengjie Zhu et.al.|[2306.10988v1](http://arxiv.org/abs/2306.10988v1)|[link](https://github.com/shngjz/wildcamera)|3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D object detection, has become increasingly important. However, the unknown intrinsic parameter hinders their development and deployment. Previous methods for the monocular camera calibration rely on specific 3D objects or strong geometry prior, such as using a checkerboard or imposing a Manhattan World assumption. This work solves the problem from the other perspective by exploiting the monocular 3D prior. Our method is assumption-free and calibrates the complete $4$ Degree-of-Freedom (DoF) intrinsic parameters. First, we demonstrate intrinsic is solved from two well-studied monocular priors, i.e., monocular depthmap, and surface normal map. However, this solution imposes a low-bias and low-variance requirement for depth estimation. Alternatively, we introduce a novel monocular 3D prior, the incidence field, defined as the incidence rays between points in 3D space and pixels in the 2D imaging plane. The incidence field is a pixel-wise parametrization of the intrinsic invariant to image cropping and resizing. With the estimated incidence field, a robust RANSAC algorithm recovers intrinsic. We demonstrate the effectiveness of our method by showing superior performance on synthetic and zero-shot testing datasets. Beyond calibration, we demonstrate downstream applications in image manipulation detection & restoration, uncalibrated two-view pose estimation, and 3D sensing. Codes, models, and data will be held in https://github.com/ShngJZ/WildCamera.|
|**2023-06-19**|**PowerBEV: A Powerful Yet Lightweight Framework for Instance Prediction in Bird's-Eye View**|Peizheng Li et.al.|[2306.10761v1](http://arxiv.org/abs/2306.10761v1)|[link](https://github.com/edwardleelpz/powerbev)|Accurately perceiving instances and predicting their future motion are key tasks for autonomous vehicles, enabling them to navigate safely in complex urban traffic. While bird's-eye view (BEV) representations are commonplace in perception for autonomous driving, their potential in a motion prediction setting is less explored. Existing approaches for BEV instance prediction from surround cameras rely on a multi-task auto-regressive setup coupled with complex post-processing to predict future instances in a spatio-temporally consistent manner. In this paper, we depart from this paradigm and propose an efficient novel end-to-end framework named POWERBEV, which differs in several design choices aimed at reducing the inherent redundancy in previous methods. First, rather than predicting the future in an auto-regressive fashion, POWERBEV uses a parallel, multi-scale module built from lightweight 2D convolutional networks. Second, we show that segmentation and centripetal backward flow are sufficient for prediction, simplifying previous multi-task objectives by eliminating redundant output modalities. Building on this output representation, we propose a simple, flow warping-based post-processing approach which produces more stable instance associations across time. Through this lightweight yet powerful design, POWERBEV outperforms state-of-the-art baselines on the NuScenes Dataset and poses an alternative paradigm for BEV instance prediction. We made our code publicly available at: https://github.com/EdwardLeeLPZ/PowerBEV.|
|**2023-06-18**|**STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced Audio-Visual Diarization**|Kyle Min et.al.|[2306.10608v1](http://arxiv.org/abs/2306.10608v1)|null|This report introduces our novel method named STHG for the Audio-Visual Diarization task of the Ego4D Challenge 2023. Our key innovation is that we model all the speakers in a video using a single, unified heterogeneous graph learning framework. Unlike previous approaches that require a separate component solely for the camera wearer, STHG can jointly detect the speech activities of all people including the camera wearer. Our final method obtains 61.1% DER on the test set of Ego4D, which significantly outperforms all the baselines as well as last year's winner. Our submission achieved 1st place in the Ego4D Challenge 2023. We additionally demonstrate that applying the off-the-shelf speech recognition system to the diarized speech segments by STHG produces a competitive performance on the Speech Transcription task of this challenge.|
