# arxiv-daily latest papers around wearable device
Automated deployment @ 2023-06-25 20:32:12 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`]({repo_url}/blob/main/database/topic.yml).
> You can also view historical data through the [storage]({repo_url}/blob/main/database/storage).

## ai

### infant+ai
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-20**|**Deep Learning Methods for Retinal Blood Vessel Segmentation: Evaluation on Images with Retinopathy of Prematurity**|Gorana GojiÄ‡ et.al.|[2306.11576v1](http://arxiv.org/abs/2306.11576v1)|null|Automatic blood vessel segmentation from retinal images plays an important role in the diagnosis of many systemic and eye diseases, including retinopathy of prematurity. Current state-of-the-art research in blood vessel segmentation from retinal images is based on convolutional neural networks. The solutions proposed so far are trained and tested on images from a few available retinal blood vessel segmentation datasets, which might limit their performance when given an image with retinopathy of prematurity signs. In this paper, we evaluate the performance of three high-performing convolutional neural networks for retinal blood vessel segmentation in the context of blood vessel segmentation on retinopathy of prematurity retinal images. The main motive behind the study is to test if existing public datasets suffice to develop a high-performing predictor that could assist an ophthalmologist in retinopathy of prematurity diagnosis. To do so, we create a dataset consisting solely of retinopathy of prematurity images with retinal blood vessel annotations manually labeled by two observers, where one is the ophthalmologist experienced in retinopathy of prematurity treatment. Experimental results show that all three solutions have difficulties in detecting the retinal blood vessels of infants due to a lower contrast compared to images from public datasets as demonstrated by a significant drop in classification sensitivity. All three solutions segment alongside retinal also choroidal blood vessels which are not used to diagnose retinopathy of prematurity, but instead represent noise and are confused with retinal blood vessels. By visual and numerical observations, we observe that existing solutions for retinal blood vessel segmentation need improvement toward more detailed datasets or deeper models in order to assist the ophthalmologist in retinopathy of prematurity diagnosis.|
|**2023-06-14**|**The generalized hyperbolic family and automatic model selection through the multiple-choice LASSO**|Luca Bagnato et.al.|[2306.08692v1](http://arxiv.org/abs/2306.08692v1)|null|We revisit the generalized hyperbolic (GH) distribution and its nested models. These include widely used parametric choices like the multivariate normal, skew-t, Laplace, and several others. We also introduce the multiple-choice LASSO, a novel penalized method for choosing among alternative constraints on the same parameter. A hierarchical multiple-choice LASSO penalized likelihood is optimized to perform simultaneous model selection and inference within the GH family. We illustrate our approach through a simulation study and a real data example about pre-term infants. The methodology proposed in this paper has been implemented in R functions which are available as supplementary material.|
|**2023-06-13**|**Overfitting Affects the Reliability of Radial Velocity Mass Estimates of the V1298 Tau Planets**|Sarah Blunt et.al.|[2306.08145v1](http://arxiv.org/abs/2306.08145v1)|[link](https://github.com/sblunt/v1298tauri)|Mass, radius, and age measurements of young (<100 Myr) planets have the power to shape our understanding of planet formation. However, young stars tend to be extremely variable in both photometry and radial velocity, which makes constraining these properties challenging. The V1298 Tau system of four ~0.5 Rjup planets transiting a pre-main sequence star presents an important, if stress-inducing, opportunity to directly observe and measure the properties of infant planets. Su\'arez-Mascare\~no et al. (2021) published radial-velocity-derived masses for two of the V1298 Tau planets using a state-of-the-art Gaussian Process regression framework. The planetary densities computed from these masses were surprisingly high, implying extremely rapid contraction after formation in tension with most existing planet formation theories. In an effort to further constrain the masses of the V1298 Tau planets, we obtained 36 RVs using Keck/HIRES, and analyzed them in concert with published RVs and photometry. Through performing a suite of cross validation tests, we found evidence that the preferred model of SM21 suffers from overfitting, defined as the inability to predict unseen data, rendering the masses unreliable. We detail several potential causes of this overfitting, many of which may be important for other RV analyses of other active stars, and recommend that additional time and resources be allocated to understanding and mitigating activity in active young stars such as V1298 Tau.|
|**2023-06-09**|**Two Independent Teachers are Better Role Model**|Afifa Khaled et.al.|[2306.05745v1](http://arxiv.org/abs/2306.05745v1)|[link](https://github.com/AfifaKhaled/Two-Independent-Teachers-are-Better-Role-Model)|Recent deep learning models have attracted substantial attention in infant brain analysis. These models have performed state-of-the-art performance, such as semi-supervised techniques (e.g., Temporal Ensembling, mean teacher). However, these models depend on an encoder-decoder structure with stacked local operators to gather long-range information, and the local operators limit the efficiency and effectiveness. Besides, the $MRI$ data contain different tissue properties ($TPs$) such as $T1$ and $T2$. One major limitation of these models is that they use both data as inputs to the segment process, i.e., the models are trained on the dataset once, and it requires much computational and memory requirements during inference. In this work, we address the above limitations by designing a new deep-learning model, called 3D-DenseUNet, which works as adaptable global aggregation blocks in down-sampling to solve the issue of spatial information loss. The self-attention module connects the down-sampling blocks to up-sampling blocks, and integrates the feature maps in three dimensions of spatial and channel, effectively improving the representation potential and discriminating ability of the model. Additionally, we propose a new method called Two Independent Teachers ($2IT$), that summarizes the model weights instead of label predictions. Each teacher model is trained on different types of brain data, $T1$ and $T2$, respectively. Then, a fuse model is added to improve test accuracy and enable training with fewer parameters and labels compared to the Temporal Ensembling method without modifying the network architecture. Empirical results demonstrate the effectiveness of the proposed method.|
|**2023-06-08**|**Design of Sturm global attractors 2: Time-reversible Chafee-Infante lattices of 3-nose meanders**|Bernold Fiedler et.al.|[2306.05232v1](http://arxiv.org/abs/2306.05232v1)|null|This sequel continues our exploration arxiv:2302.12531 of a deceptively ``simple'' class of global attractors, called Sturm due to nodal properties. They arise for the semilinear scalar parabolic PDE   \begin{equation}\label{eq:*}   u_t = u_{xx} + f(x,u,u_x) \tag{$*$}   \end{equation} on the unit interval $0 < x<1$, under Neumann boundary conditions. This models the interplay of reaction, advection, and diffusion.   Our classification is based on the Sturm meanders, which arise from a shooting approach to the ODE boundary value problem of equilibrium solutions $u=v(x)$. Specifically, we address meanders with only three ``noses'', each of which is innermost to a nested family of upper or lower meander arcs. The Chafee-Infante paradigm of 1974, with cubic nonlinearity $f=f(u)$, features just two noses.   We present, and fully prove, a precise description of global PDE connection graphs, graded by Morse index, for such gradient-like Morse-Smale systems \eqref{eq:*}. The directed edges denote PDE heteroclinic orbits $v_1 \leadsto v_2$ between equilibrium vertices $v_1, v_2$ of adjacent Morse index. The connection graphs can be described as a lattice-like structure of Chafee-Infante subgraphs. However, this simple description requires us to adjoin a single ``equilibrium'' vertex, formally, at Morse level -1. Surprisingly, for parabolic PDEs based on irreversible diffusion, the connection graphs then also exhibit global time reversibility.|
|**2023-06-02**|**BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models**|Marvin Lavechin et.al.|[2306.01506v2](http://arxiv.org/abs/2306.01506v2)|[link](https://github.com/marvinlvn/babyslm)|Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.|
|**2023-06-01**|**Generalizability analyses with a partially nested trial design: the Necrotizing Enterocolitis Surgery Trial**|Sarah E. Robertson et.al.|[2306.00855v1](http://arxiv.org/abs/2306.00855v1)|null|We discuss generalizability analyses under a partially nested trial design, where part of the trial is nested within a cohort of trial-eligible individuals, while the rest of the trial is not nested. This design arises, for example, when only some centers participating in a trial are able to collect data on non-randomized individuals, or when data on non-randomized individuals cannot be collected for the full duration of the trial. Our work is motivated by the Necrotizing Enterocolitis Surgery Trial (NEST) that compared initial laparotomy versus peritoneal drain for infants with necrotizing enterocolitis or spontaneous intestinal perforation. During the first phase of the study, data were collected from randomized individuals as well as consenting non-randomized individuals; during the second phase of the study, however, data were only collected from randomized individuals, resulting in a partially nested trial design. We propose methods for generalizability analyses with partially nested trial designs. We describe identification conditions and propose estimators for causal estimands in the target population of all trial-eligible individuals, both randomized and non-randomized, in the part of the data where the trial is nested, while using trial information spanning both parts. We evaluate the estimators in a simulation study.|
|**2023-05-25**|**Emergence of a phonological bias in ChatGPT**|Juan Manuel Toro et.al.|[2305.15929v2](http://arxiv.org/abs/2305.15929v2)|null|Current large language models, such as OpenAI's ChatGPT, have captured the public's attention because how remarkable they are in the use of language. Here, I demonstrate that ChatGPT displays phonological biases that are a hallmark of human language processing. More concretely, just like humans, ChatGPT has a consonant bias. That is, the chatbot has a tendency to use consonants over vowels to identify words. This is observed across languages that differ in their relative distribution of consonants and vowels such as English and Spanish. Despite the differences in how current artificial intelligence language models are trained to process linguistic stimuli and how human infants acquire language, such training seems to be enough for the emergence of a phonological bias in ChatGPT|
|**2023-05-24**|**From Interactive to Co-Constructive Task Learning**|Anna-Lisa Vollmer et.al.|[2305.15535v1](http://arxiv.org/abs/2305.15535v1)|null|Humans have developed the capability to teach relevant aspects of new or adapted tasks to a social peer with very few task demonstrations by making use of scaffolding strategies that leverage prior knowledge and importantly prior joint experience to yield a joint understanding and a joint execution of the required steps to solve the task. This process has been discovered and analyzed in parent-infant interaction and constitutes a ``co-construction'' as it allows both, the teacher and the learner, to jointly contribute to the task. We propose to focus research in robot interactive learning on this co-construction process to enable robots to learn from non-expert users in everyday situations. In the following, we will review current proposals for interactive task learning and discuss their main contributions with respect to the entailing interaction. We then discuss our notion of co-construction and summarize research insights from adult-child and human-robot interactions to elucidate its nature in more detail. From this overview we finally derive research desiderata that entail the dimensions architecture, representation, interaction and explainability.|
|**2023-05-22**|**Developmental Curiosity and Social Interaction in Virtual Agents**|Chris Doyle et.al.|[2305.13396v1](http://arxiv.org/abs/2305.13396v1)|null|Infants explore their complex physical and social environment in an organized way. To gain insight into what intrinsic motivations may help structure this exploration, we create a virtual infant agent and place it in a developmentally-inspired 3D environment with no external rewards. The environment has a virtual caregiver agent with the capability to interact contingently with the infant agent in ways that resemble play. We test intrinsic reward functions that are similar to motivations that have been proposed to drive exploration in humans: surprise, uncertainty, novelty, and learning progress. These generic reward functions lead the infant agent to explore its environment and discover the contingencies that are embedded into the caregiver agent. The reward functions that are proxies for novelty and uncertainty are the most successful in generating diverse experiences and activating the environment contingencies. We also find that learning a world model in the presence of an attentive caregiver helps the infant agent learn how to predict scenarios with challenging social and physical dynamics. Taken together, our findings provide insight into how curiosity-like intrinsic rewards and contingent social interaction lead to dynamic social behavior and the creation of a robust predictive world model.|
|**2023-05-21**|**Towards Robust Family-Infant Audio Analysis Based on Unsupervised Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio**|Jialu Li et.al.|[2305.12530v2](http://arxiv.org/abs/2305.12530v2)|null|To perform automatic family audio analysis, past studies have collected recordings using phone, video, or audio-only recording devices like LENA, investigated supervised learning methods, and used or fine-tuned general-purpose embeddings learned from large pretrained models. In this study, we advance the audio component of a new infant wearable multi-modal device called LittleBeats (LB) by learning family audio representation via wav2vec 2.0 (W2V2) pertaining. We show given a limited number of labeled LB home recordings, W2V2 pretrained using 1k-hour of unlabeled home recordings outperforms oracle W2V2 pretrained on 52k-hour unlabeled audio in terms of parent/infant speaker diarization (SD) and vocalization classifications (VC) at home. Extra relevant external unlabeled and labeled data further benefit W2V2 pretraining and fine-tuning. With SpecAug and environmental speech corruptions, we obtain 12% relative gain on SD and moderate boost on VC. Code and model weights are available.|
|**2023-05-18**|**Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses**|Eliza Kosoy et.al.|[2305.11243v1](http://arxiv.org/abs/2305.11243v1)|null|Developmental psychologists have spent decades devising experiments to test the intelligence and knowledge of infants and children, tracing the origin of crucial concepts and capacities. Moreover, experimental techniques in developmental psychology have been carefully designed to discriminate the cognitive capacities that underlie particular behaviors. We propose that using classical experiments from child development is a particularly effective way to probe the computational abilities of AI models, in general, and LLMs in particular. First, the methodological techniques of developmental psychology, such as the use of novel stimuli to control for past experience or control conditions to determine whether children are using simple associations, can be equally helpful for assessing the capacities of LLMs. In parallel, testing LLMs in this way can tell us whether the information that is encoded in text is sufficient to enable particular responses, or whether those responses depend on other kinds of information, such as information from exploration of the physical world. In this work we adapt classical developmental experiments to evaluate the capabilities of LaMDA, a large language model from Google. We propose a novel LLM Response Score (LRS) metric which can be used to evaluate other language models, such as GPT. We find that LaMDA generates appropriate responses that are similar to those of children in experiments involving social understanding, perhaps providing evidence that knowledge of these domains is discovered through language. On the other hand, LaMDA's responses in early object and action understanding, theory of mind, and especially causal reasoning tasks are very different from those of young children, perhaps showing that these domains require more real-world, self-initiated exploration and cannot simply be learned from patterns in language input.|
|**2023-05-18**|**Client Selection for Federated Policy Optimization with Environment Heterogeneity**|Zhijie Xie et.al.|[2305.10978v3](http://arxiv.org/abs/2305.10978v3)|null|The development of Policy Iteration (PI) has inspired many recent algorithms for Reinforcement Learning (RL), including several policy gradient methods, that gained both theoretical soundness and empirical success on a variety of tasks. The theory of PI is rich in the context of centralized learning, but its study is still in the infant stage under the federated setting. This paper explores the federated version of Approximate PI (API) and derives its error bound, taking into account the approximation error introduced by environment heterogeneity. We theoretically prove that a proper client selection scheme can reduce this error bound. Based on the theoretical result, we propose a client selection algorithm to alleviate the additional approximation error caused by environment heterogeneity. Experiment results show that the proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem by effectively selecting clients with a lower level of heterogeneity from the population distribution.|
|**2023-05-17**|**Analyzing the Stance of Facebook Posts on Abortion Considering State-level Health and Social Compositions**|Ana Aleksandric et.al.|[2305.09889v1](http://arxiv.org/abs/2305.09889v1)|null|Abortion remains one of the most controversial topics, especially after overturning Roe v. Wade ruling in the United States. Previous literature showed that the illegality of abortion could have serious consequences, as women might seek unsafe pregnancy terminations leading to increased maternal mortality rates and negative effects on their reproductive health. Therefore, the stances of the abortion-related Facebook posts were analyzed at the state level in the United States from May 4 until June 30, 2022, right after the Supreme Court's decision was disclosed. In more detail, the pre-trained Transformer architecture-based model was fine-tuned on a manually labeled training set to obtain a stance detection model suitable for the collected dataset. Afterward, we employed appropriate statistical tests to examine the relationships between public opinion regarding abortion, abortion legality, political leaning, and factors measuring the overall population's health, health knowledge, and vulnerability per state. We found that states with a higher number of views against abortion also have higher infant and maternal mortality rates. Furthermore, the stance of social media posts per state is mostly matching with the current abortion laws in these states. While aligned with existing literature, these findings indicate how public opinion, laws, and women's and infants' health are related, and interventions are required to educate and protect women, especially in vulnerable populations.|
|**2023-05-16**|**Evaluation of self-supervised pre-training for automatic infant movement classification using wearable movement sensors**|Einari Vaaras et.al.|[2305.09366v1](http://arxiv.org/abs/2305.09366v1)|[link](https://github.com/SPEECHCOG/data2vec_maiju)|The recently-developed infant wearable MAIJU provides a means to automatically evaluate infants' motor performance in an objective and scalable manner in out-of-hospital settings. This information could be used for developmental research and to support clinical decision-making, such as detection of developmental problems and guiding of their therapeutic interventions. MAIJU-based analyses rely fully on the classification of infant's posture and movement; it is hence essential to study ways to increase the accuracy of such classifications, aiming to increase the reliability and robustness of the automated analysis. Here, we investigated how self-supervised pre-training improves performance of the classifiers used for analyzing MAIJU recordings, and we studied whether performance of the classifier models is affected by context-selective quality-screening of pre-training data to exclude periods of little infant movement or with missing sensors. Our experiments show that i) pre-training the classifier with unlabeled data leads to a robust accuracy increase of subsequent classification models, and ii) selecting context-relevant pre-training data leads to substantial further improvements in the classifier performance.|
|**2023-05-16**|**Health Impacts of Public Pawnshops in Industrializing Tokyo**|Tatsuki Inoue et.al.|[2305.09352v1](http://arxiv.org/abs/2305.09352v1)|null|This study is the first to investigate whether financial institutions for low-income populations have contributed to the historical decline in mortality rates. Using ward-level panel data from prewar Tokyo City, we found that public pawn loans were associated with reductions in infant and fetal death rates, potentially through improved nutrition and hygiene measures. Simple calculations suggest that popularizing public pawnshops led to a 6% and 8% decrease in infant mortality and fetal death rates, respectively, from 1927 to 1935. Contrarily, private pawnshops showed no significant association with health improvements. Our findings enrich the expanding literature on demographics and financial histories.|
|**2023-05-09**|**Child Palm-ID: Contactless Palmprint Recognition for Children**|Akash Godbole et.al.|[2305.05161v1](http://arxiv.org/abs/2305.05161v1)|null|Effective distribution of nutritional and healthcare aid for children, particularly infants and toddlers, in some of the least developed and most impoverished countries of the world, is a major problem due to the lack of reliable identification documents. Biometric authentication technology has been investigated to address child recognition in the absence of reliable ID documents. We present a mobile-based contactless palmprint recognition system, called Child Palm-ID, which meets the requirements of usability, hygiene, cost, and accuracy for child recognition. Using a contactless child palmprint database, Child-PalmDB1, consisting of 19,158 images from 1,020 unique palms (in the age range of 6 mos. to 48 mos.), we report a TAR=94.11% @ FAR=0.1%. The proposed Child Palm-ID system is also able to recognize adults, achieving a TAR=99.4% on the CASIA contactless palmprint database and a TAR=100% on the COEP contactless adult palmprint database, both @ FAR=0.1%. These accuracies are competitive with the SOTA provided by COTS systems. Despite these high accuracies, we show that the TAR for time-separated child-palmprints is only 78.1% @ FAR=0.1%.|
|**2023-05-03**|**Analysing the Impact of Audio Quality on the Use of Naturalistic Long-Form Recordings for Infant-Directed Speech Research**|MarÃ­a Andrea Cruz BlandÃ³n et.al.|[2305.01965v1](http://arxiv.org/abs/2305.01965v1)|[link](https://github.com/SPEECHCOG/ids_audio_quality_analysis)|Modelling of early language acquisition aims to understand how infants bootstrap their language skills. The modelling encompasses properties of the input data used for training the models, the cognitive hypotheses and their algorithmic implementations being tested, and the evaluation methodologies to compare models to human data. Recent developments have enabled the use of more naturalistic training data for computational models. This also motivates development of more naturalistic tests of model behaviour. A crucial step towards such an aim is to develop representative speech datasets consisting of speech heard by infants in their natural environments. However, a major drawback of such recordings is that they are typically noisy, and it is currently unclear how the sound quality could affect analyses and modelling experiments conducted on such data. In this paper, we explore this aspect for the case of infant-directed speech (IDS) and adult-directed speech (ADS) analysis. First, we manually and automatically annotated audio quality of utterances extracted from two corpora of child-centred long-form recordings (in English and French). We then compared acoustic features of IDS and ADS in an in-lab dataset and across different audio quality subsets of naturalistic data. Finally, we assessed how the audio quality and recording environment may change the conclusions of a modelling analysis using a recent self-supervised learning model. Our results show that the use of modest and high audio quality naturalistic speech data result in largely similar conclusions on IDS and ADS in terms of acoustic analyses and modelling experiments. We also found that an automatic sound quality assessment tool can be used to screen out useful parts of long-form recordings for a closer analysis with comparable results to that of manual quality annotation.|
|**2023-05-02**|**DeCom: Deep Coupled-Factorization Machine for Post COVID-19 Respiratory Syncytial Virus Prediction with Nonpharmaceutical Interventions Awareness**|Xinyan Li et.al.|[2305.01770v1](http://arxiv.org/abs/2305.01770v1)|null|Respiratory syncytial virus (RSV) is one of the most dangerous respiratory diseases for infants and young children. Due to the nonpharmaceutical intervention (NPI) imposed in the COVID-19 outbreak, the seasonal transmission pattern of RSV has been discontinued in 2020 and then shifted months ahead in 2021 in the northern hemisphere. It is critical to understand how COVID-19 impacts RSV and build predictive algorithms to forecast the timing and intensity of RSV reemergence in post-COVID-19 seasons. In this paper, we propose a deep coupled tensor factorization machine, dubbed as DeCom, for post COVID-19 RSV prediction. DeCom leverages tensor factorization and residual modeling. It enables us to learn the disrupted RSV transmission reliably under COVID-19 by taking both the regular seasonal RSV transmission pattern and the NPI into consideration. Experimental results on a real RSV dataset show that DeCom is more accurate than the state-of-the-art RSV prediction algorithms and achieves up to 46% lower root mean square error and 49% lower mean absolute error for country-level prediction compared to the baselines.|
|**2023-05-02**|**Self-supervised learning for infant cry analysis**|Arsenii Gorin et.al.|[2305.01578v1](http://arxiv.org/abs/2305.01578v1)|null|In this paper, we explore self-supervised learning (SSL) for analyzing a first-of-its-kind database of cry recordings containing clinical indications of more than a thousand newborns. Specifically, we target cry-based detection of neurological injury as well as identification of cry triggers such as pain, hunger, and discomfort. Annotating a large database in the medical setting is expensive and time-consuming, typically requiring the collaboration of several experts over years. Leveraging large amounts of unlabeled audio data to learn useful representations can lower the cost of building robust models and, ultimately, clinical solutions. In this work, we experiment with self-supervised pre-training of a convolutional neural network on large audio datasets. We show that pre-training with SSL contrastive loss (SimCLR) performs significantly better than supervised pre-training for both neuro injury and cry triggers. In addition, we demonstrate further performance gains through SSL-based domain adaptation using unlabeled infant cries. We also show that using such SSL-based pre-training for adaptation to cry sounds decreases the need for labeled data of the overall system.|
|**2023-05-01**|**CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds**|David Budaghyan et.al.|[2305.00969v3](http://arxiv.org/abs/2305.00969v3)|[link](https://github.com/ubenwa/cryceleb2023)|This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.|
|**2023-04-27**|**Cluster Flow: how a hierarchical clustering layer make allows deep-NNs more resilient to hacking, more human-like and easily implements relational reasoning**|Ella Gale et.al.|[2304.14081v1](http://arxiv.org/abs/2304.14081v1)|null|Despite the huge recent breakthroughs in neural networks (NNs) for artificial intelligence (specifically deep convolutional networks) such NNs do not achieve human-level performance: they can be hacked by images that would fool no human and lack `common sense'. It has been argued that a basis of human-level intelligence is mankind's ability to perform relational reasoning: the comparison of different objects, measuring similarity, grasping of relations between objects and the converse, figuring out the odd one out in a set of objects. Mankind can even do this with objects they have never seen before. Here we show how ClusterFlow, a semi-supervised hierarchical clustering framework can operate on trained NNs utilising the rich multi-dimensional class and feature data found at the pre-SoftMax layer to build a hyperspacial map of classes/features and this adds more human-like functionality to modern deep convolutional neural networks. We demonstrate this with 3 tasks. 1. the statistical learning based `mistakes' made by infants when attending to images of cats and dogs. 2. improving both the resilience to hacking images and the accurate measure of certainty in deep-NNs. 3. Relational reasoning over sets of images, including those not known to the NN nor seen before. We also demonstrate that ClusterFlow can work on non-NN data and deal with missing data by testing it on a Chemistry dataset. This work suggests that modern deep NNs can be made more human-like without re-training of the NNs. As it is known that some methods used in deep and convolutional NNs are not biologically plausible or perhaps even the best approach: the ClusterFlow framework can sit on top of any NN and will be a useful tool to add as NNs are improved in this regard.|
|**2023-04-19**|**Detection of a Super-Virial Hot Component in the Milky Way Circumgalactic Medium Along Multiple Sight-Lines by Using the Stacking Technique**|Armando Lara-DI et.al.|[2304.09641v1](http://arxiv.org/abs/2304.09641v1)|null|The study of the elusive hot component ($T \gtrsim 10^7$ K) of the Milky Way circumgalactic medium (CGM) is a novel topic to understand Galactic formation and evolution. In this work, we use the stacking technique through 46 lines of sight with Chandra ACIS-S HETG totaling over 10Ms of exposure time and 9 lines of sight with ACIS-S LETG observations totaling over 1Ms of exposure time, to study in absorption the presence of highly ionized metals arising from the super-virial temperature phase of the CGM. Focusing in the spectral range $4 - 8$ $\r{A}$, we were able to confirm the presence of this hot phase with high significance. We detected transitions of Si XIV K$\alpha$ (with total significance of 6.0$\sigma$) and, for the first time, SXVI K (total significance 4.8$\sigma$) in the rest frame of our own Galaxy. For S XVI K$\alpha$ we found a column density of $1.50^{+0.44}_{-0.38} \times 10^{16} \mathrm{cm}^{-2}$. For Si XIV K$\alpha$ we measured a column density of $0.87\pm{0.16} \times 10^{16} \mathrm{cm}^{-2}$. The lines of sight used in this work are spread across the sky, probing widely separated regions of the CGM. Therefore, our results indicate that this newly discovered hot medium extends throughout the halo, and is not related only to the Galactic Bubbles. The hot gas location, distribution, and covering factor, however, remain unknown. This component might contribute significantly to the missing baryons and metals in the Milky Way.|
|**2023-04-08**|**Predator-prey dynamics pertaining to structuralizing predator species into three stages coupled with maturation delay owing to juvenile hunting**|Debasish Bhattacharjee et.al.|[2304.05159v1](http://arxiv.org/abs/2304.05159v1)|null|The predator-prey dynamic appertaining to two species is explored, wherein the predator species is structured into different stages. As evidenced from natural documentation, the immature predators possess the potential to predate albeit not as competently as the adults. Nevertheless, this potentiality is not acquired immediately after their incipience of life, hence, the immature stage is branched off into the infant stage, the stage with extensive reliance on the adults, and the juvenile stage, the stage with the potential to predate but not to procreate. In this paper, this inaugural concept is coupled with injuries in the juvenile stage as the repercussion of their incompetency in predating, thereby ensuing a delay in their maturation. With the incentive to investigate the ascendancy of these refinements over the whole system, stability analyses along with various bifurcation analyses around the equilibrium points of the system are corroborated. In addition to Hopf, transcritical, and saddle node bifurcations, the existence of Bogdanov-Takens point, cusp point, Bautin bifurcation point, bloom phenomenon, twice occurring Hopf bifurcation, and bi-stability phenomenon make the paper appreciably more rich and efficacious.|
|**2023-04-05**|**IHCV: Discovery of Hidden Time-Dependent Control Variables in Non-Linear Dynamical Systems**|Juan Munoz et.al.|[2304.02443v1](http://arxiv.org/abs/2304.02443v1)|null|Discovering non-linear dynamical models from data is at the core of science. Recent progress hinges upon sparse regression of observables using extensive libraries of candidate functions. However, it remains challenging to model hidden non-observable control variables governing switching between different dynamical regimes. Here we develop a data-efficient derivative-free method, IHCV, for the Identification of Hidden Control Variables. First, the performance and robustness of IHCV against noise are evaluated by benchmarking the IHCV method using well-known bifurcation models (saddle-node, transcritical, pitchfork, Hopf). Next, we demonstrate that IHCV discovers hidden driver variables in the Lorenz, van der Pol, Hodgkin-Huxley, and Fitzhugh-Nagumo models. Finally, IHCV generalizes to the case when only partial observational is given, as demonstrated using the toggle switch model, the genetic repressilator oscillator, and a Waddington landscape model. Our proof-of-principle illustrates that utilizing normal forms could facilitate the data-efficient and scalable discovery of hidden variables controlling transitions between different dynamical regimes and non-linear models.|
|**2023-04-02**|**Origin of high-velocity ejecta and early red excess emission in the infant Type Ia supernova 2021aefx**|Yuan Qi Ni et.al.|[2304.00625v2](http://arxiv.org/abs/2304.00625v2)|null|\object{SN 2021aefx} is a normal Type Ia Supernova (SN) with red excess emission over the first $\sim$ 2 days. We present detailed analysis of this SN using our high-cadence KMTNet multi-band photometry, spectroscopy, and publicly available data. We provide the first measurements of its epochs of explosion (MJD 59529.32 $\pm$ 0.16) as well as ``first light'' (MJD 59529.85 $\pm$ 0.55) associated with the main ejecta ${\rm{^{56}Ni}}$ distribution. This places our first detection of SN 2021aefx at $\sim -$0.5 hours since ``first light'', indicating the presence of additional power sources. Our peak-spectrum confirms its Type Ia sub-classification as intermediate between Core-Normal and Broad-Line, and we estimate the ejecta mass to be $\sim$ 1.34 $M_{\odot}$. The pre-peak spectral evolution identifies fast-expanding material reaching $>$ 40,000 km s$^{-1}$ (the fastest ever observed in Type Ia SNe) and at least two distinct homologously-expanding ejecta components: (1) a normal-velocity (12,400 km s$^{-1}$) component consistent with the typical photospheric evolution of Chandrasekhar-mass ejecta; and (2) a high-velocity (23,500 km s$^{-1}$) component visible during the first $\sim$ 3.6 days post-explosion, which locates the component within the outer $<$ 16\% of the ejecta mass. Asymmetric, subsonic explosion processes producing a non-spherical photosphere provide an explanation for the simultaneous presence of the two components, as well as the red excess emission via a slight ${\rm{^{56}Ni}}$ enrichment in the outer $\sim$ 0.5\% of the ejecta mass. Our spectrum from 300 days post-peak advances the constraint against non-degenerate companions and further supports a near-Chandrasekhar-mass explosion origin. Off-center ignited delayed-detonations of Chandrasekhar-mass white dwarfs may be responsible for the observed features of SN 2021aefx in some normal Type Ia SNe.|
|**2023-04-02**|**The short- and long-term determinants of fertility in Uruguay**|Zuleika Ferre et.al.|[2304.00539v1](http://arxiv.org/abs/2304.00539v1)|null|This paper examines the determinants of fertility among women at different stages of their reproductive lives in Uruguay. To this end, we employ time series analysis methods based on data from 1968 to 2021 and panel data techniques based on department-level statistical information from 1984 to 2019. The results of our first econometric exercise indicate a cointegration relationship between fertility and economic performance, education and infant mortality, with differences observed by reproductive stage. We find a negative relationship between income and fertility for women aged 20-29 that persists for women aged 30 and over. This result suggests that having children is perceived as an opportunity cost for women in this age group. We also observe a negative relationship between education and adolescent fertility, which has implications for the design of public policies. A panel data analysis with econometric techniques allowing us to control for unobserved heterogeneity confirms that income is a relevant factor for all groups of women and reinforces the crucial role of education in reducing teenage fertility. We also identify a negative correlation between fertility and employment rates for women aged 30 and above. We outline some possible explanations for these findings in the context of work-life balance issues and argue for the importance of implementing social policies to address them.|
|**2023-04-01**|**N,N,N-Trimethyl chitosan as a permeation enhancer for inhalation drug delivery: interaction with a model pulmonary surfactant**|Jana SzabovÃ¡ et.al.|[2304.04547v1](http://arxiv.org/abs/2304.04547v1)|null|N,N,N-Trimethyl chitosan (TMC), a biocompatible and biodegradable derivative of chitosan, is currently used as a permeation enhancer to increase the translocation of drugs to the bloodstream in the lungs. This article discusses the effect of TMC on a mimetic pulmonary surfactant, Curosurf, a low-viscosity lipid formulation administered to preterm infants with acute respiratory distress syndrome. Curosurf exhibits a strong interaction with TMC, resulting in the formation of aggregates at electrostatic charge stoichiometry. At nanoscale, Curosurf undergoes a profound reorganization of its lipid vesicles in terms of size and lamellarity. The initial micron-sized vesicles (average size 4.8 microns) give way to a froth-like network of unilamellar vesicles about 300 nm in size. Under such conditions, neutralization of the cationic charges by pulmonary surfactant may inhibit TMC permeation enhancer capacity, especially as electrostatic charge complexation is found at low TMC content. The permeation properties of pulmonary surfactant-neutralized TMC should then be evaluated for its applicability as a permeation enhancer for inhalation in the alveolar region.|
|**2023-03-31**|**Symmetry Groupoids for Pattern-Selective Feedback Stabilization of the Chafee--Infante Equation**|Isabelle Schneider et.al.|[2303.18078v2](http://arxiv.org/abs/2303.18078v2)|null|Reaction-diffusion equations are ubiquitous in various scientific domains and their patterns represent a fascinating area of investigation. However, many of these patterns are unstable and therefore challenging to observe. To overcome this limitation, we present new noninvasive feedback controls based on symmetry groupoids. As a concrete example, we employ these controls to selectively stabilize unstable equilibria of the Chafee--Infante equation under Dirichlet boundary conditions on the interval. Unlike conventional reflection-based control schemes, our approach incorporates additional symmetries that enable us to design new convolution controls for stabilization. By demonstrating the efficacy of our method, we provide a new tool for investigating and controlling systems with unstable patterns, with potential implications for a wide range of scientific disciplines.|
|**2023-03-29**|**A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants**|Shaotong Zhu et.al.|[2303.16867v1](http://arxiv.org/abs/2303.16867v1)|[link](https://github.com/ostadabbas/nns-detection-and-segmentation)|We present an end-to-end computer vision pipeline to detect non-nutritive sucking (NNS) -- an infant sucking pattern with no nutrition delivered -- as a potential biomarker for developmental delays, using off-the-shelf baby monitor video footage. One barrier to clinical (or algorithmic) assessment of NNS stems from its sparsity, requiring experts to wade through hours of footage to find minutes of relevant activity. Our NNS activity segmentation algorithm solves this problem by identifying periods of NNS with high certainty -- up to 94.0\% average precision and 84.9\% average recall across 30 heterogeneous 60 s clips, drawn from our manually annotated NNS clinical in-crib dataset of 183 hours of overnight baby monitor footage from 19 infants. Our method is based on an underlying NNS action recognition algorithm, which uses spatiotemporal deep learning networks and infant-specific pose estimation, achieving 94.9\% accuracy in binary classification of 960 2.5 s balanced NNS vs. non-NNS clips. Tested on our second, independent, and public NNS in-the-wild dataset, NNS recognition classification reaches 92.3\% accuracy, and NNS segmentation achieves 90.8\% precision and 84.2\% recall.|

### neonatal+ai
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-16**|**MedFMC: A Real-world Dataset and Benchmark For Foundation Model Adaptation in Medical Image Classification**|Dequan Wang et.al.|[2306.09579v1](http://arxiv.org/abs/2306.09579v1)|null|Foundation models, often pre-trained with large-scale data, have achieved paramount success in jump-starting various vision and language applications. Recent advances further enable adapting foundation models in downstream tasks efficiently using only a few training samples, e.g., in-context learning. Yet, the application of such learning paradigms in medical image analysis remains scarce due to the shortage of publicly accessible data and benchmarks. In this paper, we aim at approaches adapting the foundation models for medical image classification and present a novel dataset and benchmark for the evaluation, i.e., examining the overall performance of accommodating the large-scale foundation models downstream on a set of diverse real-world clinical tasks. We collect five sets of medical imaging data from multiple institutes targeting a variety of real-world clinical tasks (22,349 images in total), i.e., thoracic diseases screening in X-rays, pathological lesion tissue screening, lesion detection in endoscopy images, neonatal jaundice evaluation, and diabetic retinopathy grading. Results of multiple baseline methods are demonstrated using the proposed dataset from both accuracy and cost-effective perspectives.|
|**2023-05-28**|**A joint estimation approach for monotonic regression functions in general dimensions**|Christian Rohrbeck et.al.|[2305.17711v1](http://arxiv.org/abs/2305.17711v1)|null|Regression analysis under the assumption of monotonicity is a well-studied statistical problem and has been used in a wide range of applications. However, there remains a lack of a broadly applicable methodology that permits information borrowing, for efficiency gains, when jointly estimating multiple monotonic regression functions. We introduce such a methodology by extending the isotonic regression problem presented in the article "The isotonic regression problem and its dual" (Barlow and Brunk, 1972). The presented approach can be applied to both fixed and random designs and any number of explanatory variables (regressors). Our framework penalizes pairwise differences in the values (levels) of the monotonic function estimates, with the weight of penalty being determined based on a statistical test, which results in information being shared across data sets if similarities in the regression functions exist. Function estimates are subsequently derived using an iterative optimization routine that uses existing solution algorithms for the isotonic regression problem. Simulation studies for normally and binomially distributed response data illustrate that function estimates are consistently improved if similarities between functions exist, and are not oversmoothed otherwise. We further apply our methodology to analyse two public health data sets: neonatal mortality data for Porto Alegre, Brazil, and stroke patient data for North West England.|
|**2023-05-02**|**Establishing a Learning Model for Correct Hand Hygiene Technique in a NICU**|IrÃ©n A. KopcsÃ³nÃ© NÃ©meth et.al.|[2305.01366v1](http://arxiv.org/abs/2305.01366v1)|null|The ability of healthcare workers to learn proper hand hygiene has been an understudied area of research. Generally, hand hygiene skills are regarded as a key contributor to reduce critical infections and healthcare-associated infections. In a clinical setup, at a Neonatal Intensive Care Unit (NICU), the outcome of a multi-modal training initiative was recorded, where objective feedback was provided to the staff. It was hypothesized that staff at the NICU are more sensitive towards applying increased patient safety measures. Outcomes were recorded as the ability to cover all hand surfaces with Alcohol-Based Handrub (ABHR), modelled as a time-series of measurements. The learning ability to rub in with 1.5 mL and with 3 mL was also assessed. As a secondary outcome, handrub consumption and infection numbers were recorded. It has been observed that some staff members were able to quickly learn the proper hand hygiene, even with the limited 1.5 mL, while others were not capable of acquiring the technique even with 3 mL. When analyzing the 1.5 mL group, it was deemed an insufficient ABHR amount, while with 3 mL, the critical necessity of skill training to achieve complete coverage was documented. Identifying these individuals helps the infection control staff to better focus their training efforts. The training led to a 157% increase in handrub consumption. The setting of the study did not allow to show a measurable reduction in the number of hospital infections. It has been concluded that the training method chosen by the staff greatly affects the quality of the outcomes.|
|**2023-04-26**|**ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges**|Ruizhe Zheng et.al.|[2304.14919v1](http://arxiv.org/abs/2304.14919v1)|[link](https://github.com/albertcheng19/scatterformer)|Patient-independent detection of epileptic activities based on visual spectral representation of continuous EEG (cEEG) has been widely used for diagnosing epilepsy. However, precise detection remains a considerable challenge due to subtle variabilities across subjects, channels and time points. Thus, capturing fine-grained, discriminative features of EEG patterns, which is associated with high-frequency textural information, is yet to be resolved. In this work, we propose Scattering Transformer (ScatterFormer), an invariant scattering transform-based hierarchical Transformer that specifically pays attention to subtle features. In particular, the disentangled frequency-aware attention (FAA) enables the Transformer to capture clinically informative high-frequency components, offering a novel clinical explainability based on visual encoding of multichannel EEG signals. Evaluations on two distinct tasks of epileptiform detection demonstrate the effectiveness our method. Our proposed model achieves median AUCROC and accuracy of 98.14%, 96.39% in patients with Rolandic epilepsy. On a neonatal seizure detection benchmark, it outperforms the state-of-the-art by 9% in terms of average AUCROC.|
|**2023-04-12**|**NRTS: A Client-Server architecture for supporting data recording, transmission and evaluation of multidisciplinary teams during the neonatal resuscitation simulation scenario**|Manuel Striani et.al.|[2304.09860v1](http://arxiv.org/abs/2304.09860v1)|null|In this technical report, we describe Neonatal Resuscitation Training Simulator (NRTS), an Android mobile app designed to support medical experts to input, transmit and record data during a High-Fidelity Simulation course for neonatal resuscitation. This mobile app allows one to automatically send all the recorded data from "Neonatal Intensive Care Unit" (NICU) of Casale Monferrato Children's Hospital, (Italy) to a server located at the Department of Science and Technological Innovation (DiSIT), University of Piemonte Orientale (Italy). Finally, the medical instructor can view statistics on a simulation exercise that may be used during the de-briefing phase for the evaluation of multidisciplinary teams involved in the simulation scenarios.|
|**2023-03-28**|**Predicting Adverse Neonatal Outcomes for Preterm Neonates with Multi-Task Learning**|Jingyang Lin et.al.|[2303.15656v1](http://arxiv.org/abs/2303.15656v1)|null|Diagnosis of adverse neonatal outcomes is crucial for preterm survival since it enables doctors to provide timely treatment. Machine learning (ML) algorithms have been demonstrated to be effective in predicting adverse neonatal outcomes. However, most previous ML-based methods have only focused on predicting a single outcome, ignoring the potential correlations between different outcomes, and potentially leading to suboptimal results and overfitting issues. In this work, we first analyze the correlations between three adverse neonatal outcomes and then formulate the diagnosis of multiple neonatal outcomes as a multi-task learning (MTL) problem. We then propose an MTL framework to jointly predict multiple adverse neonatal outcomes. In particular, the MTL framework contains shared hidden layers and multiple task-specific branches. Extensive experiments have been conducted using Electronic Health Records (EHRs) from 121 preterm neonates. Empirical results demonstrate the effectiveness of the MTL framework. Furthermore, the feature importance is analyzed for each neonatal outcome, providing insights into model interpretability.|
|**2023-03-21**|**The Multiscale Surface Vision Transformer**|Simon Dahan et.al.|[2303.11909v1](http://arxiv.org/abs/2303.11909v1)|[link](https://github.com/metrics-lab/surface-vision-transformers)|Surface meshes are a favoured domain for representing structural and functional information on the human cortex, but their complex topology and geometry pose significant challenges for deep learning analysis. While Transformers have excelled as domain-agnostic architectures for sequence-to-sequence learning, notably for structures where the translation of the convolution operation is non-trivial, the quadratic cost of the self-attention operation remains an obstacle for many dense prediction tasks. Inspired by some of the latest advances in hierarchical modelling with vision transformers, we introduce the Multiscale Surface Vision Transformer (MS-SiT) as a backbone architecture for surface deep learning. The self-attention mechanism is applied within local-mesh-windows to allow for high-resolution sampling of the underlying data, while a shifted-window strategy improves the sharing of information between windows. Neighbouring patches are successively merged, allowing the MS-SiT to learn hierarchical representations suitable for any prediction task. Results demonstrate that the MS-SiT outperforms existing surface deep learning methods for neonatal phenotyping prediction tasks using the Developing Human Connectome Project (dHCP) dataset. Furthermore, building the MS-SiT backbone into a U-shaped architecture for surface segmentation demonstrates competitive results on cortical parcellation using the UK Biobank (UKB) and manually-annotated MindBoggle datasets. Code and trained models are publicly available at https://github.com/metrics-lab/surface-vision-transformers .|
|**2023-03-14**|**Activity Recognition From Newborn Resuscitation Videos**|Ã˜yvind Meinich-Bache et.al.|[2303.07789v1](http://arxiv.org/abs/2303.07789v1)|null|Objective: Birth asphyxia is one of the leading causes of neonatal deaths. A key for survival is performing immediate and continuous quality newborn resuscitation. A dataset of recorded signals during newborn resuscitation, including videos, has been collected in Haydom, Tanzania, and the aim is to analyze the treatment and its effect on the newborn outcome. An important step is to generate timelines of relevant resuscitation activities, including ventilation, stimulation, suction, etc., during the resuscitation episodes. Methods: We propose a two-step deep neural network system, ORAA-net, utilizing low-quality video recordings of resuscitation episodes to do activity recognition during newborn resuscitation. The first step is to detect and track relevant objects using Convolutional Neural Networks (CNN) and post-processing, and the second step is to analyze the proposed activity regions from step 1 to do activity recognition using 3D CNNs. Results: The system recognized the activities newborn uncovered, stimulation, ventilation and suction with a mean precision of 77.67 %, a mean recall of 77,64 %, and a mean accuracy of 92.40 %. Moreover, the accuracy of the estimated number of Health Care Providers (HCPs) present during the resuscitation episodes was 68.32 %. Conclusion: The results indicate that the proposed CNN-based two-step ORAAnet could be used for object detection and activity recognition in noisy low-quality newborn resuscitation videos. Significance: A thorough analysis of the effect the different resuscitation activities have on the newborn outcome could potentially allow us to optimize treatment guidelines, training, debriefing, and local quality improvement in newborn resuscitation.|
|**2023-02-14**|**Classification of Lung Pathologies in Neonates using Dual Tree Complex Wavelet Transform**|Sagarjit Aujla et.al.|[2302.07157v2](http://arxiv.org/abs/2302.07157v2)|null|Annually 8500 neonatal deaths are reported in the US due to respiratory failure. Recently, Lung Ultrasound (LUS), due to its radiation free nature, portability, and being cheaper is gaining wide acceptability as a diagnostic tool for lung conditions. However, lack of highly trained medical professionals has limited its use especially in remote areas. To address this, an automated screening system that captures characteristics of the LUS patterns can be of significant assistance to clinicians who are not experts in lung ultrasound (LUS) images. In this paper, we propose a feature extraction method designed to quantify the spatially-localized line patterns and texture patterns found in LUS images. Using the dual-tree complex wavelet transform (DTCWT) and four types of common image features we propose a method to classify the LUS images into 6 common neonatal lung conditions. These conditions are normal lung, pneumothorax (PTX), transient tachypnea of the newborn (TTN), respiratory distress syndrome (RDS), chronic lung disease (CLD) and consolidation (CON) that could be pneumonia or atelectasis. The proposed method using DTCWT decomposition extracted global statistical, grey-level co-occurrence matrix (GLCM), grey-level run length matrix (GLRLM) and linear binary pattern (LBP) features to be fed to a linear discriminative analysis (LDA) based classifier. Using 15 best DTCWT features along with 3 clinical features the proposed approach achieved a per-image classification accuracy of 92.78% with a balanced dataset containing 720 images from 24 patients and 74.39% with the larger unbalanced dataset containing 1550 images from 42 patients. Likewise, the proposed method achieved a maximum per-subject classification accuracy of 81.53% with 43 DTCWT features and 3 clinical features using the balanced dataset and 64.97% with 13 DTCWT features and 3 clinical features using the unbalanced dataset.|
|**2023-02-08**|**Neonatal Face and Facial Landmark Detection from Video Recordings**|Ethan Grooby et.al.|[2302.04341v1](http://arxiv.org/abs/2302.04341v1)|null|This paper explores automated face and facial landmark detection of neonates, which is an important first step in many video-based neonatal health applications, such as vital sign estimation, pain assessment, sleep-wake classification, and jaundice detection. Utilising three publicly available datasets of neonates in the clinical environment, 366 images (258 subjects) and 89 (66 subjects) were annotated for training and testing, respectively. Transfer learning was applied to two YOLO-based models, with input training images augmented with random horizontal flipping, photo-metric colour distortion, translation and scaling during each training epoch. Additionally, the re-orientation of input images and fusion of trained deep learning models was explored. Our proposed model based on YOLOv7Face outperformed existing methods with a mean average precision of 84.8% for face detection, and a normalised mean error of 0.072 for facial landmark detection. Overall, this will assist in the development of fully automated neonatal health assessment algorithms.|
|**2023-02-01**|**The Past, Current, and Future of Neonatal Intensive Care Units with Artificial Intelligence**|Elif Keles et.al.|[2302.00225v1](http://arxiv.org/abs/2302.00225v1)|null|Artificial intelligence (AI), specifically a branch of AI called deep learning (DL), has proven revolutionary developments in almost all fields, from computer vision to health sciences, and its effects in medicine have changed clinical applications significantly. Although some sub-fields of medicine such as pediatrics have been relatively slow in receiving critical benefits of AI, related research in pediatrics started to be accumulated to a significant level too. Hence, in this paper, we review recently developed machine learning and deep learning based systems for neonatology applications. We systematically evaluate the role of AI in neonatology applications, define the methodologies, including algorithmic developments, and describe the remaining challenges in neonatal diseases. To date, survival analysis, neuroimaging, EEG, pattern analysis of vital parameters, and retinopathy of prematurity diagnosis with AI have been the main focus in neonatology. We have categorically summarized 96 research articles, from 1996 to 2022, and discussed their pros and cons, respectively. We also discuss possible directions for new AI models and the future of neonatology with the rising power of AI, suggesting roadmaps for integration of AI into neonatal intensive care units.|
|**2022-12-26**|**Investigation of the aptness of newly developed epoxy-based equivalent tissues for newborn and 5-years old in paediatric radiology**|Nabeel Ibrahim Ashour et.al.|[2212.13002v1](http://arxiv.org/abs/2212.13002v1)|null|The varied radiological applications of tissue equivalent (TE) materials encompass quality checks, diagnostic imaging and dose evaluations. Nevertheless, the availability of compounds representative of paediatric patient tissues for scientific use in lower diagnostic photon energy spectra is limited. In this study, several TE substitutes were developed which replicate the radiographic characteristics of human tissue within these energy ranges, i.e. TE materials for neonatal soft tissue (ESST-NB), neonatal skeletal tissue (ESTB-NB), and the equivalent tissue types representative of a 5 year old child (ESST and ESBT, respectively). The ORNL stylised computational model series was used as a source for the desired elemental proportions. The density, effective atomic number, CT numbers and electron densities calculated for the developed tissue substitutes approximated those of the phantom system used as a reference. Additionally, in keeping with the material choice and production limitations, as close correlations as possible were achieved for all the materials in relation to the reference data for mass densities, mass attenuation coefficients and mass energy-absorption coefficients. The TE substitutes for the newborn over an energy range of 47 keV to 66 keV exhibited maximum discrepancies for {\mu}/\r{ho} of 1.6% to -3.01%, and for {\mu}_en/\r{ho} of 1.15% to -1.4% in relation to the ORNL reference samples. The respective equivalent data ranges were 1.09 % to -3.02% and 1.92% to -2.53% for the TE materials representative of a 5-year-old. Given the excellent concordance achieved between the newly constructed TE materials and the reference data, these compounds can subsequently be utilised to create physical phantoms representative of tissue types in neonates and children aged 5 years.|
|**2022-12-12**|**Estimating the timing of stillbirths in countries worldwide using a Bayesian hierarchical penalized splines regression model**|Michael Y. C. Chong et.al.|[2212.06219v1](http://arxiv.org/abs/2212.06219v1)|null|Reducing the global burden of stillbirths is important to improving child and maternal health. Of interest is understanding patterns in the timing of stillbirths -- that is, whether they occur in the intra- or antepartum period -- because stillbirths that occur intrapartum are largely preventable. However, data availability on the timing of stillbirths is highly variable across the world, with low- and middle-income countries generally having few reliable observations. In this paper we develop a Bayesian penalized splines regression framework to estimate the proportion of stillbirths that are intrapartum for all countries worldwide. The model accounts for known relationships with neonatal mortality, pools information across geographic regions, incorporates different errors based on data attributes, and allows for data-driven temporal trends. A weighting procedure is proposed to account for unrepresentative subnational data. Results suggest that the intrapartum proportion is generally decreasing over time, but progress is slower in some regions, particularly Sub-Saharan Africa.|
|**2022-12-05**|**Robust multiple method comparison and transformation**|Florian Dufey et.al.|[2212.02306v1](http://arxiv.org/abs/2212.02306v1)|null|A generalization of Passing-Bablok regression for the simultaneous comparison of multiple methods is proposed. Possible applications include assay migration studies or interlaboratory trials. The method is shown to reduce to the usual Passing--Bablok estimator if only two methods are compared. It is close in spirit to reduced major axis regression, which is, however, not robust. To obtain a robust estimator, the major axis is replaced by the (hyper-)spherical median axis. The method is applied to the comparison of SARS-CoV-2 serological tests, bilirubin in neonates, and to a clinical test using different instruments, sample preparations and reagent lots. Plots, similar to the well known Bland-Altman plots, are developed for a posteriori checks of the assumed variance structure.|
|**2022-11-16**|**Neurodevelopmental Phenotype Prediction: A State-of-the-Art Deep Learning Model**|DÃ¡niel Unyi et.al.|[2211.08831v1](http://arxiv.org/abs/2211.08831v1)|[link](https://github.com/daniel-unyi-42/neurodevelopmental-phenotype-prediction)|A major challenge in medical image analysis is the automated detection of biomarkers from neuroimaging data. Traditional approaches, often based on image registration, are limited in capturing the high variability of cortical organisation across individuals. Deep learning methods have been shown to be successful in overcoming this difficulty, and some of them have even outperformed medical professionals on certain datasets. In this paper, we apply a deep neural network to analyse the cortical surface data of neonates, derived from the publicly available Developing Human Connectome Project (dHCP). Our goal is to identify neurodevelopmental biomarkers and to predict gestational age at birth based on these biomarkers. Using scans of preterm neonates acquired around the term-equivalent age, we were able to investigate the impact of preterm birth on cortical growth and maturation during late gestation. Besides reaching state-of-the-art prediction accuracy, the proposed model has much fewer parameters than the baselines, and its error stays low on both unregistered and registered cortical surfaces.|
|**2022-11-08**|**Automated CFD shape optimization of stator blades for the PediaFlow pediatric ventricular assist device**|Mansur Zhussupbekov et.al.|[2211.04401v1](http://arxiv.org/abs/2211.04401v1)|null|PediaFlow is a miniature mixed-flow ventricular assist device for neonates and toddlers. PediaFlow has a fully magnetically levitated rotor which improves biocompatibility, but the increased length of the rotor creates a long annular passage where fluid energy is lost. Therefore, a set of helical stator blades was proposed immediately after the impeller stage to remove the swirling flow and recover the dynamic head as static pressure. Automated computational fluid dynamics (CFD) shape optimization of the stator blades was performed to maximize pressure recovery at the operating point of 1.5 LPM and 16,000 RPM. Additionally, the effect on hemolysis and thrombogenicity was assessed using numerical modeling. The optimization algorithm favored fewer blades of greater length over a larger number of short blades. The ratio of wrap angle to axial length emerged as a key constraint to ensure the viability of a design. The best design had 2 blades and generated 73 mmHg of pressure recovery in an isolated stage. When re-introduced to the CFD simulation of the complete flow path, the added stator stage increased the pump head by 46% and improved the pump efficiency from 21.9% to 25.7% at the selected operating point. Automated CFD shape optimization combined with in silico evaluation of hemocompatibility can be an effective tool for exploring design choices and informing early development process.|
|**2022-09-20**|**Unresolved excess accumulation of myelin-derived cholesterol contributes to scar formation after spinal cord injury**|Bolin Zheng et.al.|[2209.09700v1](http://arxiv.org/abs/2209.09700v1)|null|Background: Spinal cord injury triggers complex pathological cascades, resulting in destructive tissue damage and incomplete tissue repair. Scar formation is generally considered as a barrier for regeneration in central nervous system (CNS), while the intrinsic mechanism of scar-forming after spinal cord injury has not been completed deciphered. Methods: We assessed cholesterol hemostasis in spinal cord lesions and injured peripheral nerves using confocal reflection microscopy and real-time PCR analyses. The involvement of the proteins, which were predicted to promote cholesterol efflux in spinal cord lesions, were assessed with Liver X receptor (LXR) agonist and Apolipoprotein E (APOE) deficiency. The role of reverse cholesterol transport (RCT) in cholesterol clearance was examined in APOE KO mice injured sciatic nerves and myelin-overloaded macrophages in vitro. Finally, we determined the consequence of excess cholesterol accumulation in CNS by transplantation of myelin into neonatal spinal cord lesions. Results: We found that excess cholesterol accumulates in phagocytes and is inefficiently removed in spinal cord lesions in young-adult mice. Interestingly, we observed that excessive cholesterol also accumulates in injured peripheral nerves, but is subsequently removed by RCT. Meanwhile, preventing RCT led to macrophage accumulation and fibrosis in injured peripheral nerves. Furthermore, the neonatal mouse spinal cord lesions are devoid of myelin-derived lipids, and able to heal without excess cholesterol accumulation. We found that transplantation of myelin into neonatal lesions disrupts healing with excessive cholesterol accumulation, persistent macrophage activation and fibrosis, indicating myelin-derived cholesterol plays a critical role in impaired wound healing.|
|**2022-08-29**|**Slice estimation in diffusion MRI of neonatal and fetal brains in image and spherical harmonics domains using autoencoders**|Hamza Kebiri et.al.|[2208.13328v1](http://arxiv.org/abs/2208.13328v1)|null|Diffusion MRI (dMRI) of the developing brain can provide valuable insights into the white matter development. However, slice thickness in fetal dMRI is typically high (i.e., 3-5 mm) to freeze the in-plane motion, which reduces the sensitivity of the dMRI signal to the underlying anatomy. In this study, we aim at overcoming this problem by using autoencoders to learn unsupervised efficient representations of brain slices in a latent space, using raw dMRI signals and their spherical harmonics (SH) representation. We first learn and quantitatively validate the autoencoders on the developing Human Connectome Project pre-term newborn data, and further test the method on fetal data. Our results show that the autoencoder in the signal domain better synthesized the raw signal. Interestingly, the fractional anisotropy and, to a lesser extent, the mean diffusivity, are best recovered in missing slices by using the autoencoder trained with SH coefficients. A comparison was performed with the same maps reconstructed using an autoencoder trained with raw signals, as well as conventional interpolation methods of raw signals and SH coefficients. From these results, we conclude that the recovery of missing/corrupted slices should be performed in the signal domain if the raw signal is aimed to be recovered, and in the SH domain if diffusion tensor properties (i.e., fractional anisotropy) are targeted. Notably, the trained autoencoders were able to generalize to fetal dMRI data acquired using a much smaller number of diffusion gradients and a lower b-value, where we qualitatively show the consistency of the estimated diffusion tensor maps.|
|**2022-08-25**|**Development of Sleep State Trend (SST), a bedside measure of neonatal sleep state fluctuations based on single EEG channels**|Saeed Montazeri Moghadam et.al.|[2208.11933v1](http://arxiv.org/abs/2208.11933v1)|null|Objective: To develop and validate an automated method for bedside monitoring of sleep state fluctuations in neonatal intensive care units.   Methods: A deep learning -based algorithm was designed and trained using 53 EEG recordings from a long-term (a)EEG monitoring in 30 near-term neonates. The results were validated using an external dataset from 30 polysomnography recordings. In addition to training and validating a single EEG channel quiet sleep detector, we constructed Sleep State Trend (SST), a bedside-ready means for visualizing classifier outputs.   Results: The accuracy of quiet sleep detection in the training data was 90%, and the accuracy was comparable (85-86%) in all bipolar derivations available from the 4-electrode recordings. The algorithm generalized well to an external dataset, showing 81% overall accuracy despite different signal derivations. SST allowed an intuitive, clear visualization of the classifier output.   Conclusions: Fluctuations in sleep states can be detected at high fidelity from a single EEG channel, and the results can be visualized as a transparent and intuitive trend in the bedside monitors.   Significance: The Sleep State Trend (SST) may provide caregivers a real-time view of sleep state fluctuations and its cyclicity.|
|**2022-08-23**|**Regression discontinuity design in perinatal epidemiology and birth cohort research**|Maja Popovic et.al.|[2208.11047v1](http://arxiv.org/abs/2208.11047v1)|null|Regression discontinuity design (RDD) is a quasi-experimental approach to study the causal effects of an intervention/treatment on later health outcomes. It exploits a continuously measured assignment variable with a clearly defined cut-off above or below which the population is at least partially assigned to the intervention/treatment. We describe the RDD and outline the applications of RDD in the context of perinatal epidemiology and birth cohort research.   There is an increasing number of studies using RDD in perinatal and pediatric epidemiology. Most of these studies were conducted in the context of education, social and welfare policies, healthcare organization, insurance, and preventive programs. Additional thematic fields include clinically relevant research questions, shock events, social and environmental factors, and changes in guidelines. Maternal and perinatal characteristics, such as age, birth weight and gestational age are frequently used assignment variables to study the effects of the type and intensity of neonatal care, health insurance, and supplemental newborn benefits. Different socioeconomic measures have been used to study the effects of social, welfare and cash transfer programs, while age or date of birth served as assignment variables to study the effects of vaccination programs, pregnancy-specific guidelines, maternity and paternity leave policies and introduction of newborn-based welfare programs.   RDD has advantages, including relatively weak and testable assumptions, strong internal validity, intuitive interpretation, and transparent and simple graphical representation. However, its use in birth cohort research is hampered by the rarity of settings outside of policy and program evaluations, low statistical power, limited external validity (geographic- and time-specific settings) and potential contamination by other exposures/interventions.|
|**2022-07-25**|**Deep learning based non-contact physiological monitoring in Neonatal Intensive Care Unit**|Nicky Nirlipta Sahoo et.al.|[2207.11886v1](http://arxiv.org/abs/2207.11886v1)|null|Preterm babies in the Neonatal Intensive Care Unit (NICU) have to undergo continuous monitoring of their cardiac health. Conventional monitoring approaches are contact-based, making the neonates prone to various nosocomial infections. Video-based monitoring approaches have opened up potential avenues for contactless measurement. This work presents a pipeline for remote estimation of cardiopulmonary signals from videos in NICU setup. We have proposed an end-to-end deep learning (DL) model that integrates a non-learning based approach to generate surrogate ground truth (SGT) labels for supervision, thus refraining from direct dependency on true ground truth labels. We have performed an extended qualitative and quantitative analysis to examine the efficacy of our proposed DL-based pipeline and achieved an overall average mean absolute error of 4.6 beats per minute (bpm) and root mean square error of 6.2 bpm in the estimated heart rate.|
|**2022-07-18**|**Superficial White Matter Analysis: An Efficient Point-cloud-based Deep Learning Framework with Supervised Contrastive Learning for Consistent Tractography Parcellation across Populations and dMRI Acquisitions**|Tengfei Xue et.al.|[2207.08975v3](http://arxiv.org/abs/2207.08975v3)|null|Diffusion MRI tractography is an advanced imaging technique that enables in vivo mapping of the brain's white matter connections. White matter parcellation classifies tractography streamlines into clusters or anatomically meaningful tracts. It enables quantification and visualization of whole-brain tractography. Currently, most parcellation methods focus on the deep white matter (DWM), whereas fewer methods address the superficial white matter (SWM) due to its complexity. We propose a novel two-stage deep-learning-based framework, Superficial White Matter Analysis (SupWMA), that performs an efficient and consistent parcellation of 198 SWM clusters from whole-brain tractography. A point-cloud-based network is adapted to our SWM parcellation task, and supervised contrastive learning enables more discriminative representations between plausible streamlines and outliers for SWM. We train our model on a large-scale tractography dataset including streamline samples from labeled long- and medium-range (over 40 mm) SWM clusters and anatomically implausible streamline samples, and we perform testing on six independently acquired datasets of different ages and health conditions (including neonates and patients with space-occupying brain tumors). Compared to several state-of-the-art methods, SupWMA obtains highly consistent and accurate SWM parcellation results on all datasets, showing good generalization across the lifespan in health and disease. In addition, the computational speed of SupWMA is much faster than other methods.|
|**2022-07-14**|**Spatial Aggregation with Respect to a Population Distribution**|John Paige et.al.|[2207.06700v1](http://arxiv.org/abs/2207.06700v1)|[link](https://github.com/paigejo/summer)|Spatial aggregation with respect to a population distribution involves estimating aggregate quantities for a population based on an observation of individuals in a subpopulation. In this context, a geostatistical workflow must account for three major sources of `aggregation error': aggregation weights, fine scale variation, and finite population variation. However, common practice is to treat the unknown population distribution as a known population density and ignore empirical variability in outcomes. We improve common practice by introducing a `sampling frame model' that allows aggregation models to account for the three sources of aggregation error simply and transparently.   We compare the proposed and the traditional approach using two simulation studies that mimic neonatal mortality rate (NMR) data from the 2014 Kenya Demographic and Health Survey (KDHS2014). For the traditional approach, undercoverage/overcoverage depends arbitrarily on the aggregation grid resolution, while the new approach exhibits low sensitivity. The differences between the two aggregation approaches increase as the population of an area decreases. The differences are substantial at the second administrative level and finer, but also at the first administrative level for some population quantities. We find differences between the proposed and traditional approach are consistent with those we observe in an application to NMR data from the KDHS2014.|
|**2022-06-27**|**ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration**|Neel Dey et.al.|[2206.13434v1](http://arxiv.org/abs/2206.13434v1)|null|Establishing voxelwise semantic correspondence across distinct imaging modalities is a foundational yet formidable computer vision task. Current multi-modality registration techniques maximize hand-crafted inter-domain similarity functions, are limited in modeling nonlinear intensity-relationships and deformations, and may require significant re-engineering or underperform on new tasks, datasets, and domain pairs. This work presents ContraReg, an unsupervised contrastive representation learning approach to multi-modality deformable registration. By projecting learned multi-scale local patch features onto a jointly learned inter-domain embedding space, ContraReg obtains representations useful for non-rigid multi-modality alignment. Experimentally, ContraReg achieves accurate and robust results with smooth and invertible deformations across a series of baselines and ablations on a neonatal T1-T2 brain MRI registration task with all methods validated over a wide range of deformation regularization strengths.|
|**2022-06-20**|**PhaTYP: Predicting the lifestyle for bacteriophages using BERT**|Jiayu Shang et.al.|[2206.09693v1](http://arxiv.org/abs/2206.09693v1)|[link](https://github.com/kennthshang/phatyp)|Bacteriophages (or phages), which infect bacteria, have two distinct lifestyles: virulent and temperate. Predicting the lifestyle of phages helps decipher their interactions with their bacterial hosts, aiding phages' applications in fields such as phage therapy. Because experimental methods for annotating the lifestyle of phages cannot keep pace with the fast accumulation of sequenced phages, computational method for predicting phages' lifestyles has become an attractive alternative. Despite some promising results, computational lifestyle prediction remains difficult because of the limited known annotations and the sheer amount of sequenced phage contigs assembled from metagenomic data. In particular, most of the existing tools cannot precisely predict phages' lifestyles for short contigs. In this work, we develop PhaTYP (Phage TYPe prediction tool) to improve the accuracy of lifestyle prediction on short contigs. We design two different training tasks, self-supervised and fine-tuning tasks, to overcome lifestyle prediction difficulties. We rigorously tested and compared PhaTYP with four state-of-the-art methods: DeePhage, PHACTS, PhagePred, and BACPHLIP. The experimental results show that PhaTYP outperforms all these methods and achieves more stable performance on short contigs. In addition, we demonstrated the utility of PhaTYP for analyzing the phage lifestyle on human neonates' gut data. This application shows that PhaTYP is a useful means for studying phages in metagenomic data and helps extend our understanding of microbial communities.|
|**2022-06-15**|**A Deep Generative Model of Neonatal Cortical Surface Development**|Abdulah Fawaz et.al.|[2206.07542v2](http://arxiv.org/abs/2206.07542v2)|null|The neonatal cortical surface is known to be affected by preterm birth, and the subsequent changes to cortical organisation have been associated with poorer neurodevelopmental outcomes. Deep Generative models have the potential to lead to clinically interpretable models of disease, but developing these on the cortical surface is challenging since established techniques for learning convolutional filters are inappropriate on non-flat topologies. To close this gap, we implement a surface-based CycleGAN using mixture model CNNs (MoNet) to translate sphericalised neonatal cortical surface features (curvature and T1w/T2w cortical myelin) between different stages of cortical maturity. Results show our method is able to reliably predict changes in individual patterns of cortical organisation at later stages of gestation, validated by comparison to longitudinal data; and translate appearance between preterm and term gestation (> 37 weeks gestation), validated through comparison with a trained term/preterm classifier. Simulated differences in cortical maturation are consistent with observations in the literature.|
|**2022-06-09**|**Neonatal EEG graded for severity of background abnormalities in hypoxic-ischaemic encephalopathy**|John M O'Toole et.al.|[2206.04420v2](http://arxiv.org/abs/2206.04420v2)|[link](https://github.com/otoolej/downsample_open_eeg)|This report describes a set of neonatal electroencephalogram (EEG) recordings graded according to the severity of abnormalities in the background pattern. The dataset consists of 169 hours of multichannel EEG from 53 neonates recorded in a neonatal intensive care unit. All neonates received a diagnosis of hypoxic-ischaemic encephalopathy (HIE), the most common cause of brain injury in full term infants. For each neonate, multiple 1-hour epochs of good quality EEG were selected and then graded for background abnormalities. The grading system assesses EEG attributes such as amplitude and frequency, continuity, sleep--wake cycling, symmetry and synchrony, and abnormal waveforms. Background severity was then categorised into 4 grades: normal or mildly abnormal EEG, moderately abnormal EEG, severely abnormal EEG, and inactive EEG. The data can be used as a reference set of multi-channel EEG for neonates with HIE, for EEG training purposes, or for developing and evaluating automated grading algorithms.|
|**2022-05-16**|**An automatic pipeline for atlas-based fetal and neonatal brain segmentation and analysis**|Urru et.al.|[2205.07575v1](http://arxiv.org/abs/2205.07575v1)|[link](https://github.com/urrand/perinatal-pipeline)|The automatic segmentation of perinatal brain structures in magnetic resonance imaging (MRI) is of utmost importance for the study of brain growth and related complications. While different methods exist for adult and pediatric MRI data, there is a lack for automatic tools for the analysis of perinatal imaging. In this work, a new pipeline for fetal and neonatal segmentation has been developed. We also report the creation of two new fetal atlases, and their use within the pipeline for atlas-based segmentation, based on novel registration methods. The pipeline is also able to extract cortical and pial surfaces and compute features, such as curvature, thickness, sulcal depth, and local gyrification index. Results show that the introduction of the new templates together with our segmentation strategy leads to accurate results when compared to expert annotations, as well as better performances when compared to a reference pipeline (developing Human Connectome Project (dHCP)), for both early and late-onset fetal brains.|
|**2022-04-11**|**Ensemble learning using individual neonatal data for seizure detection**|Ana Borovac et.al.|[2204.07043v2](http://arxiv.org/abs/2204.07043v2)|[link](https://github.com/anaborovac/distributed-nsda)|Sharing medical data between institutions is difficult in practice due to data protection laws and official procedures within institutions. Therefore, most existing algorithms are trained on relatively small electroencephalogram (EEG) data sets which is likely to be detrimental to prediction accuracy. In this work, we simulate a case when the data can not be shared by splitting the publicly available data set into disjoint sets representing data in individual institutions. We propose to train a (local) detector in each institution and aggregate their individual predictions into one final prediction. Four aggregation schemes are compared, namely, the majority vote, the mean, the weighted mean and the Dawid-Skene method. The method was validated on an independent data set using only a subset of EEG channels. The ensemble reaches accuracy comparable to a single detector trained on all the data when sufficient amount of data is available in each institution. The weighted mean aggregation scheme showed best performance, it was only marginally outperformed by the Dawid--Skene method when local detectors approach performance of a single detector trained on all available data.|
|**2022-04-08**|**NeoRS: a neonatal resting state fMRI data preprocessing pipeline**|V. Enguix et.al.|[2204.05137v1](http://arxiv.org/abs/2204.05137v1)|[link](https://github.com/venguix/neors)|Resting state fMRI (rsfMRI) has been shown to be a promising tool to study intrinsic functional connectivity and assess its integrity in cerebral development. In neonates, where fMRI is limited to few paradigms, rsfMRI was shown to be a relevant tool to explore regional interactions of brain networks. However, to identify the resting state networks, data needs to be carefully processed. Because of the non-collaborative nature of the neonates, the differences in brain size and the reversed contrast compared to adults, neonates can't be processed with the existing adult pipelines. Therefore, we developed NeoRS. The main processing steps include atlas registration, skull tripping, segmentation, slice timing and head motion correction and confounds regression. To address the specificity of neonatal brain imaging, particular attention was given to registration including neonatal atlas type and parameters, such as brain size variations, and contrast differences compared to adults. Furthermore, head motion was scrutinized and optimized, as it is a major issue when processing neonatal data. The pipeline includes visual quality control assessment checkpoints. To assess its effectiveness, we used the data from the Baby Connectome Project including 10 neonates. NeoRS was designed to work on both multi-band and single-band acquisitions and is applicable on smaller datasets. It also includes popular functional connectivity analysis features such as seed based correlations. Language, default mode, dorsal attention, visual, ventral attention, motor and fronto parietal networks were evaluated. The different analyzed networks were in agreement with previously published studies in the neonate. NeoRS is coded in Matlab, it is open-source and available on https://github.com/venguix/NeoRS. NeoRS allows robust image processing of the neonatal rsfMRI data that can be readily customized to different datasets.|

## infant

### infant
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-20**|**Deep Learning Methods for Retinal Blood Vessel Segmentation: Evaluation on Images with Retinopathy of Prematurity**|Gorana GojiÄ‡ et.al.|[2306.11576v1](http://arxiv.org/abs/2306.11576v1)|null|Automatic blood vessel segmentation from retinal images plays an important role in the diagnosis of many systemic and eye diseases, including retinopathy of prematurity. Current state-of-the-art research in blood vessel segmentation from retinal images is based on convolutional neural networks. The solutions proposed so far are trained and tested on images from a few available retinal blood vessel segmentation datasets, which might limit their performance when given an image with retinopathy of prematurity signs. In this paper, we evaluate the performance of three high-performing convolutional neural networks for retinal blood vessel segmentation in the context of blood vessel segmentation on retinopathy of prematurity retinal images. The main motive behind the study is to test if existing public datasets suffice to develop a high-performing predictor that could assist an ophthalmologist in retinopathy of prematurity diagnosis. To do so, we create a dataset consisting solely of retinopathy of prematurity images with retinal blood vessel annotations manually labeled by two observers, where one is the ophthalmologist experienced in retinopathy of prematurity treatment. Experimental results show that all three solutions have difficulties in detecting the retinal blood vessels of infants due to a lower contrast compared to images from public datasets as demonstrated by a significant drop in classification sensitivity. All three solutions segment alongside retinal also choroidal blood vessels which are not used to diagnose retinopathy of prematurity, but instead represent noise and are confused with retinal blood vessels. By visual and numerical observations, we observe that existing solutions for retinal blood vessel segmentation need improvement toward more detailed datasets or deeper models in order to assist the ophthalmologist in retinopathy of prematurity diagnosis.|
|**2023-06-14**|**The generalized hyperbolic family and automatic model selection through the multiple-choice LASSO**|Luca Bagnato et.al.|[2306.08692v1](http://arxiv.org/abs/2306.08692v1)|null|We revisit the generalized hyperbolic (GH) distribution and its nested models. These include widely used parametric choices like the multivariate normal, skew-t, Laplace, and several others. We also introduce the multiple-choice LASSO, a novel penalized method for choosing among alternative constraints on the same parameter. A hierarchical multiple-choice LASSO penalized likelihood is optimized to perform simultaneous model selection and inference within the GH family. We illustrate our approach through a simulation study and a real data example about pre-term infants. The methodology proposed in this paper has been implemented in R functions which are available as supplementary material.|
|**2023-06-13**|**Overfitting Affects the Reliability of Radial Velocity Mass Estimates of the V1298 Tau Planets**|Sarah Blunt et.al.|[2306.08145v1](http://arxiv.org/abs/2306.08145v1)|[link](https://github.com/sblunt/v1298tauri)|Mass, radius, and age measurements of young (<100 Myr) planets have the power to shape our understanding of planet formation. However, young stars tend to be extremely variable in both photometry and radial velocity, which makes constraining these properties challenging. The V1298 Tau system of four ~0.5 Rjup planets transiting a pre-main sequence star presents an important, if stress-inducing, opportunity to directly observe and measure the properties of infant planets. Su\'arez-Mascare\~no et al. (2021) published radial-velocity-derived masses for two of the V1298 Tau planets using a state-of-the-art Gaussian Process regression framework. The planetary densities computed from these masses were surprisingly high, implying extremely rapid contraction after formation in tension with most existing planet formation theories. In an effort to further constrain the masses of the V1298 Tau planets, we obtained 36 RVs using Keck/HIRES, and analyzed them in concert with published RVs and photometry. Through performing a suite of cross validation tests, we found evidence that the preferred model of SM21 suffers from overfitting, defined as the inability to predict unseen data, rendering the masses unreliable. We detail several potential causes of this overfitting, many of which may be important for other RV analyses of other active stars, and recommend that additional time and resources be allocated to understanding and mitigating activity in active young stars such as V1298 Tau.|
|**2023-06-09**|**Two Independent Teachers are Better Role Model**|Afifa Khaled et.al.|[2306.05745v1](http://arxiv.org/abs/2306.05745v1)|[link](https://github.com/AfifaKhaled/Two-Independent-Teachers-are-Better-Role-Model)|Recent deep learning models have attracted substantial attention in infant brain analysis. These models have performed state-of-the-art performance, such as semi-supervised techniques (e.g., Temporal Ensembling, mean teacher). However, these models depend on an encoder-decoder structure with stacked local operators to gather long-range information, and the local operators limit the efficiency and effectiveness. Besides, the $MRI$ data contain different tissue properties ($TPs$) such as $T1$ and $T2$. One major limitation of these models is that they use both data as inputs to the segment process, i.e., the models are trained on the dataset once, and it requires much computational and memory requirements during inference. In this work, we address the above limitations by designing a new deep-learning model, called 3D-DenseUNet, which works as adaptable global aggregation blocks in down-sampling to solve the issue of spatial information loss. The self-attention module connects the down-sampling blocks to up-sampling blocks, and integrates the feature maps in three dimensions of spatial and channel, effectively improving the representation potential and discriminating ability of the model. Additionally, we propose a new method called Two Independent Teachers ($2IT$), that summarizes the model weights instead of label predictions. Each teacher model is trained on different types of brain data, $T1$ and $T2$, respectively. Then, a fuse model is added to improve test accuracy and enable training with fewer parameters and labels compared to the Temporal Ensembling method without modifying the network architecture. Empirical results demonstrate the effectiveness of the proposed method.|
|**2023-06-08**|**Design of Sturm global attractors 2: Time-reversible Chafee-Infante lattices of 3-nose meanders**|Bernold Fiedler et.al.|[2306.05232v1](http://arxiv.org/abs/2306.05232v1)|null|This sequel continues our exploration arxiv:2302.12531 of a deceptively ``simple'' class of global attractors, called Sturm due to nodal properties. They arise for the semilinear scalar parabolic PDE   \begin{equation}\label{eq:*}   u_t = u_{xx} + f(x,u,u_x) \tag{$*$}   \end{equation} on the unit interval $0 < x<1$, under Neumann boundary conditions. This models the interplay of reaction, advection, and diffusion.   Our classification is based on the Sturm meanders, which arise from a shooting approach to the ODE boundary value problem of equilibrium solutions $u=v(x)$. Specifically, we address meanders with only three ``noses'', each of which is innermost to a nested family of upper or lower meander arcs. The Chafee-Infante paradigm of 1974, with cubic nonlinearity $f=f(u)$, features just two noses.   We present, and fully prove, a precise description of global PDE connection graphs, graded by Morse index, for such gradient-like Morse-Smale systems \eqref{eq:*}. The directed edges denote PDE heteroclinic orbits $v_1 \leadsto v_2$ between equilibrium vertices $v_1, v_2$ of adjacent Morse index. The connection graphs can be described as a lattice-like structure of Chafee-Infante subgraphs. However, this simple description requires us to adjoin a single ``equilibrium'' vertex, formally, at Morse level -1. Surprisingly, for parabolic PDEs based on irreversible diffusion, the connection graphs then also exhibit global time reversibility.|
|**2023-06-02**|**BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models**|Marvin Lavechin et.al.|[2306.01506v2](http://arxiv.org/abs/2306.01506v2)|[link](https://github.com/marvinlvn/babyslm)|Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.|
|**2023-06-01**|**Generalizability analyses with a partially nested trial design: the Necrotizing Enterocolitis Surgery Trial**|Sarah E. Robertson et.al.|[2306.00855v1](http://arxiv.org/abs/2306.00855v1)|null|We discuss generalizability analyses under a partially nested trial design, where part of the trial is nested within a cohort of trial-eligible individuals, while the rest of the trial is not nested. This design arises, for example, when only some centers participating in a trial are able to collect data on non-randomized individuals, or when data on non-randomized individuals cannot be collected for the full duration of the trial. Our work is motivated by the Necrotizing Enterocolitis Surgery Trial (NEST) that compared initial laparotomy versus peritoneal drain for infants with necrotizing enterocolitis or spontaneous intestinal perforation. During the first phase of the study, data were collected from randomized individuals as well as consenting non-randomized individuals; during the second phase of the study, however, data were only collected from randomized individuals, resulting in a partially nested trial design. We propose methods for generalizability analyses with partially nested trial designs. We describe identification conditions and propose estimators for causal estimands in the target population of all trial-eligible individuals, both randomized and non-randomized, in the part of the data where the trial is nested, while using trial information spanning both parts. We evaluate the estimators in a simulation study.|
|**2023-05-25**|**Emergence of a phonological bias in ChatGPT**|Juan Manuel Toro et.al.|[2305.15929v2](http://arxiv.org/abs/2305.15929v2)|null|Current large language models, such as OpenAI's ChatGPT, have captured the public's attention because how remarkable they are in the use of language. Here, I demonstrate that ChatGPT displays phonological biases that are a hallmark of human language processing. More concretely, just like humans, ChatGPT has a consonant bias. That is, the chatbot has a tendency to use consonants over vowels to identify words. This is observed across languages that differ in their relative distribution of consonants and vowels such as English and Spanish. Despite the differences in how current artificial intelligence language models are trained to process linguistic stimuli and how human infants acquire language, such training seems to be enough for the emergence of a phonological bias in ChatGPT|
|**2023-05-24**|**From Interactive to Co-Constructive Task Learning**|Anna-Lisa Vollmer et.al.|[2305.15535v1](http://arxiv.org/abs/2305.15535v1)|null|Humans have developed the capability to teach relevant aspects of new or adapted tasks to a social peer with very few task demonstrations by making use of scaffolding strategies that leverage prior knowledge and importantly prior joint experience to yield a joint understanding and a joint execution of the required steps to solve the task. This process has been discovered and analyzed in parent-infant interaction and constitutes a ``co-construction'' as it allows both, the teacher and the learner, to jointly contribute to the task. We propose to focus research in robot interactive learning on this co-construction process to enable robots to learn from non-expert users in everyday situations. In the following, we will review current proposals for interactive task learning and discuss their main contributions with respect to the entailing interaction. We then discuss our notion of co-construction and summarize research insights from adult-child and human-robot interactions to elucidate its nature in more detail. From this overview we finally derive research desiderata that entail the dimensions architecture, representation, interaction and explainability.|
|**2023-05-22**|**Developmental Curiosity and Social Interaction in Virtual Agents**|Chris Doyle et.al.|[2305.13396v1](http://arxiv.org/abs/2305.13396v1)|null|Infants explore their complex physical and social environment in an organized way. To gain insight into what intrinsic motivations may help structure this exploration, we create a virtual infant agent and place it in a developmentally-inspired 3D environment with no external rewards. The environment has a virtual caregiver agent with the capability to interact contingently with the infant agent in ways that resemble play. We test intrinsic reward functions that are similar to motivations that have been proposed to drive exploration in humans: surprise, uncertainty, novelty, and learning progress. These generic reward functions lead the infant agent to explore its environment and discover the contingencies that are embedded into the caregiver agent. The reward functions that are proxies for novelty and uncertainty are the most successful in generating diverse experiences and activating the environment contingencies. We also find that learning a world model in the presence of an attentive caregiver helps the infant agent learn how to predict scenarios with challenging social and physical dynamics. Taken together, our findings provide insight into how curiosity-like intrinsic rewards and contingent social interaction lead to dynamic social behavior and the creation of a robust predictive world model.|
|**2023-05-21**|**Towards Robust Family-Infant Audio Analysis Based on Unsupervised Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio**|Jialu Li et.al.|[2305.12530v2](http://arxiv.org/abs/2305.12530v2)|null|To perform automatic family audio analysis, past studies have collected recordings using phone, video, or audio-only recording devices like LENA, investigated supervised learning methods, and used or fine-tuned general-purpose embeddings learned from large pretrained models. In this study, we advance the audio component of a new infant wearable multi-modal device called LittleBeats (LB) by learning family audio representation via wav2vec 2.0 (W2V2) pertaining. We show given a limited number of labeled LB home recordings, W2V2 pretrained using 1k-hour of unlabeled home recordings outperforms oracle W2V2 pretrained on 52k-hour unlabeled audio in terms of parent/infant speaker diarization (SD) and vocalization classifications (VC) at home. Extra relevant external unlabeled and labeled data further benefit W2V2 pretraining and fine-tuning. With SpecAug and environmental speech corruptions, we obtain 12% relative gain on SD and moderate boost on VC. Code and model weights are available.|
|**2023-05-18**|**Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses**|Eliza Kosoy et.al.|[2305.11243v1](http://arxiv.org/abs/2305.11243v1)|null|Developmental psychologists have spent decades devising experiments to test the intelligence and knowledge of infants and children, tracing the origin of crucial concepts and capacities. Moreover, experimental techniques in developmental psychology have been carefully designed to discriminate the cognitive capacities that underlie particular behaviors. We propose that using classical experiments from child development is a particularly effective way to probe the computational abilities of AI models, in general, and LLMs in particular. First, the methodological techniques of developmental psychology, such as the use of novel stimuli to control for past experience or control conditions to determine whether children are using simple associations, can be equally helpful for assessing the capacities of LLMs. In parallel, testing LLMs in this way can tell us whether the information that is encoded in text is sufficient to enable particular responses, or whether those responses depend on other kinds of information, such as information from exploration of the physical world. In this work we adapt classical developmental experiments to evaluate the capabilities of LaMDA, a large language model from Google. We propose a novel LLM Response Score (LRS) metric which can be used to evaluate other language models, such as GPT. We find that LaMDA generates appropriate responses that are similar to those of children in experiments involving social understanding, perhaps providing evidence that knowledge of these domains is discovered through language. On the other hand, LaMDA's responses in early object and action understanding, theory of mind, and especially causal reasoning tasks are very different from those of young children, perhaps showing that these domains require more real-world, self-initiated exploration and cannot simply be learned from patterns in language input.|
|**2023-05-18**|**Client Selection for Federated Policy Optimization with Environment Heterogeneity**|Zhijie Xie et.al.|[2305.10978v3](http://arxiv.org/abs/2305.10978v3)|null|The development of Policy Iteration (PI) has inspired many recent algorithms for Reinforcement Learning (RL), including several policy gradient methods, that gained both theoretical soundness and empirical success on a variety of tasks. The theory of PI is rich in the context of centralized learning, but its study is still in the infant stage under the federated setting. This paper explores the federated version of Approximate PI (API) and derives its error bound, taking into account the approximation error introduced by environment heterogeneity. We theoretically prove that a proper client selection scheme can reduce this error bound. Based on the theoretical result, we propose a client selection algorithm to alleviate the additional approximation error caused by environment heterogeneity. Experiment results show that the proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem by effectively selecting clients with a lower level of heterogeneity from the population distribution.|
|**2023-05-17**|**Analyzing the Stance of Facebook Posts on Abortion Considering State-level Health and Social Compositions**|Ana Aleksandric et.al.|[2305.09889v1](http://arxiv.org/abs/2305.09889v1)|null|Abortion remains one of the most controversial topics, especially after overturning Roe v. Wade ruling in the United States. Previous literature showed that the illegality of abortion could have serious consequences, as women might seek unsafe pregnancy terminations leading to increased maternal mortality rates and negative effects on their reproductive health. Therefore, the stances of the abortion-related Facebook posts were analyzed at the state level in the United States from May 4 until June 30, 2022, right after the Supreme Court's decision was disclosed. In more detail, the pre-trained Transformer architecture-based model was fine-tuned on a manually labeled training set to obtain a stance detection model suitable for the collected dataset. Afterward, we employed appropriate statistical tests to examine the relationships between public opinion regarding abortion, abortion legality, political leaning, and factors measuring the overall population's health, health knowledge, and vulnerability per state. We found that states with a higher number of views against abortion also have higher infant and maternal mortality rates. Furthermore, the stance of social media posts per state is mostly matching with the current abortion laws in these states. While aligned with existing literature, these findings indicate how public opinion, laws, and women's and infants' health are related, and interventions are required to educate and protect women, especially in vulnerable populations.|
|**2023-05-16**|**Evaluation of self-supervised pre-training for automatic infant movement classification using wearable movement sensors**|Einari Vaaras et.al.|[2305.09366v1](http://arxiv.org/abs/2305.09366v1)|[link](https://github.com/SPEECHCOG/data2vec_maiju)|The recently-developed infant wearable MAIJU provides a means to automatically evaluate infants' motor performance in an objective and scalable manner in out-of-hospital settings. This information could be used for developmental research and to support clinical decision-making, such as detection of developmental problems and guiding of their therapeutic interventions. MAIJU-based analyses rely fully on the classification of infant's posture and movement; it is hence essential to study ways to increase the accuracy of such classifications, aiming to increase the reliability and robustness of the automated analysis. Here, we investigated how self-supervised pre-training improves performance of the classifiers used for analyzing MAIJU recordings, and we studied whether performance of the classifier models is affected by context-selective quality-screening of pre-training data to exclude periods of little infant movement or with missing sensors. Our experiments show that i) pre-training the classifier with unlabeled data leads to a robust accuracy increase of subsequent classification models, and ii) selecting context-relevant pre-training data leads to substantial further improvements in the classifier performance.|
|**2023-05-16**|**Health Impacts of Public Pawnshops in Industrializing Tokyo**|Tatsuki Inoue et.al.|[2305.09352v1](http://arxiv.org/abs/2305.09352v1)|null|This study is the first to investigate whether financial institutions for low-income populations have contributed to the historical decline in mortality rates. Using ward-level panel data from prewar Tokyo City, we found that public pawn loans were associated with reductions in infant and fetal death rates, potentially through improved nutrition and hygiene measures. Simple calculations suggest that popularizing public pawnshops led to a 6% and 8% decrease in infant mortality and fetal death rates, respectively, from 1927 to 1935. Contrarily, private pawnshops showed no significant association with health improvements. Our findings enrich the expanding literature on demographics and financial histories.|
|**2023-05-09**|**Child Palm-ID: Contactless Palmprint Recognition for Children**|Akash Godbole et.al.|[2305.05161v1](http://arxiv.org/abs/2305.05161v1)|null|Effective distribution of nutritional and healthcare aid for children, particularly infants and toddlers, in some of the least developed and most impoverished countries of the world, is a major problem due to the lack of reliable identification documents. Biometric authentication technology has been investigated to address child recognition in the absence of reliable ID documents. We present a mobile-based contactless palmprint recognition system, called Child Palm-ID, which meets the requirements of usability, hygiene, cost, and accuracy for child recognition. Using a contactless child palmprint database, Child-PalmDB1, consisting of 19,158 images from 1,020 unique palms (in the age range of 6 mos. to 48 mos.), we report a TAR=94.11% @ FAR=0.1%. The proposed Child Palm-ID system is also able to recognize adults, achieving a TAR=99.4% on the CASIA contactless palmprint database and a TAR=100% on the COEP contactless adult palmprint database, both @ FAR=0.1%. These accuracies are competitive with the SOTA provided by COTS systems. Despite these high accuracies, we show that the TAR for time-separated child-palmprints is only 78.1% @ FAR=0.1%.|
|**2023-05-03**|**Analysing the Impact of Audio Quality on the Use of Naturalistic Long-Form Recordings for Infant-Directed Speech Research**|MarÃ­a Andrea Cruz BlandÃ³n et.al.|[2305.01965v1](http://arxiv.org/abs/2305.01965v1)|[link](https://github.com/SPEECHCOG/ids_audio_quality_analysis)|Modelling of early language acquisition aims to understand how infants bootstrap their language skills. The modelling encompasses properties of the input data used for training the models, the cognitive hypotheses and their algorithmic implementations being tested, and the evaluation methodologies to compare models to human data. Recent developments have enabled the use of more naturalistic training data for computational models. This also motivates development of more naturalistic tests of model behaviour. A crucial step towards such an aim is to develop representative speech datasets consisting of speech heard by infants in their natural environments. However, a major drawback of such recordings is that they are typically noisy, and it is currently unclear how the sound quality could affect analyses and modelling experiments conducted on such data. In this paper, we explore this aspect for the case of infant-directed speech (IDS) and adult-directed speech (ADS) analysis. First, we manually and automatically annotated audio quality of utterances extracted from two corpora of child-centred long-form recordings (in English and French). We then compared acoustic features of IDS and ADS in an in-lab dataset and across different audio quality subsets of naturalistic data. Finally, we assessed how the audio quality and recording environment may change the conclusions of a modelling analysis using a recent self-supervised learning model. Our results show that the use of modest and high audio quality naturalistic speech data result in largely similar conclusions on IDS and ADS in terms of acoustic analyses and modelling experiments. We also found that an automatic sound quality assessment tool can be used to screen out useful parts of long-form recordings for a closer analysis with comparable results to that of manual quality annotation.|
|**2023-05-02**|**DeCom: Deep Coupled-Factorization Machine for Post COVID-19 Respiratory Syncytial Virus Prediction with Nonpharmaceutical Interventions Awareness**|Xinyan Li et.al.|[2305.01770v1](http://arxiv.org/abs/2305.01770v1)|null|Respiratory syncytial virus (RSV) is one of the most dangerous respiratory diseases for infants and young children. Due to the nonpharmaceutical intervention (NPI) imposed in the COVID-19 outbreak, the seasonal transmission pattern of RSV has been discontinued in 2020 and then shifted months ahead in 2021 in the northern hemisphere. It is critical to understand how COVID-19 impacts RSV and build predictive algorithms to forecast the timing and intensity of RSV reemergence in post-COVID-19 seasons. In this paper, we propose a deep coupled tensor factorization machine, dubbed as DeCom, for post COVID-19 RSV prediction. DeCom leverages tensor factorization and residual modeling. It enables us to learn the disrupted RSV transmission reliably under COVID-19 by taking both the regular seasonal RSV transmission pattern and the NPI into consideration. Experimental results on a real RSV dataset show that DeCom is more accurate than the state-of-the-art RSV prediction algorithms and achieves up to 46% lower root mean square error and 49% lower mean absolute error for country-level prediction compared to the baselines.|
|**2023-05-02**|**Self-supervised learning for infant cry analysis**|Arsenii Gorin et.al.|[2305.01578v1](http://arxiv.org/abs/2305.01578v1)|null|In this paper, we explore self-supervised learning (SSL) for analyzing a first-of-its-kind database of cry recordings containing clinical indications of more than a thousand newborns. Specifically, we target cry-based detection of neurological injury as well as identification of cry triggers such as pain, hunger, and discomfort. Annotating a large database in the medical setting is expensive and time-consuming, typically requiring the collaboration of several experts over years. Leveraging large amounts of unlabeled audio data to learn useful representations can lower the cost of building robust models and, ultimately, clinical solutions. In this work, we experiment with self-supervised pre-training of a convolutional neural network on large audio datasets. We show that pre-training with SSL contrastive loss (SimCLR) performs significantly better than supervised pre-training for both neuro injury and cry triggers. In addition, we demonstrate further performance gains through SSL-based domain adaptation using unlabeled infant cries. We also show that using such SSL-based pre-training for adaptation to cry sounds decreases the need for labeled data of the overall system.|
|**2023-05-01**|**CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds**|David Budaghyan et.al.|[2305.00969v3](http://arxiv.org/abs/2305.00969v3)|[link](https://github.com/ubenwa/cryceleb2023)|This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.|
|**2023-04-27**|**Cluster Flow: how a hierarchical clustering layer make allows deep-NNs more resilient to hacking, more human-like and easily implements relational reasoning**|Ella Gale et.al.|[2304.14081v1](http://arxiv.org/abs/2304.14081v1)|null|Despite the huge recent breakthroughs in neural networks (NNs) for artificial intelligence (specifically deep convolutional networks) such NNs do not achieve human-level performance: they can be hacked by images that would fool no human and lack `common sense'. It has been argued that a basis of human-level intelligence is mankind's ability to perform relational reasoning: the comparison of different objects, measuring similarity, grasping of relations between objects and the converse, figuring out the odd one out in a set of objects. Mankind can even do this with objects they have never seen before. Here we show how ClusterFlow, a semi-supervised hierarchical clustering framework can operate on trained NNs utilising the rich multi-dimensional class and feature data found at the pre-SoftMax layer to build a hyperspacial map of classes/features and this adds more human-like functionality to modern deep convolutional neural networks. We demonstrate this with 3 tasks. 1. the statistical learning based `mistakes' made by infants when attending to images of cats and dogs. 2. improving both the resilience to hacking images and the accurate measure of certainty in deep-NNs. 3. Relational reasoning over sets of images, including those not known to the NN nor seen before. We also demonstrate that ClusterFlow can work on non-NN data and deal with missing data by testing it on a Chemistry dataset. This work suggests that modern deep NNs can be made more human-like without re-training of the NNs. As it is known that some methods used in deep and convolutional NNs are not biologically plausible or perhaps even the best approach: the ClusterFlow framework can sit on top of any NN and will be a useful tool to add as NNs are improved in this regard.|
|**2023-04-19**|**Detection of a Super-Virial Hot Component in the Milky Way Circumgalactic Medium Along Multiple Sight-Lines by Using the Stacking Technique**|Armando Lara-DI et.al.|[2304.09641v1](http://arxiv.org/abs/2304.09641v1)|null|The study of the elusive hot component ($T \gtrsim 10^7$ K) of the Milky Way circumgalactic medium (CGM) is a novel topic to understand Galactic formation and evolution. In this work, we use the stacking technique through 46 lines of sight with Chandra ACIS-S HETG totaling over 10Ms of exposure time and 9 lines of sight with ACIS-S LETG observations totaling over 1Ms of exposure time, to study in absorption the presence of highly ionized metals arising from the super-virial temperature phase of the CGM. Focusing in the spectral range $4 - 8$ $\r{A}$, we were able to confirm the presence of this hot phase with high significance. We detected transitions of Si XIV K$\alpha$ (with total significance of 6.0$\sigma$) and, for the first time, SXVI K (total significance 4.8$\sigma$) in the rest frame of our own Galaxy. For S XVI K$\alpha$ we found a column density of $1.50^{+0.44}_{-0.38} \times 10^{16} \mathrm{cm}^{-2}$. For Si XIV K$\alpha$ we measured a column density of $0.87\pm{0.16} \times 10^{16} \mathrm{cm}^{-2}$. The lines of sight used in this work are spread across the sky, probing widely separated regions of the CGM. Therefore, our results indicate that this newly discovered hot medium extends throughout the halo, and is not related only to the Galactic Bubbles. The hot gas location, distribution, and covering factor, however, remain unknown. This component might contribute significantly to the missing baryons and metals in the Milky Way.|
|**2023-04-08**|**Predator-prey dynamics pertaining to structuralizing predator species into three stages coupled with maturation delay owing to juvenile hunting**|Debasish Bhattacharjee et.al.|[2304.05159v1](http://arxiv.org/abs/2304.05159v1)|null|The predator-prey dynamic appertaining to two species is explored, wherein the predator species is structured into different stages. As evidenced from natural documentation, the immature predators possess the potential to predate albeit not as competently as the adults. Nevertheless, this potentiality is not acquired immediately after their incipience of life, hence, the immature stage is branched off into the infant stage, the stage with extensive reliance on the adults, and the juvenile stage, the stage with the potential to predate but not to procreate. In this paper, this inaugural concept is coupled with injuries in the juvenile stage as the repercussion of their incompetency in predating, thereby ensuing a delay in their maturation. With the incentive to investigate the ascendancy of these refinements over the whole system, stability analyses along with various bifurcation analyses around the equilibrium points of the system are corroborated. In addition to Hopf, transcritical, and saddle node bifurcations, the existence of Bogdanov-Takens point, cusp point, Bautin bifurcation point, bloom phenomenon, twice occurring Hopf bifurcation, and bi-stability phenomenon make the paper appreciably more rich and efficacious.|
|**2023-04-05**|**IHCV: Discovery of Hidden Time-Dependent Control Variables in Non-Linear Dynamical Systems**|Juan Munoz et.al.|[2304.02443v1](http://arxiv.org/abs/2304.02443v1)|null|Discovering non-linear dynamical models from data is at the core of science. Recent progress hinges upon sparse regression of observables using extensive libraries of candidate functions. However, it remains challenging to model hidden non-observable control variables governing switching between different dynamical regimes. Here we develop a data-efficient derivative-free method, IHCV, for the Identification of Hidden Control Variables. First, the performance and robustness of IHCV against noise are evaluated by benchmarking the IHCV method using well-known bifurcation models (saddle-node, transcritical, pitchfork, Hopf). Next, we demonstrate that IHCV discovers hidden driver variables in the Lorenz, van der Pol, Hodgkin-Huxley, and Fitzhugh-Nagumo models. Finally, IHCV generalizes to the case when only partial observational is given, as demonstrated using the toggle switch model, the genetic repressilator oscillator, and a Waddington landscape model. Our proof-of-principle illustrates that utilizing normal forms could facilitate the data-efficient and scalable discovery of hidden variables controlling transitions between different dynamical regimes and non-linear models.|
|**2023-04-02**|**Origin of high-velocity ejecta and early red excess emission in the infant Type Ia supernova 2021aefx**|Yuan Qi Ni et.al.|[2304.00625v2](http://arxiv.org/abs/2304.00625v2)|null|\object{SN 2021aefx} is a normal Type Ia Supernova (SN) with red excess emission over the first $\sim$ 2 days. We present detailed analysis of this SN using our high-cadence KMTNet multi-band photometry, spectroscopy, and publicly available data. We provide the first measurements of its epochs of explosion (MJD 59529.32 $\pm$ 0.16) as well as ``first light'' (MJD 59529.85 $\pm$ 0.55) associated with the main ejecta ${\rm{^{56}Ni}}$ distribution. This places our first detection of SN 2021aefx at $\sim -$0.5 hours since ``first light'', indicating the presence of additional power sources. Our peak-spectrum confirms its Type Ia sub-classification as intermediate between Core-Normal and Broad-Line, and we estimate the ejecta mass to be $\sim$ 1.34 $M_{\odot}$. The pre-peak spectral evolution identifies fast-expanding material reaching $>$ 40,000 km s$^{-1}$ (the fastest ever observed in Type Ia SNe) and at least two distinct homologously-expanding ejecta components: (1) a normal-velocity (12,400 km s$^{-1}$) component consistent with the typical photospheric evolution of Chandrasekhar-mass ejecta; and (2) a high-velocity (23,500 km s$^{-1}$) component visible during the first $\sim$ 3.6 days post-explosion, which locates the component within the outer $<$ 16\% of the ejecta mass. Asymmetric, subsonic explosion processes producing a non-spherical photosphere provide an explanation for the simultaneous presence of the two components, as well as the red excess emission via a slight ${\rm{^{56}Ni}}$ enrichment in the outer $\sim$ 0.5\% of the ejecta mass. Our spectrum from 300 days post-peak advances the constraint against non-degenerate companions and further supports a near-Chandrasekhar-mass explosion origin. Off-center ignited delayed-detonations of Chandrasekhar-mass white dwarfs may be responsible for the observed features of SN 2021aefx in some normal Type Ia SNe.|
|**2023-04-02**|**The short- and long-term determinants of fertility in Uruguay**|Zuleika Ferre et.al.|[2304.00539v1](http://arxiv.org/abs/2304.00539v1)|null|This paper examines the determinants of fertility among women at different stages of their reproductive lives in Uruguay. To this end, we employ time series analysis methods based on data from 1968 to 2021 and panel data techniques based on department-level statistical information from 1984 to 2019. The results of our first econometric exercise indicate a cointegration relationship between fertility and economic performance, education and infant mortality, with differences observed by reproductive stage. We find a negative relationship between income and fertility for women aged 20-29 that persists for women aged 30 and over. This result suggests that having children is perceived as an opportunity cost for women in this age group. We also observe a negative relationship between education and adolescent fertility, which has implications for the design of public policies. A panel data analysis with econometric techniques allowing us to control for unobserved heterogeneity confirms that income is a relevant factor for all groups of women and reinforces the crucial role of education in reducing teenage fertility. We also identify a negative correlation between fertility and employment rates for women aged 30 and above. We outline some possible explanations for these findings in the context of work-life balance issues and argue for the importance of implementing social policies to address them.|
|**2023-04-01**|**N,N,N-Trimethyl chitosan as a permeation enhancer for inhalation drug delivery: interaction with a model pulmonary surfactant**|Jana SzabovÃ¡ et.al.|[2304.04547v1](http://arxiv.org/abs/2304.04547v1)|null|N,N,N-Trimethyl chitosan (TMC), a biocompatible and biodegradable derivative of chitosan, is currently used as a permeation enhancer to increase the translocation of drugs to the bloodstream in the lungs. This article discusses the effect of TMC on a mimetic pulmonary surfactant, Curosurf, a low-viscosity lipid formulation administered to preterm infants with acute respiratory distress syndrome. Curosurf exhibits a strong interaction with TMC, resulting in the formation of aggregates at electrostatic charge stoichiometry. At nanoscale, Curosurf undergoes a profound reorganization of its lipid vesicles in terms of size and lamellarity. The initial micron-sized vesicles (average size 4.8 microns) give way to a froth-like network of unilamellar vesicles about 300 nm in size. Under such conditions, neutralization of the cationic charges by pulmonary surfactant may inhibit TMC permeation enhancer capacity, especially as electrostatic charge complexation is found at low TMC content. The permeation properties of pulmonary surfactant-neutralized TMC should then be evaluated for its applicability as a permeation enhancer for inhalation in the alveolar region.|
|**2023-03-31**|**Symmetry Groupoids for Pattern-Selective Feedback Stabilization of the Chafee--Infante Equation**|Isabelle Schneider et.al.|[2303.18078v2](http://arxiv.org/abs/2303.18078v2)|null|Reaction-diffusion equations are ubiquitous in various scientific domains and their patterns represent a fascinating area of investigation. However, many of these patterns are unstable and therefore challenging to observe. To overcome this limitation, we present new noninvasive feedback controls based on symmetry groupoids. As a concrete example, we employ these controls to selectively stabilize unstable equilibria of the Chafee--Infante equation under Dirichlet boundary conditions on the interval. Unlike conventional reflection-based control schemes, our approach incorporates additional symmetries that enable us to design new convolution controls for stabilization. By demonstrating the efficacy of our method, we provide a new tool for investigating and controlling systems with unstable patterns, with potential implications for a wide range of scientific disciplines.|
|**2023-03-29**|**A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants**|Shaotong Zhu et.al.|[2303.16867v1](http://arxiv.org/abs/2303.16867v1)|[link](https://github.com/ostadabbas/nns-detection-and-segmentation)|We present an end-to-end computer vision pipeline to detect non-nutritive sucking (NNS) -- an infant sucking pattern with no nutrition delivered -- as a potential biomarker for developmental delays, using off-the-shelf baby monitor video footage. One barrier to clinical (or algorithmic) assessment of NNS stems from its sparsity, requiring experts to wade through hours of footage to find minutes of relevant activity. Our NNS activity segmentation algorithm solves this problem by identifying periods of NNS with high certainty -- up to 94.0\% average precision and 84.9\% average recall across 30 heterogeneous 60 s clips, drawn from our manually annotated NNS clinical in-crib dataset of 183 hours of overnight baby monitor footage from 19 infants. Our method is based on an underlying NNS action recognition algorithm, which uses spatiotemporal deep learning networks and infant-specific pose estimation, achieving 94.9\% accuracy in binary classification of 960 2.5 s balanced NNS vs. non-NNS clips. Tested on our second, independent, and public NNS in-the-wild dataset, NNS recognition classification reaches 92.3\% accuracy, and NNS segmentation achieves 90.8\% precision and 84.2\% recall.|
