# arxiv-daily latest papers around wearable device
Automated deployment @ 2023-06-09 16:43:29 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`]({repo_url}/blob/main/database/topic.yml).
> You can also view historical data through the [storage]({repo_url}/blob/main/database/storage).

## actigraphy

### actigraphy
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-03-14**|**Transfer Learning for Real-time Deployment of a Screening Tool for Depression Detection Using Actigraphy**|Rajanikant Ghate et.al.|[2303.07847v1](http://arxiv.org/abs/2303.07847v1)|null|Automated depression screening and diagnosis is a highly relevant problem today. There are a number of limitations of the traditional depression detection methods, namely, high dependence on clinicians and biased self-reporting. In recent years, research has suggested strong potential in machine learning (ML) based methods that make use of the user's passive data collected via wearable devices. However, ML is data hungry. Especially in the healthcare domain primary data collection is challenging. In this work, we present an approach based on transfer learning, from a model trained on a secondary dataset, for the real time deployment of the depression screening tool based on the actigraphy data of users. This approach enables machine learning modelling even with limited primary data samples. A modified version of leave one out cross validation approach performed on the primary set resulted in mean accuracy of 0.96, where in each iteration one subject's data from the primary set was set aside for testing.|
|**2023-01-04**|**KIDS: kinematics-based (in)activity detection and segmentation in a sleep case study**|Omar Elnaggar et.al.|[2301.03469v1](http://arxiv.org/abs/2301.03469v1)|null|Sleep behaviour and in-bed movements contain rich information on the neurophysiological health of people, and have a direct link to the general well-being and quality of life. Standard clinical practices rely on polysomnography for sleep assessment; however, it is intrusive, performed in unfamiliar environments and requires trained personnel. Progress has been made on less invasive sensor technologies, such as actigraphy, but clinical validation raises concerns over their reliability and precision. Additionally, the field lacks a widely acceptable algorithm, with proposed approaches ranging from raw signal or feature thresholding to data-hungry classification models, many of which are unfamiliar to medical staff. This paper proposes an online Bayesian probabilistic framework for objective (in)activity detection and segmentation based on clinically meaningful joint kinematics, measured by a custom-made wearable sensor. Intuitive three-dimensional visualisations of kinematic timeseries were accomplished through dimension reduction based preprocessing, offering out-of-the-box framework explainability potentially useful for clinical monitoring and diagnosis. The proposed framework attained up to 99.2\% $F_1$-score and 0.96 Pearson's correlation coefficient in, respectively, the posture change detection and inactivity segmentation tasks. The work paves the way for a reliable home-based analysis of movements during sleep which would serve patient-centred longitudinal care plans.|
|**2022-12-31**|**Definition and clinical validation of Pain Patient States from high-dimensional mobile data: application to a chronic pain cohort**|Jenna M. Reinen et.al.|[2301.00299v1](http://arxiv.org/abs/2301.00299v1)|null|The technical capacity to monitor patients with a mobile device has drastically expanded, but data produced from this approach are often difficult to interpret. We present a solution to produce a meaningful representation of patient status from large, complex data streams, leveraging both a data-driven approach, and use clinical knowledge to validate results. Data were collected from a clinical trial enrolling chronic pain patients, and included questionnaires, voice recordings, actigraphy, and standard health assessments. The data were reduced using a clustering analysis. In an initial exploratory analysis with only questionnaire data, we found up to 3 stable cluster solutions that grouped symptoms on a positive to negative spectrum. Objective features (actigraphy, speech) expanded the cluster solution granularity. Using a 5 state solution with questionnaire and actigraphy data, we found significant correlations between cluster properties and assessments of disability and quality-of-life. The correlation coefficient values showed an ordinal distinction, confirming the cluster ranking on a negative to positive spectrum. This suggests we captured novel, distinct Pain Patient States with this approach, even when multiple clusters were equated on pain magnitude. Relative to using complex time courses of many variables, Pain Patient States holds promise as an interpretable, useful, and actionable metric for a clinician or caregiver to simplify and provide timely delivery of care.|
|**2022-12-21**|**A hidden Markov modeling approach combining objective measure of activity and subjective measure of self-reported sleep to estimate the sleep-wake cycle**|Semhar B. Ogbagaber et.al.|[2212.11224v1](http://arxiv.org/abs/2212.11224v1)|null|Characterizing the sleep-wake cycle in adolescents is an important prerequisite to better understand the association of abnormal sleep patterns with subsequent clinical and behavioral outcomes. The aim of this research was to develop hidden Markov models (HMM) that incorporate both objective (actigraphy) and subjective (sleep log) measures to estimate the sleep-wake cycle using data from the NEXT longitudinal study, a large population-based cohort study. The model was estimated with a negative binomial distribution for the activity counts (1-minute epochs) to account for overdispersion relative to a Poisson process. Furthermore, self-reported measures were dichotomized (for each one-minute interval) and subject to misclassification. We assumed that the unobserved sleep-wake cycle follows a two-state Markov chain with transitional probabilities varying according to a circadian rhythm. Maximum-likelihood estimation using a backward-forward algorithm was applied to fit the longitudinal data on a subject by subject basis. The algorithm was used to reconstruct the sleep-wake cycle from sequences of self-reported sleep and activity data. Furthermore, we conduct simulations to examine the properties of this approach under different observational patterns including both complete and partially observed measurements on each individual.|
|**2022-08-30**|**Mediation analysis with densities as mediators with an application to iCOMPARE trial**|Jingru Zhang et.al.|[2208.13939v1](http://arxiv.org/abs/2208.13939v1)|null|Physical activity has long been shown to be associated with biological and physiological performance and risk of diseases. It is of great interest to assess whether the effect of an exposure or intervention on an outcome is mediated through physical activity measured by modern wearable devices such as actigraphy. However, existing methods for mediation analysis focus almost exclusively on mediation variable that is in the Euclidean space, which cannot be applied directly to the actigraphy data of physical activity. Such data is best summarized in the form of an histogram or density. In this paper, we extend the structural equation models (SEMs) to the settings where a density is treated as the mediator to study the indirect mediation effect of physical activity on an outcome. We provide sufficient conditions for identifying the average causal effects of density mediator and present methods for estimating the direct and mediating effects of density on an outcome. We apply our method to the data set from the iCOMPARE trial that compares flexible duty-hour policies and standard duty-hour policies on interns' sleep related outcomes to explore the mediation effect of physical activity on the causal path between flexible duty-hour policies and sleep related outcomes.|
|**2021-11-29**|**Validating CircaCP: a Generic Sleep-Wake Cycle Detection Algorithm**|Shanshan Chen et.al.|[2111.14960v1](http://arxiv.org/abs/2111.14960v1)|[link](https://github.com/shanshanchen-biostat/circacp)|Sleep-wake cycle detection is a key step when extrapolating sleep patterns from actigraphy data. Numerous supervised detection algorithms have been developed with parameters estimated from and optimized for a particular dataset, yet their generalizability from sensor to sensor or study to study is unknown. In this paper, we propose and validate an unsupervised algorithm -- CircaCP -- to detect sleep-wake cycles from minute-by-minute actigraphy data. It first uses a robust cosinor model to estimate circadian rhythm, then searches for a single change point (CP) within each cycle. We used CircaCP to estimate sleep/wake onset times (S/WOTs) from 2125 indviduals' data in the MESA Sleep study and compared the estimated S/WOTs against self-reported S/WOT event markers. Lastly, we quantified the biases between estimated and self-reported S/WOTs, as well as variation in S/WOTs contributed by the two methods, using linear mixed-effects models and variance component analysis.   On average, SOTs estimated by CircaCP were five minutes behind those reported by event markers, and WOTs estimated by CircaCP were less than one minute behind those reported by markers. These differences accounted for less than 0.2% variability in SOTs and in WOTs, taking into account other sources of between-subject variations. By focusing on the commonality in human circadian rhythms captured by actigraphy, our algorithm transferred seamlessly from hip-worn ActiGraph data collected from children in our previous study to wrist-worn Actiwatch data collected from adults. The large between- and within-subject variability highlights the need for estimating individual-level S/WOTs when conducting actigraphy research. The generalizability of our algorithm also suggests that it could be widely applied to actigraphy data collected by other wearable sensors.|
|**2021-07-08**|**Circadian Rhythms are Not Captured Equal: Exploring Circadian Metrics Extracted by Different Computational Methods from Smartphone Accelerometer and GPS Sensors in Daily Life Tracking**|Congyu Wu et.al.|[2107.04135v1](http://arxiv.org/abs/2107.04135v1)|null|Circadian rhythm is the natural biological cycle manifested in human daily routines. A regular and stable rhythm is found to be correlated with good physical and mental health. With the wide adoption of mobile and wearable technology, many types of sensor data, such as GPS and actigraphy, provide evidence for researchers to objectively quantify the circadian rhythm of a user and further use these quantified metrics of circadian rhythm to infer the user's health status. Researchers in computer science and psychology have investigated circadian rhythm using various mobile and wearable sensors in ecologically valid human sensing studies, but questions remain whether and how different data types produce different circadian rhythm results when simultaneously used to monitor a user. We hypothesize that different sensor data reveal different aspects of the user's daily behavior, thus producing different circadian rhythm patterns. In this paper we focus on two data types: GPS and accelerometer data from smartphones. We used smartphone data from 225 college student participants and applied four circadian rhythm characterization methods. We found significant and interesting discrepancies in the rhythmic patterns discovered among sensors, which suggests circadian rhythms discovered from different personal tracking sensors have different levels of sensitivity to device usage and aspects of daily behavior.|
|**2021-07-01**|**Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors**|Ulysse Côté-Allard et.al.|[2107.00710v3](http://arxiv.org/abs/2107.00710v3)|[link](https://github.com/UlysseCoteAllard/LongShortNetworkBipolar)|Manic episodes of bipolar disorder can lead to uncritical behaviour and delusional psychosis, often with destructive consequences for those affected and their surroundings. Early detection and intervention of a manic episode are crucial to prevent escalation, hospital admission and premature death. However, people with bipolar disorder may not recognize that they are experiencing a manic episode and symptoms such as euphoria and increased productivity can also deter affected individuals from seeking help. This work proposes to perform user-independent, automatic mood-state detection based on actigraphy and electrodermal activity acquired from a wrist-worn device during mania and after recovery (euthymia). This paper proposes a new deep learning-based ensemble method leveraging long (20h) and short (5 minutes) time-intervals to discriminate between the mood-states. When tested on 47 bipolar patients, the proposed classification scheme achieves an average accuracy of 91.59% in euthymic/manic mood-state recognition.|
|**2021-05-05**|**Activity-Aware Deep Cognitive Fatigue Assessment using Wearables**|Mohammad Arif Ul Alam et.al.|[2105.02824v1](http://arxiv.org/abs/2105.02824v1)|null|Cognitive fatigue has been a common problem among workers which has become an increasing global problem since the emergence of COVID-19 as a global pandemic. While existing multi-modal wearable sensors-aided automatic cognitive fatigue monitoring tools have focused on physical and physiological sensors (ECG, PPG, Actigraphy) analytic on specific group of people (say gamers, athletes, construction workers), activity-awareness is utmost importance due to its different responses on physiology in different person. In this paper, we propose a novel framework, Activity-Aware Recurrent Neural Network (\emph{AcRoNN}), that can generalize individual activity recognition and improve cognitive fatigue estimation significantly. We evaluate and compare our proposed method with state-of-art methods using one real-time collected dataset from 5 individuals and another publicly available dataset from 27 individuals achieving max. 19% improvement.|
|**2021-04-28**|**Optimizing Rescoring Rules with Interpretable Representations of Long-Term Information**|Aaron Fisher et.al.|[2104.14291v1](http://arxiv.org/abs/2104.14291v1)|null|Analyzing temporal data (e.g., wearable device data) requires a decision about how to combine information from the recent and distant past. In the context of classifying sleep status from actigraphy, Webster's rescoring rules offer one popular solution based on the long-term patterns in the output of a moving-window model. Unfortunately, the question of how to optimize rescoring rules for any given setting has remained unsolved. To address this problem and expand the possible use cases of rescoring rules, we propose rephrasing these rules in terms of epoch-specific features. Our features take two general forms: (1) the time lag between now and the most recent [or closest upcoming] bout of time spent in a given state, and (2) the length of the most recent [or closest upcoming] bout of time spent in a given state. Given any initial moving window model, these features can be defined recursively, allowing for straightforward optimization of rescoring rules. Joint optimization of the moving window model and the subsequent rescoring rules can also be implemented using gradient-based optimization software, such as Tensorflow. Beyond binary classification problems (e.g., sleep-wake), the same approach can be applied to summarize long-term patterns for multi-state classification problems (e.g., sitting, walking, or stair climbing). We find that optimized rescoring rules improve the performance of sleep-wake classifiers, achieving accuracy comparable to that of certain neural network architectures.|
|**2021-01-05**|**Bayesian Hierarchical Modeling and Analysis for Actigraph Data from Wearable Devices**|Pierfrancesco Alaimo Di Loro et.al.|[2101.01624v4](http://arxiv.org/abs/2101.01624v4)|[link](https://github.com/minmar94/EfficientTNNGPforActigraph)|The majority of Americans fail to achieve recommended levels of physical activity, which leads to numerous preventable health problems such as diabetes, hypertension, and heart diseases. This has generated substantial interest in monitoring human activity to gear interventions toward environmental features that may relate to higher physical activity. Wearable devices, such as wrist-worn sensors that monitor gross motor activity (actigraph units) continuously record the activity levels of a subject, producing massive amounts of high-resolution measurements. Analyzing actigraph data needs to account for spatial and temporal information on trajectories or paths traversed by subjects wearing such devices. Inferential objectives include estimating a subject's physical activity levels along a given trajectory; identifying trajectories that are more likely to produce higher levels of physical activity for a given subject; and predicting expected levels of physical activity in any proposed new trajectory for a given set of health attributes. Here, we devise a Bayesian hierarchical modeling framework for spatial-temporal actigraphy data to deliver fully model-based inference on trajectories while accounting for subject-level health attributes and spatial-temporal dependencies. We undertake a comprehensive analysis of an original dataset from the Physical Activity through Sustainable Transport Approaches in Los Angeles (PASTA-LA) study to ascertain spatial zones and trajectories exhibiting significantly higher levels of physical activity while accounting for various sources of heterogeneity.|
|**2020-11-14**|**Using Convolutional Variational Autoencoders to Predict Post-Trauma Health Outcomes from Actigraphy Data**|Ayse S. Cakmak et.al.|[2011.07406v2](http://arxiv.org/abs/2011.07406v2)|null|Depression and post-traumatic stress disorder (PTSD) are psychiatric conditions commonly associated with experiencing a traumatic event. Estimating mental health status through non-invasive techniques such as activity-based algorithms can help to identify successful early interventions. In this work, we used locomotor activity captured from 1113 individuals who wore a research grade smartwatch post-trauma. A convolutional variational autoencoder (VAE) architecture was used for unsupervised feature extraction from four weeks of actigraphy data. By using VAE latent variables and the participant's pre-trauma physical health status as features, a logistic regression classifier achieved an area under the receiver operating characteristic curve (AUC) of 0.64 to estimate mental health outcomes. The results indicate that the VAE model is a promising approach for actigraphy data analysis for mental health outcomes in long-term studies.|
|**2020-08-06**|**Fatigue Assessment using ECG and Actigraphy Sensors**|Yang Bai et.al.|[2008.02871v2](http://arxiv.org/abs/2008.02871v2)|[link](https://github.com/baiyang4/Sjogrens_questionnaire)|Fatigue is one of the key factors in the loss of work efficiency and health-related quality of life, and most fatigue assessment methods were based on self-reporting, which may suffer from many factors such as recall bias. To address this issue, we developed an automated system using wearable sensing and machine learning techniques for objective fatigue assessment. ECG/Actigraphy data were collected from subjects in free-living environments. Preprocessing and feature engineering methods were applied, before interpretable solution and deep learning solution were introduced. Specifically, for interpretable solution, we proposed a feature selection approach which can select less correlated and high informative features for better understanding system's decision-making process. For deep learning solution, we used state-of-the-art self-attention model, based on which we further proposed a consistency self-attention (CSA) mechanism for fatigue assessment. Extensive experiments were conducted, and very promising results were achieved.|
|**2019-06-03**|**Deep learning from wristband sensor data: towards wearable, non-invasive seizure forecasting**|Christian Meisel et.al.|[1906.00511v2](http://arxiv.org/abs/1906.00511v2)|null|Seizure forecasting may provide patients with timely warnings to adapt their daily activities and help clinicians deliver more objective, personalized treatments. While recent work has convincingly demonstrated that seizure risk assessment is possible, these early approaches relied largely on complex, often invasive setups including intracranial electrocorticography, implanted devices and multi-channel EEG, which limits translation of these methods to broad clinical application. To facilitate broader adaptation of seizure forecasting in clinical practice, non-invasive, easily applicable techniques that reliably assess seizure risk, in combination with clinical information, are crucial. Wristbands that continuously record physiological parameters, including electrodermal activity, body temperature, blood volume pressure and actigraphy, may afford monitoring of autonomous nervous system function and movement relevant for such a task, hence minimizing potential complications associated with invasive monitoring, and avoiding stigma associated with bulky external monitoring devices on the head. Here, we use deep learning to analyze long-term, multi-modal wristband sensor data from 50 patients with epilepsy (total duration $>$1400 hours) to assess its capability to distinguish preictal from interictal states. Prediction performance is assessed using area under the receiver operating charateristic (AUC) and improvement over chance (IoC) based on F1 scores. Using one- and two-dimensional convolutional neural networks, we identified better-than-chance predictability in out-of-sample test data in 60\% of the patients in leave-one-out and 43\% of patients in pseudo-prospective approaches. These results provide a step towards developing easier to apply, non-invasive methods for seizure risk assessments in patients with epilepsy.|
|**2019-03-28**|**A Generic Algorithm for Sleep-Wake Cycle Detection using Unlabeled Actigraphy Data**|Shanshan Chen et.al.|[1904.05313v1](http://arxiv.org/abs/1904.05313v1)|null|One key component when analyzing actigraphy data for sleep studies is sleep-wake cycle detection. Most detection algorithms rely on accurate sleep diary labels to generate supervised classifiers, with parameters optimized for a particular dataset. However, once the actigraphy trackers are deployed in the field, labels for training models and validating detection accuracy are often not available.   In this paper, we propose a generic, training-free algorithm to detect sleep-wake cycles from minute-by-minute actigraphy. Leveraging a robust nonlinear parametric model, our proposed method refines the detection region by searching for a single change point within bounded regions defined by the parametric model. Challenged by the absence of ground truth labels, we also propose an evaluation metric dedicated to this problem. Tested on week-long actigraphy from 112 children, the results show that the proposed algorithm improves on the baseline model consistently and significantly (p<3e-15). Moreover, focusing on the commonality in human circadian rhythm captured by actigraphy, the proposed method is generic to data collected by various actigraphy trackers, circumventing the laborious label collection step in developing customized classifiers for sleep detection.|
|**2019-02-10**|**Classifying attention deficit hyperactivity disorder in children with non-linearities in actigraphy**|Jeremi K. Ochab et.al.|[1902.03530v1](http://arxiv.org/abs/1902.03530v1)|null|Objective This study provides an objective measure based on actigraphy for Attention Deficit Hyperactivity Disorder (ADHD) diagnosis in children. We search for motor activity features that could allow further investigation into their association with other neurophysiological disordered traits.   Method The study involved $n=29$ (48 eligible) male participants aged $9.89\pm0.92$ years (8 controls, and 7 in each group: ADHD combined subtype, ADHD hyperactive-impulsive subtype, and autism spectrum disorder, ASD) wearing a wristwatch actigraph continuously for a week ($9\%$ losses in daily records) in two acquisition modes. We analyzed 47 quantities: from sleep duration or movement intensity to theory-driven scaling exponents or non-linear prediction errors of both diurnal and nocturnal activity. We used them in supervised classification to obtain cross-validated diagnostic performance.   Results We report the best performing measures, including a nearest neighbors 4-feature classifier providing $69.4\pm1.6\%$ accuracy, $78.0\pm2.2\%$ sensitivity and $60.8\pm2.6\%$ specificity in a binary ADHD vs control classification and $46.5\pm1.1\%$ accuracy (against $25\%$ baseline), $61.8\pm1.4\%$ sensitivity and $79.30 \pm0.43\%$ specificity in 4-class task (two ADHD subtypes, ASD, and control). The most informative feature is skewness of the shape of Zero Crossing Mode (ZCM) activity. Mean and standard deviation of nocturnal activity are among the least informative.   Conclusion Actigraphy causes only minor discomfort to the subjects and is inexpensive. The range of existing mathematical and machine learning tools also allow it to be a useful add-on test for ADHD or differential diagnosis between ADHD subtypes. The study was limited to a small, male sample without the inattentive ADHD subtype.|
|**2018-12-03**|**A Hidden Markov Model Based Unsupervised Algorithm for Sleep/Wake Identification Using Actigraphy**|Xinyue Li et.al.|[1812.00553v2](http://arxiv.org/abs/1812.00553v2)|null|Actigraphy is widely used in sleep studies but lacks a universal unsupervised algorithm for sleep/wake identification. In this study, we proposed a Hidden Markov Model (HMM) based unsupervised algorithm that can automatically and effectively infer sleep/wake states. It is an individualized data-driven approach that analyzes actigraphy from each individual respectively to learn activity characteristics and further separate sleep and wake states. We used Actiwatch and polysomnography (PSG) data from 43 individuals in the Multi-Ethnic Study of Atherosclerosis to evaluate the performance of our method. Epoch-by-epoch comparisons were made between our HMM algorithm and that embedded in the Actiwatch software (AS). The percent agreement between HMM and PSG was 85.7%, and that between AS and PSG was 84.7%. Positive predictive values for sleep epochs were 85.6% and 84.6% for HMM and AS, respectively, and 95.5% and 85.6% for wake epochs. Both methods have similar performance and tend to overestimate sleep and underestimate wake compared to PSG. Our HMM approach is able to quantify the variability in activity counts that allow us to differentiate relatively active and sedentary individuals: individuals with higher estimated variabilities tend to show more frequent sedentary behaviors. In conclusion, our unsupervised data-driven HMM algorithm achieves slightly better performance compared to the commonly used algorithm in the Actiwatch software. HMM can help expand the application of actigraphy in large-scale studies and in cases where intrusive PSG is hard to acquire or unavailable. In addition, the estimated HMM parameters can characterize individual activity patterns that can be utilized for further analysis.|
|**2018-08-20**|**Bayesian Function-on-Scalars Regression for High Dimensional Data**|Daniel R. Kowal et.al.|[1808.06689v2](http://arxiv.org/abs/1808.06689v2)|null|We develop a fully Bayesian framework for function-on-scalars regression with many predictors. The functional data response is modeled nonparametrically using unknown basis functions, which produces a flexible and data-adaptive functional basis. We incorporate shrinkage priors that effectively remove unimportant scalar covariates from the model and reduce sensitivity to the number of (unknown) basis functions. For variable selection in functional regression, we propose a decision theoretic posterior summarization technique, which identifies a subset of covariates that retains nearly the predictive accuracy of the full model. Our approach is broadly applicable for Bayesian functional regression models, and unlike existing methods provides joint rather than marginal selection of important predictor variables. Computationally scalable posterior inference is achieved using a Gibbs sampler with linear time complexity in the number of predictors. The resulting algorithm is empirically faster than existing frequentist and Bayesian techniques, and provides joint estimation of model parameters, prediction and imputation of functional trajectories, and uncertainty quantification via the posterior distribution. A simulation study demonstrates improvements in estimation accuracy, uncertainty quantification, and variable selection relative to existing alternatives. The methodology is applied to actigraphy data to investigate the association between intraday physical activity and responses to a sleep questionnaire.|
|**2018-04-25**|**The Intelligent ICU Pilot Study: Using Artificial Intelligence Technology for Autonomous Patient Monitoring**|Anis Davoudi et.al.|[1804.10201v2](http://arxiv.org/abs/1804.10201v2)|null|Currently, many critical care indices are repetitively assessed and recorded by overburdened nurses, e.g. physical function or facial pain expressions of nonverbal patients. In addition, many essential information on patients and their environment are not captured at all, or are captured in a non-granular manner, e.g. sleep disturbance factors such as bright light, loud background noise, or excessive visitations. In this pilot study, we examined the feasibility of using pervasive sensing technology and artificial intelligence for autonomous and granular monitoring of critically ill patients and their environment in the Intensive Care Unit (ICU). As an exemplar prevalent condition, we also characterized delirious and non-delirious patients and their environment. We used wearable sensors, light and sound sensors, and a high-resolution camera to collected data on patients and their environment. We analyzed collected data using deep learning and statistical analysis. Our system performed face detection, face recognition, facial action unit detection, head pose detection, facial expression recognition, posture recognition, actigraphy analysis, sound pressure and light level detection, and visitation frequency detection. We were able to detect patient's face (Mean average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their postures (F1=0.94). We also found that all facial expressions, 11 activity features, visitation frequency during the day, visitation frequency during the night, light levels, and sound pressure levels during the night were significantly different between delirious and non-delirious patients (p-value<0.05). In summary, we showed that granular and autonomous monitoring of critically ill patients and their environment is feasible and can be used for characterizing critical care conditions and related environment factors.|
|**2018-03-31**|**Continuous Circadian Phase Estimation Using Adaptive Notch Filter**|Wei Qiao et.al.|[1804.00115v1](http://arxiv.org/abs/1804.00115v1)|null|Actigraphy has been widely used for the analysis of circadian rhythm. Current practice applies regression analysis to data from multiple days to estimate the circadian phase. This paper presents a filtering method for online processing of biometric data to estimate the circadian phase. We apply the proposed method on actigraphy data of fruit flies (Drosophila melanogaster).|
|**2018-02-22**|**Actigraphy-based Sleep/Wake Pattern Detection using Convolutional Neural Networks**|Lena Granovsky et.al.|[1802.07945v1](http://arxiv.org/abs/1802.07945v1)|null|Common medical conditions are often associated with sleep abnormalities. Patients with medical disorders often suffer from poor sleep quality compared to healthy individuals, which in turn may worsen the symptoms of the disorder. Accurate detection of sleep/wake patterns is important in developing personalized digital markers, which can be used for objective measurements and efficient disease management. Big Data technologies and advanced analytics methods hold the promise to revolutionize clinical research processes, enabling the effective blending of digital data into clinical trials. Actigraphy, a non-invasive activity monitoring method is heavily used to detect and evaluate activities and movement disorders, and assess sleep/wake behavior. In order to study the connection between sleep/wake patterns and a cluster headache disorder, activity data was collected using a wearable device in the course of a clinical trial. This study presents two novel modeling schemes that utilize Deep Convolutional Neural Networks (CNN) to identify sleep/wake states. The proposed methods are a sequential CNN, reminiscent of the bi-directional CNN for slot filling, and a Multi-Task Learning (MTL) based model. Furthermore, we expand standard "Sleep" and "Wake" activity states space by adding the "Falling asleep" and "Siesta" states. We show that the proposed methods provide promising results in accurate detection of the expanded sleep/wake states. Finally, we explore the relations between the detected sleep/wake patterns and onset of cluster headache attacks, and present preliminary observations.|
|**2017-12-27**|**Co-Morbidity Exploration on Wearables Activity Data Using Unsupervised Pre-training and Multi-Task Learning**|Karan Aggarwal et.al.|[1712.09527v1](http://arxiv.org/abs/1712.09527v1)|null|Physical activity and sleep play a major role in the prevention and management of many chronic conditions. It is not a trivial task to understand their impact on chronic conditions. Currently, data from electronic health records (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid increase in the popularity of wearable health devices provides a significant new data source, making it possible to track the user's lifestyle real-time through web interfaces, both to consumer as well as their healthcare provider, potentially. However, at present there is a gap between lifestyle data (e.g., sleep, physical activity) and clinical outcomes normally captured in EHRs. This is a critical barrier for the use of this new source of signal for healthcare decision making. Applying deep learning to wearables data provides a new opportunity to overcome this barrier.   To address the problem of the unavailability of clinical data from a major fraction of subjects and unrepresentative subject populations, we propose a novel unsupervised (task-agnostic) time-series representation learning technique called act2vec. act2vec learns useful features by taking into account the co-occurrence of activity levels along with periodicity of human activity patterns. The learned representations are then exploited to boost the performance of disorder-specific supervised learning models. Furthermore, since many disorders are often related to each other, a phenomenon referred to as co-morbidity, we use a multi-task learning framework for exploiting the shared structure of disorder inducing life-style choices partially captured in the wearables data. Empirical evaluation using actigraphy data from 4,124 subjects shows that our proposed method performs and generalizes substantially better than the conventional time-series symbolic representational methods and task-specific deep learning models.|
|**2017-12-18**|**Activity and Circadian Rhythm of Sepsis Patients in the Intensive Care Unit**|Anis Davoudi et.al.|[1712.06631v1](http://arxiv.org/abs/1712.06631v1)|null|Early mobilization of critically ill patients in the Intensive Care Unit (ICU) can prevent adverse outcomes such as delirium and post-discharge physical impairment. To date, no studies have characterized activity of sepsis patients in the ICU using granular actigraphy data. This study characterizes the activity of sepsis patients in the ICU to aid in future mobility interventions. We have compared the actigraphy features of 24 patients in four groups: Chronic Critical Illness (CCI) sepsis patients in the ICU, Rapid Recovery (RR) sepsis patients in the ICU, non-sepsis ICU patients (control-ICU), and healthy subjects. We used several statistical and circadian rhythm features extracted from the patients' actigraphy data collected over a five-day period. Our results show that the four groups are significantly different in terms of activity features. In addition, we observed that the CCI and control-ICU patients show less regularity in their circadian rhythm compared to the RR patients. These results show the potential of using actigraphy data for guiding mobilization practices, classifying sepsis recovery subtype, as well as for tracking patients' recovery.|
|**2017-11-02**|**Sleep Stage Classification Based on Multi-level Feature Learning and Recurrent Neural Networks via Wearable Device**|Xin Zhang et.al.|[1711.00629v1](http://arxiv.org/abs/1711.00629v1)|null|This paper proposes a practical approach for automatic sleep stage classification based on a multi-level feature learning framework and Recurrent Neural Network (RNN) classifier using heart rate and wrist actigraphy derived from a wearable device. The feature learning framework is designed to extract low- and mid-level features. Low-level features capture temporal and frequency domain properties and mid-level features learn compositions and structural information of signals. Since sleep staging is a sequential problem with long-term dependencies, we take advantage of RNNs with Bidirectional Long Short-Term Memory (BLSTM) architectures for sequence data learning. To simulate the actual situation of daily sleep, experiments are conducted with a resting group in which sleep is recorded in resting state, and a comprehensive group in which both resting sleep and non-resting sleep are included.We evaluate the algorithm based on an eight-fold cross validation to classify five sleep stages (W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision, recall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%, 61.1%, and 58.5% in the comprehensive group, respectively. Various comparison experiments demonstrate the effectiveness of feature learning and BLSTM. We further explore the influence of depth and width of RNNs on performance. Our method is specially proposed for wearable devices and is expected to be applicable for long-term sleep monitoring at home. Without using too much prior domain knowledge, our method has the potential to generalize sleep disorder detection.|
|**2017-05-10**|**Visualization of Wearable Data and Biometrics for Analysis and Recommendations in Childhood Obesity**|Michael Aupetit et.al.|[1705.03691v1](http://arxiv.org/abs/1705.03691v1)|null|Obesity is one of the major health risk factors be- hind the rise of non-communicable conditions. Understanding the factors influencing obesity is very complex since there are many variables that can affect the health behaviors leading to it. Nowadays, multiple data sources can be used to study health behaviors, such as wearable sensors for physical activity and sleep, social media, mobile and health data. In this paper we describe the design of a dashboard for the visualization of actigraphy and biometric data from a childhood obesity camp in Qatar. This dashboard allows quantitative discoveries that can be used to guide patient behavior and orient qualitative research.|
|**2017-02-13**|**On multifractals: a non-linear study of actigraphy data**|Lucas Gabriel Souza França et.al.|[1702.03912v2](http://arxiv.org/abs/1702.03912v2)|[link](https://github.com/lucasfr/actiMF)|This work aimed, to determine the characteristics of activity series from fractal geometry concepts application, in addition to evaluate the possibility of identifying individuals with fibromyalgia. Activity level data were collected from 27 healthy subjects and 27 fibromyalgia patients, with the use of clock-like devices equipped with accelerometers, for about four weeks, all day long. The activity series were evaluated through fractal and multifractal methods. Hurst exponent analysis exhibited values according to other studies ($H>0.5$) for both groups ($H=0.98\pm0.04$ for healthy subjects and $H=0.97\pm0.03$ for fibromyalgia patients), however, it is not possible to distinguish between the two groups by such analysis. Activity time series also exhibited a multifractal pattern. A paired analysis of the spectra indices for the sleep and awake states revealed differences between healthy subjects and fibromyalgia patients. The individuals feature differences between awake and sleep states, having statistically significant differences for $\alpha_{q-} - \alpha_{0}$ in healthy subjects ($p = 0.014$) and $D_{0}$ for patients with fibromyalgia ($p = 0.013$). The approach has proven to be an option on the characterisation of such kind of signals and was able to differ between both healthy and fibromyalgia groups. This outcome suggests changes in the physiologic mechanisms of movement control.|
|**2016-09-12**|**Hearables: Multimodal physiological in-ear sensing**|Valentin Goverdovsky et.al.|[1609.03330v2](http://arxiv.org/abs/1609.03330v2)|null|Future health systems require the means to assess and track the neural and physiological function of a user over long periods of time and in the community. Human body responses are manifested through multiple modalities, such as the mechanical, electrical and chemical; yet current physiological monitors (actigraphy, heart rate) largely lack in both the desired cross-modal and non-stigmatizing aspects. We address these challenges through an inconspicuous and comfortable earpiece, equipped with miniature multimodal sensors, which benefits from the relatively stable position of the ear canal with respect to vital organs to robustly measure the brain, cardiac and respiratory functions. Comprehensive experiments validate each modality within the proposed earpiece, while its potential in health monitoring is illustrated through case studies. We further demonstrate how combining data from multiple sensors within such an integrated wearable device improves both the accuracy of measurements and the ability to deal with artifacts in real-life scenarios.|
|**2016-07-30**|**Learning Tree-Structured Detection Cascades for Heterogeneous Networks of Embedded Devices**|Hamid Dadkhahi et.al.|[1608.00159v4](http://arxiv.org/abs/1608.00159v4)|null|In this paper, we present a new approach to learning cascaded classifiers for use in computing environments that involve networks of heterogeneous and resource-constrained, low-power embedded compute and sensing nodes. We present a generalization of the classical linear detection cascade to the case of tree-structured cascades where different branches of the tree execute on different physical compute nodes in the network. Different nodes have access to different features, as well as access to potentially different computation and energy resources. We concentrate on the problem of jointly learning the parameters for all of the classifiers in the cascade given a fixed cascade architecture and a known set of costs required to carry out the computation at each node.To accomplish the objective of joint learning of all detectors, we propose a novel approach to combining classifier outputs during training that better matches the hard cascade setting in which the learned system will be deployed. This work is motivated by research in the area of mobile health where energy efficient real time detectors integrating information from multiple wireless on-body sensors and a smart phone are needed for real-time monitoring and delivering just- in-time adaptive interventions. We apply our framework to two activity recognition datasets as well as the problem of cigarette smoking detection from a combination of wrist-worn actigraphy data and respiration chest band data.|
|**2016-07-24**|**Impact of Physical Activity on Sleep:A Deep Learning Based Exploration**|Aarti Sathyanarayana et.al.|[1607.07034v1](http://arxiv.org/abs/1607.07034v1)|null|The importance of sleep is paramount for maintaining physical, emotional and mental wellbeing. Though the relationship between sleep and physical activity is known to be important, it is not yet fully understood. The explosion in popularity of actigraphy and wearable devices, provides a unique opportunity to understand this relationship. Leveraging this information source requires new tools to be developed to facilitate data-driven research for sleep and activity patient-recommendations.   In this paper we explore the use of deep learning to build sleep quality prediction models based on actigraphy data. We first use deep learning as a pure model building device by performing human activity recognition (HAR) on raw sensor data, and using deep learning to build sleep prediction models. We compare the deep learning models with those build using classical approaches, i.e. logistic regression, support vector machines, random forest and adaboost. Secondly, we employ the advantage of deep learning with its ability to handle high dimensional datasets. We explore several deep learning models on the raw wearable sensor output without performing HAR or any other feature extraction.   Our results show that using a convolutional neural network on the raw wearables output improves the predictive value of sleep quality from physical activity, by an additional 8% compared to state-of-the-art non-deep learning approaches, which itself shows a 15% improvement over current practice. Moreover, utilizing deep learning on raw data eliminates the need for data pre-processing and simplifies the overall workflow to analyze actigraphy data for sleep and physical activity research.|
|**2016-07-13**|**Learning Shallow Detection Cascades for Wearable Sensor-Based Mobile Health Applications**|Hamid Dadkhahi et.al.|[1607.03730v1](http://arxiv.org/abs/1607.03730v1)|null|The field of mobile health aims to leverage recent advances in wearable on-body sensing technology and smart phone computing capabilities to develop systems that can monitor health states and deliver just-in-time adaptive interventions. However, existing work has largely focused on analyzing collected data in the off-line setting. In this paper, we propose a novel approach to learning shallow detection cascades developed explicitly for use in a real-time wearable-phone or wearable-phone-cloud systems. We apply our approach to the problem of cigarette smoking detection from a combination of wrist-worn actigraphy data and respiration chest band data using two and three stage cascades.|

## Electroencephalography

### Electroencephalography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-05**|**Gotta Go Fast: Measuring Input/Output Latencies of Virtual Reality 3D Engines for Cognitive Experiments**|Taeho Kang et.al.|[2306.02637v1](http://arxiv.org/abs/2306.02637v1)|null|Virtual Reality (VR) is seeing increased adoption across many fields. The field of experimental cognitive science is also testing utilization of the technology combined with physiological measures such as electroencephalography (EEG) and eye tracking. Quantitative measures of human behavior and cognition process, however, are sensitive to minuscule time resolutions that are often overlooked in the scope of consumer-level VR hardware and software stacks. In this preliminary study, we implement VR testing environments in two prominent 3D Virtual Reality frameworks (Unity and Unreal Engine) to measure latency values for stimulus onset execution code to Head-Mount Display (HMD) pixel change, as well as the latency between human behavioral response input to its registration in the engine environment under a typical cognitive experiment hardware setup. We find that whereas the specifics of the latency may further be influenced by different hardware and software setups, the variations in consumer hardware is apparent regardless and report detailed statistics on these latencies. Such consideration should be taken into account when designing VR-based cognitive experiments that measure human behavior.|
|**2023-05-22**|**Towards Ultrasound Tongue Image prediction from EEG during speech production**|Tamás Gábor Csapó et.al.|[2306.05374v1](http://arxiv.org/abs/2306.05374v1)|null|Previous initial research has already been carried out to propose speech-based BCI using brain signals (e.g.~non-invasive EEG and invasive sEEG / ECoG), but there is a lack of combined methods that investigate non-invasive brain, articulation, and speech signals together and analyze the cognitive processes in the brain, the kinematics of the articulatory movement and the resulting speech signal. In this paper, we describe our multimodal (electroencephalography, ultrasound tongue imaging, and speech) analysis and synthesis experiments, as a feasibility study. We extend the analysis of brain signals recorded during speech production with ultrasound-based articulation data. From the brain signal measured with EEG, we predict ultrasound images of the tongue with a fully connected deep neural network. The results show that there is a weak but noticeable relationship between EEG and ultrasound tongue images, i.e. the network can differentiate articulated speech and neutral tongue position.|
|**2023-05-19**|**Energy-efficient memcapacitive physical reservoir computing system for temporal data processing**|Md Razuan Hossain et.al.|[2305.12025v1](http://arxiv.org/abs/2305.12025v1)|null|Reservoir computing is a highly efficient machine learning framework for processing temporal data by extracting features from the input signal and mapping them into higher dimensional spaces. Physical reservoir layers have been realized using spintronic oscillators, atomic switch networks, silicon photonic modules, ferroelectric transistors, and volatile memristors. However, these devices are intrinsically energy-dissipative due to their resistive nature, which leads to increased power consumption. Therefore, capacitive memory devices can provide a more energy-efficient approach. Here, we leverage volatile biomembrane-based memcapacitors that closely mimic certain short-term synaptic plasticity functions as reservoirs to solve classification tasks and analyze time-series data in simulation and experimentally. Our system achieves a 98% accuracy rate for spoken digit classification and a normalized mean square error of 0.0012 in a second-order non-linear regression task. Further, to demonstrate the device's real-time temporal data processing capability, we demonstrate a 100% accuracy for an electroencephalography (EEG) signal classification problem for epilepsy detection. Most importantly, we demonstrate that for a random input sequence, each memcapacitor consumes on average 41.5fJ of energy per spike, irrespective of the chosen input voltage pulse width, and 415fW of average power for 100 ms pulse width, orders of magnitude lower than the state-of-the-art devices. Lastly, we believe the biocompatible, soft nature of our memcapacitor makes it highly suitable for computing and signal-processing applications in biological environments.|
|**2023-05-18**|**Temporal Aware Mixed Attention-based Convolution and Transformer Network (MACTN) for EEG Emotion Recognition**|Xiaopeng Si et.al.|[2305.18234v1](http://arxiv.org/abs/2305.18234v1)|null|Emotion recognition plays a crucial role in human-computer interaction, and electroencephalography (EEG) is advantageous for reflecting human emotional states. In this study, we propose MACTN, a hierarchical hybrid model for jointly modeling local and global temporal information. The model is inspired by neuroscience research on the temporal dynamics of emotions. MACTN extracts local emotional features through a convolutional neural network (CNN) and integrates sparse global emotional features through a transformer. Moreover, we employ channel attention mechanisms to identify the most task-relevant channels. Through extensive experimentation on two publicly available datasets, namely THU-EP and DEAP, our proposed method, MACTN, consistently achieves superior classification accuracy and F1 scores compared to other existing methods in most experimental settings. Furthermore, ablation studies have shown that the integration of both self-attention mechanisms and channel attention mechanisms leads to improved classification performance. Finally, an earlier version of this method, which shares the same ideas, won the Emotional BCI Competition's final championship in the 2022 World Robot Contest.|
|**2023-05-18**|**Robust inference of causality in high-dimensional dynamical processes from the Information Imbalance of distance ranks**|Vittorio Del Tatto et.al.|[2305.10817v2](http://arxiv.org/abs/2305.10817v2)|[link](https://github.com/vdeltatto/imbalance-gain-causality)|We introduce an approach which allows inferring causal relationships between variables for which the time evolution is available. Our method builds on the ideas of Granger Causality and Transfer Entropy, but overcomes most of their limitations. Specifically, our approach tests whether the predictability of a putative driven system Y can be improved by incorporating information from a potential driver system X, without making assumptions on the underlying dynamics and without the need to compute probability densities of the dynamic variables. Causality is assessed by a rigorous variational scheme based on the Information Imbalance of distance ranks, a recently developed statistical test capable of inferring the relative information content of different distance measures. This framework makes causality detection possible even for high-dimensional systems where only few of the variables are known or measured. Benchmark tests on coupled dynamical systems demonstrate that our approach outperforms other model-free causality detection methods, successfully handling both unidirectional and bidirectional couplings, and it is capable of detecting the arrow of time when present. We also show that the method can be used to robustly detect causality in electroencephalography data in humans.|
|**2023-05-17**|**BASEN: Time-Domain Brain-Assisted Speech Enhancement Network with Convolutional Cross Attention in Multi-talker Conditions**|Jie Zhang et.al.|[2305.09994v1](http://arxiv.org/abs/2305.09994v1)|[link](https://github.com/jzhangu/basen)|Time-domain single-channel speech enhancement (SE) still remains challenging to extract the target speaker without any prior information on multi-talker conditions. It has been shown via auditory attention decoding that the brain activity of the listener contains the auditory information of the attended speaker. In this paper, we thus propose a novel time-domain brain-assisted SE network (BASEN) incorporating electroencephalography (EEG) signals recorded from the listener for extracting the target speaker from monaural speech mixtures. The proposed BASEN is based on the fully-convolutional time-domain audio separation network. In order to fully leverage the complementary information contained in the EEG signals, we further propose a convolutional multi-layer cross attention module to fuse the dual-branch features. Experimental results on a public dataset show that the proposed model outperforms the state-of-the-art method in several evaluation metrics. The reproducible code is available at https://github.com/jzhangU/Basen.git.|
|**2023-04-24**|**Time delay multi-feature correlation analysis to extract subtle dependencies from EEG signals**|Jarek Duda et.al.|[2305.09478v2](http://arxiv.org/abs/2305.09478v2)|null|Electroencephalography (EEG) signals are resultants of extremely complex brain activity. Some details of this hidden dynamics might be accessible through e.g. joint distributions $\rho_{\Delta t}$ of signals of pairs of electrodes shifted by various time delays (lag $\Delta t$). A standard approach is monitoring a single evaluation of such joint distributions, like Pearson correlation (or mutual information), which turns out relatively uninteresting - as expected, there is usually a small peak for zero delay and nearly symmetric drop with delay. In contrast, such a complex signal might be composed of multiple types of statistical dependencies - this article proposes approach to automatically decompose and extract them. Specifically, we model such joint distributions as polynomials, estimated separately for all considered lag dependencies, then with PCA dimensionality reduction we find the dominant joint density distortion directions $f_v$. This way we get a few lag dependent features $a_i(\Delta t)$ describing separate dominating statistical dependencies of known contributions: $\rho_{\Delta t}(y,z)\approx \sum_{i=1}^r a_i(\Delta t)\, f_{v_i}(y,z)$. Such features complement Pearson correlation, extracting hidden more complex behavior, e.g. with asymmetry which might be related with direction of information transfer, extrema suggesting characteristic delays, or oscillatory behavior suggesting some periodicity. There is also discussed extension of Granger causality to such multi-feature joint density analysis, suggesting e.g. two separate causality waves. While this early article is initial fundamental research, in future it might help e.g. with understanding of cortex hidden dynamics, diagnosis of pathologies like epilepsy, determination of precise electrode position, or building brain-computer interface.|
|**2023-04-21**|**A Convolutional Spiking Network for Gesture Recognition in Brain-Computer Interfaces**|Yiming Ai et.al.|[2304.11106v2](http://arxiv.org/abs/2304.11106v2)|null|Brain-computer interfaces are being explored for a wide variety of therapeutic applications. Typically, this involves measuring and analyzing continuous-time electrical brain activity via techniques such as electrocorticogram (ECoG) or electroencephalography (EEG) to drive external devices. However, due to the inherent noise and variability in the measurements, the analysis of these signals is challenging and requires offline processing with significant computational resources. In this paper, we propose a simple yet efficient machine learning-based approach for the exemplary problem of hand gesture classification based on brain signals. We use a hybrid machine learning approach that uses a convolutional spiking neural network employing a bio-inspired event-driven synaptic plasticity rule for unsupervised feature learning of the measured analog signals encoded in the spike domain. We demonstrate that this approach generalizes to different subjects with both EEG and ECoG data and achieves superior accuracy in the range of 92.74-97.07% in identifying different hand gesture classes and motor imagery tasks.|
|**2023-04-21**|**Interpretable and Robust AI in EEG Systems: A Survey**|Xinliang Zhou et.al.|[2304.10755v1](http://arxiv.org/abs/2304.10755v1)|null|The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it into three types: backpropagation, perturbation, and inherently interpretable methods. Then we classify the robustness mechanisms into four classes: noise and artifacts, human variability, data acquisition instability, and adversarial attacks. Finally, we identify several critical and unresolved challenges for interpretable and robust AI in EEG systems and further discuss their future directions.|
|**2023-04-12**|**Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data**|Dominik Klepl et.al.|[2304.05874v1](http://arxiv.org/abs/2304.05874v1)|null|Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the proposed AGGCN model generates consistent explanations of its predictions that might be relevant for further study of AD-related alterations of brain networks.|
|**2023-04-12**|**Dynamic Graph Representation Learning with Neural Networks: A Survey**|Leshanshui Yang et.al.|[2304.05729v1](http://arxiv.org/abs/2304.05729v1)|null|In recent years, Dynamic Graph (DG) representations have been increasingly used for modeling dynamic systems due to their ability to integrate both topological and temporal information in a compact representation. Dynamic graphs allow to efficiently handle applications such as social network prediction, recommender systems, traffic forecasting or electroencephalography analysis, that can not be adressed using standard numeric representations. As a direct consequence of the emergence of dynamic graph representations, dynamic graph learning has emerged as a new machine learning problem, combining challenges from both sequential/temporal data processing and static graph learning. In this research area, Dynamic Graph Neural Network (DGNN) has became the state of the art approach and plethora of models have been proposed in the very recent years. This paper aims at providing a review of problems and models related to dynamic graph learning. The various dynamic graph supervised learning settings are analysed and discussed. We identify the similarities and differences between existing models with respect to the way time information is modeled. Finally, general guidelines for a DGNN designer when faced with a dynamic graph learning problem are provided.|
|**2023-04-01**|**Upper Limb Movement Execution Classification using Electroencephalography for Brain Computer Interface**|Saadat Ullah Khan et.al.|[2304.06036v1](http://arxiv.org/abs/2304.06036v1)|null|An accurate classification of upper limb movements using electroencephalography (EEG) signals is gaining significant importance in recent years due to the prevalence of brain-computer interfaces. The upper limbs in the human body are crucial since different skeletal segments combine to make a range of motion that helps us in our trivial daily tasks. Decoding EEG-based upper limb movements can be of great help to people with spinal cord injury (SCI) or other neuro-muscular diseases such as amyotrophic lateral sclerosis (ALS), primary lateral sclerosis, and periodic paralysis. This can manifest in a loss of sensory and motor function, which could make a person reliant on others to provide care in day-to-day activities. We can detect and classify upper limb movement activities, whether they be executed or imagined using an EEG-based brain-computer interface (BCI). Toward this goal, we focus our attention on decoding movement execution (ME) of the upper limb in this study. For this purpose, we utilize a publicly available EEG dataset that contains EEG signal recordings from fifteen subjects acquired using a 61-channel EEG device. We propose a method to classify four ME classes for different subjects using spectrograms of the EEG data through pre-trained deep learning (DL) models. Our proposed method of using EEG spectrograms for the classification of ME has shown significant results, where the highest average classification accuracy (for four ME classes) obtained is 87.36%, with one subject achieving the best classification accuracy of 97.03%.|
|**2023-03-29**|**Parkinsons Disease Detection via Resting-State Electroencephalography Using Signal Processing and Machine Learning Techniques**|Krish Desai et.al.|[2304.01214v1](http://arxiv.org/abs/2304.01214v1)|null|Parkinsons Disease (PD) is a neurodegenerative disorder resulting in motor deficits due to advancing degeneration of dopaminergic neurons. PD patients report experiencing tremor, rigidity, visual impairment, bradykinesia, and several cognitive deficits. Although Electroencephalography (EEG) indicates abnormalities in PD patients, one major challenge is the lack of a consistent, accurate, and systemic biomarker for PD in order to closely monitor the disease with therapeutic treatments and medication. In this study, we collected Electroencephalographic data from 15 PD patients and 16 Healthy Controls (HC). We first preprocessed every EEG signal using several techniques and extracted relevant features using many feature extraction algorithms. Afterwards, we applied several machine learning algorithms to classify PD versus HC. We found the most significant metrics to be achieved by the Random Forest ensemble learning approach, with an accuracy, precision, recall, F1 score, and AUC of 97.5%, 100%, 95%, 0.967, and 0.975, respectively. The results of this study show promise for exposing PD abnormalities using EEG during clinical diagnosis, and automating this process using signal processing techniques and ML algorithms to evaluate the difference between healthy individuals and PD patients.|
|**2023-03-27**|**EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition**|Rushuang Zhou et.al.|[2304.06496v1](http://arxiv.org/abs/2304.06496v1)|[link](https://github.com/kazabana/eegmatch)|Electroencephalography (EEG) is an objective tool for emotion recognition and shows promising performance. However, the label scarcity problem is a main challenge in this field, which limits the wide application of EEG-based emotion recognition. In this paper, we propose a novel semi-supervised learning framework (EEGMatch) to leverage both labeled and unlabeled EEG data. First, an EEG-Mixup based data augmentation method is developed to generate more valid samples for model learning. Second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between EEG data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among EEG data. Third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled source domain, unlabeled source domain, and target domain), where the distribution mismatch is alleviated. Extensive experiments are conducted on two benchmark databases (SEED and SEED-IV) under a cross-subject leave-one-subject-out cross-validation evaluation protocol. The results show the proposed EEGmatch performs better than the state-of-the-art methods under different incomplete label conditions (with 6.89% improvement on SEED and 1.44% improvement on SEED-IV), which demonstrates the effectiveness of the proposed EEGMatch in dealing with the label scarcity problem in emotion recognition using EEG signals. The source code is available at https://github.com/KAZABANA/EEGMatch.|
|**2023-03-26**|**Driver Drowsiness Detection with Commercial EEG Headsets**|Qazal Rezaee et.al.|[2303.14841v1](http://arxiv.org/abs/2303.14841v1)|null|Driver Drowsiness is one of the leading causes of road accidents. Electroencephalography (EEG) is highly affected by drowsiness; hence, EEG-based methods detect drowsiness with the highest accuracy. Developments in manufacturing dry electrodes and headsets have made recording EEG more convenient. Vehicle-based features used for detecting drowsiness are easy to capture but do not have the best performance. In this paper, we investigated the performance of EEG signals recorded in 4 channels with commercial headsets against the vehicle-based technique in drowsiness detection. We recorded EEG signals of 50 volunteers driving a simulator in drowsy and alert states by commercial devices. The observer rating of the drowsiness method was used to determine the drowsiness level of the subjects. The meaningful separation of vehicle-based features, recorded by the simulator, and EEG-based features of the two states of drowsiness and alertness have been investigated. The comparison results indicated that the EEG-based features are separated with lower p-values than the vehicle-based ones in the two states. It is concluded that EEG headsets can be feasible alternatives with better performance compared to vehicle-based methods for detecting drowsiness.|
|**2023-03-20**|**Relate auditory speech to EEG by shallow-deep attention-based network**|Fan Cui et.al.|[2303.10897v1](http://arxiv.org/abs/2303.10897v1)|null|Electroencephalography (EEG) plays a vital role in detecting how brain responses to different stimulus. In this paper, we propose a novel Shallow-Deep Attention-based Network (SDANet) to classify the correct auditory stimulus evoking the EEG signal. It adopts the Attention-based Correlation Module (ACM) to discover the connection between auditory speech and EEG from global aspect, and the Shallow-Deep Similarity Classification Module (SDSCM) to decide the classification result via the embeddings learned from the shallow and deep layers. Moreover, various training strategies and data augmentation are used to boost the model robustness. Experiments are conducted on the dataset provided by Auditory EEG challenge (ICASSP Signal Processing Grand Challenge 2023). Results show that the proposed model has a significant gain over the baseline on the match-mismatch track.|
|**2023-03-19**|**Enabling Immersion and Presence in the Metaverse with Over-the-Air Brain-Computer Interface**|Nguyen Quang Hieu et.al.|[2303.10577v1](http://arxiv.org/abs/2303.10577v1)|null|Decoding brain signals can not only reveal Metaverse users' expectations but also early detect error-related behaviors such as stress, drowsiness, and motion sickness. For that, this article proposes a pioneering framework using wireless/over-the-air Brain-Computer Interface (BCI) to assist creation of virtual avatars as human representation in the Metaverse. Specifically, to eliminate the computational burden for Metaverse users' devices, we leverage Wireless Edge Servers (WES) that are popular in 5G architecture and therein URLLC, enhanced broadband features to obtain and process the brain activities, i.e., electroencephalography (EEG) signals (via uplink wireless channels). As a result, the WES can learn human behaviors, adapt system configurations, and allocate radio resources to create individualized settings and enhance user experiences. Despite the potential of BCI, the inherent noisy/fading wireless channels and the uncertainty in Metaverse users' demands and behaviors make the related resource allocation and learning/classification problems particularly challenging. We formulate the joint learning and resource allocation problem as a Quality-of-Experience (QoE) maximization problem that takes into the latency, brain classification accuracy, and resources of the system. To tackle this mixed integer programming problem, we then propose two novel algorithms that are (i) a hybrid learning algorithm to maximize the user QoE and (ii) a meta-learning algorithm to exploit the neurodiversity of the brain signals among multiple Metaverse users. The extensive experiment results with different BCI datasets show that our proposed algorithms can not only provide low delay for virtual reality (VR) applications but also can achieve high classification accuracy for the collected brain signals.|
|**2023-03-13**|**Correlates of Programmer Efficacy and Their Link to Experience: A Combined EEG and Eye-Tracking Study**|Norman Peitek et.al.|[2303.07071v1](http://arxiv.org/abs/2303.07071v1)|[link](https://github.com/brains-on-code/novicevsexpert)|Background: Despite similar education and background, programmers can exhibit vast differences in efficacy. While research has identified some potential factors, such as programming experience and domain knowledge, the effect of these factors on programmers' efficacy is not well understood.   Aims: We aim at unraveling the relationship between efficacy (speed and correctness) and measures of programming experience. We further investigate the correlates of programmer efficacy in terms of reading behavior and cognitive load.   Method: For this purpose, we conducted a controlled experiment with 37~participants using electroencephalography (EEG) and eye tracking. We asked participants to comprehend up to 32 Java source-code snippets and observed their eye gaze and neural correlates of cognitive load. We analyzed the correlation of participants' efficacy with popular programming experience measures.   Results: We found that programmers with high efficacy read source code more targeted and with lower cognitive load. Commonly used experience levels do not predict programmer efficacy well, but self-estimation and indicators of learning eagerness are fairly accurate.   Implications: The identified correlates of programmer efficacy can be used for future research and practice (e.g., hiring). Future research should also consider efficacy as a group sampling method, rather than using simple experience measures.|
|**2023-03-11**|**Assessing gender fairness in EEG-based machine learning detection of Parkinson's disease: A multi-center study**|Anna Kurbatskaya et.al.|[2303.06376v1](http://arxiv.org/abs/2303.06376v1)|[link](https://github.com/biomedical-data-analysis-laboratory/multicentric-ml-parkinson-detection)|As the number of automatic tools based on machine learning (ML) and resting-state electroencephalography (rs-EEG) for Parkinson's disease (PD) detection keeps growing, the assessment of possible exacerbation of health disparities by means of fairness and bias analysis becomes more relevant. Protected attributes, such as gender, play an important role in PD diagnosis development. However, analysis of sub-group populations stemming from different genders is seldom taken into consideration in ML models' development or the performance assessment for PD detection. In this work, we perform a systematic analysis of the detection ability for gender sub-groups in a multi-center setting of a previously developed ML algorithm based on power spectral density (PSD) features of rs-EEG. We find significant differences in the PD detection ability for males and females at testing time (80.5% vs. 63.7% accuracy) and significantly higher activity for a set of parietal and frontal EEG channels and frequency sub-bands for PD and non-PD males that might explain the differences in the PD detection ability for the gender sub-groups.|
|**2023-03-07**|**Sufficient dimension reduction for feature matrices**|Chanwoo Lee et.al.|[2303.04286v1](http://arxiv.org/abs/2303.04286v1)|null|We address the problem of sufficient dimension reduction for feature matrices, which arises often in sensor network localization, brain neuroimaging, and electroencephalography analysis. In general, feature matrices have both row- and column-wise interpretations and contain structural information that can be lost with naive vectorization approaches. To address this, we propose a method called principal support matrix machine (PSMM) for the matrix sufficient dimension reduction. The PSMM converts the sufficient dimension reduction problem into a series of classification problems by dividing the response variables into slices. It effectively utilizes the matrix structure by finding hyperplanes with rank-1 normal matrix that optimally separate the sliced responses. Additionally, we extend our approach to the higher-order tensor case. Our numerical analysis demonstrates that the PSMM outperforms existing methods and has strong interpretability in real data applications.|
|**2023-03-06**|**EEG Synthetic Data Generation Using Probabilistic Diffusion Models**|Giulio Tosato et.al.|[2303.06068v1](http://arxiv.org/abs/2303.06068v1)|[link](https://github.com/devjake/eeg-diffusion-pytorch)|Electroencephalography (EEG) plays a significant role in the Brain Computer Interface (BCI) domain, due to its non-invasive nature, low cost, and ease of use, making it a highly desirable option for widespread adoption by the general public. This technology is commonly used in conjunction with deep learning techniques, the success of which is largely dependent on the quality and quantity of data used for training. To address the challenge of obtaining sufficient EEG data from individual participants while minimizing user effort and maintaining accuracy, this study proposes an advanced methodology for data augmentation: generating synthetic EEG data using denoising diffusion probabilistic models. The synthetic data are generated from electrode-frequency distribution maps (EFDMs) of emotionally labeled EEG recordings. To assess the validity of the synthetic data generated, both a qualitative and a quantitative comparison with real EEG data were successfully conducted. This study opens up the possibility for an open\textendash source accessible and versatile toolbox that can process and generate data in both time and frequency dimensions, regardless of the number of channels involved. Finally, the proposed methodology has potential implications for the broader field of neuroscience research by enabling the creation of large, publicly available synthetic EEG datasets without privacy concerns.|
|**2023-02-27**|**Predicting EEG Responses to Attended Speech via Deep Neural Networks for Speech**|Emina Alickovic et.al.|[2302.13553v1](http://arxiv.org/abs/2302.13553v1)|null|Attending to the speech stream of interest in multi-talker environments can be a challenging task, particularly for listeners with hearing impairment. Research suggests that neural responses assessed with electroencephalography (EEG) are modulated by listener`s auditory attention, revealing selective neural tracking (NT) of the attended speech. NT methods mostly rely on hand-engineered acoustic and linguistic speech features to predict the neural response. Only recently, deep neural network (DNN) models without specific linguistic information have been used to extract speech features for NT, demonstrating that speech features in hierarchical DNN layers can predict neural responses throughout the auditory pathway. In this study, we go one step further to investigate the suitability of similar DNN models for speech to predict neural responses to competing speech observed in EEG. We recorded EEG data using a 64-channel acquisition system from 17 listeners with normal hearing instructed to attend to one of two competing talkers. Our data revealed that EEG responses are significantly better predicted by DNN-extracted speech features than by hand-engineered acoustic features. Furthermore, analysis of hierarchical DNN layers showed that early layers yielded the highest predictions. Moreover, we found a significant increase in auditory attention classification accuracies with the use of DNN-extracted speech features over the use of hand-engineered acoustic features. These findings open a new avenue for development of new NT measures to evaluate and further advance hearing technology.|
|**2023-02-25**|**Partial Label Learning for Emotion Recognition from EEG**|Guangyi Zhang et.al.|[2302.13170v1](http://arxiv.org/abs/2302.13170v1)|[link](https://github.com/guangyizhangbci/pll-emotion-eeg)|Fully supervised learning has recently achieved promising performance in various electroencephalography (EEG) learning tasks by training on large datasets with ground truth labels. However, labeling EEG data for affective experiments is challenging, as it can be difficult for participants to accurately distinguish between similar emotions, resulting in ambiguous labeling (reporting multiple emotions for one EEG instance). This notion could cause model performance degradation, as the ground truth is hidden within multiple candidate labels. To address this issue, Partial Label Learning (PLL) has been proposed to identify the ground truth from candidate labels during the training phase, and has shown good performance in the computer vision domain. However, PLL methods have not yet been adopted for EEG representation learning or implemented for emotion recognition tasks. In this paper, we adapt and re-implement six state-of-the-art PLL approaches for emotion recognition from EEG on a large emotion dataset (SEED-V, containing five emotion classes). We evaluate the performance of all methods in classical and real-world experiments. The results show that PLL methods can achieve strong results in affective computing from EEG and achieve comparable performance to fully supervised learning. We also investigate the effect of label disambiguation, a key step in many PLL methods. The results show that in most cases, label disambiguation would benefit the model when the candidate labels are generated based on their similarities to the ground truth rather than obeying a uniform distribution. This finding suggests the potential of using label disambiguation-based PLL methods for real-world affective tasks. We make the source code of this paper publicly available at: https://github.com/guangyizhangbci/PLL-Emotion-EEG.|
|**2023-02-24**|**Annotating Covert Hazardous Driving Scenarios Online: Utilizing Drivers' Electroencephalography (EEG) Signals**|Chen Zheng et.al.|[2302.12424v1](http://arxiv.org/abs/2302.12424v1)|null|As autonomous driving systems prevail, it is becoming increasingly critical that the systems learn from databases containing fine-grained driving scenarios. Most databases currently available are human-annotated; they are expensive, time-consuming, and subject to behavioral biases. In this paper, we provide initial evidence supporting a novel technique utilizing drivers' electroencephalography (EEG) signals to implicitly label hazardous driving scenarios while passively viewing recordings of real-road driving, thus sparing the need for manual annotation and avoiding human annotators' behavioral biases during explicit report. We conducted an EEG experiment using real-life and animated recordings of driving scenarios and asked participants to report danger explicitly whenever necessary. Behavioral results showed the participants tended to report danger only when overt hazards (e.g., a vehicle or a pedestrian appearing unexpectedly from behind an occlusion) were in view. By contrast, their EEG signals were enhanced at the sight of both an overt hazard and a covert hazard (e.g., an occlusion signalling possible appearance of a vehicle or a pedestrian from behind). Thus, EEG signals were more sensitive to driving hazards than explicit reports. Further, the Time-Series AI (TSAI) successfully classified EEG signals corresponding to overt and covert hazards. We discuss future steps necessary to materialize the technique in real life.|
|**2023-02-19**|**Electrode Clustering and Bandpass Analysis of EEG Data for Gaze Estimation**|Ard Kastrati et.al.|[2302.12710v1](http://arxiv.org/abs/2302.12710v1)|null|In this study, we validate the findings of previously published papers, showing the feasibility of an Electroencephalography (EEG) based gaze estimation. Moreover, we extend previous research by demonstrating that with only a slight drop in model performance, we can significantly reduce the number of electrodes, indicating that a high-density, expensive EEG cap is not necessary for the purposes of EEG-based eye tracking. Using data-driven approaches, we establish which electrode clusters impact gaze estimation and how the different types of EEG data preprocessing affect the models' performance. Finally, we also inspect which recorded frequencies are most important for the defined tasks.|
|**2023-02-17**|**Deep comparisons of Neural Networks from the EEGNet family**|Csaba Márton Köllőd et.al.|[2302.08797v1](http://arxiv.org/abs/2302.08797v1)|[link](https://github.com/kolcs/bionic_apps)|Most of the Brain-Computer Interface (BCI) publications, which propose artificial neural networks for Motor Imagery (MI) Electroencephalography (EEG) signal classification, are presented using one of the BCI Competition datasets. However, these databases contain MI EEG data from less than or equal to 10 subjects . In addition, these algorithms usually include only bandpass filtering to reduce noise and increase signal quality. In this article, we compared 5 well-known neural networks (Shallow ConvNet, Deep ConvNet, EEGNet, EEGNet Fusion, MI-EEGNet) using open-access databases with many subjects next to the BCI Competition 4 2a dataset to acquire statistically significant results. We removed artifacts from the EEG using the FASTER algorithm as a signal processing step. Moreover, we investigated whether transfer learning can further improve the classification results on artifact filtered data. We aimed to rank the neural networks; therefore, next to the classification accuracy, we introduced two additional metrics: the accuracy improvement from chance level and the effect of transfer learning. The former can be used with different class-numbered databases, while the latter can highlight neural networks with sufficient generalization abilities. Our metrics showed that the researchers should not avoid Shallow ConvNet and Deep ConvNet because they can perform better than the later published ones from the EEGNet family.|
|**2023-02-17**|**Sleep Model -- A Sequence Model for Predicting the Next Sleep Stage**|Iksoo Choi et.al.|[2302.12709v1](http://arxiv.org/abs/2302.12709v1)|null|As sleep disorders are becoming more prevalent there is an urgent need to classify sleep stages in a less disturbing way.In particular, sleep-stage classification using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical $n$-gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the $n$-gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.|
|**2023-02-09**|**Pressure-Poisson Equation in Numerical Simulation of Cerebral Arterial Circulation and Its Effect on the Electrical Conductivity of the Brain**|Maryam Samavaki et.al.|[2302.04814v3](http://arxiv.org/abs/2302.04814v3)|null|Background and Objective: This study considers dynamic modelling of the cerebral arterial circulation and reconstructing an atlas for the electrical conductivity of the brain. The conductivity is a governing parameter in several electrophysiological modalities such as electroencephalography (EEG) and transcranial electrical stimulation (tES). While high-resolution 7 Tesla Magnetic Resonance Imaging (MRI) data allows for reconstructing the cerebral arteries with a cross-sectional diameter larger than the voxel size, the conductivity cannot be directly inferred from MRI data. The state-of-the-art head models applied in EEG and tES typically associate each head tissue compartment with a constant conductivity, omitting any dynamical effects of cerebral circulation. Incorporating those effects poses the challenge of solving a system of incompressible Navier-Stokes equations (NSEs) in a realistic multi-compartment head model.   Methods: We propose that circulation in the distinguishable arteries can be estimated via the pressure Poisson equation (PPE). To establish a fluid exchange model between arteries and microarteries, a boundary condition derived from the Hagen-Poisseuille model is applied. The relationship between the estimated blood concentration and the tissue conductivity is approximated through Archie's law for fluid flow in porous media.   Results: Through the formulation of the PPE and a set of boundary conditions based on the Hagen-Poisseuille model, we obtained an equivalent formulation of the incompressible NSEs. Thus, allowing effective blood pressure estimation in cerebral arteries segmented from open 7 Tesla MRI data.   Conclusions: We developed and built a useful modeling framework that accounts for the effects of dynamic blood flow on a novel MRI-based conductivity atlas.|
|**2023-02-09**|**Classification of BCI-EEG based on augmented covariance matrix**|Igor Carrara et.al.|[2302.04508v1](http://arxiv.org/abs/2302.04508v1)|null|Objective: Electroencephalography signals are recorded as a multidimensional dataset. We propose a new framework based on the augmented covariance extracted from an autoregressive model to improve motor imagery classification. Methods: From the autoregressive model can be derived the Yule-Walker equations, which show the emergence of a symmetric positive definite matrix: the augmented covariance matrix. The state-of the art for classifying covariance matrices is based on Riemannian Geometry. A fairly natural idea is therefore to extend the standard approach using these augmented covariance matrices. The methodology for creating the augmented covariance matrix shows a natural connection with the delay embedding theorem proposed by Takens for dynamical systems. Such an embedding method is based on the knowledge of two parameters: the delay and the embedding dimension, respectively related to the lag and the order of the autoregressive model. This approach provides new methods to compute the hyper-parameters in addition to standard grid search. Results: The augmented covariance matrix performed noticeably better than any state-of-the-art methods. We will test our approach on several datasets and several subjects using the MOABB framework, using both within-session and cross-session evaluation. Conclusion: The improvement in results is due to the fact that the augmented covariance matrix incorporates not only spatial but also temporal information, incorporating nonlinear components of the signal through an embedding procedure, which allows the leveraging of dynamical systems algorithms. Significance: These results extend the concepts and the results of the Riemannian distance based classification algorithm.|
|**2023-02-06**|**First steps towards quantum machine learning applied to the classification of event-related potentials**|Grégoire Cattan et.al.|[2302.02648v1](http://arxiv.org/abs/2302.02648v1)|null|Low information transfer rate is a major bottleneck for brain-computer interfaces based on non-invasive electroencephalography (EEG) for clinical applications. This led to the development of more robust and accurate classifiers. In this study, we investigate the performance of quantum-enhanced support vector classifier (QSVC). Training (predicting) balanced accuracy of QSVC was 83.17 (50.25) %. This result shows that the classifier was able to learn from EEG data, but that more research is required to obtain higher predicting accuracy. This could be achieved by a better configuration of the classifier, such as increasing the number of shots.|

## huawei

### huawei watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-06**|**Minimizing Hitting Time between Disparate Groups with Shortcut Edges**|Florian Adriaens et.al.|[2306.03571v1](http://arxiv.org/abs/2306.03571v1)|null|Structural bias or segregation of networks refers to situations where two or more disparate groups are present in the network, so that the groups are highly connected internally, but loosely connected to each other. In many cases it is of interest to increase the connectivity of disparate groups so as to, e.g., minimize social friction, or expose individuals to diverse viewpoints. A commonly-used mechanism for increasing the network connectivity is to add edge shortcuts between pairs of nodes. In many applications of interest, edge shortcuts typically translate to recommendations, e.g., what video to watch, or what news article to read next. The problem of reducing structural bias or segregation via edge shortcuts has recently been studied in the literature, and random walks have been an essential tool for modeling navigation and connectivity in the underlying networks. Existing methods, however, either do not offer approximation guarantees, or engineer the objective so that it satisfies certain desirable properties that simplify the optimization~task. In this paper we address the problem of adding a given number of shortcut edges in the network so as to directly minimize the average hitting time and the maximum hitting time between two disparate groups. Our algorithm for minimizing average hitting time is a greedy bicriteria that relies on supermodularity. In contrast, maximum hitting time is not supermodular. Despite, we develop an approximation algorithm for that objective as well, by leveraging connections with average hitting time and the asymmetric k-center problem.|
|**2023-06-06**|**Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation**|Xiao Lin et.al.|[2306.03392v1](http://arxiv.org/abs/2306.03392v1)|null|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|
|**2023-06-01**|**GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception Tasks?**|Ning Ding et.al.|[2306.00693v2](http://arxiv.org/abs/2306.00693v2)|[link](https://github.com/huawei-noah/Efficient-Computing)|The recent upsurge in pre-trained large models (e.g. GPT-4) has swept across the entire deep learning community. Such powerful large language models (LLMs) demonstrate advanced generative ability and multimodal understanding capability, which quickly achieve new state-of-the-art performances on a variety of benchmarks. The pre-trained LLM usually plays the role as a universal AI model that can conduct various tasks, including context reasoning, article analysis and image content comprehension. However, considering the prohibitively high memory and computational cost for implementing such a large model, the conventional models (such as CNN and ViT), are still essential for many visual perception tasks. In this paper, we propose to enhance the representation ability of ordinary vision models for perception tasks (e.g. image classification) by taking advantage of large pre-trained models. We present a new learning paradigm in which the knowledge extracted from large pre-trained models are utilized to help models like CNN and ViT learn enhanced representations and achieve better performance. Firstly, we curate a high quality description set by prompting a multimodal LLM to generate descriptive text for all training images. Furthermore, we feed these detailed descriptions into a pre-trained encoder to extract text embeddings with rich semantic information that encodes the content of images. During training, text embeddings will serve as extra supervising signals and be aligned with image representations learned by vision models. The alignment process helps vision models learn better and achieve higher accuracy with the assistance of pre-trained LLMs. We conduct extensive experiments to verify that the proposed algorithm consistently improves the performance for various vision models with heterogeneous architectures.|
|**2023-06-01**|**MindBigData 2023 MNIST-8B The 8 billion datapoints Multimodal Dataset of Brain Signals**|David Vivancos et.al.|[2306.00455v1](http://arxiv.org/abs/2306.00455v1)|null|MindBigData 2023 MNIST-8B is the largest, to date (June 1st 2023), brain signals open dataset created for Machine Learning, based on EEG signals from a single subject captured using a custom 128 channels device, replicating the full 70,000 digits from Yaan LeCun et all MNIST dataset. The brain signals were captured while the subject was watching the pixels of the original digits one by one on a screen and listening at the same time to the spoken number 0 to 9 from the real label. The data, collection procedures, hardware and software created are described in detail, background extra information and other related datasets can be found at our previous paper MindBigData 2022: A Large Dataset of Brain Signals.|
|**2023-06-01**|**BiSync: A Bilingual Editor for Synchronized Monolingual Texts**|Josep Crego et.al.|[2306.00400v1](http://arxiv.org/abs/2306.00400v1)|[link](https://github.com/jmcrego/bisync)|In our globalized world, a growing number of situations arise where people are required to communicate in one or several foreign languages. In the case of written communication, users with a good command of a foreign language may find assistance from computer-aided translation (CAT) technologies. These technologies often allow users to access external resources, such as dictionaries, terminologies or bilingual concordancers, thereby interrupting and considerably hindering the writing process. In addition, CAT systems assume that the source sentence is fixed and also restrict the possible changes on the target side. In order to make the writing process smoother, we present BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. We also include additional functionalities, such as the display of alternative prefix translations and paraphrases, which are intended to facilitate the authoring of texts. We detail the model architecture used for synchronization and evaluate the resulting tool, showing that high accuracy can be attained with limited computational resources. The interface and models are publicly available at https://github.com/jmcrego/BiSync and a demonstration video can be watched on YouTube at https://youtu.be/_l-ugDHfNgU .|
|**2023-06-01**|**Example-based Motion Synthesis via Generative Motion Matching**|Weiyu Li et.al.|[2306.00378v1](http://arxiv.org/abs/2306.00378v1)|null|We present GenMM, a generative model that "mines" as many diverse motions as possible from a single or few example sequences. In stark contrast to existing data-driven methods, which typically require long offline training time, are prone to visual artifacts, and tend to fail on large and complex skeletons, GenMM inherits the training-free nature and the superior quality of the well-known Motion Matching method. GenMM can synthesize a high-quality motion within a fraction of a second, even with highly complex and large skeletal structures. At the heart of our generative framework lies the generative motion matching module, which utilizes the bidirectional visual similarity as a generative cost function to motion matching, and operates in a multi-stage framework to progressively refine a random guess using exemplar motion matches. In addition to diverse motion generation, we show the versatility of our generative framework by extending it to a number of scenarios that are not possible with motion matching alone, including motion completion, key frame-guided generation, infinite looping, and motion reassembly. Code and data for this paper are at https://wyysf-98.github.io/GenMM/|
|**2023-05-31**|**ReDSEa: Automated Acceleration of Triangular Solver on Supercloud Heterogeneous Systems**|Georgios Zacharopoulos et.al.|[2305.19917v1](http://arxiv.org/abs/2305.19917v1)|null|When utilized effectively, Supercloud heterogeneous systems have the potential to significantly enhance performance. Our ReDSEa tool-chain automates the mapping, load balancing, scheduling, parallelism, and overlapping processes for the Triangular System Solver (TS) on a heterogeneous system consisting of a Huawei Kunpeng ARM multi-core CPU and an Ascend 910 AI HW accelerator. We propose an LLVM compiler tool-chain that a) leverages compiler analysis and b) utilizes novel performance models exploring recursive, iterative, and blocked computation models. Our tool-chain facilitates a speedup of up to 16x compared to an optimized 48-core CPU-only implementation.|
|**2023-05-31**|**Few-Shot Speaker Identification Using Lightweight Prototypical Network with Feature Grouping and Interaction**|Yanxiong Li et.al.|[2305.19541v1](http://arxiv.org/abs/2305.19541v1)|null|Existing methods for few-shot speaker identification (FSSI) obtain high accuracy, but their computational complexities and model sizes need to be reduced for lightweight applications. In this work, we propose a FSSI method using a lightweight prototypical network with the final goal to implement the FSSI on intelligent terminals with limited resources, such as smart watches and smart speakers. In the proposed prototypical network, an embedding module is designed to perform feature grouping for reducing the memory requirement and computational complexity, and feature interaction for enhancing the representational ability of the learned speaker embedding. In the proposed embedding module, audio feature of each speech sample is split into several low-dimensional feature subsets that are transformed by a recurrent convolutional block in parallel. Then, the operations of averaging, addition, concatenation, element-wise summation and statistics pooling are sequentially executed to learn a speaker embedding for each speech sample. The recurrent convolutional block consists of a block of bidirectional long short-term memory, and a block of de-redundancy convolution in which feature grouping and interaction are conducted too. Our method is compared to baseline methods on three datasets that are selected from three public speech corpora (VoxCeleb1, VoxCeleb2, and LibriSpeech). The results show that our method obtains higher accuracy under several conditions, and has advantages over all baseline methods in computational complexity and model size.|
|**2023-05-30**|**AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation**|Chuhao Jin et.al.|[2305.18898v1](http://arxiv.org/abs/2305.18898v1)|null|We propose a novel framework for learning high-level cognitive capabilities in robot manipulation tasks, such as making a smiley face using building blocks. These tasks often involve complex multi-step reasoning, presenting significant challenges due to the limited paired data connecting human instructions (e.g., making a smiley face) and robot actions (e.g., end-effector movement). Existing approaches relieve this challenge by adopting an open-loop paradigm decomposing high-level instructions into simple sub-task plans, and executing them step-by-step using low-level control models. However, these approaches are short of instant observations in multi-step reasoning, leading to sub-optimal results. To address this issue, we propose to automatically collect a cognitive robot dataset by Large Language Models (LLMs). The resulting dataset AlphaBlock consists of 35 comprehensive high-level tasks of multi-step text plans and paired observation sequences. To enable efficient data acquisition, we employ elaborated multi-round prompt designs that effectively reduce the burden of extensive human involvement. We further propose a closed-loop multi-modal embodied planning model that autoregressively generates plans by taking image observations as input. To facilitate effective learning, we leverage MiniGPT-4 with a frozen visual encoder and LLM, and finetune additional vision adapter and Q-former to enable fine-grained spatial perception for manipulation tasks. We conduct experiments to verify the superiority over existing open and closed-loop methods, and achieve a significant increase in success rate by 21.4% and 14.5% over ChatGPT and GPT-4 based robot tasks. Real-world demos are shown in https://www.youtube.com/watch?v=ayAzID1_qQk .|
|**2023-05-29**|**minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts, Transitivities, and Lattices**|Animesh Chaturvedi et.al.|[2305.17984v1](http://arxiv.org/abs/2305.17984v1)|null|Hate speech classification has become an important problem due to the spread of hate speech on social media platforms. For a given set of Hate Terms lists (HTs-lists) and Hate Speech data (HS-data), it is challenging to understand which hate term contributes the most for hate speech classification. This paper contributes two approaches to quantitatively measure and qualitatively visualise the relationship between co-occurring Hate Terms (HTs). Firstly, we propose an approach for the classification of hate-speech by producing a Severe Hate Terms list (Severe HTs-list) from existing HTs-lists. To achieve our goal, we proposed three metrics (Hatefulness, Relativeness, and Offensiveness) to measure the severity of HTs. These metrics assist to create an Inter-agreement HTs-list, which explains the contribution of an individual hate term toward hate speech classification. Then, we used the Offensiveness metric values of HTs above a proposed threshold minimum Offense (minOffense) to generate a new Severe HTs-list. To evaluate our approach, we used three hate speech datasets and six hate terms lists. Our approach shown an improvement from 0.845 to 0.923 (best) as compared to the baseline. Secondly, we also proposed Stable Hate Rule (SHR) mining to provide ordered co-occurrence of various HTs with minimum Stability (minStab). The SHR mining detects frequently co-occurring HTs to form Stable Hate Rules and Concepts. These rules and concepts are used to visualise the graphs of Transitivities and Lattices formed by HTs.|
|**2023-05-29**|**Bayesian feedback in the framework of ecological sciences**|Mario Figueira-Pereira et.al.|[2305.17922v1](http://arxiv.org/abs/2305.17922v1)|null|In ecology we may find scenarios where the same phenomenon (species occurrence, species abundance, etc.) is observed using two different types of samplers. For instance, species data can be collected from scientific surveys with a completely random sample pattern, but also from opportunistic sampling (e.g., whale or bird watching fishery commercial vessels), in which observers tend to look for a specific species in areas where they expect to find it.   Species Distribution Models (SDMs) are a widely used tool for analyzing this kind of ecological data. Specifically, we have two models available for the above data: an independent model (IM) for the data coming from a complete random sampler and a dependent model (DM) for data from opportunistic sampling.   In this work, we propose a sequential Bayesian procedure to connect these two models through the update of prior distributions. Implementation of the Bayesian paradigm is done through the integrated nested Laplace approximation (INLA) methodology, a good option to make inference and prediction in spatial models with high performance and low computational costs. This sequential approach has been evaluated by simulating several scenarios and comparing the results of sharing information from one model to another using different criteria.   Our main results imply that, in general, it is better to share information from the independent (completely random) to the dependent model than the alternative way. However, it depends on different factors such as the spatial range or the spatial arrangement of sampling locations.|
|**2023-05-26**|**DES Y3 + KiDS-1000: Consistent cosmology combining cosmic shear surveys**|Dark Energy Survey et.al.|[2305.17173v1](http://arxiv.org/abs/2305.17173v1)|null|We present a joint cosmic shear analysis of the Dark Energy Survey (DES Y3) and the Kilo-Degree Survey (KiDS-1000) in a collaborative effort between the two survey teams. We find consistent cosmological parameter constraints between DES Y3 and KiDS-1000 which, when combined in a joint-survey analysis, constrain the parameter $S_8 = \sigma_8 \sqrt{\Omega_{\rm m}/0.3}$ with a mean value of $0.790^{+0.018}_{-0.014}$. The mean marginal is lower than the maximum a posteriori estimate, $S_8=0.801$, owing to skewness in the marginal distribution and projection effects in the multi-dimensional parameter space. Our results are consistent with $S_8$ constraints from observations of the cosmic microwave background by Planck, with agreement at the $1.7\sigma$ level. We use a Hybrid analysis pipeline, defined from a mock survey study quantifying the impact of the different analysis choices originally adopted by each survey team. We review intrinsic alignment models, baryon feedback mitigation strategies, priors, samplers and models of the non-linear matter power spectrum.|
|**2023-05-26**|**Regular access to constantly renewed online content favors radicalization of opinions**|Guillaume Deffuant et.al.|[2305.16855v1](http://arxiv.org/abs/2305.16855v1)|null|Worry over polarization has grown alongside the digital information consumption revolution. Where most scientific work considered user-generated and user-disseminated (i.e.,~Web 2.0) content as the culprit, the potential of purely increased access to information (or Web 1.0) has been largely overlooked. Here, we suggest that the shift to Web 1.0 alone could include a powerful mechanism of belief extremization. We study an empirically calibrated persuasive argument model with confirmation bias. We compare an offline setting -- in which a limited number of arguments is broadcast by traditional media -- with an online setting -- in which the agent can choose to watch contents within a very wide set of possibilities. In both cases, we assume that positive and negative arguments are balanced. The simulations show that the online setting leads to significantly more extreme opinions and amplifies initial prejudice.|
|**2023-05-25**|**Break-A-Scene: Extracting Multiple Concepts from a Single Image**|Omri Avrahami et.al.|[2305.16311v1](http://arxiv.org/abs/2305.16311v1)|null|Text-to-image model personalization aims to introduce a user-provided concept to the model, allowing its synthesis in diverse contexts. However, current methods primarily focus on the case of learning a single concept from multiple images with variations in backgrounds and poses, and struggle when adapted to a different scenario. In this work, we introduce the task of textual scene decomposition: given a single image of a scene that may contain several concepts, we aim to extract a distinct text token for each concept, enabling fine-grained control over the generated scenes. To this end, we propose augmenting the input image with masks that indicate the presence of target concepts. These masks can be provided by the user or generated automatically by a pre-trained segmentation model. We then present a novel two-phase customization process that optimizes a set of dedicated textual embeddings (handles), as well as the model weights, striking a delicate balance between accurately capturing the concepts and avoiding overfitting. We employ a masked diffusion loss to enable handles to generate their assigned concepts, complemented by a novel loss on cross-attention maps to prevent entanglement. We also introduce union-sampling, a training strategy aimed to improve the ability of combining multiple concepts in generated images. We use several automatic metrics to quantitatively compare our method against several baselines, and further affirm the results using a user study. Finally, we showcase several applications of our method. Project page is available at: https://omriavrahami.com/break-a-scene/|
|**2023-05-25**|**PDE+: Enhancing Generalization via PDE with Adaptive Distributional Diffusion**|Yige Yuan et.al.|[2305.15835v1](http://arxiv.org/abs/2305.15835v1)|null|The generalization of neural networks is a central challenge in machine learning, especially concerning the performance under distributions that differ from training ones. Current methods, mainly based on the data-driven paradigm such as data augmentation, adversarial training, and noise injection, may encounter limited generalization due to model non-smoothness. In this paper, we propose to investigate generalization from a Partial Differential Equation (PDE) perspective, aiming to enhance it directly through the underlying function of neural networks, rather than focusing on adjusting input data. Specifically, we first establish the connection between neural network generalization and the smoothness of the solution to a specific PDE, namely ``transport equation''. Building upon this, we propose a general framework that introduces adaptive distributional diffusion into transport equation to enhance the smoothness of its solution, thereby improving generalization. In the context of neural networks, we put this theoretical framework into practice as PDE+ (\textbf{PDE} with \textbf{A}daptive \textbf{D}istributional \textbf{D}iffusion) which diffuses each sample into a distribution covering semantically similar inputs. This enables better coverage of potentially unobserved distributions in training, thus improving generalization beyond merely data-driven methods. The effectiveness of PDE+ is validated in extensive settings, including clean samples and various corruptions, demonstrating its superior performance compared to SOTA methods.|
|**2023-05-25**|**IDEA: Invariant Causal Defense for Graph Adversarial Robustness**|Shuchang Tao et.al.|[2305.15792v1](http://arxiv.org/abs/2305.15792v1)|null|Graph neural networks (GNNs) have achieved remarkable success in various tasks, however, their vulnerability to adversarial attacks raises concerns for the real-world applications. Existing defense methods can resist some attacks, but suffer unbearable performance degradation under other unknown attacks. This is due to their reliance on either limited observed adversarial examples to optimize (adversarial training) or specific heuristics to alter graph or model structures (graph purification or robust aggregation). In this paper, we propose an Invariant causal DEfense method against adversarial Attacks (IDEA), providing a new perspective to address this issue. The method aims to learn causal features that possess strong predictability for labels and invariant predictability across attacks, to achieve graph adversarial robustness. Through modeling and analyzing the causal relationships in graph adversarial attacks, we design two invariance objectives to learn the causal features. Extensive experiments demonstrate that our IDEA significantly outperforms all the baselines under both poisoning and evasion attacks on five benchmark datasets, highlighting the strong and invariant predictability of IDEA. The implementation of IDEA is available at https://anonymous.4open.science/r/IDEA_repo-666B.|
|**2023-05-24**|**Large Language Models for User Interest Journeys**|Konstantina Christakopoulou et.al.|[2305.15498v1](http://arxiv.org/abs/2305.15498v1)|null|Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation. Their potential for deeper user understanding and improved personalized user experience on recommendation platforms is, however, largely untapped. This paper aims to address this gap. Recommender systems today capture users' interests through encoding their historical activities on the platforms. The generated user representations are hard to examine or interpret. On the other hand, if we were to ask people about interests they pursue in their life, they might talk about their hobbies, like I just started learning the ukulele, or their relaxation routines, e.g., I like to watch Saturday Night Live, or I want to plant a vertical garden. We argue, and demonstrate through extensive experiments, that LLMs as foundation models can reason through user activities, and describe their interests in nuanced and interesting ways, similar to how a human would.   We define interest journeys as the persistent and overarching user interests, in other words, the non-transient ones. These are the interests that we believe will benefit most from the nuanced and personalized descriptions. We introduce a framework in which we first perform personalized extraction of interest journeys, and then summarize the extracted journeys via LLMs, using techniques like few-shot prompting, prompt-tuning and fine-tuning. Together, our results in prompting LLMs to name extracted user journeys in a large-scale industrial platform demonstrate great potential of these models in providing deeper, more interpretable, and controllable user understanding. We believe LLM powered user understanding can be a stepping stone to entirely new user experiences on recommendation platforms that are journey-aware, assistive, and enabling frictionless conversation down the line.|
|**2023-05-24**|**LLMDet: A Large Language Models Detection Tool**|Kangxi Wu et.al.|[2305.15004v1](http://arxiv.org/abs/2305.15004v1)|[link](https://github.com/trustedllm/llmdet)|With the advancement of generative language models, the generated text has come remarkably close to high-quality human-authored text in terms of fluency and diversity. This calls for a highly practical detection tool that can identify the source of text, preferably pinpointing the language model it originates from. However, existing detection tools typically require access to language models and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of rapid detection and text tracing. Therefore, in this paper, we propose an efficient, secure, and scalable detection tool called LLMDet, which calculates the proxy perplexity of text by utilizing the prior information of the model's next-token probabilities, obtained through pre-training. Subsequently, we use the self-watermarking information of the model, as measured by proxy perplexity, to detect the source of the text. We found that our method demonstrates impressive detection performance while ensuring speed and security, particularly achieving a recognition accuracy of 97.97\% for human-authored text. Furthermore, our detection tool also shows promising results in identifying the large language model (e.g., GPT-2, OPT, LLaMA, Vicuna...) responsible for the text. We release the code and processed data at \url{https://github.com/TrustedLLM/LLMDet}.|
|**2023-05-24**|**Constraints on black hole charges in M87* and Sgr A* with the EHT observations**|Alexander F. Zakharov et.al.|[2305.15446v1](http://arxiv.org/abs/2305.15446v1)|null|In May 2022 ICRANet organized the Workshop dedicated to the 80th anniversary of Professor Ruffini. This paper is based on the talk delivered at the meeting.   Professor Ruffini was well known for Soviet scientific community not only due to his publications in leading journals but also due Russian translations of his books where he was an author or a contributor in collection of articles.   But only in 1988 I had an opportunity to watch and listen professor R. Ruffini at the Conference dedicated to the century since the birthday of Alexander Alexandrovich Friedmann. This conference was organized in Leningrad (Soviet Union) in June during a short magic period when there are white nights there. In June 2023 we celebrate the 135th anniversary of Friedmann's birth. Friedmann and his closed friend V. K. Frederics were the founders of Soviet school of general relativity and George Gamow was one of the brilliant representative of the school and he was the author of the hot Universe model which is the most popular now. In the USSR a development of general relativity and relativistic cosmology was not smooth and only in sixties of the last century these branches of science freed from the total control of representatives of the ideology of Marxism -- Leninism. I also discussed a Soviet contribution in a discovery of cosmic microwave background radiation done by T. Shmaonov in 1957 and reasons why his supervisors did not connect these results with the hot Universe models discussed by G. Gamow. Author's results about observational features of supemassive black holes (including the black hole in our Galactic Center) are also briefly discussed, it was considered   an opportunity to evaluate a (tidal) charge of Reissner -- Nordstr\"om black hole from observational estimates of shadow size in the Galactic Center and M87* done by the EHT Collaboration based its observations in April 2017.|
|**2023-05-22**|**pytest-inline: An Inline Testing Tool for Python**|Yu Liu et.al.|[2305.13486v1](http://arxiv.org/abs/2305.13486v1)|[link](https://github.com/pytest-dev/pytest-inline)|We present pytest-inline, the first inline testing framework for Python. We recently proposed inline tests to make it easier to test individual program statements. But, there is no framework-level support for developers to write inline tests in Python. To fill this gap, we design and implement pytest-inline as a plugin for pytest, the most popular Python testing framework. Using pytest-inline, a developer can write an inline test by assigning test inputs to variables in a target statement and specifying the expected test output. Then, pytest-inline runs each inline test and fails if the target statement's output does not match the expected output. In this paper, we describe our design of pytest-inline, the testing features that it provides, and the intended use cases. Our evaluation on inline tests that we wrote for 80 target statements from 31 open-source Python projects shows that using pytest-inline incurs negligible overhead, at 0.012x. pytest-inline is integrated into the pytest-dev organization, and a video demo is at https://www.youtube.com/watch?v=pZgiAxR_uJg.|
|**2023-05-22**|**VanillaNet: the Power of Minimalism in Deep Learning**|Hanting Chen et.al.|[2305.12972v2](http://arxiv.org/abs/2305.12972v2)|[link](https://github.com/huawei-noah/vanillanet)|At the heart of foundation models is the philosophy of "more is different", exemplified by the astonishing success in computer vision and natural language processing. However, the challenges of optimization and inherent complexity of transformer models call for a paradigm shift towards simplicity. In this study, we introduce VanillaNet, a neural network architecture that embraces elegance in design. By avoiding high depth, shortcuts, and intricate operations like self-attention, VanillaNet is refreshingly concise yet remarkably powerful. Each layer is carefully crafted to be compact and straightforward, with nonlinear activation functions pruned after training to restore the original architecture. VanillaNet overcomes the challenges of inherent complexity, making it ideal for resource-constrained environments. Its easy-to-understand and highly simplified architecture opens new possibilities for efficient deployment. Extensive experimentation demonstrates that VanillaNet delivers performance on par with renowned deep neural networks and vision transformers, showcasing the power of minimalism in deep learning. This visionary journey of VanillaNet has significant potential to redefine the landscape and challenge the status quo of foundation model, setting a new path for elegant and effective model design. Pre-trained models and codes are available at https://github.com/huawei-noah/VanillaNet and https://gitee.com/mindspore/models/tree/master/research/cv/vanillanet.|
|**2023-05-22**|**MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space**|Hanxing Ding et.al.|[2305.12785v1](http://arxiv.org/abs/2305.12785v1)|null|Multi-aspect controllable text generation aims to generate fluent sentences that possess multiple desired attributes simultaneously. Traditional methods either combine many operators in the decoding stage, often with costly iteration or search in the discrete text space, or train separate controllers for each aspect, resulting in a degeneration of text quality due to the discrepancy between different aspects. To address these limitations, we introduce a novel approach for multi-aspect control, namely MacLaSa, that estimates compact latent space for multiple aspects and performs efficient sampling with a robust sampler based on ordinary differential equations (ODEs). To eliminate the domain gaps between different aspects, we utilize a Variational Autoencoder (VAE) network to map text sequences from varying data sources into close latent representations. The estimated latent space enables the formulation of joint energy-based models (EBMs) and the plugging in of arbitrary attribute discriminators to achieve multi-aspect control. Afterwards, we draw latent vector samples with an ODE-based sampler and feed sampled examples to the VAE decoder to produce target text sequences. Experimental results demonstrate that MacLaSa outperforms several strong baselines on attribute relevance and textual quality while maintaining a high inference speed.|
|**2023-05-20**|**Inferring Attracting Basins of Power System with Machine Learning**|Yao Du et.al.|[2305.14374v1](http://arxiv.org/abs/2305.14374v1)|null|Power systems dominated by renewable energy encounter frequently large, random disturbances, and a critical challenge faced in power-system management is how to anticipate accurately whether the perturbed systems will return to the functional state after the transient or collapse. Whereas model-based studies show that the key to addressing the challenge lies in the attracting basins of the functional and dysfunctional states in the phase space, the finding of the attracting basins for realistic power systems remains a challenge, as accurate models describing the system dynamics are generally unavailable. Here we propose a new machine learning technique, namely balanced reservoir computing, to infer the attracting basins of a typical power system based on measured data. Specifically, trained by the time series of a handful of perturbation events, we demonstrate that the trained machine can predict accurately whether the system will return to the functional state in response to a large, random perturbation, thereby reconstructing the attracting basin of the functional state. The working mechanism of the new machine is analyzed, and it is revealed that the success of the new machine is attributed to the good balance between the echo and fading properties of the reservoir network; the effect of noisy signals on the prediction performance is also investigated, and a stochastic-resonance-like phenomenon is observed. Finally, we demonstrate that the new technique can be also utilized to infer the attracting basins of coexisting attractors in typical chaotic systems.|
|**2023-05-20**|**Efficient Multimodal Neural Networks for Trigger-less Voice Assistants**|Sai Srujana Buddi et.al.|[2305.12063v1](http://arxiv.org/abs/2305.12063v1)|null|The adoption of multimodal interactions by Voice Assistants (VAs) is growing rapidly to enhance human-computer interactions. Smartwatches have now incorporated trigger-less methods of invoking VAs, such as Raise To Speak (RTS), where the user raises their watch and speaks to VAs without an explicit trigger. Current state-of-the-art RTS systems rely on heuristics and engineered Finite State Machines to fuse gesture and audio data for multimodal decision-making. However, these methods have limitations, including limited adaptability, scalability, and induced human biases. In this work, we propose a neural network based audio-gesture multimodal fusion system that (1) Better understands temporal correlation between audio and gesture data, leading to precise invocations (2) Generalizes to a wide range of environments and scenarios (3) Is lightweight and deployable on low-power devices, such as smartwatches, with quick launch times (4) Improves productivity in asset development processes.|
|**2023-05-20**|**DADIN: Domain Adversarial Deep Interest Network for Cross Domain Recommender Systems**|Menglin Kong et.al.|[2305.12058v1](http://arxiv.org/abs/2305.12058v1)|null|Click-Through Rate (CTR) prediction is one of the main tasks of the recommendation system, which is conducted by a user for different items to give the recommendation results. Cross-domain CTR prediction models have been proposed to overcome problems of data sparsity, long tail distribution of user-item interactions, and cold start of items or users. In order to make knowledge transfer from source domain to target domain more smoothly, an innovative deep learning cross-domain CTR prediction model, Domain Adversarial Deep Interest Network (DADIN) is proposed to convert the cross-domain recommendation task into a domain adaptation problem. The joint distribution alignment of two domains is innovatively realized by introducing domain agnostic layers and specially designed loss, and optimized together with CTR prediction loss in a way of adversarial training. It is found that the Area Under Curve (AUC) of DADIN is 0.08% higher than the most competitive baseline on Huawei dataset and is 0.71% higher than its competitors on Amazon dataset, achieving the state-of-the-art results on the basis of the evaluation of this model performance on two real datasets. The ablation study shows that by introducing adversarial method, this model has respectively led to the AUC improvements of 2.34% on Huawei dataset and 16.67% on Amazon dataset.|
|**2023-05-19**|**Quantifying stimulus-relevant representational drift using cross-modality contrastive learning**|Siwei Wang et.al.|[2305.11953v1](http://arxiv.org/abs/2305.11953v1)|null|The representational drift observed in neural populations raises serious questions about how accurate decoding survives these changes. In primary visual cortex, it is hotly debated whether such variation is a direct tuning shift that would corrupt decoding or if it can be explained by changes in behavioral or internal state, which could be compensated by joint encoding of the stimulus and the state. We estimate the effects of stimulus-relevant representational drift on decoding using a publicly accessible dataset of mouse V1 responses to a natural movie. Because the only invariant component of the sensory experience across all 24 animals is that they all watch the same natural movie, we can learn a subject-invariant efficient neural representation that retains only stimulus-relevant components. We use contrastive learning between the neural response and the stimulus to learn a neural representation for stimulus-relevant features. This learned representation minimizes decoding error as quantified by Bayes risk. We show that it can be used to read out behaviorally relevant stimulus features (time, static scene, optic flow, and joint spatio-temporal features) at 33ms resolution accurately, a finer timescale than what has previously been explored. When we use the model trained on one recording session to derive feature activations on another, decoding performance is reduced by approximately $40\%$. Motion encoding is most susceptible to representational drift. In addition, when we enlarge the error tolerance window to 1sec, we recover stable stimulus encoding across sessions, echoing previous findings. This shows that decoding stimulus features that vary on fast timescales may require complex computation downstream of V1 to compensate for representational drift.|
|**2023-05-18**|**SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation**|Junkai Zhou et.al.|[2305.11130v2](http://arxiv.org/abs/2305.11130v2)|null|Language models trained on large-scale corpora can generate remarkably fluent results in open-domain dialogue. However, for the persona-based dialogue generation task, consistency and coherence are also key factors, which are great challenges for language models. Existing works mainly focus on valuable data filtering, model structure modifying, or objective function designing, while their improvements are limited and hard to generalize to all types of pre-trained language models. However, we find that language models can produce consistent and coherent responses if we consider enough generations. Thus, the problems lay in large-scale response generation and target response selection. In this work, a simple but effective two-stage SimOAP strategy is proposed, i.e., over-sampling and post-evaluation. The over-sampling stage takes large-scale responses from existing trained models efficiently via off-the-shelf distilling and compressing methods, and the post-evaluation stage selects a good response based on multiple well-designed evaluation metrics from large-scale candidates. Experimental results show that the proposed plug-in SimOAP strategy improves the backbone models and outperforms the baseline strategies in both automatic and human evaluations.|
|**2023-05-18**|**XFormer: Fast and Accurate Monocular 3D Body Capture**|Lihui Qian et.al.|[2305.11101v1](http://arxiv.org/abs/2305.11101v1)|null|We present XFormer, a novel human mesh and motion capture method that achieves real-time performance on consumer CPUs given only monocular images as input. The proposed network architecture contains two branches: a keypoint branch that estimates 3D human mesh vertices given 2D keypoints, and an image branch that makes predictions directly from the RGB image features. At the core of our method is a cross-modal transformer block that allows information to flow across these two branches by modeling the attention between 2D keypoint coordinates and image spatial features. Our architecture is smartly designed, which enables us to train on various types of datasets including images with 2D/3D annotations, images with 3D pseudo labels, and motion capture datasets that do not have associated images. This effectively improves the accuracy and generalization ability of our system. Built on a lightweight backbone (MobileNetV3), our method runs blazing fast (over 30fps on a single CPU core) and still yields competitive accuracy. Furthermore, with an HRNet backbone, XFormer delivers state-of-the-art performance on Huamn3.6 and 3DPW datasets.|
|**2023-05-18**|**BERM: Training the Balanced and Extractable Representation for Matching to Improve Generalization Ability of Dense Retrieval**|Shicheng Xu et.al.|[2305.11052v1](http://arxiv.org/abs/2305.11052v1)|null|Dense retrieval has shown promise in the first-stage retrieval process when trained on in-domain labeled datasets. However, previous studies have found that dense retrieval is hard to generalize to unseen domains due to its weak modeling of domain-invariant and interpretable feature (i.e., matching signal between two texts, which is the essence of information retrieval). In this paper, we propose a novel method to improve the generalization of dense retrieval via capturing matching signal called BERM. Fully fine-grained expression and query-oriented saliency are two properties of the matching signal. Thus, in BERM, a single passage is segmented into multiple units and two unit-level requirements are proposed for representation as the constraint in training to obtain the effective matching signal. One is semantic unit balance and the other is essential matching unit extractability. Unit-level view and balanced semantics make representation express the text in a fine-grained manner. Essential matching unit extractability makes passage representation sensitive to the given query to extract the pure matching information from the passage containing complex context. Experiments on BEIR show that our method can be effectively combined with different dense retrieval training methods (vanilla, hard negatives mining and knowledge distillation) to improve its generalization ability without any additional inference overhead and target domain data.|
|**2023-05-18**|**A Virtual Reality Teleoperation Interface for Industrial Robot Manipulators**|Eric Rosen et.al.|[2305.10960v1](http://arxiv.org/abs/2305.10960v1)|null|We address the problem of teleoperating an industrial robot manipulator via a commercially available Virtual Reality (VR) interface. Previous works on VR teleoperation for robot manipulators focus primarily on collaborative or research robot platforms (whose dynamics and constraints differ from industrial robot arms), or only address tasks where the robot's dynamics are not as important (e.g: pick and place tasks). We investigate the usage of commercially available VR interfaces for effectively teleoeprating industrial robot manipulators in a variety of contact-rich manipulation tasks. We find that applying standard practices for VR control of robot arms is challenging for industrial platforms because torque and velocity control is not exposed, and position control is mediated through a black-box controller. To mitigate these problems, we propose a simplified filtering approach to process command signals to enable operators to effectively teleoperate industrial robot arms with VR interfaces in dexterous manipulation tasks. We hope our findings will help robot practitioners implement and setup effective VR teleoperation interfaces for robot manipulators. The proposed method is demonstrated on a variety of contact-rich manipulation tasks which can also involve very precise movement of the robot during execution (videos can be found at https://www.youtube.com/watch?v=OhkCB9mOaBc)|

### huawei band
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Scalar curvature rigidity of degenerate warped product spaces**|Jinmin Wang et.al.|[2306.05413v1](http://arxiv.org/abs/2306.05413v1)|null|In this paper we prove the scalar curvature extremality and rigidity for a class of warped product spaces that are possibly degenerate at the two ends. The leaves of these warped product spaces can be any closed Riemannian manifold with nonnegative curvature operator and nonvanishing Euler characteristic, flat tori, round spheres and their direct products. In particular, we obtain the scalar curvature extremality and rigidity for certain degenerate toric bands and also for round spheres with two antipodal points removed. This answers the corresponding questions of Gromov in all dimensions.|
|**2023-06-08**|**Rate Forecaster based Energy Aware Band Assignment in Multiband Networks**|Brijesh Soni et.al.|[2306.05369v1](http://arxiv.org/abs/2306.05369v1)|null|The high frequency communication bands (mmWave and sub-THz) promise tremendous data rates, however, they also have very high power consumption which is particularly significant for battery-power-limited user-equipment (UE). In this context, we design an energy aware band assignment system which reduces the power consumption while also achieving a target sum rate of M in T time-slots. We do this by using 1) Rate forecaster(s); 2) Channel forecaster(s) which forecasts T direct multistep ahead using a stacked (long short term memory) LSTM architecture. We propose an iterative rate updating algorithm which updates the target rate based on current rate and future predicted rates in a frame. The proposed approach is validated on the publicly available `DeepMIMO' dataset. Research findings shows that the rate forecaster based approach performs better than the channel forecaster. Furthermore, LSTM based predictions outperforms well celebrated Transformer predictions in terms of NRMSE and NMAE. Research findings reveals that the power consumption with this approach is ~ 300 mW lower compared to a greedy band assignment at a 1.5Gb/s target rate.|
|**2023-06-08**|**Olympicene radicals as building blocks of two-dimensional anisotropic networks**|Ricardo Ortiz et.al.|[2306.05346v1](http://arxiv.org/abs/2306.05346v1)|null|I propose monoradical nanographenes without C3 symmetry as building blocks to design two-dimensional (2D) carbon crystals. As representative examples I study the honeycomb and Kagome lattices, showing that by replacing the sites with olympicene radicals the band dispersion near the Fermi energy corresponds, respectively, to that of Kekul\'e/anti-Kekul\'e graphene and breathing Kagome tight-binding models. As a consequence, finite islands of these new crystals present corner states close to the Fermi energy, just like the parent models. In the case of Kekul\'e/anti-Kekul\'e graphene, such states are topologically protected, standing as examples of second-order topological insulators with a non-zero Z2- or Z6-Berry phase. Differently, those of the breathing Kagome lattice are of trivial nature, but the ground state has been predicted to be a spin liquid in the antiferromagnetic Heisenberg model. Hence, 2D systems made of low-symmetric nanographenes may be convenient platforms to explore exotic physics in carbon materials.|
|**2023-06-08**|**The Star-forming and Ionizing Properties of Dwarf z~6-9 Galaxies in JADES: Insights on Bursty Star Formation and Ionized Bubble Growth**|Ryan Endsley et.al.|[2306.05295v1](http://arxiv.org/abs/2306.05295v1)|null|Reionization is thought to be driven by faint star-forming galaxies, but characterizing this population in detail has long remained very challenging. Here we utilize deep nine-band NIRCam imaging from JADES to study the star-forming and ionizing properties of 756 $z\sim6-9$ galaxies, including hundreds of very UV-faint objects ($M_\mathrm{UV}>-18$). The faintest ($m\sim30$) galaxies in our sample typically have stellar masses of $M_\ast\sim(1-3)\times10^7$ $M_\odot$ and young light-weighted ages ($\sim$50 Myr), though some show strong Balmer breaks implying much older ages ($\sim$500 Myr). We find no evidence for extremely massive galaxies ($>3\times10^{10}$ $M_\odot$) in our sample. We infer a strong (factor $>$2) decline in the typical [OIII]$+$H$\beta$ EWs towards very faint $z\sim6-9$ galaxies, yet a weak UV luminosity dependence on the H$\alpha$ EWs at $z\sim6$. We demonstrate that these EW trends can be explained if fainter galaxies have systematically lower metallicities as well as more recently-declining star formation histories relative to the most UV-luminous galaxies in our sample. Our data provide evidence that the brightest galaxies are frequently experiencing a recent strong upturn in SFR. We also discuss how the EW trends may be influenced by a strong correlation between $M_\mathrm{UV}$ and Lyman continuum escape fraction. This alternative explanation has dramatically different implications for the contribution of galaxies along the luminosity function to cosmic reionization, highlighting the need for deep spectroscopic follow-up. Finally, we quantify the photometric overdensities around two $z>7$ strong Ly$\alpha$ emitters in the JADES footprint. One Ly$\alpha$ emitter lies close to a strong photometric overdensity while the other shows no significant nearby overdensity, perhaps implying that not all strong $z>7$ Ly$\alpha$ emitters reside in large ionized bubbles.|
|**2023-06-08**|**Solitons induced by an in-plane magnetic field in rhombohedral multilayer graphene**|Max Tymczyszyn et.al.|[2306.05237v1](http://arxiv.org/abs/2306.05237v1)|null|We model the influence of an in-plane magnetic field on the orbital motion of electrons in rhombohedral graphene multilayers. For zero field, the low-energy band structure includes a pair of flat bands near zero energy which are localized on the surface layers of a finite thin film. For finite field, we find that the zero-energy bands persist and that level bifurcations occur at energies determined by the component of the in-plane wave vector $q$ that is parallel to the external field. The occurrence of level bifurcations is explained by invoking semiclassical quantization of the zero field Fermi surface of rhombohedral graphite. We find parameter regions with a single isoenergetic contour of Berry phase zero corresponding to a conventional Landau level spectrum and regions with two isoenergetic contours, each of Berry phase $\pi$, corresponding to a Dirac-like spectrum of levels. We write down an analogous one-dimensional tight-binding model and relate the persistence of the zero-energy bands in large magnetic fields to a soliton texture supporting zero-energy states in the Su-Schreiffer-Heeger model. We show that different states contributing to the zero-energy flat bands in rhombohedral graphene multilayers in a large field, as determined by the wave vector $q$, are localized on different bulk layers of the system, not just the surfaces.|
|**2023-06-08**|**Wannier-Stark localization in one-dimensional amplitude-chirped lattices**|Qi-Bo Zeng et.al.|[2306.05193v1](http://arxiv.org/abs/2306.05193v1)|null|We study the Wannier-Stark (WS) localization in one-dimensional amplitude-chirped lattices with the $j$th onsite potential modulated by a function $Fj\cos(2\pi \alpha j)$, where $F$ is the external field with a period determined by $\alpha=p/q$ ($p$ and $q$ are co-prime integers). In the Hermitian (or non-Hermitian) systems with real (or imaginary) fields, we can obtain real (or imaginary) WS ladders in the eigenenergy spectrum. In most cases with $q \geq 2$, there are multiple WS ladders with all the eigenstates localized in the strong field limit. However, in the lattices with $q=4$, the energy-dependent localization phenomenon emerges due to the competition between spatially periodic and linearly increasing behaviors in the onsite potential. About half the number of eigenstates are gathered at the band center and can extend over a wide region or even the full range of the lattice, even when the field becomes very strong. Moreover, in the non-Hermitian lattices with odd $q$, some of the WS ladders become doubly degenerate, where the eigenstates are evenly distributed at two neighboring sites in a wide regime of field strength. Our work opens an avenue for exploring WS localization in both Hermitian and non-Hermitian amplitude-chirped lattices.|
|**2023-06-08**|**Straintronics in Phosphorene: Tensile vs Shear Strains and Their Combinations for Manipulating the Band Gap**|Anastasiia G. Solomenko et.al.|[2306.05163v1](http://arxiv.org/abs/2306.05163v1)|null|We study the effects of the uniaxial tensile strain and shear deformation as well as their combinations on the electronic properties of single-layer black phosphorene. The evolutions of the strain-dependent band gap are obtained using the numerical calculations within the tight-binding (TB) model as well as the first-principles (DFT) simulations and compared with previous findings. The TB-model-based findings show that the band gap of the strain-free phosphorene agrees with the experimental value and linearly depends on both stretching and shearing: increases (decreases) as the stretching increases (decreases), whereas gradually decreases with increasing the shear. A linear dependence is less or more similar as compared to that obtained from the ab initio simulations for shear strain, however disagrees with a non-monotonic behaviour from the DFT-based calculations for tensile strain. Possible reasons for the discrepancy are discussed. In case of a combined deformation, when both strain types (tensile/compression + shear) are loaded simultaneously, their mutual influence extends the realizable band gap range: from zero up to the values respective to the wide-band-gap semiconductors. At a switched-on combined strain, the semiconductor-semimetal phase transition in the phosphorene is reachable at a weaker (strictly non-destructive) strain, which contributes to progress in fundamental and breakthroughs.|
|**2023-06-08**|**Engineering flat bands in twisted-bilayer graphene away from the magic angle with chiral optical cavities**|Cunyuan Jiang et.al.|[2306.05149v1](http://arxiv.org/abs/2306.05149v1)|null|Twisted bilayer graphene (TBG) is a recently discovered two-dimensional superlattice structure which exhibits strongly-correlated quantum many-body physics, including strange metallic behavior and unconventional superconductivity. Most of TBG exotic properties are connected to the emergence of a pair of isolated and topological flat electronic bands at the so-called magic angle, $\theta \approx 1.05^{\circ}$, which are nevertheless very fragile. In this work, we show that, by employing chiral optical cavities, the topological flat bands can be stabilized away from the magic angle in an interval of approximately $0.8^{\circ}<\theta<1.3^{\circ}$. As highlighted by a simplified theoretical model, time reversal symmetry breaking, induced by the chiral nature of the cavity, plays a fundamental role in flattening the isolated bands and gapping out the rest of the spectrum. The efficiency of the cavity is discussed as a function of the twisting angle, the light-matter coupling and the optical cavity characteristic frequency. Our results demonstrate the possibility of engineering flat bands in TBG using optical devices, extending the onset of strongly-correlated topological electronic phases in Moir\'e superlattices to a wider range in the twisting angle.|
|**2023-06-08**|**Orthogonal Sampling based Broad-Band Signal Generation with Low-Bandwidth Electronics**|Mohamed I. Hosni et.al.|[2306.05125v1](http://arxiv.org/abs/2306.05125v1)|null|High-bandwidth signals are needed in many applications like radar, sensing, measurement and communications. Especially in optical networks, the sampling rate and analog bandwidth of digital-to-analog converters (DACs) is a bottleneck for further increasing data rates. To circumvent the sampling rate and bandwidth problem of electronic DACs, we demonstrate the generation of wide-band signals with low-bandwidth electronics. This generation is based on orthogonal sampling with sinc-pulse sequences in N parallel branches. The method not only reduces the sampling rate and bandwidth, at the same time the effective number of bits (ENOB) is improved, dramatically reducing the requirements on the electronic signal processing. In proof of concept experiments the generation of analog signals, as well as Nyquist shaped and normal data will be shown. In simulations we investigate the performance of 60 GHz data generation by 20 and 12 GHz electronics. The method can easily be integrated together with already existing electronic DAC designs and would be of great interest for all high-bandwidth applications.|
|**2023-06-08**|**Electronic correlations and superconducting instability in La$_3$Ni$_2$O$_7$ under high pressure**|Frank Lechermann et.al.|[2306.05121v1](http://arxiv.org/abs/2306.05121v1)|null|Motivated by the report of superconductivity in bilayer La$_3$Ni$_2$O$_7$ at high pressure, we examine the interacting electrons in this system. First-principles many-body theory is utilized to study the normal-state electronic properties. Below 100\,K, a multi-orbital non-Fermi liquid state resulting from loss of Ni-ligand coherence within a flat-band dominated low-energy landscape is uncovered. The incoherent low-temperature Fermi surface displays strong mixing between Ni-$d_{z^2}$ and Ni-$d_{x^2-y^2}$ orbital character. In a model-Hamiltonian picture, spin fluctuations originating mostly from the Ni-$d_{z^2}$ orbital give rise to strong tendencies towards a superconducting instability with $d_{x^2-y^2}$ order parameter. The dramatic enhancement of $T_{\rm c}$ in pressurized La$_3$Ni$_2$O$_7$ is due to stronger Ni-$d_{z^2}$ correlations compared to those in the infinite-layer nickelates.|
|**2023-06-08**|**Recurrent mini-outbursts and a magnetic white dwarf in the symbiotic system FN Sgr**|J. Magdolen et.al.|[2306.05095v1](http://arxiv.org/abs/2306.05095v1)|null|AIMS: We investigated the optical variability of the symbiotic binary FN Sgr, with photometric monitoring during $\simeq$55 years and with a high-cadence Kepler light curve lasting 81 days. METHODS: The data obtained in the V and I bands were reduced with standard photometric methods. The Kepler data were divided into subsamples and analyses with the Lomb-Scargle algorithm. RESULTS: The V and I band light curves showed a phenomenon never before observed with such recurrence in any symbiotic system, namely short outbursts, starting between orbital phase 0.3 and 0.5 and lasting about a month, with a fast rise and a slower decline, and amplitude of 0.5-1 mag. In the Kepler light curve we discovered three frequencies with sidebands. We attribute a stable frequency of 127.5 d$^{-1}$ (corresponding to an 11.3 minutes period) to the white dwarf rotation. We suggest that this detection probably implies that the white dwarf accretes through a magnetic stream, like in intermediate polars. The small outbursts may be ascribed to the stream-disc interaction. Another possibility is that they are due to localized thermonuclear burning, perhaps confined by the magnetic field, like recently inferred in intermediate polars, albeit on different timescales. We measured also a second frequency around 116.9 d$^{-1}$ (corresponding to about 137 minutes), which is much less stable and has a drift. It may be due to rocky detritus around the white dwarf, but it is more likely to be caused by an inhomogeneity in the accretion disk. Finally, there is a third frequency close to the first one that appears to correspond to the beating between the rotation and the second frequency.|
|**2023-06-08**|**Selenium and the role of defects for photovoltaic applications**|Hadeel Moustafa et.al.|[2306.05092v1](http://arxiv.org/abs/2306.05092v1)|null|We present first principles calculations of the electronic properties of trigonal selenium with emphasis on photovoltaic applications. The band gap and optical absorption spectrum of pristine selenium is calculated from many-body perturbation theory yielding excellent agreement with experiments. We then investigate the role of intrinsic as well as extrinsic defects and estimate the equilibrium concentrations resulting from realistic synthesis conditions. The intrinsic defects are dominated by vacancies, which act as acceptor levels and implies $p$-doping in agreement with previous predictions and measurements, and we show that these do not give rise to significant non-radiative recombination. The charge balance remains dominated by vacancies when extrinsic defects are included, but these may give rise to sizable non-radiative recombination rates, which could severely limit the performance of selenium based solar cells. Our results thus imply that the pollution by external elements is a decisive factor for the photovoltaic efficiency, which will be of crucial importance when considering synthesis conditions for any type of device engineering.|
|**2023-06-08**|**A multi-band AGN-SFG classifier for extragalactic radio surveys using machine learning**|J. Karsten et.al.|[2306.05062v1](http://arxiv.org/abs/2306.05062v1)|null|Extragalactic radio continuum surveys play an increasingly more important role in galaxy evolution and cosmology studies. While radio galaxies and radio quasars dominate at the bright end, star-forming galaxies (SFGs) and radio-quiet Active Galactic Nuclei (AGNs) are more common at fainter flux densities. Our aim is to develop a machine learning classifier that can efficiently and reliably separate AGNs and SFGs in radio continuum surveys. We perform supervised classification of SFGs vs AGNs using the Light Gradient Boosting Machine (LGBM) on three LOFAR Deep Fields (Lockman Hole, Bootes and ELAIS-N1), which benefit from a wide range of high-quality multi-wavelength data and classification labels derived from extensive spectral energy distribution (SED) analyses. Our trained model has a precision of 0.92(0.01) and a recall of 0.87(0.02) for SFGs. For AGNs, the model has slightly worse performance, with a precision of 0.87(0.02) and recall of 0.78(0.02). These results demonstrate that our trained model can successfully reproduce the classification labels derived from detailed SED analysis. The model performance decreases towards higher redshifts, mainly due to smaller training sample sizes. To make the classifier more adaptable to other radio galaxy surveys, we also investigate how our classifier performs with a poorer multi-wavelength sampling of the SED. In particular, we find that the far-infrared (FIR) and radio bands are of great importance. We also find that higher S/N in some photometric bands leads to a significant boost in the model's performance. In addition to using the 150 MHz radio data, our model can also be used with 1.4 GHz radio data. Converting 1.4 GHz to 150 MHz radio data reduces performance by about 4% in precision and 3% in recall. The final trained model is publicly available at https://github.com/Jesper-Karsten/MBASC|
|**2023-06-08**|**Influence of native defects on magneto-optoelectronic properties of $α$-MoO$_{3}$**|Poonam Sharma et.al.|[2306.04978v1](http://arxiv.org/abs/2306.04978v1)|null|Semiconducting oxides possess a variety of intriguing electronic, optical, and magnetic properties, and native defects play a crucial role in these systems. In this study, we study the influence of native defects on these properties of $\alpha$-MoO$_{3}$ using the first-principles density functional theory (DFT) calculations. From the formation energy calculations, it is concluded that Mo vacancies are difficult to form in the system, while O and Mo-O co-vacancies are energetically quite favorable. We further find that vacancies give rise to mid-gap states (trap states) that remarkably affect the magneto-optoelectronic properties of the material. Our calculations indicate that a single Mo vacancy leads to half-metallic behavior, and also induces a large magnetic moment of 5.98 $\mu_{B}$. On the other hand, for the single O vacancy case, the band gap disappears completely, but the system remains in a non-magnetic state. For Mo-O co-vacancies of two types considered in this work, a reduced band gap is found, along with an induced magnetic moment of 2.0 $\mu_{B}$. Furthermore, a few finite peaks below the main band edge are observed in the absorption spectra of configurations with Mo and O vacancies, while they are absent in the Mo-O co-vacancies of both types, just like in the pristine state. From the ab-initio molecular dynamics simulations, stability and sustainability of induced magnetic moment at room temperate is verified. Our findings will enable the development of defect strategies that maximize the functionality of the system, and further help in designing highly efficient magneto-optoelectronic and spintronic devices.|
|**2023-06-08**|**Triplet State and Auger-Type Excitation Originating from Two-Electron Tunneling in Field Emission Resonance on Ag(100)**|Shin-Ming Lu et.al.|[2306.04916v1](http://arxiv.org/abs/2306.04916v1)|null|In this study, we discovered that the energy gap above the vacuum level in the projected bulk band structure of Ag(100) prevents electrons in the first-order field emission resonance (FER) from inducing the surface plasmons. This mechanism allows light emission from FER to reveal characteristics of triplet states and Auger-type excitation resulting from two-electron tunneling in FER. According to optical spectra, surface plasmons can be induced by electrons in the zeroth-order FER. However, corresponding radiative decay can also trigger Auger-type excitation, whose energy state is influenced by the sharpness-dependent image potential acting on the scanning tunneling microscope tip.|
|**2023-06-08**|**Three consecutive quantum anomalous Hall gaps in a metal-organic network**|Xiang-Long Yu et.al.|[2306.04912v1](http://arxiv.org/abs/2306.04912v1)|null|In the quantum anomalous Hall (QAH) effect, chiral edge states are present in the absence of magnetic fields due to the intrinsic band topology. In this work, we predict that a synthesized two-dimensional metal-organic material, a Fe(biphenolate)$_3$ network, can be a unique QAH insulator, in which there are three consecutive nontrivial bandgaps. Based on first-principles calculations with effective model analysis, we reveal such nontrivial topology is from the $3$d$_{xz}$ and $3$d$_{yz}$ orbitals of Fe atoms. Moreover, we further study the effect of substrates, and the results shows that the metallic substrates used in the experiments (Ag and Cu) are unfavorable for observing the QAH effect whereas a hexagonal boron nitride substrate with a large bandgap may be a good candidate, where the three consecutive QAH gaps appear inside the substrate gap. The presence of three consecutive bandgaps near the Fermi level will significantly facilitate observations of the QAH effect in experiments.|
|**2023-06-08**|**Eigenstates and spectral projection for quantized baker's map**|Laura Shou et.al.|[2306.04908v1](http://arxiv.org/abs/2306.04908v1)|null|We extend the approach from [arXiv:2110.15301] to prove windowed spectral projection estimates and a generalized Weyl law for the (Weyl) quantized baker's map on the torus. The spectral window is allowed to shrink. As a consequence, we obtain a strengthening of the quantum ergodic theorem from [arXiv:math-ph/0412058] to hold in shrinking spectral windows, a Weyl law on uniform spreading of eigenvalues, and statistics of random band-limited waves. Using similar techniques, we also investigate generic random eigenbases of a different (non-Weyl) quantization, the Walsh-quantized $D$-baker map, which has high degeneracies in its spectrum. For generic random eigenbases, we prove gaussian eigenstate statistics and QUE with high probability in the semiclassical limit.|
|**2023-06-08**|**Spectrum Sharing between High Altitude Platform Network and Terrestrial Network: Modeling and Performance Analysis**|Zhiqing Wei et.al.|[2306.04906v1](http://arxiv.org/abs/2306.04906v1)|null|Achieving seamless global coverage is one of the ultimate goals of space-air-ground integrated network, as a part of which High Altitude Platform (HAP) network can provide wide-area coverage. However, deploying a large number of HAPs will lead to severe congestion of existing frequency bands. Spectrum sharing improves spectrum utilization. The coverage performance improvement and interference caused by spectrum sharing need to be investigated. To this end, this paper analyzes the performance of spectrum sharing between HAP network and terrestrial network. We firstly generalize the Poisson Point Process (PPP) to curves, surfaces and manifolds to model the distribution of terrestrial Base Stations (BSs) and HAPs. Then, the closed-form expressions for coverage probability of HAP network and terrestrial network are derived based on differential geometry and stochastic geometry. We verify the accuracy of closed-form expressions by Monte Carlo simulation. The results show that HAP network has less interference to terrestrial network. Low height and suitable deployment density can improve the coverage probability and transmission capacity of HAP network.|
|**2023-06-08**|**Double SSA Spectrum and Magnetic Field Strength of the FSRQ 3C 454.3**|Hyeon-Woo Jeong et.al.|[2306.04888v1](http://arxiv.org/abs/2306.04888v1)|null|We present the results of a radio multi-frequency ($\rm 3-340~GHz$) study of the blazar 3C~454.3. After subtracting the quiescent spectrum corresponding to optically thin emission, we found two individual synchrotron self-absorption (SSA) features in the wide-band spectrum. The one SSA had a relatively low turnover frequency ($\nu_{\rm m}$) in the range of $\rm 3-37~GHz$ (lower $\nu_{\rm m}$ SSA spectrum, LSS), and the other one had a relatively high $\nu_{\rm m}$ of $\rm 55-124~GHz$ (higher $\nu_{\rm m}$ SSA spectrum, HSS). Using the SSA parameters, we estimated magnetic field strengths at the surface where optical depth $\tau=1$. The estimated magnetic field strengths were $\rm >7~mG$ and $\rm >0.2~mG$ for the LSS and HSS, respectively. The LSS emitting region was magnetically dominated before the June 2014 $\gamma$-ray flare. The quasi-stationary component (C), $\sim 0.6~{\rm mas}$ apart from the 43 GHz radio core, became brighter than the core with decreasing observing frequency, and we found that component C was related to the LSS. A decrease in jet width was found near component C. As a moving component, K14 approached component C, and the flux density of the component was enhanced while the angular size decreased. The high intrinsic brightness temperature in the fluid frame was obtained as $T_{\rm B, int} \approx (7.0\pm1.0) \times 10^{11}~{\rm K}$ from the jet component after the 2015 August $\gamma$-ray flare, suggesting that component C is a high-energy emitting region. The observed local minimum of jet width and re-brightening behavior suggest a possible recollimation shock in component C.|
|**2023-06-07**|**Compressibility and speeds of sound across the superfluid to supersolid phase transition of an elongated dipolar gas**|P. B. Blakie et.al.|[2306.04794v1](http://arxiv.org/abs/2306.04794v1)|null|We investigate the excitation spectrum and compressibility of a dipolar Bose-Einstein condensate in an infinite tube potential in the parameter regime where the transition between superfluid and supersolid phases occurs. Our study focuses on the density range in which crystalline order develops continuously across the transition. Above the transition the superfluid shows a single gapless excitation band, phononic at small momenta and with a roton at a finite momentum. Below the transition, two gapless excitations branches (three at the transition point) emerge in the supersolid. We examine the two gapless excitation bands and their associated speeds of sound in the supersolid phase. Our results show that the speeds of sound and the compressibility are discontinuous at the transition, indicating a second-order phase transition. These results provide valuable insights into the identification of supersolid phenomena in dipolar quantum gases and the relationship to supersolidity in spin-orbit coupled gases.|
|**2023-06-07**|**Renormalization of the band gap in 2D materials near an interface between two dielectrics**|Alessandra N. Braga et.al.|[2306.04759v1](http://arxiv.org/abs/2306.04759v1)|null|We investigate how the renormalization of the band gap in a planar 2D material is affected by the consideration of two nondispersive semi-infinite dielectrics, with dielectric constants $\epsilon_1$ and $\epsilon_2$, separated by a planar interface. Using the pseudo quantum electrodynamics to model the Coulomb interaction between electrons, we show how the renormalization of the band gap depends on $\epsilon_1$ and $\epsilon_2$, and also of the distance between the 2D material and the interface between the two dielectrics. In the appropriate limits, our results reproduce those found in the literature for the band gap renormalization when a single dielectric medium is considered.|
|**2023-06-07**|**SN2023ixf in Messier 101: A Variable Red Supergiant as the Progenitor Candidate to a Type II Supernova**|Charles D. Kilpatrick et.al.|[2306.04722v1](http://arxiv.org/abs/2306.04722v1)|null|We present pre-explosion optical and infrared (IR) imaging at the site of the type II supernova (SN II) 2023ixf in Messier 101 at 6.9 Mpc. We astrometrically registered a ground-based image of SN 2023ixf to archival Hubble Space Telescope (HST), Spitzer Space Telescope (Spitzer), and ground-based near-IR images. A single point source is detected at a position consistent with the SN at wavelengths ranging from HST $R$-band to Spitzer 4.5 $\mu$m. Fitting to blackbody and red supergiant (RSG) spectral-energy distributions (SEDs), we find that the source is anomalously cool with a significant mid-IR excess. We interpret this SED as reprocessed emission in a 8600 $R_{\odot}$ circumstellar shell of dusty material with a mass $\sim$5$\times10^{-5} M_{\odot}$ surrounding a $\log(L/L_{\odot})=4.74\pm0.07$ and $T_{\rm eff}=3920\substack{+200\\-160}$ K RSG. This luminosity is consistent with RSG models of initial mass 11 $M_{\odot}$, depending on assumptions of rotation and overshooting. In addition, the counterpart was significantly variable in pre-explosion Spitzer 3.6 $\mu$m and 4.5 $\mu$m imaging, exhibiting $\sim$70% variability in both bands correlated across 9 yr and 29 epochs of imaging. The variations appear to have a timescale of 2.8 yr, which is consistent with $\kappa$-mechanism pulsations observed in RSGs, albeit with a much larger amplitude than RSGs such as $\alpha$ Orionis (Betelgeuse).|
|**2023-06-07**|**Soft X-ray emission from warm gas in IllustrisTNG circum-cluster environments**|Celine Gouin et.al.|[2306.04694v1](http://arxiv.org/abs/2306.04694v1)|null|Context. Whereas X-ray clusters are extensively used for cosmology, their idealistic modelling, through the hypotheses of spherical symmetry and hydrostatic equilibrium, are more and more being questioned. Along these lines, the soft X-ray emission detected in tens of clusters with ROSAT was found to be higher than what expected from the idealistic hot gas modelling, pointing to our incomplete understanding of these objects. Aims. Given that cluster environments are at the interface between the hot intra-cluster medium (ICM), warm circum-galactic medium (WCGM) and warm-hot intergalactic medium (WHIM), we aim to explore the relative soft X-ray emission of different gas phases in circum-cluster environments. Method. By using the most massive halos in IllustrisTNG at z=0, we have predicted the hydrodynamical properties of the gas from cluster centers to their outskirts (5 R200), and modelled their X-ray radiation for various plasma phases. Results. First, we found that the radial profile of temperature, density, metallicity and clumpiness of the ICM are in good agreement with recent X-ray observations of clusters. Secondly, we have developed a method to predict the radial profile of soft X-ray emission in different bands, the column density of ions and the X-ray absorption lines (O VIII, O VII, Ne IX, and Ne IX) of warm-hot gas inside and around clusters. Conclusion. The warm gas (in the form of both WCGM and WHIM gas) is a strong emitter in soft X-ray bands, and is qualitatively consistent with the observational measurements. Our results suggest that the cluster soft excess is induced by the thermal emission of warm gas in the circum-cluster environments.|
|**2023-06-07**|**Moiré fractals in twisted graphene layers**|Deepanshu Aggarwal et.al.|[2306.04580v1](http://arxiv.org/abs/2306.04580v1)|null|Twisted bilayer graphene (TBLG) subject to a sequence of commensurate external periodic potentials reveals the formation of moir\'e fractals that share striking similarities with the central place theory (CPT) of economic geography, thus uncovering a remarkable connection between twistronics and the geometry of economic zones. The moir\'e fractals arise from the self-similarity of the hierarchy of Brillouin zones (BZ) so formed, forming a nested subband structure within the bandwidth of the original moir\'e bands. The fractal generators for TBLG under these external potentials are derived and we explore their impact on the hierarchy of the BZ edges. Furthermore, we uncover parallels between the modification of the BZ hierarchy and magnetic BZ formation in the Hofstadter butterfly, allowing us to construct an incommensurability measure for moir\'e fractals as a function of the twist angle. The resulting band structure hierarchy bolsters correlation effects, pushing more bands within the same energy window for both commensurate and incommensurate structures.|
|**2023-06-07**|**The Effect of Length on Key Fingerprint Verification Security and Usability**|Dan Turner et.al.|[2306.04574v1](http://arxiv.org/abs/2306.04574v1)|null|In applications such as end-to-end encrypted instant messaging, secure email, and device pairing, users need to compare key fingerprints to detect impersonation and adversary-in-the-middle attacks. Key fingerprints are usually computed as truncated hashes of each party's view of the channel keys, encoded as an alphanumeric or numeric string, and compared out-of-band, e.g. manually, to detect any inconsistencies. Previous work has extensively studied the usability of various verification strategies and encoding formats, however, the exact effect of key fingerprint length on the security and usability of key fingerprint verification has not been rigorously investigated. We present a 162-participant study on the effect of numeric key fingerprint length on comparison time and error rate. While the results confirm some widely-held intuitions such as general comparison times and errors increasing significantly with length, a closer look reveals interesting nuances. The significant rise in comparison time only occurs when highly similar fingerprints are compared, and comparison time remains relatively constant otherwise. On errors, our results clearly distinguish between security non-critical errors that remain low irrespective of length and security critical errors that significantly rise, especially at higher fingerprint lengths. A noteworthy implication of this latter result is that Signal/WhatsApp key fingerprints provide a considerably lower level of security than usually assumed.|
|**2023-06-07**|**Implications of a Possible Spectral Structure of Cosmic-ray Protons Unveiled by the DAMPE**|Lin Nie et.al.|[2306.04558v2](http://arxiv.org/abs/2306.04558v2)|null|The recent observations revealed that the cosmic-ray (CR) proton spectrum showed a complex structure: the hardening at $\rm \sim 200~GeV$ and softening at $\rm \sim 10~TeV$. However, so far the physical origins of this spectral feature remain strongly debated. In this work, we simulate the acceleration of cosmic-ray protons in a nearby Supernova remnant (SNR) by solving numerically the hydrodynamic equations and the equation for the quasi-isotropic CR momentum distribution in the spherically symmetrical case to derive the spectrum of protons injected into the interstellar medium (ISM), and then simulate the propagation process of those accelerated CR particles to calculate the proton fluxes reaching the Earth. Besides, we use the DRAGON numerical code to calculate the large-scale cosmic-ray proton spectrum. Our simulated results are in good agreement with the observed data (including the observed data of proton fluxes and dipole anisotropy). We conclude that the spectral feature of cosmic-ray protons in this energy band may originate from the superposition of the distribution from the nearby SNR and background diffusive cosmic-ray component. We find that the release of particles from this nearby SNR has a time delay. Besides, it can be found that the nonlinear response of energetic particles, release time of CR protons, and age of the local SNR can leave strong signatures in the spectrum of the resulting CR proton fluxes.|
|**2023-06-07**|**Active Reconfigurable Intelligent Surfaces for the Millimeter-Wave Frequency Band: System Design and Measurement**|Hamed Radpour et.al.|[2306.04515v1](http://arxiv.org/abs/2306.04515v1)|null|Reconfigurable intelligent surfaces (RISs) will play a key role to establish millimeter wave (mmWave) ultra-reliable low-latency communication systems for sixth-generation (6G) applications. Currently, there are a few working prototypes of RISs operating in the mmWave frequency band and all of them are based on passive reflective elements. However, to fabricate an efficiently working RIS at mmWave frequencies, it is crucial to take care of the strong signal attenuation, reflective element losses and undesired radio frequency (RF) circuit effects. In this paper, we provide measurement campaign results for an active RIS in the mmWave frequency band as well as its analysis and system design. The obtained results demonstrate that an active RIS outperforms a RIS working in passive mode and provides a higher signal-to-noise-ratio (SNR). The active RIS consists of active reflective elements that amplify the impinging signal and reflect the signal to the desired beam direction. To obtain an efficient RIS in terms of power consumption and RIS state switch time, we design a hexagonal RIS with 37 elements working at 26 GHz. These elements are designed to work whether in passive state (binary phase shifting) or in active state (switch OFF or amplifying). We provide a comparison between the performance of a RIS working in passive and active mode using numerical simulations and empirical measurements. This comparison reveals that the active reflective intelligent surface (RIS) provides a received power that is at least 4 dB higher than that of the equivalent passive RIS. These results demonstrate the strong advantage of using active RISs for future ultra-reliable low-latency wireless communications.|
|**2023-06-07**|**ViCTORIA project: The LOFAR HBA Virgo Cluster Survey**|H. W. Edler et.al.|[2306.04513v1](http://arxiv.org/abs/2306.04513v1)|null|The Virgo cluster is the nearest massive galaxy cluster and thus a prime target to study astrophysical processes in dense large-scale environments. In the radio band, we can probe the non-thermal components of the inter-stellar medium (ISM), intracluster medium (ICM) and of active galactic nuclei (AGN). With the ViCTORIA (Virgo Cluster multi-Telescope Observations in Radio of Interacting galaxies and AGN) project, we are carrying out multiple wide-field surveys of the Virgo cluster at different frequencies. We aim to investigate the impact of the environment on the evolution of galaxies and the contribution of AGN to the ICM-heating, from the inner cluster regions out to beyond the virial radius. We present a survey of the cluster at 120-168 MHz using LOFAR. We image a 132 deg$^2$ region of the cluster, reaching an order of magnitude greater sensitivity than existing wide-field radio surveys of this field at three times higher spatial resolution compared to other low-frequency observations. We developed a tailored data processing strategy to subtract the bright central radio galaxy M87 from the data. This allowed us to correct for the systematic effects due to ionospheric variation as a function of time and direction. In the final mosaic with a resolution of 9"x5", we reach a median noise level of 140 ${\mu}$Jy/beam inside the virial radius and 280 ${\mu}$Jy/beam for the full area. We detect 112 Virgo member galaxies and 114 background galaxies. In at least 18 cases, the radio morphology of the cluster member galaxies shows clear signs of ram-pressure stripping. This includes three previously unreported candidates. In addition, we reveal for the first time 150 kpc long tails from a previous epoch of AGN activity for NGC 4472 (M 49). While no cluster-scale diffuse radio sources are discovered, we find the presence of an extended radio signature of the W$'$-group.|
|**2023-06-07**|**Observation of 2D Mott insulator and $π$-superfluid quantum phase transition in shaking optical lattice**|Jingxin Sun et.al.|[2306.04477v1](http://arxiv.org/abs/2306.04477v1)|null|The Mott insulator and superfluid phase transition is one of the most prominent phenomena in ultracold atoms. In this work, we report the observation of a novel 2D quantum phase transition between Mott insulator and $\pi$ superfluid in a shaking optical lattice. In the deep optical lattice regime, the lowest $s$-band can be tuned to Mott phase, while the higher $p_{x,y}$ bands are itinerant for having larger bandwidth. Through a shaking technique coupling the $s$ orbital to $p_{x,y}$ orbital states, we experimentally observe the transition between the states of the $s$ and $p_{x,y}$ bands, leading to a quantum phase transition from 2D $s$-orbital Mott phase to the $p_{x,y}$-orbital superfluid which condensed at $(\pi,\pi)$ momentum.|
|**2023-06-07**|**Machine Learning Universal Empirical Pseudopotentials**|Rokyeon Kim et.al.|[2306.04426v1](http://arxiv.org/abs/2306.04426v1)|null|Machine learning is used to generate empirical pseudopotentials that characterize the local screened interactions in the Kohn-Sham Hamiltonian. Our approach incorporates momentum-range-separated rotation-covariant descriptors to capture crystal symmetries as well as crucial directional information of bonds, thus realizing accurate descriptions of anisotropic solids. Trained empirical potentials are shown to be versatile and transferable such that the calculated energy bands and wave functions without cumbersome self-consistency reproduce conventional ab initio results even for semiconductors with defects, thus fostering faster and faithful data-driven materials researches.|

## all search terms

### all search terms
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Tracking Everything Everywhere All at Once**|Qianqian Wang et.al.|[2306.05422v1](http://arxiv.org/abs/2306.05422v1)|null|We present a new test-time optimization method for estimating dense and long-range motion from a video sequence. Prior optical flow or particle video tracking algorithms typically operate within limited temporal windows, struggling to track through occlusions and maintain global consistency of estimated motion trajectories. We propose a complete and globally consistent motion representation, dubbed OmniMotion, that allows for accurate, full-length motion estimation of every pixel in a video. OmniMotion represents a video using a quasi-3D canonical volume and performs pixel-wise tracking via bijections between local and canonical space. This representation allows us to ensure global consistency, track through occlusions, and model any combination of camera and object motion. Extensive evaluations on the TAP-Vid benchmark and real-world footage show that our approach outperforms prior state-of-the-art methods by a large margin both quantitatively and qualitatively. See our project page for more results: http://omnimotion.github.io/|
|**2023-06-08**|**TopoMask: Instance-Mask-Based Formulation for the Road Topology Problem via Transformer-Based Architecture**|M. Esat Kalfaoglu et.al.|[2306.05419v1](http://arxiv.org/abs/2306.05419v1)|null|Driving scene understanding task involves detecting static elements such as lanes, traffic signs, and traffic lights, and their relationships with each other. To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released. This dataset allows for the exploration of complex road connections and situations where lane markings may be absent. Instead of using traditional lane markings, the lanes in this dataset are represented by centerlines, which offer a more suitable representation of lanes and their connections. In this study, we have introduced a new approach called TopoMask for predicting centerlines in road topology. Unlike existing approaches in the literature that rely on keypoints or parametric methods, TopoMask utilizes an instance-mask based formulation with a transformer-based architecture and, in order to enrich the mask instances with flow information, a direction label representation is proposed. TopoMask have ranked 4th in the OpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction in OpenLane Topology Challenge 2023. In comparison to the current state-of-the-art method, TopoNet, the proposed method has achieved similar performance in Frechet-based lane detection and outperformed TopoNet in Chamfer-based lane detection without utilizing its scene graph neural network.|
|**2023-06-08**|**LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs**|Zezhou Cheng et.al.|[2306.05410v1](http://arxiv.org/abs/2306.05410v1)|null|A critical obstacle preventing NeRF models from being deployed broadly in the wild is their reliance on accurate camera poses. Consequently, there is growing interest in extending NeRF models to jointly optimize camera poses and scene representation, which offers an alternative to off-the-shelf SfM pipelines which have well-understood failure modes. Existing approaches for unposed NeRF operate under limited assumptions, such as a prior pose distribution or coarse pose initialization, making them less effective in a general setting. In this work, we propose a novel approach, LU-NeRF, that jointly estimates camera poses and neural radiance fields with relaxed assumptions on pose configuration. Our approach operates in a local-to-global manner, where we first optimize over local subsets of the data, dubbed mini-scenes. LU-NeRF estimates local pose and geometry for this challenging few-shot task. The mini-scene poses are brought into a global reference frame through a robust pose synchronization step, where a final global optimization of pose and scene can be performed. We show our LU-NeRF pipeline outperforms prior attempts at unposed NeRF without making restrictive assumptions on the pose prior. This allows us to operate in the general SE(3) pose setting, unlike the baselines. Our results also indicate our model can be complementary to feature-based SfM pipelines as it compares favorably to COLMAP on low-texture and low-resolution images.|
|**2023-06-08**|**SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic Understanding**|Paul-Edouard Sarlin et.al.|[2306.05407v1](http://arxiv.org/abs/2306.05407v1)|null|Semantic 2D maps are commonly used by humans and machines for navigation purposes, whether it's walking or driving. However, these maps have limitations: they lack detail, often contain inaccuracies, and are difficult to create and maintain, especially in an automated fashion. Can we use raw imagery to automatically create better maps that can be easily interpreted by both humans and machines? We introduce SNAP, a deep network that learns rich neural 2D maps from ground-level and overhead images. We train our model to align neural maps estimated from different inputs, supervised only with camera poses over tens of millions of StreetView images. SNAP can resolve the location of challenging image queries beyond the reach of traditional methods, outperforming the state of the art in localization by a large margin. Moreover, our neural maps encode not only geometry and appearance but also high-level semantics, discovered without explicit supervision. This enables effective pre-training for data-efficient semantic scene understanding, with the potential to unlock cost-efficient creation of more detailed maps.|
|**2023-06-08**|**Predictive Modeling of Equine Activity Budgets Using a 3D Skeleton Reconstructed from Surveillance Recordings**|Ernest Pokropek et.al.|[2306.05311v1](http://arxiv.org/abs/2306.05311v1)|null|In this work, we present a pipeline to reconstruct the 3D pose of a horse from 4 simultaneous surveillance camera recordings. Our environment poses interesting challenges to tackle, such as limited field view of the cameras and a relatively closed and small environment. The pipeline consists of training a 2D markerless pose estimation model to work on every viewpoint, then applying it to the videos and performing triangulation. We present numerical evaluation of the results (error analysis), as well as show the utility of the achieved poses in downstream tasks of selected behavioral predictions. Our analysis of the predictive model for equine behavior showed a bias towards pain-induced horses, which aligns with our understanding of how behavior varies across painful and healthy subjects.|
|**2023-06-08**|**EXOT: Exit-aware Object Tracker for Safe Robotic Manipulation of Moving Object**|Hyunseo Kim et.al.|[2306.05262v1](http://arxiv.org/abs/2306.05262v1)|null|Current robotic hand manipulation narrowly operates with objects in predictable positions in limited environments. Thus, when the location of the target object deviates severely from the expected location, a robot sometimes responds in an unexpected way, especially when it operates with a human. For safe robot operation, we propose the EXit-aware Object Tracker (EXOT) on a robot hand camera that recognizes an object's absence during manipulation. The robot decides whether to proceed by examining the tracker's bounding box output containing the target object. We adopt an out-of-distribution classifier for more accurate object recognition since trackers can mistrack a background as a target object. To the best of our knowledge, our method is the first approach of applying an out-of-distribution classification technique to a tracker output. We evaluate our method on the first-person video benchmark dataset, TREK-150, and on the custom dataset, RMOT-223, that we collect from the UR5e robot. Then we test our tracker on the UR5e robot in real-time with a conveyor-belt sushi task, to examine the tracker's ability to track target dishes and to determine the exit status. Our tracker shows 38% higher exit-aware performance than a baseline method. The dataset and the code will be released at https://github.com/hskAlena/EXOT.|
|**2023-06-08**|**Human Action Recognition in Egocentric Perspective Using 2D Object and Hands Pose**|Wiktor Mucha et.al.|[2306.05147v1](http://arxiv.org/abs/2306.05147v1)|null|Egocentric action recognition is essential for healthcare and assistive technology that relies on egocentric cameras because it allows for the automatic and continuous monitoring of activities of daily living (ADLs) without requiring any conscious effort from the user. This study explores the feasibility of using 2D hand and object pose information for egocentric action recognition. While current literature focuses on 3D hand pose information, our work shows that using 2D skeleton data is a promising approach for hand-based action classification, might offer privacy enhancement, and could be less computationally demanding. The study uses a state-of-the-art transformer-based method to classify sequences and achieves validation results of 94%, outperforming other existing solutions. The accuracy of the test subset drops to 76%, indicating the need for further generalization improvement. This research highlights the potential of 2D hand and object pose information for action recognition tasks and offers a promising alternative to 3D-based methods.|
|**2023-06-08**|**Variable Radiance Field for Real-Life Category-Specifc Reconstruction from Single Image**|Kun Wang et.al.|[2306.05145v1](http://arxiv.org/abs/2306.05145v1)|null|Reconstructing category-specific objects from a single image is a challenging task that requires inferring the geometry and appearance of an object from a limited viewpoint. Existing methods typically rely on local feature retrieval based on re-projection with known camera intrinsic, which are slow and prone to distortion at viewpoints distant from the input image. In this paper, we present Variable Radiance Field (VRF), a novel framework that can efficiently reconstruct category-specific objects from a single image without known camera parameters. Our key contributions are: (1) We parameterize the geometry and appearance of the object using a multi-scale global feature extractor, which avoids frequent point-wise feature retrieval and camera dependency. We also propose a contrastive learning-based pretraining strategy to improve the feature extractor. (2) We reduce the geometric complexity of the object by learning a category template, and use hypernetworks to generate a small neural radiance field for fast and instance-specific rendering. (3) We align each training instance to the template space using a learned similarity transformation, which enables semantic-consistent learning across different objects. We evaluate our method on the CO3D dataset and show that it outperforms existing methods in terms of quality and speed. We also demonstrate its applicability to shape interpolation and object placement tasks.|
|**2023-06-08**|**Neuromorphic Sampling of Signals in Shift-Invariant Spaces**|Abijith Jagannath Kamath et.al.|[2306.05103v1](http://arxiv.org/abs/2306.05103v1)|null|Neuromorphic sampling is a paradigm shift in analog-to-digital conversion where the acquisition strategy is opportunistic and measurements are recorded only when there is a significant change in the signal. Neuromorphic sampling has given rise to a new class of event-based sensors called dynamic vision sensors or neuromorphic cameras. The neuromorphic sampling mechanism utilizes low power and provides high-dynamic range sensing with low latency and high temporal resolution. The measurements are sparse and have low redundancy making it convenient for downstream tasks. In this paper, we present a sampling-theoretic perspective to neuromorphic sensing of continuous-time signals. We establish a close connection between neuromorphic sampling and time-based sampling - where signals are encoded temporally. We analyse neuromorphic sampling of signals in shift-invariant spaces, in particular, bandlimited signals and polynomial splines. We present an iterative technique for perfect reconstruction subject to the events satisfying a density criterion. We also provide necessary and sufficient conditions for perfect reconstruction. Owing to practical limitations in meeting the sufficient conditions for perfect reconstruction, we extend the analysis to approximate reconstruction from sparse events. In the latter setting, we pose signal reconstruction as a continuous-domain linear inverse problem whose solution can be obtained by solving an equivalent finite-dimensional convex optimization program using a variable-splitting approach. We demonstrate the performance of the proposed algorithm and validate our claims via experiments on synthetic signals.|
|**2023-06-08**|**Real-Time Rendering of Glinty Appearances using Distributed Binomial Laws on Anisotropic Grids**|Deliot et.al.|[2306.05051v1](http://arxiv.org/abs/2306.05051v1)|null|In this work, we render in real-time glittery materials caused by discrete flakes on the surface. To achieve this, one has to count the number of flakes reflecting the light towards the camera within every texel covered by a given pixel footprint. To do so, we derive a counting method for arbitrary footprints that, unlike previous work, outputs the correct statistics. We combine this counting method with an anisotropic parameterization of the texture space that reduces the number of texels falling under a pixel footprint. This allows our method to run with both stable performance and 1.5X to 5X faster than the state-of-the-art.|
|**2023-06-08**|**StreetSurf: Extending Multi-view Implicit Surface Reconstruction to Street Views**|Jianfei Guo et.al.|[2306.04988v1](http://arxiv.org/abs/2306.04988v1)|null|We present a novel multi-view implicit surface reconstruction technique, termed StreetSurf, that is readily applicable to street view images in widely-used autonomous driving datasets, such as Waymo-perception sequences, without necessarily requiring LiDAR data. As neural rendering research expands rapidly, its integration into street views has started to draw interests. Existing approaches on street views either mainly focus on novel view synthesis with little exploration of the scene geometry, or rely heavily on dense LiDAR data when investigating reconstruction. Neither of them investigates multi-view implicit surface reconstruction, especially under settings without LiDAR data. Our method extends prior object-centric neural surface reconstruction techniques to address the unique challenges posed by the unbounded street views that are captured with non-object-centric, long and narrow camera trajectories. We delimit the unbounded space into three parts, close-range, distant-view and sky, with aligned cuboid boundaries, and adapt cuboid/hyper-cuboid hash-grids along with road-surface initialization scheme for finer and disentangled representation. To further address the geometric errors arising from textureless regions and insufficient viewing angles, we adopt geometric priors that are estimated using general purpose monocular models. Coupled with our implementation of efficient and fine-grained multi-stage ray marching strategy, we achieve state of the art reconstruction quality in both geometry and appearance within only one to two hours of training time with a single RTX3090 GPU for each street view sequence. Furthermore, we demonstrate that the reconstructed implicit surfaces have rich potential for various downstream tasks, including ray tracing and LiDAR simulation.|
|**2023-06-08**|**Ultraviolet Photodetectors based on GaN and AlGaN/AlN Nanowire Ensembles: Effects of Planarization with Hydrogen Silsesquioxane and Nanowire Architecture**|E. Akar et.al.|[2306.04986v1](http://arxiv.org/abs/2306.04986v1)|null|The interest in nanowire photodetectors stems from their potential to improve the performance of a variety of devices, including solar cells, cameras, sensors, and communication systems. Implementing devices based on nanowire ensembles requires a planarization process which must be conceived to preserve the advantages of the nanowire geometry. This is particularly challenging in the ultraviolet (UV) range, where spin coating with hydrogen silsesquioxane (HSQ) appears as an interesting approach in terms of transmittance and refractive index. Here, we report a comprehensive study on UV photodetectors based on GaN or AlGaN/AlN nanowire ensembles encapsulated in HSQ. We show that this material is efficient for passivating the nanowire surface, it introduces a compressive strain in the nanowires and preserves their radiative efficiency. We discuss the final performance of planarized UV photodetectors based on three kinds of nanowire ensembles: (i) non-intentionally-doped (nid) GaN nanowires, (ii) Ge-doped GaN nanowires, and (iii) nid GaN nanowires terminated with an AlGaN/AlN superlattice. The incorporation of the superlattice allows tuning the spectral response with bias, which can enhance the carrier collection from the AlGaN/AlN superlattice or from the GaN stem. In all the cases, the performance of the planarized devices remains determined by the nanowire nature, since their characteristics in terms of linearity and spectral selectivity are closer to those demonstrated in single nanowires than those of planar devices. Thus, the visible rejection is several orders of magnitude and there is no indication of persistent photocurrent, which makes all the samples suitable for UV-selective photodetection applications.|
|**2023-06-08**|**Underwater Intention Recognition using Head Motion and Throat Vibration for Supernumerary Robotic Assistance**|Yuqin Guo et.al.|[2306.04928v1](http://arxiv.org/abs/2306.04928v1)|null|This study presents a multi-modal mechanism for recognizing human intentions while diving underwater, aiming to achieve natural human-robot interactions through an underwater superlimb for diving assistance. The underwater environment severely limits the divers' capabilities in intention expression, which becomes more challenging when they intend to operate tools while keeping control of body postures in 3D with the various diving suits and gears. The current literature is limited in underwater intention recognition, impeding the development of intelligent wearable systems for human-robot interactions underwater. Here, we present a novel solution to simultaneously detect head motion and throat vibrations under the water in a compact, wearable design. Experiment results show that using machine learning algorithms, we achieved high performance in integrating these two modalities to translate human intentions to robot control commands for an underwater superlimb system. This study's results paved the way for future development in underwater intention recognition and underwater human-robot interactions with supernumerary support.|
|**2023-06-08**|**Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization**|Jungwuk Park et.al.|[2306.04911v1](http://arxiv.org/abs/2306.04911v1)|null|In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully work in conjunction with various other DG schemes. Experimental results on different datasets show the effectiveness of our methods.|
|**2023-06-08**|**ViG-UNet: Vision Graph Neural Networks for Medical Image Segmentation**|Juntao Jiang et.al.|[2306.04905v1](http://arxiv.org/abs/2306.04905v1)|null|Deep neural networks have been widely used in medical image analysis and medical image segmentation is one of the most important tasks. U-shaped neural networks with encoder-decoder are prevailing and have succeeded greatly in various segmentation tasks. While CNNs treat an image as a grid of pixels in Euclidean space and Transformers recognize an image as a sequence of patches, graph-based representation is more generalized and can construct connections for each part of an image. In this paper, we propose a novel ViG-UNet, a graph neural network-based U-shaped architecture with the encoder, the decoder, the bottleneck, and skip connections. The downsampling and upsampling modules are also carefully designed. The experimental results on ISIC 2016, ISIC 2017 and Kvasir-SEG datasets demonstrate that our proposed architecture outperforms most existing classic and state-of-the-art U-shaped networks.|
|**2023-06-08**|**ExtPerFC: An Efficient 2D and 3D Perception Hardware-Software Framework for Mobile Cobot**|Tuan Dang et.al.|[2306.04853v1](http://arxiv.org/abs/2306.04853v1)|null|As the reliability of the robot's perception correlates with the number of integrated sensing modalities to tackle uncertainty, a practical solution to manage these sensors from different computers, operate them simultaneously, and maintain their real-time performance on the existing robotic system with minimal effort is needed. In this work, we present an end-to-end software-hardware framework, namely ExtPerFC, that supports both conventional hardware and software components and integrates machine learning object detectors without requiring an additional dedicated graphic processor unit (GPU). We first design our framework to achieve real-time performance on the existing robotic system, guarantee configuration optimization, and concentrate on code reusability. We then mathematically model and utilize our transfer learning strategies for 2D object detection and fuse them into depth images for 3D depth estimation. Lastly, we systematically test the proposed framework on the Baxter robot with two 7-DOF arms, a four-wheel mobility base, and an Intel RealSense D435i RGB-D camera. The results show that the robot achieves real-time performance while executing other tasks (e.g., map building, localization, navigation, object detection, arm moving, and grasping) simultaneously with available hardware like Intel onboard CPUS/GPUs on distributed computers. Also, to comprehensively control, program, and monitor the robot system, we design and introduce an end-user application. The source code is available at https://github.com/tuantdang/perception_framework.|
|**2023-06-07**|**BU-CVKit: Extendable Computer Vision Framework for Species Independent Tracking and Analysis**|Mahir Patel et.al.|[2306.04736v1](http://arxiv.org/abs/2306.04736v1)|null|A major bottleneck of interdisciplinary computer vision (CV) research is the lack of a framework that eases the reuse and abstraction of state-of-the-art CV models by CV and non-CV researchers alike. We present here BU-CVKit, a computer vision framework that allows the creation of research pipelines with chainable Processors. The community can create plugins of their work for the framework, hence improving the re-usability, accessibility, and exposure of their work with minimal overhead. Furthermore, we provide MuSeqPose Kit, a user interface for the pose estimation package of BU-CVKit, which automatically scans for installed plugins and programmatically generates an interface for them based on the metadata provided by the user. It also provides software support for standard pose estimation features such as annotations, 3D reconstruction, reprojection, and camera calibration. Finally, we show examples of behavioral neuroscience pipelines created through the sample plugins created for our framework.|
|**2023-06-07**|**ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections**|Chun-Han Yao et.al.|[2306.04619v1](http://arxiv.org/abs/2306.04619v1)|null|Estimating 3D articulated shapes like animal bodies from monocular images is inherently challenging due to the ambiguities of camera viewpoint, pose, texture, lighting, etc. We propose ARTIC3D, a self-supervised framework to reconstruct per-instance 3D shapes from a sparse image collection in-the-wild. Specifically, ARTIC3D is built upon a skeleton-based surface representation and is further guided by 2D diffusion priors from Stable Diffusion. First, we enhance the input images with occlusions/truncation via 2D diffusion to obtain cleaner mask estimates and semantic features. Second, we perform diffusion-guided 3D optimization to estimate shape and texture that are of high-fidelity and faithful to input images. We also propose a novel technique to calculate more stable image-level gradients via diffusion models compared to existing alternatives. Finally, we produce realistic animations by fine-tuning the rendered shape and texture under rigid part transformations. Extensive evaluations on multiple existing datasets as well as newly introduced noisy web image collections with occlusions and truncation demonstrate that ARTIC3D outputs are more robust to noisy images, higher quality in terms of shape and texture details, and more realistic when animated. Project page: https://chhankyao.github.io/artic3d/|
|**2023-06-07**|**Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt**|Kai Chen et.al.|[2306.04607v2](http://arxiv.org/abs/2306.04607v2)|null|Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experiments demonstrate GeoDiffusion outperforms previous L2I methods while maintaining 4x training time faster. To the best of our knowledge, this is the first work to adopt diffusion models for layout-to-image generation with geometric conditions and demonstrate that L2I-generated images can be beneficial for improving the performance of object detectors.|
|**2023-06-07**|**The CYGNO experiment, a directional detector for direct Dark Matter searches**|F. D. Amaro et.al.|[2306.04568v1](http://arxiv.org/abs/2306.04568v1)|null|The CYGNO project aims at the development of a high precision optical readout gaseous Tima Projection Chamber (TPC) for directional dark matter (DM) searches, to be hosted at Laboratori Nazionali del Gran Sasso (LNGS). CYGNO employs a He:CF$_4$ gas mixture at atmospheric pressure with a Gas Electron Multiplier (GEM) based amplification structure coupled to an optical readout comprised of sCMOS cameras and photomultiplier tubes (PMTs). This experimental setup allows to achieve 3D tracking and background rejection down to O(1) keV energy, to boost sensitivity to low WIMP masses. The characteristics of the optical readout approach in terms of the light yield will be illustrated along with the particle identification properties. The project timeline foresees, in the next 2-3 years, the realisation and installation of a 0.4 m$^3$ TPC in the underground laboratories at LNGS to act as a demonstrator. Finally, the studies of the expected DM sensitivities of the CYGNO demonstrator will be presented.|
|**2023-06-07**|**Integrated Photonic Encoder for Terapixel Image Processing**|Xiao Wang et.al.|[2306.04554v1](http://arxiv.org/abs/2306.04554v1)|null|Modern lens designs are capable of resolving >10 gigapixels, while advances in camera frame-rate and hyperspectral imaging have made Terapixel/s data acquisition a real possibility. The main bottlenecks preventing such high data-rate systems are power consumption and data storage. In this work, we show that analog photonic encoders could address this challenge, enabling high-speed image compression using orders-of-magnitude lower power than digital electronics. Our approach relies on a silicon-photonics front-end to compress raw image data, foregoing energy-intensive image conditioning and reducing data storage requirements. The compression scheme uses a passive disordered photonic structure to perform kernel-type random projections of the raw image data with minimal power consumption and low latency. A back-end neural network can then reconstruct the original images with structural similarity exceeding 90%. This scheme has the potential to process Terapixel/s data streams using less than 100 fJ/pixel, providing a path to ultra-high-resolution data and image acquisition systems.|
|**2023-06-07**|**Revising deep learning methods in parking lot occupancy detection**|Anastasia Martynova et.al.|[2306.04288v2](http://arxiv.org/abs/2306.04288v2)|[link](https://github.com/eighonet/parking-research)|Parking guidance systems have recently become a popular trend as a part of the smart cities' paradigm of development. The crucial part of such systems is the algorithm allowing drivers to search for available parking lots across regions of interest. The classic approach to this task is based on the application of neural network classifiers to camera records. However, existing systems demonstrate a lack of generalization ability and appropriate testing regarding specific visual conditions. In this study, we extensively evaluate state-of-the-art parking lot occupancy detection algorithms, compare their prediction quality with the recently emerged vision transformers, and propose a new pipeline based on EfficientNet architecture. Performed computational experiments have demonstrated the performance increase in the case of our model, which was evaluated on 5 different datasets.|
|**2023-06-07**|**Learning Probabilistic Coordinate Fields for Robust Correspondences**|Weiyue Zhao et.al.|[2306.04231v1](http://arxiv.org/abs/2306.04231v1)|null|We introduce Probabilistic Coordinate Fields (PCFs), a novel geometric-invariant coordinate representation for image correspondence problems. In contrast to standard Cartesian coordinates, PCFs encode coordinates in correspondence-specific barycentric coordinate systems (BCS) with affine invariance. To know \textit{when and where to trust} the encoded coordinates, we implement PCFs in a probabilistic network termed PCF-Net, which parameterizes the distribution of coordinate fields as Gaussian mixture models. By jointly optimizing coordinate fields and their confidence conditioned on dense flows, PCF-Net can work with various feature descriptors when quantifying the reliability of PCFs by confidence maps. An interesting observation of this work is that the learned confidence map converges to geometrically coherent and semantically consistent regions, which facilitates robust coordinate representation. By delivering the confident coordinates to keypoint/feature descriptors, we show that PCF-Net can be used as a plug-in to existing correspondence-dependent approaches. Extensive experiments on both indoor and outdoor datasets suggest that accurate geometric invariant coordinates help to achieve the state of the art in several correspondence problems, such as sparse feature matching, dense image registration, camera pose estimation, and consistency filtering. Further, the interpretable confidence map predicted by PCF-Net can also be leveraged to other novel applications from texture transfer to multi-homography classification.|
|**2023-06-07**|**StructuredMesh: 3D Structured Optimization of Façade Components on Photogrammetric Mesh Models using Binary Integer Programming**|Libin Wang et.al.|[2306.04184v1](http://arxiv.org/abs/2306.04184v1)|null|The lack of fa\c{c}ade structures in photogrammetric mesh models renders them inadequate for meeting the demands of intricate applications. Moreover, these mesh models exhibit irregular surfaces with considerable geometric noise and texture quality imperfections, making the restoration of structures challenging. To address these shortcomings, we present StructuredMesh, a novel approach for reconstructing fa\c{c}ade structures conforming to the regularity of buildings within photogrammetric mesh models. Our method involves capturing multi-view color and depth images of the building model using a virtual camera and employing a deep learning object detection pipeline to semi-automatically extract the bounding boxes of fa\c{c}ade components such as windows, doors, and balconies from the color image. We then utilize the depth image to remap these boxes into 3D space, generating an initial fa\c{c}ade layout. Leveraging architectural knowledge, we apply binary integer programming (BIP) to optimize the 3D layout's structure, encompassing the positions, orientations, and sizes of all components. The refined layout subsequently informs fa\c{c}ade modeling through instance replacement. We conducted experiments utilizing building mesh models from three distinct datasets, demonstrating the adaptability, robustness, and noise resistance of our proposed methodology. Furthermore, our 3D layout evaluation metrics reveal that the optimized layout enhances precision, recall, and F-score by 6.5%, 4.5%, and 5.5%, respectively, in comparison to the initial layout.|
|**2023-06-07**|**When to Read Documents or QA History: On Unified and Selective Open-domain QA**|Kyungjae Lee et.al.|[2306.04176v1](http://arxiv.org/abs/2306.04176v1)|null|This paper studies the problem of open-domain question answering, with the aim of answering a diverse range of questions leveraging knowledge resources. Two types of sources, QA-pair and document corpora, have been actively leveraged with the following complementary strength. The former is highly precise when the paraphrase of given question $q$ was seen and answered during training, often posed as a retrieval problem, while the latter generalizes better for unseen questions. A natural follow-up is thus leveraging both models, while a naive pipelining or integration approaches have failed to bring additional gains over either model alone. Our distinction is interpreting the problem as calibration, which estimates the confidence of predicted answers as an indicator to decide when to use a document or QA-pair corpus. The effectiveness of our method was validated on widely adopted benchmarks such as Natural Questions and TriviaQA.|
|**2023-06-07**|**BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives**|Sainan Liu et.al.|[2306.04166v1](http://arxiv.org/abs/2306.04166v1)|null|Implicit neural representation has emerged as a powerful method for reconstructing 3D scenes from 2D images. Given a set of camera poses and associated images, the models can be trained to synthesize novel, unseen views. In order to expand the use cases for implicit neural representations, we need to incorporate camera pose estimation capabilities as part of the representation learning, as this is necessary for reconstructing scenes from real-world video sequences where cameras are generally not being tracked. Existing approaches like COLMAP and, most recently, bundle-adjusting neural radiance field methods often suffer from lengthy processing times. These delays ranging from hours to days, arise from laborious feature matching, hardware limitations, dense point sampling, and long training times required by a multi-layer perceptron structure with a large number of parameters. To address these challenges, we propose a framework called bundle-adjusting accelerated neural graphics primitives (BAA-NGP). Our approach leverages accelerated sampling and hash encoding to expedite both pose refinement/estimation and 3D scene reconstruction. Experimental results demonstrate that our method achieves a more than 10 to 20 $\times$ speed improvement in novel view synthesis compared to other bundle-adjusting neural radiance field methods without sacrificing the quality of pose estimation.|
|**2023-06-07**|**Effect of viscosity on the dynamics of a non-equilibrium bubble in free-field and near a free-surface**|Y. S. Kannan et.al.|[2306.04129v1](http://arxiv.org/abs/2306.04129v1)|null|The effect of viscosity on the behaviour of a non-equilibrium bubble is investigated experimentally, in two scenarios; firstly, when the bubble is generated in the bulk of the fluid (termed as ``free-field'' bubble) and secondly when the bubble is generated near a free-surface (termed as ``free-surface'' bubble). The bubble is created using a low-voltage spark circuit and its dynamics is captured using a high-speed camera with back-lit illumination. The viscosity of the surrounding fluid is varied by using different grades of silicone oil. For a ``free-field'' bubble, the bubble oscillates radially and as the viscosity of the liquid increases, the number of oscillations, as well as the time-period of each oscillation, are increased. At high viscosities, the bubble also becomes stable and does not disintegrate into smaller bubbles. For ``free-surface'' bubbles, two parameters, namely, the initial distance of the bubble from the free-surface and the viscosity of the surrounding fluid are varied. It is observed that beyond a certain initial distance of the bubble from the free-surface, the bubble behaves as a ``free-field'' bubble with negligible influence of the free-surface on its dynamics. This limiting initial distance decreases as the liquid viscosity is increased and is not dependent on the bubble radius. For these bubbles, different behaviours of the free-surface in each liquid are also presented as a function of the two parameters.|
|**2023-06-07**|**Retrosynthesis Prediction with Local Template Retrieval**|Shufang Xie et.al.|[2306.04123v1](http://arxiv.org/abs/2306.04123v1)|null|Retrosynthesis, which predicts the reactants of a given target molecule, is an essential task for drug discovery. In recent years, the machine learing based retrosynthesis methods have achieved promising results. In this work, we introduce RetroKNN, a local reaction template retrieval method to further boost the performance of template-based systems with non-parametric retrieval. We first build an atom-template store and a bond-template store that contain the local templates in the training data, then retrieve from these templates with a k-nearest-neighbor (KNN) search during inference. The retrieved templates are combined with neural network predictions as the final output. Furthermore, we propose a lightweight adapter to adjust the weights when combing neural network and KNN predictions conditioned on the hidden representation and the retrieved templates. We conduct comprehensive experiments on two widely used benchmarks, the USPTO-50K and USPTO-MIT. Especially for the top-1 accuracy, we improved 7.1% on the USPTO-50K dataset and 12.0% on the USPTO-MIT dataset. These results demonstrate the effectiveness of our method.|
|**2023-06-06**|**Wearable Sensory Substitution for Proprioception via Deep Pressure**|Sreela Kodali et.al.|[2306.04034v1](http://arxiv.org/abs/2306.04034v1)|null|We propose a sensory substitution device that communicates one-degree-of-freedom proprioceptive feedback via deep pressure stimulation on the arm. The design is motivated by the need for a feedback modality detectable by individuals with a genetic condition known as PIEZO2 loss of function, which is characterized by absence of both proprioception and sense of light touch. We created a wearable and programmable prototype that applies up to 15 N of deep pressure stimulation to the forearm and includes an embedded force sensor. We conducted a study to evaluate the ability of participants without sensory impairment to control the position of a virtual arm to match a target angle communicated by deep pressure stimulation. A participant-specific calibration resulted in an average minimum detectable force of 0.41 N and maximum comfortable force of 6.42 N. We found that, after training, participants were able to significantly reduce angle error using the deep pressure haptic feedback compared to without it. Angle error increased only slightly with force, indicating that this sensory substitution method is a promising approach for individuals with PIEZO2 loss of function and other forms of sensory loss.|
|**2023-06-06**|**BokehOrNot: Transforming Bokeh Effect with Image Transformer and Lens Metadata Embedding**|Zhihao Yang et.al.|[2306.04032v1](http://arxiv.org/abs/2306.04032v1)|[link](https://github.com/indicator0/bokehornot)|Bokeh effect is an optical phenomenon that offers a pleasant visual experience, typically generated by high-end cameras with wide aperture lenses. The task of bokeh effect transformation aims to produce a desired effect in one set of lenses and apertures based on another combination. Current models are limited in their ability to render a specific set of bokeh effects, primarily transformations from sharp to blur. In this paper, we propose a novel universal method for embedding lens metadata into the model and introducing a loss calculation method using alpha masks from the newly released Bokeh Effect Transformation Dataset(BETD) [3]. Based on the above techniques, we propose the BokehOrNot model, which is capable of producing both blur-to-sharp and sharp-to-blur bokeh effect with various combinations of lenses and aperture sizes. Our proposed model outperforms current leading bokeh rendering and image restoration models and renders visually natural bokeh effects. Our code is available at: https://github.com/indicator0/bokehornot.|

## smart glass

### smart glass
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**A ship-in-a-bottle quantum gas microscope for magnetic mixtures**|Maximilian Sohmen et.al.|[2306.05404v1](http://arxiv.org/abs/2306.05404v1)|null|Quantum gas microscopes are versatile and powerful tools for fundamental science as well as promising candidates for enticing applications such as in quantum simulation or quantum computation. Here we present a quantum gas microscopy setup for experiments with highly magnetic atoms of the lanthanoid elements erbium and dysprosium. Our setup features a non-magnetic, non-conducting, large-working-distance, high-numerical-aperture, in-vacuum microscope objective, mounted inside a glue-free quartz glass cell. The quartz glass cell is enclosed by a compact multi-shell ferromagnetic shield that passively suppresses external magnetic field noise by a factor of more than a thousand. Our setup will enable direct manipulation and probing of the rich quantum many-body physics of dipolar atoms in optical lattices, and bears the potential to put exciting theory proposals -- including exotic magnetic phases and quantum phase transitions -- to an experimental test.|
|**2023-06-08**|**Revealing the Blind Spot of Sentence Encoder Evaluation by HEROS**|Cheng-Han Chiang et.al.|[2306.05083v1](http://arxiv.org/abs/2306.05083v1)|null|Existing sentence textual similarity benchmark datasets only use a single number to summarize how similar the sentence encoder's decision is to humans'. However, it is unclear what kind of sentence pairs a sentence encoder (SE) would consider similar. Moreover, existing SE benchmarks mainly consider sentence pairs with low lexical overlap, so it is unclear how the SEs behave when two sentences have high lexical overlap. We introduce a high-quality SE diagnostic dataset, HEROS. HEROS is constructed by transforming an original sentence into a new sentence based on certain rules to form a \textit{minimal pair}, and the minimal pair has high lexical overlaps. The rules include replacing a word with a synonym, an antonym, a typo, a random word, and converting the original sentence into its negation. Different rules yield different subsets of HEROS. By systematically comparing the performance of over 60 supervised and unsupervised SEs on HEROS, we reveal that most unsupervised sentence encoders are insensitive to negation. We find the datasets used to train the SE are the main determinants of what kind of sentence pairs an SE considers similar. We also show that even if two SEs have similar performance on STS benchmarks, they can have very different behavior on HEROS. Our result reveals the blind spot of traditional STS benchmarks when evaluating SEs.|
|**2023-06-08**|**SmartBugs 2.0: An Execution Framework for Weakness Detection in Ethereum Smart Contracts**|Monika di Angelo et.al.|[2306.05057v1](http://arxiv.org/abs/2306.05057v1)|null|Smart contracts are blockchain programs that often handle valuable assets. Writing secure smart contracts is far from trivial, and any vulnerability may lead to significant financial losses. To support developers in identifying and eliminating vulnerabilities, methods and tools for the automated analysis have been proposed. However, the lack of commonly accepted benchmark suites and performance metrics makes it difficult to compare and evaluate such tools. Moreover, the tools are heterogeneous in their interfaces and reports as well as their runtime requirements, and installing several tools is time-consuming.   In this paper, we present SmartBugs 2.0, a modular execution framework. It provides a uniform interface to 19 tools aimed at smart contract analysis and accepts both Solidity source code and EVM bytecode as input. After describing its architecture, we highlight the features of the framework. We evaluate the framework via its reception by the community and illustrate its scalability by describing its role in a study involving 3.25 million analyses.|
|**2023-06-08**|**Sequence-to-Sequence Model with Transformer-based Attention Mechanism and Temporal Pooling for Non-Intrusive Load Monitoring**|Mohammad Irani Azad et.al.|[2306.05012v1](http://arxiv.org/abs/2306.05012v1)|null|This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) of smart buildings. The paper aims to improve the accuracy of NILM by using a deep learning-based method. The proposed method uses a Seq2Seq model with a transformer-based attention mechanism to capture the long-term dependencies of NILM data. Additionally, temporal pooling is used to improve the model's accuracy by capturing both the steady-state and transient behavior of appliances. The paper evaluates the proposed method on a publicly available dataset and compares the results with other state-of-the-art NILM techniques. The results demonstrate that the proposed method outperforms the existing methods in terms of both accuracy and computational efficiency.|
|**2023-06-08**|**Parallel and Asynchronous Smart Contract Execution**|Jian Liu et.al.|[2306.05007v1](http://arxiv.org/abs/2306.05007v1)|null|Today's blockchains suffer from low throughput and high latency, which impedes their widespread adoption of more complex applications like smart contracts. In this paper, we propose a novel paradigm for smart contract execution. It distinguishes between consensus nodes and execution nodes: different groups of execution nodes can execute transactions in parallel; meanwhile, consensus nodes can asynchronously order transactions and process execution results. Moreover, it requires no coordination among execution nodes and can effectively prevent livelocks. We show two ways of applying this paradigm to blockchains. First, we show how we can make Ethereum support parallel and asynchronous contract execution \emph{without hard-forks}. Then, we propose a new public, permissionless blockchain. Our benchmark shows that, with a fast consensus layer, it can provide a high throughput even for complex transactions like Cryptokitties gene mixing. It can also protect simple transactions from being starved by complex transactions.|
|**2023-06-08**|**Modern Data Pricing Models: Taxonomy and Comprehensive Survey**|Xiaoye Miao et.al.|[2306.04945v1](http://arxiv.org/abs/2306.04945v1)|null|Data play an increasingly important role in smart data analytics, which facilitate many data-driven applications. The goal of various data markets aims to alleviate the issue of isolated data islands, so as to benefit data circulation. The problem of data pricing is indispensable yet challenging in data trade. In this paper, we conduct a comprehensive survey on the modern data pricing solutions. We divide the data pricing solutions into three major strategies and thirteen models, including query pricing strategy, feature-based data pricing strategy, and pricing strategy in machine learning. It is so far the first attempt to classify so many existing data pricing models. Moreover, we not only elaborate the thirteen specific pricing models within each pricing strategy, but also make in-depth analyses among these models. We also conclude five research directions for the data pricing field, and put forward some novel and interesting data pricing topics. This paper aims at gaining better insights, and directing the future research towards practical and sophisticated pricing mechanisms for better data trade and share.|
|**2023-06-07**|**Frequency conditions for the global stability of nonlinear delay equations with several equilibria**|Mikhail Anikushin et.al.|[2306.04716v1](http://arxiv.org/abs/2306.04716v1)|null|In our adjacent work, we developed a spectral comparison principle for compound cocycles generated by delay equations. In particular, this principle allows to derive frequency conditions (inequalities) for the uniform exponential stability of such cocycles by means of their comparison with stationary problems. Such inequalities are hard to verify analytically since they contain resolvents of additive compound operators and to compute the resolvents it is required solving a first-order PDEs with boundary conditions involving both partial derivatives and delays.   In this work, we develop approximation schemes to verify some of the arising frequency inequalities. Beside some general results, we mainly stick to the case of scalar equations. By means of the Suarez-Schopf delayed oscillator and the Mackey-Glass equations, we demonstrate applications of the theory to reveal regions in the space of parameters where the absence of closed invariant contours can be guaranteed. Since our conditions are robust, so close systems also satisfy them, we expect them to actually imply the global stability, as in known finite-dimensional results utilizing variants of the Closing Lemma which is still awaiting developments in infinite dimensions.|
|**2023-06-07**|**Forward $γ$+jet production in proton-proton and proton-lead collisions at LHC within the FoCal calorimeter acceptance**|Ishita Ganguli et.al.|[2306.04706v1](http://arxiv.org/abs/2306.04706v1)|null|Using the small-$x$ Improved Transverse Momentum Dependent factorization, which can be proved within the Color Glass Condensate theory for transverse momenta of particles greater than the saturation scale, we provide predictions for isolated forward photon and jet production in proton-proton and proton-nucleus collisions within the planned ALICE FoCal detector acceptance. We study azimuthal correlations, $p_T$ spectra, as well as normalized ratios of proton-proton cross sections for different energies. We conclude, that the process provides an excellent probe of the dipole transverse momentum dependent gluon distribution in saturation regime.|
|**2023-06-07**|**Multifractality in spin glasses**|Janus Collaboration et.al.|[2306.04591v1](http://arxiv.org/abs/2306.04591v1)|null|We unveil the multifractal behavior of Ising spin glasses in their low-temperature phase. Using the Janus II custom-built supercomputer, the spin-glass correlation function is studied locally. Dramatic fluctuations are found when pairs of sites at the same distance are compared. The scaling of these fluctuations, as the spin-glass coherence length grows with time, is characterized through the computation of the singularity spectrum and its corresponding Legendre transform. A comparatively small number of site pairs controls the average correlation that governs the response to a magnetic field. We explain how this scenario of dramatic fluctuations (at length scales smaller than the coherence length) can be reconciled with the smooth, self-averaging behavior that has long been considered to describe spin-glass dynamics.|
|**2023-06-07**|**Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network**|Haiyang Liu et.al.|[2306.04479v1](http://arxiv.org/abs/2306.04479v1)|null|The immutable and trustable characteristics of blockchain enable smart contracts to be applied in various fields. Unfortunately, smart contracts are subject to various vulnerabilities, which are frequently exploited by attackers, causing financial damage to users.In this paper, we study the problem of vulnerable smart contract function locating. We construct a novel Multi-Relational Nested contract Graph (MRNG) to better characterize the rich syntactic and semantic information in the smart contract code, including the relationships between data and instructions. An MRNG represents a smart contract, where each node represents a function in the smart contract and each edge describes the calling relationship between the functions. In addition, we create a Multi-Relational Function Graph (MRFG) for each function, which characterizes the corresponding function code. That is, each function is characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG uses different types of edges to represent the different control and data relationships between nodes within a function. We also propose a Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the edge-enhanced graph convolution network and self-attention mechanism. The extracted feature vector is then assigned to the corresponding node in the MRNG to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph convolution is used to further extract features from the FCG. Finally, a feed forward network with a Sigmoid function is used to locate the vulnerable functions. Experimental results on the real-world smart contract datasets show that model MRN-GCN can effectively improve the accuracy, precision, recall and F1-score performance of vulnerable smart contract function locating.|
|**2023-06-07**|**Hardening and Speeding Up Zero-interaction Pairing and Authentication**|Mikhail Fomichev et.al.|[2306.04458v1](http://arxiv.org/abs/2306.04458v1)|null|Establishing and maintaining secure communications in the Internet of Things (IoT) is vital to protect smart devices. Zero-interaction pairing (ZIP) and zero-interaction authentication (ZIA) enable IoT devices to establish and maintain secure communications without user interaction by utilizing devices' ambient context, e.g., audio. For autonomous operation, ZIP and ZIA require the context to have enough entropy to resist attacks and complete in a timely manner. Despite the low-entropy context being the norm, like inside an unoccupied room, the research community has yet to come up with ZIP and ZIA schemes operating under such conditions. We propose HARDZIPA, a novel approach that turns commodity IoT actuators into injecting devices, generating high-entropy context. Here, we combine the capability of IoT actuators to impact the environment, e.g., emitting a sound, with a pseudorandom number generator (PRNG) featured by many actuators to craft hard-to-predict context stimuli. To demonstrate the feasibility of HARDZIPA, we implement it on off-the-shelf IoT actuators, i.e., smart speakers, lights, and humidifiers. We comprehensively evaluate HARDZIPA, collecting over 80 hours of various context data in real-world scenarios. Our results show that HARDZIPA is able to thwart advanced active attacks on ZIP and ZIA schemes, while doubling the amount of context entropy in many cases, which allows two times faster pairing and authentication.|
|**2023-06-07**|**Revising deep learning methods in parking lot occupancy detection**|Anastasia Martynova et.al.|[2306.04288v2](http://arxiv.org/abs/2306.04288v2)|[link](https://github.com/eighonet/parking-research)|Parking guidance systems have recently become a popular trend as a part of the smart cities' paradigm of development. The crucial part of such systems is the algorithm allowing drivers to search for available parking lots across regions of interest. The classic approach to this task is based on the application of neural network classifiers to camera records. However, existing systems demonstrate a lack of generalization ability and appropriate testing regarding specific visual conditions. In this study, we extensively evaluate state-of-the-art parking lot occupancy detection algorithms, compare their prediction quality with the recently emerged vision transformers, and propose a new pipeline based on EfficientNet architecture. Performed computational experiments have demonstrated the performance increase in the case of our model, which was evaluated on 5 different datasets.|
|**2023-06-07**|**An Empirical Study of Impact of Solidity Compiler Updates on Vulnerabilities in Ethereum Smart Contracts**|Chihiro Kado et.al.|[2306.04250v1](http://arxiv.org/abs/2306.04250v1)|null|Vulnerabilities of Ethereum smart contracts often cause serious financial damage. Whereas the Solidity compiler has been updated to prevent vulnerabilities, its effectiveness has not been revealed so far, to the best of our knowledge. In this paper, we shed light on the impact of compiler versions of vulnerabilities of Ethereum smart contracts. To this end, we collected 503,572 contracts with Solidity source codes in the Ethereum blockchain and then analyzed their vulnerabilities. For three vulnerabilities with high severity, i.e., Locked Money, Using tx.origin, and Unchecked Call, we show that their appearance rates are decreased by virtue of major updates of the Solidity compiler. We then found the following four key insights. First, after the release of version 0.6, the appearance rate for Locked Money has decreased. Second, regardless of compiler updates, the appearance rate for Using tx.origin is significantly low. Third, although the appearance rate for Unchecked Call has decreased in version 0.8, it still remains high due to various factors, including code clones. Fourth, through analysis of code clones, our promising results show that the appearance rate for Unchecked Call can be further decreased by removing the code clones.|
|**2023-06-07**|**A Threat Model for Soft Privacy on Smart Cars**|Mario Raciti et.al.|[2306.04222v1](http://arxiv.org/abs/2306.04222v1)|null|Modern cars are getting so computerised that ENISA's phrase "smart cars" is a perfect fit. The amount of personal data that they process is very large and, yet, increasing. Hence, the need to address citizens' privacy while they drive and, correspondingly, the importance of privacy threat modelling (in support of a respective risk assessment, such as through a Data Protection Impact Assessment). This paper addresses privacy threats by advancing a general modelling methodology and by demonstrating it specifically on soft privacy, which ensures citizens' full control on their personal data. By considering all relevant threat agents, the paper applies the methodology to the specific automotive domain while keeping threats at the same level of detail as ENISA's. The main result beside the modelling methodology consists of both domain-independent and automotive domain-dependent soft privacy threats. While cybersecurity has been vastly threat-modelled so far, this paper extends the literature with a threat model for soft privacy on smart cars, producing 17 domain-independent threats that, associated with 41 domain-specific assets, shape a novel set of domain-dependent threats in automotive.|
|**2023-06-07**|**Is Homomorphic Encryption Feasible for Smart Mobility?**|Anika Hannemann et.al.|[2306.04195v1](http://arxiv.org/abs/2306.04195v1)|null|Smart mobility is a promising approach to meet urban transport needs in an environmentally and and user-friendly way. Smart mobility computes itineraries with multiple means of transportation, e.g., trams, rental bikes or electric scooters, according to customer preferences. A mobility platform cares for reservations, connecting transports, invoicing and billing. This requires sharing sensible personal data with multiple parties, and puts data privacy at risk. In this paper, we investigate if fully homomorphic encryption (FHE) can be applied in practice to mitigate such privacy issues. FHE allows to calculate on encrypted data, without having to decrypt it first. We implemented three typical distributed computations in a smart mobility scenario with SEAL, a recent programming library for FHE. With this implementation, we have measured memory consumption and execution times for three variants of distributed transactions, that are representative for a wide range of smart mobility tasks. Our evaluation shows, that FHE is indeed applicable to smart mobility: With today's processing capabilities, state-of-the-art FHE increases a smart mobility transaction by about 100 milliseconds and less than 3 microcents.|
|**2023-06-07**|**UCTB: An Urban Computing Tool Box for Spatiotemporal Crowd Flow Prediction**|Liyue Chen et.al.|[2306.04144v1](http://arxiv.org/abs/2306.04144v1)|[link](https://github.com/uctb/uctb)|Spatiotemporal crowd flow prediction is one of the key technologies in smart cities. Currently, there are two major pain points that plague related research and practitioners. Firstly, crowd flow is related to multiple domain knowledge factors; however, due to the diversity of application scenarios, it is difficult for subsequent work to make reasonable and comprehensive use of domain knowledge. Secondly, with the development of deep learning technology, the implementation of relevant techniques has become increasingly complex; reproducing advanced models has become a time-consuming and increasingly cumbersome task. To address these issues, we design and implement a spatiotemporal crowd flow prediction toolbox called UCTB (Urban Computing Tool Box), which integrates multiple spatiotemporal domain knowledge and state-of-the-art models simultaneously. The relevant code and supporting documents have been open-sourced at https://github.com/uctb/UCTB.|
|**2023-06-06**|**Competing Relaxation Channels in Continuously Polydisperse Fluids: A Mode-Coupling Study**|Corentin C. L. Laudicina et.al.|[2306.03992v1](http://arxiv.org/abs/2306.03992v1)|null|Systems with a high degree of size polydispersity are becoming standard in the computational study of deeply supercooled liquids. In this work we perform a systematic analysis of continuously polydisperse fluids as a function of the degree of polydispersity within the framework of the Mode-Coupling Theory of the glass transition (MCT). Our results show that a high degree of polydispersity tends to stabilize the liquid phase against vitrification, the magnitude of which depends on the shape of the polydispersity distribution. Further, we report on a separation between the localization lengths of the smallest and largest particles. A diameter-resolved analysis of the intermediate scattering functions reveals that this separation significantly stretches the relaxation patterns, which we quantitatively study by an analysis of the dynamical exponents predicted by the theory. Our observations have strong implications for our understanding of the nature of dynamical heterogeneities and localization lengths in continuously polydisperse systems. These results suggest that the dynamics of the smallest particles is of central importance to understand structural relaxation of continuously size polydisperse fluids, already in the mildly supercooled regime where MCT is usually applicable.|
|**2023-06-06**|**A machine learning potential-based generative algorithm for on-lattice crystal structure prediction**|Vadim Sotskov et.al.|[2306.03989v1](http://arxiv.org/abs/2306.03989v1)|null|We propose a method for crystal structure prediction based on a new structure generation algorithm and on-lattice machine learning interatomic potentials. Our algorithm generates the atomic configurations assigning atomic species to sites of the given lattice, and uses cluster expansion or low-rank potential to evaluate their energy. We demonstrate two benefits of such approach. First, our structure generation algorithm offers a ``smart'' configurational space sampling, targeting low-energy structures which significantly reduces computational costs. Second, the application of machine learning interatomic potentials significantly reduces the number of DFT calculations. We discuss how our algorithm resembles the latent diffusion models for image generation. We demonstrate the efficiency of our method by constructing the convex hull of Nb-Mo-Ta-W system, including binary and ternary Nb-W and Mo-Ta-W subsystems. We found new binary, ternary, and quaternary stable structures that are not reported in the AFLOW database which we choose as our baseline. Due to the computational efficiency of our method we anticipate that it can pave the way towards efficient high-throughput discovery of multicomponent materials.|
|**2023-06-06**|**From Data to Action: Exploring AI and IoT-driven Solutions for Smarter Cities**|Tiago Dias et.al.|[2306.04653v1](http://arxiv.org/abs/2306.04653v1)|null|The emergence of smart cities demands harnessing advanced technologies like the Internet of Things (IoT) and Artificial Intelligence (AI) and promises to unlock cities' potential to become more sustainable, efficient, and ultimately livable for their inhabitants. This work introduces an intelligent city management system that provides a data-driven approach to three use cases: (i) analyze traffic information to reduce the risk of traffic collisions and improve driver and pedestrian safety, (ii) identify when and where energy consumption can be reduced to improve cost savings, and (iii) detect maintenance issues like potholes in the city's roads and sidewalks, as well as the beginning of hazards like floods and fires. A case study in Aveiro City demonstrates the system's effectiveness in generating actionable insights that enhance security, energy efficiency, and sustainability, while highlighting the potential of AI and IoT-driven solutions for smart city development.|
|**2023-06-05**|**Imaging the Meissner effect and flux trapping in a hydride superconductor at megabar pressures using a nanoscale quantum sensor**|Prabudhya Bhattacharyya et.al.|[2306.03122v1](http://arxiv.org/abs/2306.03122v1)|null|By directly altering microscopic interactions, pressure provides a powerful tuning knob for the exploration of condensed phases and geophysical phenomena. The megabar regime represents an exciting frontier, where recent discoveries include novel high-temperature superconductors, as well as structural and valence phase transitions. However, at such high pressures, many conventional measurement techniques fail. Here, we demonstrate the ability to perform local magnetometry inside of a diamond anvil cell with sub-micron spatial resolution at megabar pressures. Our approach utilizes a shallow layer of Nitrogen-Vacancy (NV) color centers implanted directly within the anvil; crucially, we choose a crystal cut compatible with the intrinsic symmetries of the NV center to enable functionality at megabar pressures. We apply our technique to characterize a recently discovered hydride superconductor, CeH$_9$. By performing simultaneous magnetometry and electrical transport measurements, we observe the dual signatures of superconductivity: local diamagnetism characteristic of the Meissner effect and a sharp drop of the resistance to near zero. By locally mapping the Meissner effect and flux trapping, we directly image the geometry of superconducting regions, revealing significant inhomogeneities at the micron scale. Our work brings quantum sensing to the megabar frontier and enables the closed loop optimization of superhydride materials synthesis.|
|**2023-06-05**|**Superhydrophobicity of Auxetic Metamaterials**|Glen McHale et.al.|[2306.02916v1](http://arxiv.org/abs/2306.02916v1)|null|Superhydrophobic materials are often inspired by nature, whereas metamaterials are engineered to have properties not usually found in naturally occurring materials. In both cases, the key that unlocks their unique properties is structure. Here, we show that a negative Poisson's ratio (auxetic) mechanical metamaterial is capable of transforming into a unique type of superhydrophobic material. When stretched its surface has the counterintuitive property that it also expands in the orthogonal lateral direction. We model the change in the solid surface fraction as strain is applied and show it decreases as the space between solid elements of the auxetic lattice expands. This results in a unique dependence of the superhydrophobicity on strain. We construct experimental models illustrating the relationship between different states of strain and superhydrophobicity as the lattice structure transitions from an auxetic to a conventional (positive Poisson's ratio) one. The principles we have discovered offer a new approach to designing superhydrophobic materials for self-cleaning surfaces, droplet transportation, droplet encapsulation and oil-water separation.|
|**2023-06-05**|**Modular zk-Rollup On-Demand**|Thomas Lavaur et.al.|[2306.02785v1](http://arxiv.org/abs/2306.02785v1)|[link](https://github.com/thomaslavaur/modular-zk-rollup-on-demand)|The rapid expansion of the use of blockchain-based systems often leads to a choice between customizable private blockchains and more secure, scalable and decentralized but expensive public blockchains. This choice represents the trade-off between privacy and customization at a low cost and security, scalability, and a large user base but at a high cost. In order to improve the scalability of secure public blockchains while enabling privacy and cost reduction, zk-rollups, a layer 2 solution, appear to be a promising avenue. This paper explores the benefits of zk-rollups, including improved privacy, as well as their potential to support transactions designed for specific applications. We propose an innovative design that allows multiple zk-rollups to co-exist on the same smart contracts, simplifying their creation and customization. We then evaluate the first implementation of our system highlighting a low overhead on existing transaction types and on proof generation while strongly decreasing the cost of new transaction types and drastically reducing zk-rollup creation costs.|
|**2023-06-05**|**Sustainable Adaptive Security**|Liliana Pasquale et.al.|[2306.04481v1](http://arxiv.org/abs/2306.04481v1)|null|With software systems permeating our lives, we are entitled to expect that such systems are secure by design, and that such security endures throughout the use of these systems and their subsequent evolution. Although adaptive security systems have been proposed to continuously protect assets from harm, they can only mitigate threats arising from changes foreseen at design time. In this paper, we propose the notion of Sustainable Adaptive Security (SAS) which reflects such enduring protection by augmenting adaptive security systems with the capability of mitigating newly discovered threats. To achieve this objective, a SAS system should be designed by combining automation (e.g., to discover and mitigate security threats) and human intervention (e.g., to resolve uncertainties during threat discovery and mitigation). In this paper, we use a smart home example to showcase how we can engineer the activities of the MAPE (Monitor, Analysis, Planning, and Execution) loop of systems satisfying sustainable adaptive security. We suggest that using anomaly detection together with abductive reasoning can help discover new threats and guide the evolution of security requirements and controls. We also exemplify situations when humans can be involved in the execution of the activities of the MAPE loop and discuss the requirements to engineer human interventions.|
|**2023-06-05**|**A Study of Situational Reasoning for Traffic Understanding**|Jiarui Zhang et.al.|[2306.02520v1](http://arxiv.org/abs/2306.02520v1)|null|Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work, based on natural language inference, commonsense knowledge-graph self-supervision, multi-QA joint training, and dense retrieval of domain information. We associate each method with a relevant knowledge source, including knowledge graphs, relevant benchmarks, and driving manuals. In extensive experiments, we benchmark various knowledge-aware methods against the three datasets, under zero-shot evaluation; we provide in-depth analyses of model performance on data partitions and examine model predictions categorically, to yield useful insights on traffic understanding, given different background knowledge and reasoning strategies.|
|**2023-06-04**|**Anomaly Detection Techniques in Smart Grid Systems: A Review**|Shampa Banik et.al.|[2306.02473v1](http://arxiv.org/abs/2306.02473v1)|null|Smart grid data can be evaluated for anomaly detection in numerous fields, including cyber-security, fault detection, electricity theft, etc. The strange anomalous behaviors may have been caused by various reasons, including peculiar consumption patterns of the consumers, malfunctioning grid infrastructures, outages, external cyber-attacks, or energy fraud. Recently, anomaly detection of the smart grid has attracted a large amount of interest from researchers, and it is widely applied in a number of high-impact fields. One of the most significant challenges within the smart grid is the implementation of efficient anomaly detection for multiple forms of aberrant behaviors. In this paper, we provide a scoping review of research from the recent advancements in anomaly detection in the context of smart grids. We categorize our study from numerous aspects for deep understanding and inspection of the research challenges so far. Finally, after analyzing the gap in the reviewed paper, the direction for future research on anomaly detection in smart-grid systems has been provided briefly.|
|**2023-06-04**|**"Are you telling me to put glasses on the dog?'' Content-Grounded Annotation of Instruction Clarification Requests in the CoDraw Dataset**|Brielen Madureira et.al.|[2306.02377v1](http://arxiv.org/abs/2306.02377v1)|null|Instruction Clarification Requests are a mechanism to solve communication problems, which is very functional in instruction-following interactions. Recent work has argued that the CoDraw dataset is a valuable source of naturally occurring iCRs. Beyond identifying when iCRs should be made, dialogue models should also be able to generate them with suitable form and content. In this work, we introduce CoDraw-iCR (v2), which extends the existing iCR identifiers fine-grained information grounded in the underlying dialogue game items and possible actions. Our annotation can serve to model and evaluate repair capabilities of dialogue agents.|
|**2023-06-04**|**Softly, Deftly, Scrolls Unfurl Their Splendor: Rolling Flexible Surfaces for Wideband Wireless**|Ruichun Ma et.al.|[2306.02361v1](http://arxiv.org/abs/2306.02361v1)|null|With new frequency bands opening up, emerging wireless IoT devices are capitalizing on an increasingly divergent range of frequencies. However, existing coverage provisioning practice is often tied to specific standards and frequencies. There is little shareable wireless infrastructure for concurrent links on different frequencies, across networks and standards. This paper presents Scrolls, a frequency-tunable soft smart surface system to enhance wideband, multi-network coverage. Scrolls' hardware comprises many rows of rollable thin plastic film, each attached with flexible copper strips. When rolled to different lengths, the copper strips act as wire antennas reflecting signals on the corresponding frequencies. The surface control algorithm determines the unrolled strip lengths for link enhancement by probing the search space efficiently. We build a set of distributed, composable Scrolls prototypes and deploy them in an office. Extensive evaluation shows that Scrolls can adapt the antenna lengths effectively to provide link enhancement across diverse standards on sub-6 GHz bands. For concurrent links on 900 MHz (LoRa), 2.4 GHz (Wi-Fi), 3.7 GHz, and 5 GHz, Scrolls can provide received signal strength gains to all links simultaneously, by a median of 4 dB and up to 10 dB|
|**2023-06-02**|**SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow**|Pengcheng Lu et.al.|[2306.01665v1](http://arxiv.org/abs/2306.01665v1)|null|As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, and such methods lack interpretability and sustainability. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-training models and data flow, which only requires using the source code of smart contracts as features to explore the possibility of detecting smart Ponzi schemes from another direction. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods while increasing the interpretability of the model. Specifically, we first convert the source code of a smart contract into a data flow graph and then introduce a pre-training model based on learning code representations to build a classification model to identify Ponzi schemes in smart contracts. The experimental results show that SourceP achieves 87.2\% recall and 90.7\% F-score for detecting smart Ponzi schemes within Ethereum's smart contract dataset, outperforming state-of-the-art methods in terms of performance and sustainability. We also demonstrate through additional experiments that pre-training models and data flow play an important contribution to SourceP, as well as proving that SourceP has a good generalization ability.|
|**2023-06-02**|**Glass transition temperature of thin polymer films**|Hsiao-Ping Hsu et.al.|[2306.01560v1](http://arxiv.org/abs/2306.01560v1)|null|The glass transition temperature and its connection to statistical properties of confined and free-standing polymer films of varying thickness containing unentangled to highly entangled bead-spring chains are studied by molecular dynamics simulations. For confined films, perfect scaling of the thickness-dependent end-to-end distance and radius of gyrations normalized to their bulk values in the directions parallel and perpendicular to the surfaces is obtained. Particularly, the reduced end-to-end distance in the perpendicular direction is very well described by the extended Silberberg model. For bulk polymer melts, the relation between chain length and $T_g$ follows the Fox-Flory equation while $T_g$ for a given film thickness is almost independent of chain length. For films, $T_g$ decreases and is well described by Keddie's formula, where the reduction is more pronounced for free-standing films. For the present model, $T_g$ begins to deviate from bulk $T_g$ at the characteristic film thickness, where the average bond orientation becomes anisotropic and the entanglement density decreases.|
|**2023-06-02**|**Proxy Re-encryption based Fair Trade Protocol for Digital Goods Transactions via Smart Contracts**|Peng Zhang et.al.|[2306.01299v1](http://arxiv.org/abs/2306.01299v1)|null|With the massive amount of digital data generated everyday, transactions of digital goods become a trend. One of the essential requirements for such transactions is fairness, which is defined as that both of the seller and the buyer get what they want, or neither. Current fair trade protocols generally involve a trusted third-party (TTP), which achieves fairness by heavily relying on the TTP's behaviors and the two parties' trust in the TTP. With the emergence of Blockchain, its decentralization and transparency make it a very good candidate to replace the TTP. In this work, we attempt to design a secure and fair protocol for digital goods transactions through smart contracts on Blockchain. To ensure security of the digital goods, we propose an advanced passive proxy re-encryption (PRE) scheme, which enables smart contracts to transfer the decryption right to a buyer after receiving his/her payment. Furthermore, based on smart contracts and the proposed passive PRE scheme, a fair trade protocol for digital goods transactions is proposed, whose fairness is guaranteed by the arbitration protocol. The proposed protocol supports Ciphertext publicity and repeatable sale, while involving less number of interactions. Comprehensive experiment results validate the feasibility and effectiveness of the proposed protocol.|

## wearable device

### wearable device
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Particle-in-cell simulation of a 50~mTorr capacitively coupled argon discharge over a range of frequencies**|Saurabh Simha et.al.|[2306.05386v1](http://arxiv.org/abs/2306.05386v1)|null|The effect of driving frequency in the range of 13.56 MHz to 73 MHz on electron energy distribution and electron heating modes in a 50 mTorr capacitively coupled argon plasma discharge is studied using 1D-3V particle-in-cell simulations. Calculated electron energy probability functions exhibit three distinct ``temperatures'' for low-, mid-, and high-energy electrons. When compared to published experimental data, the calculated probability functions show a reasonable agreement for the energy range resolved in the measurements (about 2 eV to 10 eV). Discrepancies outside this range lead to differences between computational and experimental values of the electron number density determined from the distribution functions, but the predicted effective electron temperature is within 25\% of experimental values. The impedance of the discharge is interpreted in terms of a homogeneous equivalent circuit model and the driving frequency dependence of the inferred combined sheath thickness is found to obey a known, theoretically-derived, power law. The average power transferred from the field to the electrons (electron heating) is computed, and a region of negative heating near the sheath edge, particularly at higher driving frequencies, is identified. Analysis of the electron momentum equation shows that electron inertia, which would average to zero in a linear regime, is responsible for negative values of power deposition near the sheath edge at high driving frequencies due to the highly nonlinear behavior of the discharge.|
|**2023-06-08**|**Epitaxial thin films of binary Eu-compounds close to a valence transition**|Sebastian Kölsch et.al.|[2306.05355v1](http://arxiv.org/abs/2306.05355v1)|null|Intermetallic binary compounds of europium reveal a variety of interesting phenomena due to the interconnection between two different magnetic and 4f electronic (valence) states, which are particularly close in energy. The valence states or magnetic properties are thus particularly sensitive to strain-tuning in these materials. Consequently, we grew epitaxial EuPd$_2$ (magnetic Eu$^{2+}$) and EuPd$_3$ (nonmagnetic Eu$^{3+}$) thin films on MgO(001) substrates using molecular beam epitaxy. Ambient X-ray diffraction confirms an epitaxial relationship of cubic Laves-type (C15) EuPd$_2$ with an (111)-out-of plane orientation, whereby four distinct in-plane crystallographic domains develop. For simple cubic EuPd$_3$ two different out-of-plane orientations can be obtained by changing the substrate annealing temperature under ultra-high vacuum conditions from 600{\deg} C to 1000{\deg} C for one hour. A small resistance minimum evolves for EuPd$_3$ thin films grown with low temperature substrate annealing, which was previously found even in single crystals of EuPd$_3$ and might be attributed to a Kondo or weak localization effect. Absence of influence of an applied magnetic fields and magnetotransport measurements suggest always a nonmagnetic ground state for EuPd$_3$ thin films, i. e., a purely trivalent Eu valence, as previously found in EuPd3 single crystals. For EuPd$_2$ magnetic ordering below ~72 K is observed, quite similar to single crystal behaviour. Additional field dependent measurements of the magnetoresistance and the Hall effect show hysteresis effects below ~0.4 T and an anomalous Hall effect below ~70 K, which saturates around 1.4 T, thus proving a ferromagnetic ground state of the divalent Eu.|
|**2023-06-08**|**How does Mg$^{2+}_{(aq)}$ interact with ATP$_{(aq)}$? Observations through the lens of liquid-jet photoelectron spectroscopy**|Karen Mudryk et.al.|[2306.05352v1](http://arxiv.org/abs/2306.05352v1)|null|Site-specific information on how adenosine triphosphate in the aqueous phase (ATP$_{(aq)}$) interacts with magnesium (Mg$^{2+}_{(aq)}$) is a prerequisite to understanding its complex biochemistry. To gather such information, we apply liquid-jet photoelectron spectroscopy (LJ-PES) assisted by electronic-structure calculations to study ATP$_{(aq)}$ solutions with and without dissolved Mg$^{2+}$. Valence photoemission data reveal spectral changes in the phosphate and adenine features of ATP$_{(aq)}$ due to interactions with the divalent cation. Chemical shifts in Mg 2p, Mg 2s, P 2p, and P 2s core-level spectra as a function of the Mg$^{2+}$/ATP concentration ratio are correlated to the formation of [MgATP]$^{-2}_{(aq)}$ and Mg$_2$ATP$_{(aq)}$ complexes, demonstrating the element-sensitivity of the technique to Mg$^{2+}$-phosphate interactions. In addition, we report and compare P 2s data from ATP$_{(aq)}$ and adenosine mono- and di-phosphate (AMP$_{(aq)}$ and ADP$_{(aq)}$, respectively) solutions, probing the electronic structure of the phosphate chain and the local environment of individual phosphate units in ATP$_{(aq)}$. Finally, we have recorded intermolecular Coulombic decay (ICD) spectra initiated by ionization of Mg 1s electrons to probe ligand exchange in the Mg$^{2+}$-ATP$_{(aq)}$ coordination environment, demonstrating the unique capabilities of ICD for revealing structural information. Our results provide an overview of the electronic structure of ATP$_{(aq)}$ and Mg$^{2+}$-ATP$_{(aq)}$ moieties relevant to phosphorylation and dephosphorylation reactions that are central to bioenergetics in living organisms.|
|**2023-06-08**|**First constraints on the strength of the extragalactic magnetic field from $γ$-ray observations of GRB 221009A**|Timur A. Dzhatdoev et.al.|[2306.05347v1](http://arxiv.org/abs/2306.05347v1)|null|The extragalactic magnetic field (EGMF) could be probed with $\gamma$-ray observations of distant sources. Primary very high energy (VHE) $\gamma$-rays from these sources absorb on extragalactic background light photons, and secondary electrons/positrons from the pair production acts create cascade $\gamma$-rays. These cascade $\gamma$-rays could be detected with space $\gamma$-ray telescopes such as Fermi-LAT. The $\gamma$-ray burst GRB 221009A was an exceptionally bright transient well suited for intergalactic $\gamma$-ray propagation studies. Using publicly-available Fermi-LAT data, we obtain upper limits on the spectrum of delayed emission from GRB 221009A during the time window of 30 days after the burst, and compare these with model spectra calculated for various EGMF strengths $B$, obtaining lower limits on $B$. We show that the values of $B < 10^{-18}$ G are excluded. For some optimistic models of the VHE spectrum of GRB 221009A, the values of $B < 10^{-17}$ G are excluded.|
|**2023-06-08**|**A Data-Driven Approach to Positioning Grab Bars in the Sagittal Plane for Elderly Persons**|Roberto Bolli Jr. et.al.|[2306.05343v1](http://arxiv.org/abs/2306.05343v1)|null|The placement of grab bars for elderly users is based largely on ADA building codes and does not reflect the large differences in height, mobility, and muscle power between individual persons. The goal of this study is to see if there are any correlations between an elderly user's preferred handlebar pose and various demographic indicators, self-rated mobility for tasks requiring postural change, and biomechanical markers. For simplicity, we consider only the case where the handlebar is positioned directly in front of the user, as this confines the relevant body kinematics to a 2D sagittal plane. Previous eldercare devices have been constructed to position a handlebar in various poses in space. Our work augments these devices and adds to the body of knowledge by assessing how the handlebar should be positioned based on data on actual elderly people instead of simulations.|
|**2023-06-08**|**Using Earth to Search for Long-Range Spin-Velocity Interactions**|Nathan B. Clayburn et.al.|[2306.05327v1](http://arxiv.org/abs/2306.05327v1)|null|Precision measurements of the possible coupling of spin to other scalars, vectors and pseudovectors has proven to be a sensitive way to search for new particle physics beyond the standard model. Indeed, in addition to searching for exotic spin-spin interactions, studies have been undertaken to look for couplings of spin to gravity, the relative velocity between particles, and preferred directions. Several laboratory experiments have established upper bounds on the energy associated with various fermion spin-orientations relative to Earth. Here, we combine these results with a model of Earth in order to investigate the possible long-range spin-velocity interactions associated with the exchange of ultralight ($m_{z'}<1$ neV) or massless scalar or vector bosons. We establish stringent bounds on the strength of these couplings between electrons, neutrons, protons and nucleons.|
|**2023-06-08**|**A physically motivated analytical expression for the temperature dependence of the zero-field splitting of the nitrogen-vacancy center in diamond**|M. C. Cambria et.al.|[2306.05318v1](http://arxiv.org/abs/2306.05318v1)|null|The temperature dependence of the zero-field splitting (ZFS) between the $|m_{s}=0\rangle$ and $|m_{s}=\pm 1\rangle$ levels of the nitrogen-vacancy (NV) center's electronic ground-state spin triplet can be used as a robust nanoscale thermometer in a broad range of environments. However, despite numerous measurements of this dependence in different temperature ranges, to our knowledge no analytical expression has been put forward that captures the scaling of the ZFS of the NV center across all relevant temperatures. Here we present a simple, analytical, and physically motivated expression for the temperature dependence of the NV center's ZFS that matches all experimental observations, in which the ZFS shifts in proportion to the occupation numbers of two representative phonon modes. In contrast to prior models our expression does not diverge outside the regions of fitting. We show that our model quantitatively matches experimental measurements of the ZFS from 15 to 500 K in single NV centers in ultra-pure bulk diamond, and we compare our model and measurements to prior models and experimental data.|
|**2023-06-08**|**Tunable Coupling Architectures with Capacitively Connecting Pads for Large-Scale Superconducting Multi-Qubit Processors**|Gui-Han Liang et.al.|[2306.05312v1](http://arxiv.org/abs/2306.05312v1)|null|We have proposed and experimentally verified a tunable inter-qubit coupling scheme for large-scale integration of superconducting qubits. The key feature of the scheme is the insertion of connecting pads between qubit and tunable coupling element. In such a way, the distance between two qubits can be increased considerably to a few millimeters, leaving enough space for arranging control lines, readout resonators and other necessary structures. The increased inter-qubit distance provides more wiring space for flip-chip process and reduces crosstalk between qubits and from control lines to qubits. We use the term Tunable Coupler with Capacitively Connecting Pad (TCCP) to name the tunable coupling part that consists of a transmon coupler and capacitively connecting pads. With the different placement of connecting pads, different TCCP architectures can be realized. We have designed and fabricated a few multi-qubit devices in which TCCP is used for coupling. The measured results show that the performance of the qubits coupled by the TCCP, such as $T_1$ and $T_2$, was similar to that of the traditional transmon qubits without TCCP. Meanwhile, our TCCP also exhibited a wide tunable range of the effective coupling strength and a low residual ZZ interaction between the qubits by properly tuning the parameters on the design. Finally, we successfully implemented an adiabatic CZ gate with TCCP. Furthermore, by introducing TCCP, we also discuss the realization of the flip-chip process and tunable coupling qubits between different chips.|
|**2023-06-08**|**A framework for dynamically training and adapting deep reinforcement learning models to different, low-compute, and continuously changing radiology deployment environments**|Guangyao Zheng et.al.|[2306.05310v1](http://arxiv.org/abs/2306.05310v1)|null|While Deep Reinforcement Learning has been widely researched in medical imaging, the training and deployment of these models usually require powerful GPUs. Since imaging environments evolve rapidly and can be generated by edge devices, the algorithm is required to continually learn and adapt to changing environments, and adjust to low-compute devices. To this end, we developed three image coreset algorithms to compress and denoise medical images for selective experience replayed-based lifelong reinforcement learning. We implemented neighborhood averaging coreset, neighborhood sensitivity-based sampling coreset, and maximum entropy coreset on full-body DIXON water and DIXON fat MRI images. All three coresets produced 27x compression with excellent performance in localizing five anatomical landmarks: left knee, right trochanter, left kidney, spleen, and lung across both imaging environments. Maximum entropy coreset obtained the best performance of $11.97\pm 12.02$ average distance error, compared to the conventional lifelong learning framework's $19.24\pm 50.77$.|
|**2023-06-08**|**Chiral EFT calculation of neutrino reactions in warm neutron-rich matter**|Eunkyoung Shin et.al.|[2306.05280v1](http://arxiv.org/abs/2306.05280v1)|null|Neutrino scattering and absorption rates of relevance to supernovae and neutron star mergers are obtained from nuclear matter dynamical structure functions that encode many-body effects from nuclear mean fields and correlations. We employ nuclear interactions from chiral effective field theory to calculate the density, spin, isospin, and spin-isospin response functions of warm beta-equilibrium nuclear matter. We include corrections to the single-particle energies in the mean field approximation as well as vertex corrections resummed in the random phase approximation (RPA), including, for the first time, both direct and exchange diagrams. We find that correlations included through the RPA redistribute the strength of the response to higher energy for neutrino absorption and lower energy for antineutrino absorption. This tends to suppress the absorption rate of electron neutrinos across all relevant energy scales. In contrast, the inclusion of RPA correlations enhances the electron antineutrino absorption rate at low energy and supresses the rate at high energy. These effects are especially important at high-density and in the vicinity of the neutrino decoupling region. Implications for heavy element nucleosynthesis, electromagnetic signatures of compact object mergers, supernova dynamics, and neutrino detection from galactic supernovae are discussed briefly.|
|**2023-06-08**|**Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on Summarizing Patients' Active Diagnoses and Problems from Electronic Health Record Progress Notes**|Yanjun Gao et.al.|[2306.05270v1](http://arxiv.org/abs/2306.05270v1)|null|The BioNLP Workshop 2023 initiated the launch of a shared task on Problem List Summarization (ProbSum) in January 2023. The aim of this shared task is to attract future research efforts in building NLP models for real-world diagnostic decision support applications, where a system generating relevant and accurate diagnoses will augment the healthcare providers decision-making process and improve the quality of care for patients. The goal for participants is to develop models that generated a list of diagnoses and problems using input from the daily care notes collected from the hospitalization of critically ill patients. Eight teams submitted their final systems to the shared task leaderboard. In this paper, we describe the tasks, datasets, evaluation metrics, and baseline systems. Additionally, the techniques and results of the evaluation of the different approaches tried by the participating teams are summarized.|
|**2023-06-08**|**Unidirectionality of spin waves in Synthetic Antiferromagnets**|F. Millo et.al.|[2306.05259v1](http://arxiv.org/abs/2306.05259v1)|null|We study the frequency non-reciprocity of the spin waves in symmetric CoFeB/Ru/CoFeB synthetic antiferromagnets stacks set in the scissors state by in-plane applied fields. Using a combination of Brillouin Light Scattering and propagating spin wave spectroscopy experiments, we show that the acoustical spin waves in synthetic antiferromagnets possess a unique feature if their wavevector is parallel to the applied field: the frequency non-reciprocity can be so large that the acoustical spin waves transfer energy in a unidirectional manner for a wide and bipolar interval of wavevectors. Analytical modeling and full micromagnetic calculations are conducted to account for the dispersion relations of the optical and acoustical spin waves for arbitrary field orientations. Our formalism provides a simple and direct method to understand and design devices harnessing propagating spin waves in synthetic antiferromagnets.|
|**2023-06-08**|**Hawking radiation from an analogue bouncing geometry**|Alberto García Martín-Caro et.al.|[2306.05250v1](http://arxiv.org/abs/2306.05250v1)|null|We propose a setting that simulates Hawking radiation from an analogue bouncing geometry, i.e., a collapsing geometry that reverts its collapse after a finite time, in a setup consisting of a coplanar waveguide terminated in superconducting quantum-interference devices at both ends. We demonstrate experimental feasibility of the proposed setup within the current technology. Our analysis illustrates the resilience of Hawking radiation under changes in the physics at energy scales much larger than the temperature, supporting the idea that regular alternatives to black holes would also emit Hawking radiation.|
|**2023-06-08**|**Solitons induced by an in-plane magnetic field in rhombohedral multilayer graphene**|Max Tymczyszyn et.al.|[2306.05237v1](http://arxiv.org/abs/2306.05237v1)|null|We model the influence of an in-plane magnetic field on the orbital motion of electrons in rhombohedral graphene multilayers. For zero field, the low-energy band structure includes a pair of flat bands near zero energy which are localized on the surface layers of a finite thin film. For finite field, we find that the zero-energy bands persist and that level bifurcations occur at energies determined by the component of the in-plane wave vector $q$ that is parallel to the external field. The occurrence of level bifurcations is explained by invoking semiclassical quantization of the zero field Fermi surface of rhombohedral graphite. We find parameter regions with a single isoenergetic contour of Berry phase zero corresponding to a conventional Landau level spectrum and regions with two isoenergetic contours, each of Berry phase $\pi$, corresponding to a Dirac-like spectrum of levels. We write down an analogous one-dimensional tight-binding model and relate the persistence of the zero-energy bands in large magnetic fields to a soliton texture supporting zero-energy states in the Su-Schreiffer-Heeger model. We show that different states contributing to the zero-energy flat bands in rhombohedral graphene multilayers in a large field, as determined by the wave vector $q$, are localized on different bulk layers of the system, not just the surfaces.|
|**2023-06-08**|**XNOR-VSH: A Valley-Spin Hall Effect-based Compact and Energy-Efficient Synaptic Crossbar Array for Binary Neural Networks**|Karam Cho et.al.|[2306.05219v1](http://arxiv.org/abs/2306.05219v1)|null|Binary neural networks (BNNs) have shown an immense promise for resource-constrained edge artificial intelligence (AI) platforms as their binarized weights and inputs can significantly reduce the compute, storage and communication costs. Several works have explored XNOR-based BNNs using SRAMs and nonvolatile memories (NVMs). However, these designs typically need two bit-cells to encode signed weights leading to an area overhead. In this paper, we address this issue by proposing a compact and low power in-memory computing (IMC) of XNOR-based dot products featuring signed weight encoding in a single bit-cell. Our approach utilizes valley-spin Hall (VSH) effect in monolayer tungsten di-selenide to design an XNOR bit-cell (named 'XNOR-VSH') with differential storage and access-transistor-less topology. We co-optimize the proposed VSH device and a memory array to enable robust in-memory dot product computations between signed binary inputs and signed binary weights with sense margin (SM) > 1 micro-amps. Our results show that the proposed XNOR-VSH array achieves 4.8% ~ 9.0% and 37% ~ 63% lower IMC latency and energy, respectively, with 4 % ~ 64% smaller area compared to spin-transfer-torque (STT)-MRAM and spin-orbit-torque (SOT)-MRAM based XNOR-arrays.|
|**2023-06-08**|**Why Are Conversational Assistants Still Black Boxes? The Case For Transparency**|Trung Dong Huynh et.al.|[2306.05218v1](http://arxiv.org/abs/2306.05218v1)|null|Much has been written about privacy in the context of conversational and voice assistants. Yet, there have been remarkably few developments in terms of the actual privacy offered by these devices. But how much of this is due to the technical and design limitations of speech as an interaction modality? In this paper, we set out to reframe the discussion on why commercial conversational assistants do not offer meaningful privacy and transparency by demonstrating how they \emph{could}. By instrumenting the open-source voice assistant Mycroft to capture audit trails for data access, we demonstrate how such functionality could be integrated into big players in the sector like Alexa and Google Assistant. We show that this problem can be solved with existing technology and open standards and is thus fundamentally a business decision rather than a technical limitation.|
|**2023-06-08**|**Multi-client distributed blind quantum computation with the Qline architecture**|Beatrice Polacchi et.al.|[2306.05195v1](http://arxiv.org/abs/2306.05195v1)|null|Universal blind quantum computing allows users with minimal quantum resources to delegate a quantum computation to a remote quantum server, while keeping intrinsically hidden input, algorithm, and outcome. State-of-art experimental demonstrations of such a protocol have only involved one client. However, an increasing number of multi-party algorithms, e.g. federated machine learning, require the collaboration of multiple clients to carry out a given joint computation. In this work, we propose and experimentally demonstrate a lightweight multi-client blind quantum computation protocol based on a novel linear quantum network configuration (Qline). Our protocol originality resides in three main strengths: scalability, since we eliminate the need for each client to have its own trusted source or measurement device, low-loss, by optimizing the orchestration of classical communication between each client and server through fast classical electronic control, and compatibility with distributed architectures while remaining intact even against correlated attacks of server nodes and malicious clients.|
|**2023-06-08**|**Description of the proton-decaying 0$^+_2$ resonance of the $α$ particle**|N. Michel et.al.|[2306.05192v1](http://arxiv.org/abs/2306.05192v1)|null|The recent precise experimental determination of the monopole transition form factor from the ground state of $^4$He to its $0^+_2$ resonance via electron scattering has reinvigorated discussions about the nature of this first excited state of the $\alpha$ particle. The $0^+_2$ state has been traditionally interpreted in the literature as the isoscalar monopole resonance (breathing mode) or, alternatively, as a particle-hole shell-model excitation. To better understand the nature of this state, which lies only $\sim$ 410 keV above the proton emission threshold, we employ the coupled-channel representation of the no-core Gamow shell model. By considering the $[^3$H$ + p]$, $[^3$He$ + n]$, and $[^2$H+$^2$H] reaction channels, we explain the excitation energy and monopole form-factor of the $0^+_2$ state. We argue that the continuum coupling strongly impacts the nature of this state, which carries characteristics of the proton decay threshold.|
|**2023-06-08**|**FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems**|Herbert Woisetschläger et.al.|[2306.05172v1](http://arxiv.org/abs/2306.05172v1)|null|Federated Machine Learning (FL) has received considerable attention in recent years. FL benchmarks are predominantly explored in either simulated systems or data center environments, neglecting the setups of real-world systems, which are often closely linked to edge computing. We close this research gap by introducing FLEdge, a benchmark targeting FL workloads in edge computing systems. We systematically study hardware heterogeneity, energy efficiency during training, and the effect of various differential privacy levels on training in FL systems. To make this benchmark applicable to real-world scenarios, we evaluate the impact of client dropouts on state-of-the-art FL strategies with failure rates as high as 50%. FLEdge provides new insights, such as that training state-of-the-art FL workloads on older GPU-accelerated embedded devices is up to 3x more energy efficient than on modern server-grade GPUs.|
|**2023-06-08**|**Achieving higher photoabsorption than group III-V semiconductors in silicon using photon-trapping surface structures**|Wayesh Qarony et.al.|[2306.05170v1](http://arxiv.org/abs/2306.05170v1)|null|The photosensitivity of silicon is inherently very low in the visible electromagnetic spectrum, and it drops rapidly beyond 800 nm in near-infrared wavelengths. Herein, we have experimentally demonstrated a technique utilizing photon-trapping surface structures to show a prodigious improvement of photoabsorption in one-micrometer-thin silicon, surpassing the inherent absorption efficiency of gallium arsenide for a broad spectrum. The photon-trapping structures allow the bending of normally incident light by almost ninety degrees to transform into laterally propagating modes along the silicon plane. Consequently, the propagation length of light increases, contributing to more than an order of magnitude improvement in absorption efficiency in photodetectors. This high absorption phenomenon is explained by FDTD analysis, where we show an enhanced photon density of states while substantially reducing the optical group velocity of light compared to silicon without photon-trapping structures, leading to significantly enhanced light-matter interactions. Our simulations also predict an enhanced absorption efficiency of photodetectors designed using 30 and 100-nanometer silicon thin films that are compatible with CMOS electronics. Despite a very thin absorption layer, such photon-trapping structures can enable high-efficiency and high-speed photodetectors needed in ultra-fast computer networks, data communication, and imaging systems with the potential to revolutionize on-chip logic and optoelectronic integration.|
|**2023-06-08**|**Energy Efficient Skyrmion based Oscillator on Thermocoupled Nanotrack**|Ravish Kumar Raj et.al.|[2306.05164v1](http://arxiv.org/abs/2306.05164v1)|null|The magnetic skyrmion-based spin transfer nano-oscillators (STNO) are the potential candidates for next-generation microwave signal generator and has gained popularity due to their performance, integrability and compatibility with existing CMOS technology. However, these devices suffer from the Joule heating problem that neglects their non-volatility advantage in spintronic devices. Therefore, it is necessary to investigate the alternative driving mechanisms for the development of energy-efficient skyrmion based nano-oscillators. In this paper, a skyrmion-based nano-oscillator has been designed that utilizes thermal power to drive skyrmion on a thermocoupled nanotrack. The thermocoupled nanotrack is designed in such a way that both the upper and lower nanotracks have different values of damping constants and a temperature difference is maintained between the extreme ends, in order to create a temperature gradient in the two nanotracks. By employing this technique, skyrmion is able to exhibit the periodic motion on the nanotrack with the maximum achievable frequency of 2.5GHz without any external stimuli. Moreover, the proposed device offers low thermal energy consumption of 0.84fJ/oscillation. Hence, this work provides the pathway for the development of energy-efficient future spintronic devices.|
|**2023-06-08**|**Straintronics in Phosphorene: Tensile vs Shear Strains and Their Combinations for Manipulating the Band Gap**|Anastasiia G. Solomenko et.al.|[2306.05163v1](http://arxiv.org/abs/2306.05163v1)|null|We study the effects of the uniaxial tensile strain and shear deformation as well as their combinations on the electronic properties of single-layer black phosphorene. The evolutions of the strain-dependent band gap are obtained using the numerical calculations within the tight-binding (TB) model as well as the first-principles (DFT) simulations and compared with previous findings. The TB-model-based findings show that the band gap of the strain-free phosphorene agrees with the experimental value and linearly depends on both stretching and shearing: increases (decreases) as the stretching increases (decreases), whereas gradually decreases with increasing the shear. A linear dependence is less or more similar as compared to that obtained from the ab initio simulations for shear strain, however disagrees with a non-monotonic behaviour from the DFT-based calculations for tensile strain. Possible reasons for the discrepancy are discussed. In case of a combined deformation, when both strain types (tensile/compression + shear) are loaded simultaneously, their mutual influence extends the realizable band gap range: from zero up to the values respective to the wide-band-gap semiconductors. At a switched-on combined strain, the semiconductor-semimetal phase transition in the phosphorene is reachable at a weaker (strictly non-destructive) strain, which contributes to progress in fundamental and breakthroughs.|
|**2023-06-08**|**Dual Bethe-Salpeter equation for the multi-orbital lattice susceptibility within dynamical mean-field theory**|Erik G. C. P. van Loon et.al.|[2306.05157v1](http://arxiv.org/abs/2306.05157v1)|null|Dynamical mean-field theory describes the impact of strong local correlation effects in many-electron systems. While the single-particle spectral function is directly obtained within the formalism, two-particle susceptibilities can also be obtained by solving the Bethe-Salpeter equation. The solution requires handling infinite matrices in Matsubara frequency space. This is commonly treated using a finite frequency cut-off, resulting in slow linear convergence. We show that decomposing the two-particle response in local and non-local contributions enables a reformulation of the Bethe-Salpeter equation inspired by the dual boson formalism. The re-formulation has a drastically improved cubic convergence with respect to the frequency cut-off, facilitating the calculation of susceptibilities in multi-orbital systems considerably. The dual Bethe-Salpeter equation uses the fully reducible vertex which is free from vertex divergences. We benchmark the approach on several systems including the spin susceptibility of strontium ruthenate Sr$_2$RuO$_4$, a strongly correlated Hund's metal with three active orbitals. We propose the dual Bethe-Salpeter equation as a new standard for calculating two-particle response within dynamical mean-field theory.|
|**2023-06-08**|**Engineering flat bands in twisted-bilayer graphene away from the magic angle with chiral optical cavities**|Cunyuan Jiang et.al.|[2306.05149v1](http://arxiv.org/abs/2306.05149v1)|null|Twisted bilayer graphene (TBG) is a recently discovered two-dimensional superlattice structure which exhibits strongly-correlated quantum many-body physics, including strange metallic behavior and unconventional superconductivity. Most of TBG exotic properties are connected to the emergence of a pair of isolated and topological flat electronic bands at the so-called magic angle, $\theta \approx 1.05^{\circ}$, which are nevertheless very fragile. In this work, we show that, by employing chiral optical cavities, the topological flat bands can be stabilized away from the magic angle in an interval of approximately $0.8^{\circ}<\theta<1.3^{\circ}$. As highlighted by a simplified theoretical model, time reversal symmetry breaking, induced by the chiral nature of the cavity, plays a fundamental role in flattening the isolated bands and gapping out the rest of the spectrum. The efficiency of the cavity is discussed as a function of the twisting angle, the light-matter coupling and the optical cavity characteristic frequency. Our results demonstrate the possibility of engineering flat bands in TBG using optical devices, extending the onset of strongly-correlated topological electronic phases in Moir\'e superlattices to a wider range in the twisting angle.|
|**2023-06-08**|**Room-temperature magnetoelectric effect in lead-free multiferroic $(1-x)$ Ba$_{0.95}$Ca$_{0.05}$Ti$_{0.89}$Sn$_{0.11}$O$_3$-$(x)$CoFe$_2$O$_4$ particulate composites**|Youness Hadouch et.al.|[2306.05134v1](http://arxiv.org/abs/2306.05134v1)|null|Multiferroic particulate composites $(1-x)$ Ba$_{0.95}$Ca$_{0.05}$Ti$_{0.89}$Sn$_{0.11}$O$_3$-$(x)$CoFe$_2$O$_4$ with ($x$ = 0.1, 0.2, 0.3, 0.4 and 0.5) have been prepared by mechanical mixing of the calcined and milled individual ferroic phases. X-ray diffraction and Raman spectroscopy analysis confirmed the formation of both perovskite Ba$_{0.95}$Ca$_{0.05}$Ti$_{0.89}$Sn$_{0.11}$O$_3$ (BCTSn) and spinel CoFe$_2$O$_4$ (CFO) phases without the presence of additional phases. The morphological properties of the composites were provided by using Field Emission Scanning Electron Microscopy. The BCTSn-CFO composites exhibit multiferroic behavior at room temperature, as evidenced by ferroelectric and ferromagnetic hysteresis loops. The magnetoelectric (ME) coupling was measured under a magnetic field up to 10 kOe and the maximum ME response found to be 0.1 mV /cm/ Oe for the composition 0.7 BCTSn-0.3 CFO exhibiting a high degree of pseudo-cubicity and large density.|
|**2023-06-08**|**Constraints on the intergalactic magnetic field using Fermi-LAT and H.E.S.S. blazar observations**|H. E. S. S. et.al.|[2306.05132v1](http://arxiv.org/abs/2306.05132v1)|null|Magnetic fields in galaxies and galaxy clusters are believed to be the result of the amplification of intergalactic seed fields during the formation of large-scale structures in the universe. However, the origin, strength, and morphology of this intergalactic magnetic field (IGMF) remain unknown. Lower limits on (or indirect detection of) the IGMF can be obtained from observations of high-energy gamma rays from distant blazars. Gamma rays interact with the extragalactic background light to produce electron-positron pairs, which can subsequently initiate electromagnetic cascades. The $\gamma$-ray signature of the cascade depends on the IGMF since it deflects the pairs. Here we report on a new search for this cascade emission using a combined data set from the Fermi Large Area Telescope and the High Energy Stereoscopic System. Using state-of-the-art Monte Carlo predictions for the cascade signal, our results place a lower limit on the IGMF of $B > 7.1\times10^{-16}$ G for a coherence length of 1 Mpc even when blazar duty cycles as short as 10 yr are assumed. This improves on previous lower limits by a factor of 2. For longer duty cycles of $10^4$ ($10^7$) yr, IGMF strengths below $1.8\times10^{-14}$ G ($3.9\times10^{-14}$ G) are excluded, which rules out specific models for IGMF generation in the early universe.|
|**2023-06-08**|**Orthogonal Sampling based Broad-Band Signal Generation with Low-Bandwidth Electronics**|Mohamed I. Hosni et.al.|[2306.05125v1](http://arxiv.org/abs/2306.05125v1)|null|High-bandwidth signals are needed in many applications like radar, sensing, measurement and communications. Especially in optical networks, the sampling rate and analog bandwidth of digital-to-analog converters (DACs) is a bottleneck for further increasing data rates. To circumvent the sampling rate and bandwidth problem of electronic DACs, we demonstrate the generation of wide-band signals with low-bandwidth electronics. This generation is based on orthogonal sampling with sinc-pulse sequences in N parallel branches. The method not only reduces the sampling rate and bandwidth, at the same time the effective number of bits (ENOB) is improved, dramatically reducing the requirements on the electronic signal processing. In proof of concept experiments the generation of analog signals, as well as Nyquist shaped and normal data will be shown. In simulations we investigate the performance of 60 GHz data generation by 20 and 12 GHz electronics. The method can easily be integrated together with already existing electronic DAC designs and would be of great interest for all high-bandwidth applications.|
|**2023-06-08**|**Electronic correlations and superconducting instability in La$_3$Ni$_2$O$_7$ under high pressure**|Frank Lechermann et.al.|[2306.05121v1](http://arxiv.org/abs/2306.05121v1)|null|Motivated by the report of superconductivity in bilayer La$_3$Ni$_2$O$_7$ at high pressure, we examine the interacting electrons in this system. First-principles many-body theory is utilized to study the normal-state electronic properties. Below 100\,K, a multi-orbital non-Fermi liquid state resulting from loss of Ni-ligand coherence within a flat-band dominated low-energy landscape is uncovered. The incoherent low-temperature Fermi surface displays strong mixing between Ni-$d_{z^2}$ and Ni-$d_{x^2-y^2}$ orbital character. In a model-Hamiltonian picture, spin fluctuations originating mostly from the Ni-$d_{z^2}$ orbital give rise to strong tendencies towards a superconducting instability with $d_{x^2-y^2}$ order parameter. The dramatic enhancement of $T_{\rm c}$ in pressurized La$_3$Ni$_2$O$_7$ is due to stronger Ni-$d_{z^2}$ correlations compared to those in the infinite-layer nickelates.|
|**2023-06-08**|**Inverse Design of Thin-Plate Elastic Wave Devices**|James R Capers et.al.|[2306.05117v1](http://arxiv.org/abs/2306.05117v1)|null|Motivated by recent advances in the inverse design of electromagnetic materials, we develop two methods for manipulating flexural waves on thin elastic plates. Firstly, we derive a technique for determining plate pinning or mass-loading of a thin plate, designing structures that focus elastic energy, or isolate a region of space from vibrations. Taking inspiration from the adjoint method in electromagnetism, we show how to design graded plates to act as lenses or perform mode shaping. Both of the methods presented are simple, versatile and straightforward to implement, making them useful for designing a wide range of devices for sensing, energy harvesting and vibration isolation.|
|**2023-06-08**|**Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML**|Robin van de Water et.al.|[2306.05109v1](http://arxiv.org/abs/2306.05109v1)|[link](https://github.com/rvandewater/yaib)|Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. The intensive care unit (ICU) is a natural habitat for ML given the abundance of available data from electronic health records. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance - often more so than model class - indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations. Software Repository: https://github.com/rvandewater/YAIB.|

## smart watch

### smart watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**SmartBugs 2.0: An Execution Framework for Weakness Detection in Ethereum Smart Contracts**|Monika di Angelo et.al.|[2306.05057v1](http://arxiv.org/abs/2306.05057v1)|null|Smart contracts are blockchain programs that often handle valuable assets. Writing secure smart contracts is far from trivial, and any vulnerability may lead to significant financial losses. To support developers in identifying and eliminating vulnerabilities, methods and tools for the automated analysis have been proposed. However, the lack of commonly accepted benchmark suites and performance metrics makes it difficult to compare and evaluate such tools. Moreover, the tools are heterogeneous in their interfaces and reports as well as their runtime requirements, and installing several tools is time-consuming.   In this paper, we present SmartBugs 2.0, a modular execution framework. It provides a uniform interface to 19 tools aimed at smart contract analysis and accepts both Solidity source code and EVM bytecode as input. After describing its architecture, we highlight the features of the framework. We evaluate the framework via its reception by the community and illustrate its scalability by describing its role in a study involving 3.25 million analyses.|
|**2023-06-08**|**Sequence-to-Sequence Model with Transformer-based Attention Mechanism and Temporal Pooling for Non-Intrusive Load Monitoring**|Mohammad Irani Azad et.al.|[2306.05012v1](http://arxiv.org/abs/2306.05012v1)|null|This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) of smart buildings. The paper aims to improve the accuracy of NILM by using a deep learning-based method. The proposed method uses a Seq2Seq model with a transformer-based attention mechanism to capture the long-term dependencies of NILM data. Additionally, temporal pooling is used to improve the model's accuracy by capturing both the steady-state and transient behavior of appliances. The paper evaluates the proposed method on a publicly available dataset and compares the results with other state-of-the-art NILM techniques. The results demonstrate that the proposed method outperforms the existing methods in terms of both accuracy and computational efficiency.|
|**2023-06-08**|**Parallel and Asynchronous Smart Contract Execution**|Jian Liu et.al.|[2306.05007v1](http://arxiv.org/abs/2306.05007v1)|null|Today's blockchains suffer from low throughput and high latency, which impedes their widespread adoption of more complex applications like smart contracts. In this paper, we propose a novel paradigm for smart contract execution. It distinguishes between consensus nodes and execution nodes: different groups of execution nodes can execute transactions in parallel; meanwhile, consensus nodes can asynchronously order transactions and process execution results. Moreover, it requires no coordination among execution nodes and can effectively prevent livelocks. We show two ways of applying this paradigm to blockchains. First, we show how we can make Ethereum support parallel and asynchronous contract execution \emph{without hard-forks}. Then, we propose a new public, permissionless blockchain. Our benchmark shows that, with a fast consensus layer, it can provide a high throughput even for complex transactions like Cryptokitties gene mixing. It can also protect simple transactions from being starved by complex transactions.|
|**2023-06-08**|**Modern Data Pricing Models: Taxonomy and Comprehensive Survey**|Xiaoye Miao et.al.|[2306.04945v1](http://arxiv.org/abs/2306.04945v1)|null|Data play an increasingly important role in smart data analytics, which facilitate many data-driven applications. The goal of various data markets aims to alleviate the issue of isolated data islands, so as to benefit data circulation. The problem of data pricing is indispensable yet challenging in data trade. In this paper, we conduct a comprehensive survey on the modern data pricing solutions. We divide the data pricing solutions into three major strategies and thirteen models, including query pricing strategy, feature-based data pricing strategy, and pricing strategy in machine learning. It is so far the first attempt to classify so many existing data pricing models. Moreover, we not only elaborate the thirteen specific pricing models within each pricing strategy, but also make in-depth analyses among these models. We also conclude five research directions for the data pricing field, and put forward some novel and interesting data pricing topics. This paper aims at gaining better insights, and directing the future research towards practical and sophisticated pricing mechanisms for better data trade and share.|
|**2023-06-07**|**Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network**|Haiyang Liu et.al.|[2306.04479v1](http://arxiv.org/abs/2306.04479v1)|null|The immutable and trustable characteristics of blockchain enable smart contracts to be applied in various fields. Unfortunately, smart contracts are subject to various vulnerabilities, which are frequently exploited by attackers, causing financial damage to users.In this paper, we study the problem of vulnerable smart contract function locating. We construct a novel Multi-Relational Nested contract Graph (MRNG) to better characterize the rich syntactic and semantic information in the smart contract code, including the relationships between data and instructions. An MRNG represents a smart contract, where each node represents a function in the smart contract and each edge describes the calling relationship between the functions. In addition, we create a Multi-Relational Function Graph (MRFG) for each function, which characterizes the corresponding function code. That is, each function is characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG uses different types of edges to represent the different control and data relationships between nodes within a function. We also propose a Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the edge-enhanced graph convolution network and self-attention mechanism. The extracted feature vector is then assigned to the corresponding node in the MRNG to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph convolution is used to further extract features from the FCG. Finally, a feed forward network with a Sigmoid function is used to locate the vulnerable functions. Experimental results on the real-world smart contract datasets show that model MRN-GCN can effectively improve the accuracy, precision, recall and F1-score performance of vulnerable smart contract function locating.|
|**2023-06-07**|**Hardening and Speeding Up Zero-interaction Pairing and Authentication**|Mikhail Fomichev et.al.|[2306.04458v1](http://arxiv.org/abs/2306.04458v1)|null|Establishing and maintaining secure communications in the Internet of Things (IoT) is vital to protect smart devices. Zero-interaction pairing (ZIP) and zero-interaction authentication (ZIA) enable IoT devices to establish and maintain secure communications without user interaction by utilizing devices' ambient context, e.g., audio. For autonomous operation, ZIP and ZIA require the context to have enough entropy to resist attacks and complete in a timely manner. Despite the low-entropy context being the norm, like inside an unoccupied room, the research community has yet to come up with ZIP and ZIA schemes operating under such conditions. We propose HARDZIPA, a novel approach that turns commodity IoT actuators into injecting devices, generating high-entropy context. Here, we combine the capability of IoT actuators to impact the environment, e.g., emitting a sound, with a pseudorandom number generator (PRNG) featured by many actuators to craft hard-to-predict context stimuli. To demonstrate the feasibility of HARDZIPA, we implement it on off-the-shelf IoT actuators, i.e., smart speakers, lights, and humidifiers. We comprehensively evaluate HARDZIPA, collecting over 80 hours of various context data in real-world scenarios. Our results show that HARDZIPA is able to thwart advanced active attacks on ZIP and ZIA schemes, while doubling the amount of context entropy in many cases, which allows two times faster pairing and authentication.|
|**2023-06-07**|**Revising deep learning methods in parking lot occupancy detection**|Anastasia Martynova et.al.|[2306.04288v2](http://arxiv.org/abs/2306.04288v2)|[link](https://github.com/eighonet/parking-research)|Parking guidance systems have recently become a popular trend as a part of the smart cities' paradigm of development. The crucial part of such systems is the algorithm allowing drivers to search for available parking lots across regions of interest. The classic approach to this task is based on the application of neural network classifiers to camera records. However, existing systems demonstrate a lack of generalization ability and appropriate testing regarding specific visual conditions. In this study, we extensively evaluate state-of-the-art parking lot occupancy detection algorithms, compare their prediction quality with the recently emerged vision transformers, and propose a new pipeline based on EfficientNet architecture. Performed computational experiments have demonstrated the performance increase in the case of our model, which was evaluated on 5 different datasets.|
|**2023-06-07**|**An Empirical Study of Impact of Solidity Compiler Updates on Vulnerabilities in Ethereum Smart Contracts**|Chihiro Kado et.al.|[2306.04250v1](http://arxiv.org/abs/2306.04250v1)|null|Vulnerabilities of Ethereum smart contracts often cause serious financial damage. Whereas the Solidity compiler has been updated to prevent vulnerabilities, its effectiveness has not been revealed so far, to the best of our knowledge. In this paper, we shed light on the impact of compiler versions of vulnerabilities of Ethereum smart contracts. To this end, we collected 503,572 contracts with Solidity source codes in the Ethereum blockchain and then analyzed their vulnerabilities. For three vulnerabilities with high severity, i.e., Locked Money, Using tx.origin, and Unchecked Call, we show that their appearance rates are decreased by virtue of major updates of the Solidity compiler. We then found the following four key insights. First, after the release of version 0.6, the appearance rate for Locked Money has decreased. Second, regardless of compiler updates, the appearance rate for Using tx.origin is significantly low. Third, although the appearance rate for Unchecked Call has decreased in version 0.8, it still remains high due to various factors, including code clones. Fourth, through analysis of code clones, our promising results show that the appearance rate for Unchecked Call can be further decreased by removing the code clones.|
|**2023-06-07**|**A Threat Model for Soft Privacy on Smart Cars**|Mario Raciti et.al.|[2306.04222v1](http://arxiv.org/abs/2306.04222v1)|null|Modern cars are getting so computerised that ENISA's phrase "smart cars" is a perfect fit. The amount of personal data that they process is very large and, yet, increasing. Hence, the need to address citizens' privacy while they drive and, correspondingly, the importance of privacy threat modelling (in support of a respective risk assessment, such as through a Data Protection Impact Assessment). This paper addresses privacy threats by advancing a general modelling methodology and by demonstrating it specifically on soft privacy, which ensures citizens' full control on their personal data. By considering all relevant threat agents, the paper applies the methodology to the specific automotive domain while keeping threats at the same level of detail as ENISA's. The main result beside the modelling methodology consists of both domain-independent and automotive domain-dependent soft privacy threats. While cybersecurity has been vastly threat-modelled so far, this paper extends the literature with a threat model for soft privacy on smart cars, producing 17 domain-independent threats that, associated with 41 domain-specific assets, shape a novel set of domain-dependent threats in automotive.|
|**2023-06-07**|**Is Homomorphic Encryption Feasible for Smart Mobility?**|Anika Hannemann et.al.|[2306.04195v1](http://arxiv.org/abs/2306.04195v1)|null|Smart mobility is a promising approach to meet urban transport needs in an environmentally and and user-friendly way. Smart mobility computes itineraries with multiple means of transportation, e.g., trams, rental bikes or electric scooters, according to customer preferences. A mobility platform cares for reservations, connecting transports, invoicing and billing. This requires sharing sensible personal data with multiple parties, and puts data privacy at risk. In this paper, we investigate if fully homomorphic encryption (FHE) can be applied in practice to mitigate such privacy issues. FHE allows to calculate on encrypted data, without having to decrypt it first. We implemented three typical distributed computations in a smart mobility scenario with SEAL, a recent programming library for FHE. With this implementation, we have measured memory consumption and execution times for three variants of distributed transactions, that are representative for a wide range of smart mobility tasks. Our evaluation shows, that FHE is indeed applicable to smart mobility: With today's processing capabilities, state-of-the-art FHE increases a smart mobility transaction by about 100 milliseconds and less than 3 microcents.|
|**2023-06-07**|**UCTB: An Urban Computing Tool Box for Spatiotemporal Crowd Flow Prediction**|Liyue Chen et.al.|[2306.04144v1](http://arxiv.org/abs/2306.04144v1)|[link](https://github.com/uctb/uctb)|Spatiotemporal crowd flow prediction is one of the key technologies in smart cities. Currently, there are two major pain points that plague related research and practitioners. Firstly, crowd flow is related to multiple domain knowledge factors; however, due to the diversity of application scenarios, it is difficult for subsequent work to make reasonable and comprehensive use of domain knowledge. Secondly, with the development of deep learning technology, the implementation of relevant techniques has become increasingly complex; reproducing advanced models has become a time-consuming and increasingly cumbersome task. To address these issues, we design and implement a spatiotemporal crowd flow prediction toolbox called UCTB (Urban Computing Tool Box), which integrates multiple spatiotemporal domain knowledge and state-of-the-art models simultaneously. The relevant code and supporting documents have been open-sourced at https://github.com/uctb/UCTB.|
|**2023-06-06**|**A machine learning potential-based generative algorithm for on-lattice crystal structure prediction**|Vadim Sotskov et.al.|[2306.03989v1](http://arxiv.org/abs/2306.03989v1)|null|We propose a method for crystal structure prediction based on a new structure generation algorithm and on-lattice machine learning interatomic potentials. Our algorithm generates the atomic configurations assigning atomic species to sites of the given lattice, and uses cluster expansion or low-rank potential to evaluate their energy. We demonstrate two benefits of such approach. First, our structure generation algorithm offers a ``smart'' configurational space sampling, targeting low-energy structures which significantly reduces computational costs. Second, the application of machine learning interatomic potentials significantly reduces the number of DFT calculations. We discuss how our algorithm resembles the latent diffusion models for image generation. We demonstrate the efficiency of our method by constructing the convex hull of Nb-Mo-Ta-W system, including binary and ternary Nb-W and Mo-Ta-W subsystems. We found new binary, ternary, and quaternary stable structures that are not reported in the AFLOW database which we choose as our baseline. Due to the computational efficiency of our method we anticipate that it can pave the way towards efficient high-throughput discovery of multicomponent materials.|
|**2023-06-06**|**Minimizing Hitting Time between Disparate Groups with Shortcut Edges**|Florian Adriaens et.al.|[2306.03571v1](http://arxiv.org/abs/2306.03571v1)|null|Structural bias or segregation of networks refers to situations where two or more disparate groups are present in the network, so that the groups are highly connected internally, but loosely connected to each other. In many cases it is of interest to increase the connectivity of disparate groups so as to, e.g., minimize social friction, or expose individuals to diverse viewpoints. A commonly-used mechanism for increasing the network connectivity is to add edge shortcuts between pairs of nodes. In many applications of interest, edge shortcuts typically translate to recommendations, e.g., what video to watch, or what news article to read next. The problem of reducing structural bias or segregation via edge shortcuts has recently been studied in the literature, and random walks have been an essential tool for modeling navigation and connectivity in the underlying networks. Existing methods, however, either do not offer approximation guarantees, or engineer the objective so that it satisfies certain desirable properties that simplify the optimization~task. In this paper we address the problem of adding a given number of shortcut edges in the network so as to directly minimize the average hitting time and the maximum hitting time between two disparate groups. Our algorithm for minimizing average hitting time is a greedy bicriteria that relies on supermodularity. In contrast, maximum hitting time is not supermodular. Despite, we develop an approximation algorithm for that objective as well, by leveraging connections with average hitting time and the asymmetric k-center problem.|
|**2023-06-06**|**From Data to Action: Exploring AI and IoT-driven Solutions for Smarter Cities**|Tiago Dias et.al.|[2306.04653v1](http://arxiv.org/abs/2306.04653v1)|null|The emergence of smart cities demands harnessing advanced technologies like the Internet of Things (IoT) and Artificial Intelligence (AI) and promises to unlock cities' potential to become more sustainable, efficient, and ultimately livable for their inhabitants. This work introduces an intelligent city management system that provides a data-driven approach to three use cases: (i) analyze traffic information to reduce the risk of traffic collisions and improve driver and pedestrian safety, (ii) identify when and where energy consumption can be reduced to improve cost savings, and (iii) detect maintenance issues like potholes in the city's roads and sidewalks, as well as the beginning of hazards like floods and fires. A case study in Aveiro City demonstrates the system's effectiveness in generating actionable insights that enhance security, energy efficiency, and sustainability, while highlighting the potential of AI and IoT-driven solutions for smart city development.|
|**2023-06-06**|**Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation**|Xiao Lin et.al.|[2306.03392v1](http://arxiv.org/abs/2306.03392v1)|null|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|
|**2023-06-05**|**Imaging the Meissner effect and flux trapping in a hydride superconductor at megabar pressures using a nanoscale quantum sensor**|Prabudhya Bhattacharyya et.al.|[2306.03122v1](http://arxiv.org/abs/2306.03122v1)|null|By directly altering microscopic interactions, pressure provides a powerful tuning knob for the exploration of condensed phases and geophysical phenomena. The megabar regime represents an exciting frontier, where recent discoveries include novel high-temperature superconductors, as well as structural and valence phase transitions. However, at such high pressures, many conventional measurement techniques fail. Here, we demonstrate the ability to perform local magnetometry inside of a diamond anvil cell with sub-micron spatial resolution at megabar pressures. Our approach utilizes a shallow layer of Nitrogen-Vacancy (NV) color centers implanted directly within the anvil; crucially, we choose a crystal cut compatible with the intrinsic symmetries of the NV center to enable functionality at megabar pressures. We apply our technique to characterize a recently discovered hydride superconductor, CeH$_9$. By performing simultaneous magnetometry and electrical transport measurements, we observe the dual signatures of superconductivity: local diamagnetism characteristic of the Meissner effect and a sharp drop of the resistance to near zero. By locally mapping the Meissner effect and flux trapping, we directly image the geometry of superconducting regions, revealing significant inhomogeneities at the micron scale. Our work brings quantum sensing to the megabar frontier and enables the closed loop optimization of superhydride materials synthesis.|
|**2023-06-05**|**Superhydrophobicity of Auxetic Metamaterials**|Glen McHale et.al.|[2306.02916v1](http://arxiv.org/abs/2306.02916v1)|null|Superhydrophobic materials are often inspired by nature, whereas metamaterials are engineered to have properties not usually found in naturally occurring materials. In both cases, the key that unlocks their unique properties is structure. Here, we show that a negative Poisson's ratio (auxetic) mechanical metamaterial is capable of transforming into a unique type of superhydrophobic material. When stretched its surface has the counterintuitive property that it also expands in the orthogonal lateral direction. We model the change in the solid surface fraction as strain is applied and show it decreases as the space between solid elements of the auxetic lattice expands. This results in a unique dependence of the superhydrophobicity on strain. We construct experimental models illustrating the relationship between different states of strain and superhydrophobicity as the lattice structure transitions from an auxetic to a conventional (positive Poisson's ratio) one. The principles we have discovered offer a new approach to designing superhydrophobic materials for self-cleaning surfaces, droplet transportation, droplet encapsulation and oil-water separation.|
|**2023-06-05**|**Modular zk-Rollup On-Demand**|Thomas Lavaur et.al.|[2306.02785v1](http://arxiv.org/abs/2306.02785v1)|[link](https://github.com/thomaslavaur/modular-zk-rollup-on-demand)|The rapid expansion of the use of blockchain-based systems often leads to a choice between customizable private blockchains and more secure, scalable and decentralized but expensive public blockchains. This choice represents the trade-off between privacy and customization at a low cost and security, scalability, and a large user base but at a high cost. In order to improve the scalability of secure public blockchains while enabling privacy and cost reduction, zk-rollups, a layer 2 solution, appear to be a promising avenue. This paper explores the benefits of zk-rollups, including improved privacy, as well as their potential to support transactions designed for specific applications. We propose an innovative design that allows multiple zk-rollups to co-exist on the same smart contracts, simplifying their creation and customization. We then evaluate the first implementation of our system highlighting a low overhead on existing transaction types and on proof generation while strongly decreasing the cost of new transaction types and drastically reducing zk-rollup creation costs.|
|**2023-06-05**|**Sustainable Adaptive Security**|Liliana Pasquale et.al.|[2306.04481v1](http://arxiv.org/abs/2306.04481v1)|null|With software systems permeating our lives, we are entitled to expect that such systems are secure by design, and that such security endures throughout the use of these systems and their subsequent evolution. Although adaptive security systems have been proposed to continuously protect assets from harm, they can only mitigate threats arising from changes foreseen at design time. In this paper, we propose the notion of Sustainable Adaptive Security (SAS) which reflects such enduring protection by augmenting adaptive security systems with the capability of mitigating newly discovered threats. To achieve this objective, a SAS system should be designed by combining automation (e.g., to discover and mitigate security threats) and human intervention (e.g., to resolve uncertainties during threat discovery and mitigation). In this paper, we use a smart home example to showcase how we can engineer the activities of the MAPE (Monitor, Analysis, Planning, and Execution) loop of systems satisfying sustainable adaptive security. We suggest that using anomaly detection together with abductive reasoning can help discover new threats and guide the evolution of security requirements and controls. We also exemplify situations when humans can be involved in the execution of the activities of the MAPE loop and discuss the requirements to engineer human interventions.|
|**2023-06-05**|**A Study of Situational Reasoning for Traffic Understanding**|Jiarui Zhang et.al.|[2306.02520v1](http://arxiv.org/abs/2306.02520v1)|null|Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work, based on natural language inference, commonsense knowledge-graph self-supervision, multi-QA joint training, and dense retrieval of domain information. We associate each method with a relevant knowledge source, including knowledge graphs, relevant benchmarks, and driving manuals. In extensive experiments, we benchmark various knowledge-aware methods against the three datasets, under zero-shot evaluation; we provide in-depth analyses of model performance on data partitions and examine model predictions categorically, to yield useful insights on traffic understanding, given different background knowledge and reasoning strategies.|
|**2023-06-04**|**Anomaly Detection Techniques in Smart Grid Systems: A Review**|Shampa Banik et.al.|[2306.02473v1](http://arxiv.org/abs/2306.02473v1)|null|Smart grid data can be evaluated for anomaly detection in numerous fields, including cyber-security, fault detection, electricity theft, etc. The strange anomalous behaviors may have been caused by various reasons, including peculiar consumption patterns of the consumers, malfunctioning grid infrastructures, outages, external cyber-attacks, or energy fraud. Recently, anomaly detection of the smart grid has attracted a large amount of interest from researchers, and it is widely applied in a number of high-impact fields. One of the most significant challenges within the smart grid is the implementation of efficient anomaly detection for multiple forms of aberrant behaviors. In this paper, we provide a scoping review of research from the recent advancements in anomaly detection in the context of smart grids. We categorize our study from numerous aspects for deep understanding and inspection of the research challenges so far. Finally, after analyzing the gap in the reviewed paper, the direction for future research on anomaly detection in smart-grid systems has been provided briefly.|
|**2023-06-04**|**Softly, Deftly, Scrolls Unfurl Their Splendor: Rolling Flexible Surfaces for Wideband Wireless**|Ruichun Ma et.al.|[2306.02361v1](http://arxiv.org/abs/2306.02361v1)|null|With new frequency bands opening up, emerging wireless IoT devices are capitalizing on an increasingly divergent range of frequencies. However, existing coverage provisioning practice is often tied to specific standards and frequencies. There is little shareable wireless infrastructure for concurrent links on different frequencies, across networks and standards. This paper presents Scrolls, a frequency-tunable soft smart surface system to enhance wideband, multi-network coverage. Scrolls' hardware comprises many rows of rollable thin plastic film, each attached with flexible copper strips. When rolled to different lengths, the copper strips act as wire antennas reflecting signals on the corresponding frequencies. The surface control algorithm determines the unrolled strip lengths for link enhancement by probing the search space efficiently. We build a set of distributed, composable Scrolls prototypes and deploy them in an office. Extensive evaluation shows that Scrolls can adapt the antenna lengths effectively to provide link enhancement across diverse standards on sub-6 GHz bands. For concurrent links on 900 MHz (LoRa), 2.4 GHz (Wi-Fi), 3.7 GHz, and 5 GHz, Scrolls can provide received signal strength gains to all links simultaneously, by a median of 4 dB and up to 10 dB|
|**2023-06-02**|**SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow**|Pengcheng Lu et.al.|[2306.01665v1](http://arxiv.org/abs/2306.01665v1)|null|As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, and such methods lack interpretability and sustainability. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-training models and data flow, which only requires using the source code of smart contracts as features to explore the possibility of detecting smart Ponzi schemes from another direction. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods while increasing the interpretability of the model. Specifically, we first convert the source code of a smart contract into a data flow graph and then introduce a pre-training model based on learning code representations to build a classification model to identify Ponzi schemes in smart contracts. The experimental results show that SourceP achieves 87.2\% recall and 90.7\% F-score for detecting smart Ponzi schemes within Ethereum's smart contract dataset, outperforming state-of-the-art methods in terms of performance and sustainability. We also demonstrate through additional experiments that pre-training models and data flow play an important contribution to SourceP, as well as proving that SourceP has a good generalization ability.|
|**2023-06-02**|**Proxy Re-encryption based Fair Trade Protocol for Digital Goods Transactions via Smart Contracts**|Peng Zhang et.al.|[2306.01299v1](http://arxiv.org/abs/2306.01299v1)|null|With the massive amount of digital data generated everyday, transactions of digital goods become a trend. One of the essential requirements for such transactions is fairness, which is defined as that both of the seller and the buyer get what they want, or neither. Current fair trade protocols generally involve a trusted third-party (TTP), which achieves fairness by heavily relying on the TTP's behaviors and the two parties' trust in the TTP. With the emergence of Blockchain, its decentralization and transparency make it a very good candidate to replace the TTP. In this work, we attempt to design a secure and fair protocol for digital goods transactions through smart contracts on Blockchain. To ensure security of the digital goods, we propose an advanced passive proxy re-encryption (PRE) scheme, which enables smart contracts to transfer the decryption right to a buyer after receiving his/her payment. Furthermore, based on smart contracts and the proposed passive PRE scheme, a fair trade protocol for digital goods transactions is proposed, whose fairness is guaranteed by the arbitration protocol. The proposed protocol supports Ciphertext publicity and repeatable sale, while involving less number of interactions. Comprehensive experiment results validate the feasibility and effectiveness of the proposed protocol.|
|**2023-06-02**|**Recent Advances in Graph-based Machine Learning for Applications in Smart Urban Transportation Systems**|Hongde Wu et.al.|[2306.01282v1](http://arxiv.org/abs/2306.01282v1)|null|The Intelligent Transportation System (ITS) is an important part of modern transportation infrastructure, employing a combination of communication technology, information processing and control systems to manage transportation networks. This integration of various components such as roads, vehicles, and communication systems, is expected to improve efficiency and safety by providing better information, services, and coordination of transportation modes. In recent years, graph-based machine learning has become an increasingly important research focus in the field of ITS aiming at the development of complex, data-driven solutions to address various ITS-related challenges. This chapter presents background information on the key technical challenges for ITS design, along with a review of research methods ranging from classic statistical approaches to modern machine learning and deep learning-based approaches. Specifically, we provide an in-depth review of graph-based machine learning methods, including basic concepts of graphs, graph data representation, graph neural network architectures and their relation to ITS applications. Additionally, two case studies of graph-based ITS applications proposed in our recent work are presented in detail to demonstrate the potential of graph-based machine learning in the ITS domain.|
|**2023-06-01**|**Pre-Deployment Testing of Low Speed, Urban Road Autonomous Driving in a Simulated Environment**|Xinchen Li et.al.|[2306.01185v1](http://arxiv.org/abs/2306.01185v1)|null|Low speed autonomous shuttles emulating SAE Level L4 automated driving using human driver assisted autonomy have been operating in geo-fenced areas in several cities in the US and the rest of the world. These autonomous vehicles (AV) are operated by small to mid-sized technology companies that do not have the resources of automotive OEMs for carrying out exhaustive, comprehensive testing of their AV technology solutions before public road deployment. Due to the low speed of operation and hence not operating on roads containing highways, the base vehicles of these AV shuttles are not required to go through rigorous certification tests. The way the driver assisted AV technology is tested and allowed for public road deployment is continuously evolving but is not standardized and shows differences between the different states where these vehicles operate. Currently, AVs and AV shuttles deployed on public roads are using these deployments for testing and improving their technology. However, this is not the right approach. Safe and extensive testing in a lab and controlled test environment including Model-in-the-Loop (MiL), Hardware-in-the-Loop (HiL) and Autonomous-Vehicle-in-the-Loop (AViL) testing should be the prerequisite to such public road deployments. This paper presents three dimensional virtual modeling of an AV shuttle deployment site and simulation testing in this virtual environment. We have two deployment sites in Columbus of these AV shuttles through the Department of Transportation funded Smart City Challenge project named Smart Columbus. The Linden residential area AV shuttle deployment site of Smart Columbus is used as the specific example for illustrating the AV testing method proposed in this paper.|
|**2023-06-01**|**A Multi-Modal Latent-Features based Service Recommendation System for the Social Internet of Things**|Amar Khelloufi et.al.|[2306.01163v1](http://arxiv.org/abs/2306.01163v1)|null|The Social Internet of Things (SIoT), is revolutionizing how we interact with our everyday lives. By adding the social dimension to connecting devices, the SIoT has the potential to drastically change the way we interact with smart devices. This connected infrastructure allows for unprecedented levels of convenience, automation, and access to information, allowing us to do more with less effort. However, this revolutionary new technology also brings an eager need for service recommendation systems. As the SIoT grows in scope and complexity, it becomes increasingly important for businesses and individuals, and SIoT objects alike to have reliable sources for products, services, and information that are tailored to their specific needs. Few works have been proposed to provide service recommendations for SIoT environments. However, these efforts have been confined to only focusing on modeling user-item interactions using contextual information, devices' SIoT relationships, and correlation social groups but these schemes do not account for latent semantic item-item structures underlying the sparse multi-modal contents in SIoT environment. In this paper, we propose a latent-based SIoT recommendation system that learns item-item structures and aggregates multiple modalities to obtain latent item graphs which are then used in graph convolutions to inject high-order affinities into item representations. Experiments showed that the proposed recommendation system outperformed state-of-the-art SIoT recommendation methods and validated its efficacy at mining latent relationships from multi-modal features.|
|**2023-06-01**|**An XRI Mixed-Reality Internet-of-Things Architectural Framework Toward Immersive and Adaptive Smart Environments**|Alexis Morris et.al.|[2306.01139v1](http://arxiv.org/abs/2306.01139v1)|null|The internet-of-things (IoT) refers to the growing number of embedded interconnected devices within everyday ubiquitous objects and environments, especially their networks, edge controllers, data gathering and management, sharing, and contextual analysis capabilities. However, the IoT suffers from inherent limitations in terms of human-computer interaction. In this landscape, there is a need for interfaces that have the potential to translate the IoT more solidly into the foreground of everyday smart environments, where its users are multimodal, multifaceted, and where new forms of presentation, adaptation, and immersion are essential. This work highlights the synergetic opportunities for both IoT and XR to converge toward hybrid XR objects with strong real-world connectivity, and IoT objects with rich XR interfaces. The paper contributes i) an understanding of this multi-disciplinary domain XR-IoT (XRI); ii) a theoretical perspective on how to design XRI agents based on the literature; iii) a system design architectural framework for XRI smart environment development; and iv) an early discussion of this process. It is hoped that this research enables future researchers in both communities to better understand and deploy hybrid smart XRI environments.|
|**2023-06-01**|**Extending the Metaverse: Hyper-Connected Smart Environments with Mixed Reality and the Internet of Things**|Jie Guan et.al.|[2306.01137v1](http://arxiv.org/abs/2306.01137v1)|null|The metaverse, i.e., the collection of technologies that provide a virtual twin of the real world via mixed reality, internet of things, and others, is gaining prominence. However, the metaverse faces challenges as it grows toward mainstream adoption. Among these is the lack of strong connections between metaverse objects and traditional physical objects and environments, which leads to inconsistencies for users within metaverse environments. To address this issue, this work explores the design and development of a framework for bridging the physical environment and the metaverse through the use of internet-of-things objects and mixed reality designs. The contributions of this include: i) an architectural framework for extending the metaverse, ii) design prototypes using the framework. Together, this exploration charts the course toward a more cohesive and hyper-connected metaverse smart environment.|
|**2023-06-01**|**Cross-Reality for Extending the Metaverse: Designing Hyper-Connected Immersive Environments with XRI**|Jie Guan et.al.|[2306.01113v1](http://arxiv.org/abs/2306.01113v1)|null|The Metaverse comprises technologies to enable virtual twins of the real world, via mixed reality, internet of things, and others. As it matures unique challenges arise such as a lack of strong connections between virtual and physical worlds. This work presents design frameworks for cross-reality hybrid spaces. Contributions include: i) clarifying the metaverse "disconnect", ii) extended metaverse design frameworks, iii) prototypes, and iv) discussions toward new metaverse smart environments.|

## Electromyography

### Electromyography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-05-28**|**Multi-Modal Wireless Flexible Gel-Free Sensors with Edge Deep Learning for Detecting and Alerting Freezing of Gait in Parkinson's Patients**|Yuhan Hou et.al.|[2305.17629v1](http://arxiv.org/abs/2305.17629v1)|null|Freezing of gait (FoG) is a debilitating symptom of Parkinson's disease (PD). This work develops flexible wearable sensors that can detect FoG and alert patients and companions to help prevent falls. FoG is detected on the sensors using a deep learning (DL) model with multi-modal sensory inputs collected from distributed wireless sensors. Two types of wireless sensors are developed, including: (1) a C-shape central node placed around the patient's ears, which collects electroencephalogram (EEG), detects FoG using an on-device DL model, and generates auditory alerts when FoG is detected; (2) a stretchable patch-type sensor attached to the patient's legs, which collects electromyography (EMG) and movement information from accelerometers. The patch-type sensors wirelessly send collected data to the central node through low-power ultra-wideband (UWB) transceivers. All sensors are fabricated on flexible printed circuit boards. Adhesive gel-free acetylene carbon black and polydimethylsiloxane electrodes are fabricated on the flexible substrate to allow conformal wear over the long term. Custom integrated circuits (IC) are developed in 180 nm CMOS technology and used in both types of sensors for signal acquisition, digitization, and wireless communication. A novel lightweight DL model is trained using multi-modal sensory data. The inference of the DL model is performed on a low-power microcontroller in the central node. The DL model achieves a high detection sensitivity of 0.81 and a specificity of 0.88. The developed wearable sensors are ready for clinical experiments and hold great promise in improving the quality of life of patients with PD. The proposed design methodologies can be used in wearable medical devices for the monitoring and treatment of a wide range of neurodegenerative diseases.|
|**2023-05-26**|**A Multi-Resolution Physics-Informed Recurrent Neural Network: Formulation and Application to Musculoskeletal Systems**|Karan Taneja et.al.|[2305.16593v1](http://arxiv.org/abs/2305.16593v1)|null|This work presents a multi-resolution physics-informed recurrent neural network (MR PI-RNN), for simultaneous prediction of musculoskeletal (MSK) motion and parameter identification of the MSK systems. The MSK application was selected as the model problem due to its challenging nature in mapping the high-frequency surface electromyography (sEMG) signals to the low-frequency body joint motion controlled by the MSK and muscle contraction dynamics. The proposed method utilizes the fast wavelet transform to decompose the mixed frequency input sEMG and output joint motion signals into nested multi-resolution signals. The prediction model is subsequently trained on coarser-scale input-output signals using a gated recurrent unit (GRU), and then the trained parameters are transferred to the next level of training with finer-scale signals. These training processes are repeated recursively under a transfer-learning fashion until the full-scale training (i.e., with unfiltered signals) is achieved, while satisfying the underlying dynamic equilibrium. Numerical examples on recorded subject data demonstrate the effectiveness of the proposed framework in generating a physics-informed forward-dynamics surrogate, which yields higher accuracy in motion predictions of elbow flexion-extension of an MSK system compared to the case with single-scale training. The framework is also capable of identifying muscle parameters that are physiologically consistent with the subject's kinematics data.|
|**2023-05-18**|**Adaptive Learning based Upper-Limb Rehabilitation Training System with Collaborative Robot**|Jun Hong Lim et.al.|[2305.10642v1](http://arxiv.org/abs/2305.10642v1)|null|Rehabilitation training for patients with motor disabilities usually requires specialized devices in rehabilitation centers. Home-based multi-purpose training would significantly increase treatment accessibility and reduce medical costs. While it is unlikely to equip a set of rehabilitation robots at home, we investigate the feasibility to use the general-purpose collaborative robot for rehabilitation therapies. In this work, we developed a new system for multi-purpose upper-limb rehabilitation training using a generic robot arm with human motor feedback and preference. We integrated surface electromyography, force/torque sensors, RGB-D cameras, and robot controllers with the Robot Operating System to enable sensing, communication, and control of the system. Imitation learning methods were adopted to imitate expert-provided training trajectories which could adapt to subject capabilities to facilitate in-home training. Our rehabilitation system is able to perform gross motor function and fine motor skill training with a gripper-based end-effector. We simulated system control in Gazebo and training effects (muscle activation level) in OpenSim and evaluated its real performance with human subjects. For all the subjects enrolled, our system achieved better training outcomes compared to specialist-assisted rehabilitation under the same conditions. Our work demonstrates the potential of utilizing collaborative robots for in-home motor rehabilitation training.|
|**2023-05-06**|**Electromyography Signal Classification Using Deep Learning**|Mekia Shigute Gaso et.al.|[2305.04006v1](http://arxiv.org/abs/2305.04006v1)|null|We have implemented a deep learning model with L2 regularization and trained it on Electromyography (EMG) data. The data comprises of EMG signals collected from control group, myopathy and ALS patients. Our proposed deep neural network consists of eight layers; five fully connected, two batch normalization and one dropout layers. The data is divided into training and testing sections by subsequently dividing the training data into sub-training and validation sections. Having implemented this model, an accuracy of 99 percent is achieved on the test data set. The model was able to distinguishes the normal cases (control group) from the others at a precision of 100 percent and classify the myopathy and ALS with high accuracy of 97.4 and 98.2 percents, respectively. Thus we believe that, this highly improved classification accuracies will be beneficial for their use in the clinical diagnosis of neuromuscular disorders.|
|**2023-04-08**|**Overview of processing techniques for surface electromyography signals**|Alejandra Manjarres-Triana et.al.|[2304.04098v1](http://arxiv.org/abs/2304.04098v1)|null|Surface electromyography (sEMG) is a technology to assess muscle activation, which is an important component in applications related to diagnosis, treatment, progression assessment, and rehabilitation of specific individuals' conditions. Recently, sEMG potential has been shown, since it can be used in a non-invasive manner; nevertheless, it requires careful signal analysis to support health professionals reliably. This paper briefly described the basic concepts involved in the sEMG, such as the physiology of the muscles, the data acquisition, the signal processing techniques, and classification methods that may be used to identify disorders or signs of abnormalities according to muscular patterns. Specifically, classification methods encompass digital signal processing techniques and machine learning with high potential in the field. We hope that this work serves as an introduction to researchers interested in this field.|
|**2023-04-02**|**A Framework and Call to Action for the Future Development of EMG-Based Input in HCI**|Ethan Eddy et.al.|[2304.00582v1](http://arxiv.org/abs/2304.00582v1)|null|Electromyography (EMG) has been explored as an HCI input modality following a long history of success for prosthesis control. While EMG has the potential to address a range of hands-free interaction needs, it has yet to be widely accepted outside of prosthetics due to a perceived lack of robustness and intuitiveness. To understand how EMG input systems can be better designed, we sampled the ACM digital library to identify limitations in the approaches taken. Leveraging these works in combination with our research group's extensive interdisciplinary experience in this field, four themes emerged (1) interaction design, (2) model design, (3) system evaluation, and (4) reproducibility. Using these themes, we provide a step-by-step framework for designing EMG-based input systems to strengthen the foundation on which EMG-based interactions are built. Additionally, we provide a call-to-action for researchers to unlock the hidden potential of EMG as a widely applicable and highly usable input modality.|
|**2023-03-13**|**Discriminative sEMG-based features to assess damping ability and interpret activation patterns in lower-limb muscles of ACLR athletes**|Mehran Hatamzadeh et.al.|[2303.06954v1](http://arxiv.org/abs/2303.06954v1)|null|Objective: The main goal of the athletes who undergo anterior cruciate ligament reconstruction (ACLR) surgery is a successful return-to-sport. At this stage, identifying muscular deficits becomes important. Hence, in this study, three discriminative features based on surface electromyographic signals (sEMG) acquired in a dynamic protocol are introduced to assess the damping ability and interpret activation patterns in lower-limb muscles of ACLR athletes. Methods: The features include the median frequency of the power spectrum density (PSD), the relative percentage of the equivalent damping or equivalent stiffness derived from the median frequency, and the energy of the signals in the time-frequency plane of the pseudo-Wigner-Ville distribution (PWVD). To evaluate the features, 11 healthy and 11 ACLR athletes (6 months post-reconstruction surgery) were recruited to acquire the sEMG signals from the medial and the lateral parts of the hamstrings, quadriceps, and gastrocnemius muscles in pre- and post-fatigue single-leg landings. Results: A significant damping deficiency is observed in the hamstring muscles of ACLR athletes by evaluating the proposed features. This deficiency indicates that more attention should be paid to this muscle of ACLR athletes in pre-return-to-sport rehabilitations. Conclusion: The quality of electromyography-based pre-return-to-sport assessments on ACLR subjects depends on the sEMG acquisition protocol, as well as the type and nature of the extracted features. Hence, combinatorial application of both energy-based features (derived from the PWVD) and power-based features (derived from the PSD) could facilitate the assessment process by providing additional biomechanical information regarding the behavior of the muscles surrounding the knee.|
|**2023-03-11**|**AI-Enhanced Intensive Care Unit: Revolutionizing Patient Care with Pervasive Sensing**|Subhash Nerella et.al.|[2303.06252v1](http://arxiv.org/abs/2303.06252v1)|null|The intensive care unit (ICU) is a specialized hospital space where critically ill patients receive intensive care and monitoring. Comprehensive monitoring is imperative in assessing patients conditions, in particular acuity, and ultimately the quality of care. However, the extent of patient monitoring in the ICU is limited due to time constraints and the workload on healthcare providers. Currently, visual assessments for acuity, including fine details such as facial expressions, posture, and mobility, are sporadically captured, or not captured at all. These manual observations are subjective to the individual, prone to documentation errors, and overburden care providers with the additional workload. Artificial Intelligence (AI) enabled systems has the potential to augment the patient visual monitoring and assessment due to their exceptional learning capabilities. Such systems require robust annotated data to train. To this end, we have developed pervasive sensing and data processing system which collects data from multiple modalities depth images, color RGB images, accelerometry, electromyography, sound pressure, and light levels in ICU for developing intelligent monitoring systems for continuous and granular acuity, delirium risk, pain, and mobility assessment. This paper presents the Intelligent Intensive Care Unit (I2CU) system architecture we developed for real-time patient monitoring and visual assessment.|
|**2023-02-19**|**Estimation and Early Prediction of Grip Force Based on sEMG Signals and Deep Recurrent Neural Networks**|Atusa Ghorbani et.al.|[2302.09555v1](http://arxiv.org/abs/2302.09555v1)|null|Hands are used for communicating with the surrounding environment and have a complex structure that enables them to perform various tasks with their multiple degrees of freedom. Hand amputation can prevent a person from performing their daily activities. In that event, finding a suitable, fast, and reliable alternative for the missing limb can affect the lives of people who suffer from such conditions. As the most important use of the hands is to grasp objects, the purpose of this study is to accurately predict gripping force from surface electromyography (sEMG) signals during a pinch-type grip. In that regard, gripping force and sEMG signals are derived from 10 healthy subjects. Results show that for this task, recurrent networks outperform nonrecurrent ones, such as a fully connected multilayer perceptron (MLP) network. Gated recurrent unit (GRU) and long short-term memory (LSTM) networks can predict the gripping force with R-squared values of 0.994 and 0.992, respectively, and a prediction rate of over 1300 predictions per second. The predominant advantage of using such frameworks is that the gripping force can be predicted straight from preprocessed sEMG signals without any form of feature extraction, not to mention the ability to predict future force values using larger prediction horizons adequately. The methods presented in this study can be used in the myoelectric control of prosthetic hands or robotic grippers.|
|**2023-02-17**|**Sleep Model -- A Sequence Model for Predicting the Next Sleep Stage**|Iksoo Choi et.al.|[2302.12709v1](http://arxiv.org/abs/2302.12709v1)|null|As sleep disorders are becoming more prevalent there is an urgent need to classify sleep stages in a less disturbing way.In particular, sleep-stage classification using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical $n$-gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the $n$-gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.|
|**2023-02-15**|**Automated Movement Detection with Dirichlet Process Mixture Models and Electromyography**|Navin Cooray et.al.|[2302.07509v1](http://arxiv.org/abs/2302.07509v1)|null|Numerous sleep disorders are characterised by movement during sleep, these include rapid-eye movement sleep behaviour disorder (RBD) and periodic limb movement disorder. The process of diagnosing movement related sleep disorders requires laborious and time-consuming visual analysis of sleep recordings. This process involves sleep clinicians visually inspecting electromyogram (EMG) signals to identify abnormal movements. The distribution of characteristics that represent movement can be diverse and varied, ranging from brief moments of tensing to violent outbursts. This study proposes a framework for automated limb-movement detection by fusing data from two EMG sensors (from the left and right limb) through a Dirichlet process mixture model. Several features are extracted from 10 second mini-epochs, where each mini-epoch has been classified as 'leg-movement' or 'no leg-movement' based on annotations of movement from sleep clinicians. The distributions of the features from each category can be estimated accurately using Gaussian mixture models with the Dirichlet process as a prior. The available dataset includes 36 participants that have all been diagnosed with RBD. The performance of this framework was evaluated by a 10-fold cross validation scheme (participant independent). The study was compared to a random forest model and outperformed it with a mean accuracy, sensitivity, and specificity of 94\%, 48\%, and 95\%, respectively. These results demonstrate the ability of this framework to automate the detection of limb movement for the potential application of assisting clinical diagnosis and decision-making.|
|**2023-02-08**|**Simplified markerless stride detection pipeline (sMaSDP) for surface EMG segmentation**|Rafael Castro Aguiar et.al.|[2302.04243v1](http://arxiv.org/abs/2302.04243v1)|null|People with mobility impairments are often recommended for gait assessment studies to diagnose their condition and to select appropriate physiotherapy to improve their mobility. These studies are often conducted in clinical or lab settings, where subjects are assessed in a foreign environment, which may influence their motivation, coordination and overall mobility. Alternatively, if the subject's gait could be assessed in their daily-lives, in unconstrained settings, a more naturalistic gait assessment could be performed. Kinematic analysis of a gait pattern on its own may not be sufficient to characterise a subject's mobility. To better diagnose gait deficiencies, analysis of the patient's muscle activity should be conducted as well. To do so, gait studies should collect, synchronously, Electromyography (EMG) and kinematic data. This method introduces a simplified markerless gait event detection pipeline for the segmentation of EMG signals, via synchronously recorded Inertial Measurement Unit (IMU) data. In an unconstrained walking experiment, healthy subjects walk through a designed course with their kinematic and EMG data recorded. This course comprises 5 different walking modalities (level walking, ramp up/down, staircase up/down), mimicking everyday walking. Through timepoint matching, segmentation and filtering, we generate an algorithm that detects heel-strike (HS) events using a single IMU, and isolates EMG activity of gait cycles, in the different walking modalities. This gait event detection algorithm can be adapted to different datasets, and was tested in both healthy and Parkinson's Disease (PD) gait. Results demonstrate the extracted muscle activity levels in a healthy subject's level ground walking, and the extracted HS events of a PD patient. Adjustments to algorithm parameters are possible (e.g., expected velocity, cadence) and can further increase the detection accuracy.|
|**2023-02-01**|**Upper-limb Geometric MyoPassivity Map for Physical Human-Robot Interaction**|Xingyuan Zhou et.al.|[2302.00495v1](http://arxiv.org/abs/2302.00495v1)|null|The intrinsic biomechanical characteristic of the human upper limb plays a central role in absorbing the interactive energy during physical human-robot interaction (pHRI). We have recently shown that based on the concept of ``Excess of Passivity (EoP)," from nonlinear control theory, it is possible to decode such energetic behavior for both upper and lower limbs. The extracted knowledge can be used in the design of controllers for optimizing the transparency and fidelity of force fields in human-robot interaction and in haptic systems. In this paper, for the first time, we investigate the frequency behavior of the passivity map for the upper limb when the muscle co-activation was controlled in real-time through visual electromyographic feedback. Five healthy subjects (age: 27 +/- 5) were included in this study. The energetic behavior was evaluated at two stimulation frequencies at eight interaction directions over two controlled muscle co-activation levels. Electromyography (EMG) was captured using the Delsys Wireless Trigno system. Results showed a correlation between EMG and EoP, which was further altered by increasing the frequency. The proposed energetic behavior is named the Geometric MyoPassivity (GMP) map. The findings indicate that the GMP map has the potential to be used in real-time to quantify the absorbable energy, thus passivity margin of stability for upper limb interaction during pHRI.|
|**2023-01-31**|**A Prototype System for High Frame Rate Ultrasound Imaging based Prosthetic Arm Control**|Ayush Singh et.al.|[2301.13809v3](http://arxiv.org/abs/2301.13809v3)|null|The creation of unique control methods for a hand prosthesis is still a problem that has to be addressed. The best choice of a human-machine interface (HMI) that should be used to enable natural control is still a challenge. Surface electromyography (sEMG), the most popular option, has a variety of difficult-to-fix issues (electrode displacement, sweat, fatigue). The ultrasound imaging-based methodology offers a means of recognising complex muscle activity and configuration with a greater SNR and less hardware requirements as compared to sEMG. In this study, a prototype system for high frame rate ultrasound imaging for prosthetic arm control is proposed. Using the proposed framework, a virtual robotic hand simulation is developed that can mimic a human hand as illustrated in the link [10]. The proposed classification model simulating four hand gestures has a classification accuracy of more than 90%.|
|**2023-01-23**|**Long-term stable Electromyography classification using Canonical Correlation Analysis**|Elisa Donati et.al.|[2301.09729v1](http://arxiv.org/abs/2301.09729v1)|null|Discrimination of hand gestures based on the decoding of surface electromyography (sEMG) signals is a well-establish approach for controlling prosthetic devices and for Human-Machine Interfaces (HMI). However, despite the promising results achieved by this approach in well-controlled experimental conditions, its deployment in long-term real-world application scenarios is still hindered by several challenges. One of the most critical challenges is maintaining high EMG data classification performance across multiple days without retraining the decoding system. The drop in performance is mostly due to the high EMG variability caused by electrodes shift, muscle artifacts, fatigue, user adaptation, or skin-electrode interfacing issues. Here we propose a novel statistical method based on canonical correlation analysis (CCA) that stabilizes EMG classification performance across multiple days for long-term control of prosthetic devices. We show how CCA can dramatically decrease the performance drop of standard classifiers observed across days, by maximizing the correlation among multiple-day acquisition data sets. Our results show how the performance of a classifier trained on EMG data acquired only of the first day of the experiment maintains 90% relative accuracy across multiple days, compensating for the EMG data variability that occurs over long-term periods, using the CCA transformation on data obtained from a small number of gestures. This approach eliminates the need for large data sets and multiple or periodic training sessions, which currently hamper the usability of conventional pattern recognition based approaches|
|**2023-01-23**|**High-density magnetomyography is superior over surface electromyography for the decomposition of motor units: a simulation study**|Thomas Klotz et.al.|[2301.09494v1](http://arxiv.org/abs/2301.09494v1)|null|Studying motor units (MUs) is essential for understanding motor control, the detection of neuromuscular disorders and the control of human-machine interfaces. Individual motor unit firings are currently identified in vivo by decomposing electromyographic (EMG) signals. Due to our body's electric properties, individual motor units can only be separated to a limited extent with surface EMG. Unlike electrical signals, magnetic fields pass through biological tissues without distortion. This physical property and emerging technology of quantum sensors make magnetomyography (MMG) a highly promising methodology. However, the full potential of MMG to study neuromuscular physiology has not yet been explored. In this work, we perform in silico trials that combine a biophysical model of EMG and MMG with state-of-the-art algorithms for the decomposition of motor units. This allows the prediction of an upper-bound for the motor unit decomposition accuracy. It is shown that non-invasive MMG is superior over surface EMG for the robust identification of the discharge patterns of individual motor units. Decomposing MMG instead of EMG increased the number of identifiable motor units by 71%. Notably, MMG exhibits a less pronounced bias to detect superficial motor units. The presented simulations provide insights into methods to study the neuromuscular system non-invasively and in vivo that would not be easily feasible by other means. Hence, this study provides guidance for the development of novel biomedical technologies.|
|**2023-01-13**|**Analysis of LGM Model for sEMG Signals related to Weight Training**|Durgesh Kusuru et.al.|[2301.05417v1](http://arxiv.org/abs/2301.05417v1)|null|Statistical models of Surface electromyography (sEMG) signals have several applications such as better understanding of sEMG signal generation, improved pattern recognition based control of wearable exoskeletons and prostheses, improving training strategies in sports activities, and EMG simulation studies. Most of the existing studies analysed the statistical model of sEMG signals acquired under isometric contractions. However, there is no study that addresses the statistical model under isotonic contractions. In this work, a new dataset, electromyography analysis of human activities - database 2 (EMAHA-DB2) is developed. It consists of two experiments based on both isometric and isotonic activities during weight training. Previously, a novel Laplacian-Gaussian Mixture (LGM) model was demonstrated for a few benchmark datasets consisting of basic movements and gestures. In this work, the model suitability analysis is extended to the EMAHA-DB2 dataset. Further, the LGM model is compared with three existing statistical models including the recent scale-mixture model. According to qualitative and quantitative analyses, the LGM model has a better fit to the empirical pdf of the recorded sEMG signals compared with the scale mixture model and the other standard models. The variance and mixing weight of the Laplacian component of the signal are analyzed with respect to the type of muscle, type of muscle contraction, dumb-bell weight and training experience of the subjects. The sEMG variance (the Laplacian component) increases with respect to the weights, is greater for isotonic activity especially for the biceps. For isotonic activity, the signal variance increases with training experience. Importantly, the ratio of the variances from the two muscle sites is observed to be nearly independent of the lifted weight and consistently increases with the training experience.|
|**2023-01-09**|**EMAHA-DB1: A New Upper Limb sEMG Dataset for Classification of Activities of Daily Living**|Naveen Kumar Karnam et.al.|[2301.03325v1](http://arxiv.org/abs/2301.03325v1)|null|In this paper, we present electromyography analysis of human activity - database 1 (EMAHA-DB1), a novel dataset of multi-channel surface electromyography (sEMG) signals to evaluate the activities of daily living (ADL). The dataset is acquired from 25 able-bodied subjects while performing 22 activities categorised according to functional arm activity behavioral system (FAABOS) (3 - full hand gestures, 6 - open/close office draw, 8 - grasping and holding of small office objects, 2 - flexion and extension of finger movements, 2 - writing and 1 - rest). The sEMG data is measured by a set of five Noraxon Ultium wireless sEMG sensors with Ag/Agcl electrodes placed on a human hand. The dataset is analyzed for hand activity recognition classification performance. The classification is performed using four state-ofthe-art machine learning classifiers, including Random Forest (RF), Fine K-Nearest Neighbour (KNN), Ensemble KNN (sKNN) and Support Vector Machine (SVM) with seven combinations of time domain and frequency domain feature sets. The state-of-theart classification accuracy on five FAABOS categories is 83:21% by using the SVM classifier with the third order polynomial kernel using energy feature and auto regressive feature set ensemble. The classification accuracy on 22 class hand activities is 75:39% by the same SVM classifier with the log moments in frequency domain (LMF) feature, modified LMF, time domain statistical (TDS) feature, spectral band powers (SBP), channel cross correlation and local binary patterns (LBP) set ensemble. The analysis depicts the technical challenges addressed by the dataset. The developed dataset can be used as a benchmark for various classification methods as well as for sEMG signal analysis corresponding to ADL and for the development of prosthetics and other wearable robotics.|
|**2023-01-04**|**A Novel Power-optimized CMOS sEMG Device with Ultra Low-noise integrated with ConvNet (VGG16) for Biomedical Applications**|Ahmed Ayman - Mohamed Sabry et.al.|[2301.09570v2](http://arxiv.org/abs/2301.09570v2)|null|The needle bio-potential sensors for measuring muscle and brain activity need invasive surgical targeted muscle reinnervation (TMR) and a demanding process to maintain, but surface bio-potential sensors lack clear bio-signal reading (Signal-Interference). In this research, a novel power-optimized complementary metal-oxide-semiconductor (CMOS) Surface Electromyography (sEMG) is developed to improve the efficiency and quality of captured bio-signal for biomedical application: The early diagnosis of neurological disorders (Dystonia) and a novel compatible mind-controlled prosthetic leg with human daily activities. A novel sEMG composed of CMOS Op-Amp based PIC16F877A 8-bit CMOS Flash-based Microcontroller is utilized to minimize power consumption and data processing time. sEMG Circuit is implemented with developed analog filter along with infinite impulse response (IIR) digital filter via Fast Fourier Transform (FFT), Z-transform, and difference equations. The analysis shows a significant improvement of 169.2% noise-reduction in recorded EMG signal using developed digital filter compared to analog one according to numerical root mean square error (RMSE). Moreover, digital IIR was tested in two stages: algorithmic and real-world. As a result, IIR's algorithmic (MATLAB) and real-world RMSEs were 0.03616 and 0.05224, respectively. A notable advancement of 20.8% in data processing duration in EMG signal analysis. Optimizing VGG, AlexNet, and ResNet ConvNet as trained and tested on 15 public EEG (62-electrode) and 18 subjects' observed EMG data. The results indicate that VGG16-1D is 98.43% higher. During real testing, the accuracy was 95.8 +/- 4.6% for 16 subjects (6 Amputees-10 Dystonia). This study demonstrates the potential for sEMG, paving the way for biomedical applications.|
|**2023-01-03**|**A Laplacian Gaussian Mixture Model for Surface EMG Signals of Human Arm Activity**|Durgesh Kusuru et.al.|[2301.01080v1](http://arxiv.org/abs/2301.01080v1)|null|The probability density function (pdf) of surface Electromyography (sEMG) signals follows any one of the standalone standard distributions: the Gaussian or the Laplacian. Further, the choice of the model is dependent on muscle contraction force (MCF) levels. Hence, a unified model is proposed which explains the statistical nature of sEMG signals at different MCF levels. In this paper, we propose the Laplacian Gaussian Mixture (LGM) model for the signals recorded from upper limbs. This model is able to explain the sEMG signals from different activities corresponding to different MCF levels. The model is tested on different bench-mark sEMG data sets and is validated using both the qualitative and quantitative perspectives. It is determined that for low and medium contraction force levels the proposed mixture model is more accurate than both the Laplacian and the Gaussian models. Whereas for high contraction force level, the LGM model behaves as a Gaussian model. The mixing weights of the LGM model are analyzed and it is observed that for low and medium MCF levels both the mixing weights of LGM model do contribute. Whereas for high contraction force levels the Laplacian weight becomes weaker. The proposed LGM model for sEMG signals from upper limbs explains sEMG signals at different MCF levels. The proposed model helps in improved understanding of statistical nature of sEMG signals and better feature representation in the classification problems.|
|**2022-12-28**|**Joint Action is a Framework for Understanding Partnerships Between Humans and Upper Limb Prostheses**|Michael R. Dawson et.al.|[2212.14124v1](http://arxiv.org/abs/2212.14124v1)|null|Recent advances in upper limb prostheses have led to significant improvements in the number of movements provided by the robotic limb. However, the method for controlling multiple degrees of freedom via user-generated signals remains challenging. To address this issue, various machine learning controllers have been developed to better predict movement intent. As these controllers become more intelligent and take on more autonomy in the system, the traditional approach of representing the human-machine interface as a human controlling a tool becomes limiting. One possible approach to improve the understanding of these interfaces is to model them as collaborative, multi-agent systems through the lens of joint action. The field of joint action has been commonly applied to two human partners who are trying to work jointly together to achieve a task, such as singing or moving a table together, by effecting coordinated change in their shared environment. In this work, we compare different prosthesis controllers (proportional electromyography with sequential switching, pattern recognition, and adaptive switching) in terms of how they present the hallmarks of joint action. The results of the comparison lead to a new perspective for understanding how existing myoelectric systems relate to each other, along with recommendations for how to improve these systems by increasing the collaborative communication between each partner.|
|**2022-12-24**|**Agent-based Modeling and Simulation of Human Muscle For Development of Software to Analyze the Human Gait**|Sina Saadati et.al.|[2212.12760v1](http://arxiv.org/abs/2212.12760v1)|null|In this research, we are about to present an agentbased model of human muscle which can be used in analysis of human movement. As the model is designed based on the physiological structure of the muscle, The simulation calculations would be natural, and also, It can be possible to analyze human movement using reverse engineering methods. The model is also a suitable choice to be used in modern prostheses, because the calculation of the model is less than other machine learning models such as artificial neural network algorithms and It makes our algorithm battery-friendly. We will also devise a method that can calculate the intensity of human muscle during gait cycle using a reverse engineering solution. The algorithm called Boots is different from some optimization methods, so It would be able to compute the activities of both agonist and antagonist muscles in a joint. As a consequence, By having an agent-based model of human muscle and Boots algorithm, We would be capable to develop software that can calculate the nervous stimulation of human's lower body muscle based on the angular displacement during gait cycle without using painful methods like electromyography. By developing the application as open-source software, We are hopeful to help researchers and physicians who are studying in medical and biomechanical fields.|
|**2022-12-20**|**Pain level and pain-related behaviour classification using GRU-based sparsely-connected RNNs**|Mohammad Mahdi Dehshibi et.al.|[2212.14806v1](http://arxiv.org/abs/2212.14806v1)|null|There is a growing body of studies on applying deep learning to biometrics analysis. Certain circumstances, however, could impair the objective measures and accuracy of the proposed biometric data analysis methods. For instance, people with chronic pain (CP) unconsciously adapt specific body movements to protect themselves from injury or additional pain. Because there is no dedicated benchmark database to analyse this correlation, we considered one of the specific circumstances that potentially influence a person's biometrics during daily activities in this study and classified pain level and pain-related behaviour in the EmoPain database. To achieve this, we proposed a sparsely-connected recurrent neural networks (s-RNNs) ensemble with the gated recurrent unit (GRU) that incorporates multiple autoencoders using a shared training framework. This architecture is fed by multidimensional data collected from inertial measurement unit (IMU) and surface electromyography (sEMG) sensors. Furthermore, to compensate for variations in the temporal dimension that may not be perfectly represented in the latent space of s-RNNs, we fused hand-crafted features derived from information-theoretic approaches with represented features in the shared hidden state. We conducted several experiments which indicate that the proposed method outperforms the state-of-the-art approaches in classifying both pain level and pain-related behaviour.|
|**2022-12-06**|**TripCEAiR: A Multi-Loss minimization approach for surface EMG based Airwriting Recognition**|Ayush Tripathi et.al.|[2212.02870v3](http://arxiv.org/abs/2212.02870v3)|null|Airwriting Recognition refers to the problem of identification of letters written in space with movement of the finger. It can be seen as a special case of dynamic gesture recognition wherein the set of gestures are letters in a particular language. Surface Electromyography (sEMG) is a non-invasive approach used to capture electrical signals generated as a result of contraction and relaxation of the muscles. sEMG has been widely adopted for gesture recognition applications. Unlike static gestures, dynamic gestures are user-friendly and can be used as a method for input with applications in Human Computer Interaction. There has been limited work in recognition of dynamic gestures such as airwriting, using sEMG signals and forms the core of the current work. In this work, a multi-loss minimization framework for sEMG based airwriting recognition is proposed. The proposed framework aims at learning a feature embedding vector that minimizes the triplet loss, while simultaneously learning the parameters of a classifier head to recognize corresponding alphabets. The proposed method is validated on a dataset recorded in the lab comprising of sEMG signals from 50 participants writing English uppercase alphabets. The effect of different variations of triplet loss, triplet mining strategies and feature embedding dimension is also presented. The best-achieved accuracy was 81.26% and 65.62% in user-dependent and independent scenarios respectively by using semihard positive and hard negative triplet mining. The code for our implementation will be made available at https://github.com/ayushayt/TripCEAiR.|
|**2022-12-05**|**Muscles in Action**|Mia Chiquier et.al.|[2212.02978v3](http://arxiv.org/abs/2212.02978v3)|null|Human motion is created by, and constrained by, our muscles. We take a first step at building computer vision methods that represent the internal muscle activity that causes motion. We present a new dataset, Muscles in Action (MIA), to learn to incorporate muscle activity into human motion representations. The dataset consists of 12.5 hours of synchronized video and surface electromyography (sEMG) data of 10 subjects performing various exercises. Using this dataset, we learn a bidirectional representation that predicts muscle activation from video, and conversely, reconstructs motion from muscle activation. We evaluate our model on in-distribution subjects and exercises, as well as on out-of-distribution subjects and exercises. We demonstrate how advances in modeling both modalities jointly can serve as conditioning for muscularly consistent motion generation. Putting muscles into computer vision systems will enable richer models of virtual humans, with applications in sports, fitness, and AR/VR.|
|**2022-11-13**|**Review of medical data analysis based on spiking neural networks**|X. Li et.al.|[2212.02234v1](http://arxiv.org/abs/2212.02234v1)|null|Medical data mainly includes various biomedical signals and medical images, and doctors can make judgments on the physical condition of patients through medical data. However, the interpretation of medical data requires a lot of labor costs and may be misjudged, so many scholars use neural networks and deep learning to classify and study medical data, thereby improving doctors' work efficiency and accuracy, achieving early detection of diseases and early diagnosis, so it has a wide range of application prospects. However, traditional neural networks have disadvantages such as high energy consumption and high latency (slow calculation speed). This paper introduces the research on signal classification and disease diagnosis based on the third-generation neural network - pulse neural network in recent years, using medical data, such as electroencephalogram (EEG), electrocardiogram (ECG), electromyography (EMG), magnetic resonance imaging (MRI), etc., summarizes the advantages and disadvantages of pulse neural networks compared with traditional networks, and looks forward to the future development direction.|
|**2022-11-07**|**Novel Muscle Monitoring by Radiomyography(RMG) and Application to Hand Gesture Recognition**|Zijing Zhang et.al.|[2211.03767v1](http://arxiv.org/abs/2211.03767v1)|null|Conventional electromyography (EMG) measures the continuous neural activity during muscle contraction, but lacks explicit quantification of the actual contraction. Mechanomyography (MMG) and accelerometers only measure body surface motion, while ultrasound, CT-scan and MRI are restricted to in-clinic snapshots. Here we propose a novel radiomyography (RMG) for continuous muscle actuation sensing that can be wearable and touchless, capturing both superficial and deep muscle groups. We verified RMG experimentally by a forearm wearable sensor for detailed hand gesture recognition. We first converted the radio sensing outputs to the time-frequency spectrogram, and then employed the vision transformer (ViT) deep learning network as the classification model, which can recognize 23 gestures with an average accuracy up to 99% on 8 subjects. By transfer learning, high adaptivity to user difference and sensor variation were achieved at an average accuracy up to 97%. We further demonstrated RMG to monitor eye and leg muscles and achieved high accuracy for eye movement and body postures tracking. RMG can be used with synchronous EMG to derive stimulation-actuation waveforms for many future applications in kinesiology, physiotherapy, rehabilitation, and human-machine interface.|
|**2022-10-31**|**SurfMyoAiR: A surface Electromyography based framework for Airwriting Recognition**|Ayush Tripathi et.al.|[2210.17185v1](http://arxiv.org/abs/2210.17185v1)|null|Airwriting Recognition is the task of identifying letters written in free space with finger movement. Electromyography (EMG) is a technique used to record electrical activity during muscle contraction and relaxation as a result of movement and is widely used for gesture recognition. Most of the current research in gesture recognition is focused on identifying static gestures. However, dynamic gestures are natural and user-friendly for being used as alternate input methods in Human-Computer Interaction applications. Airwriting recognition using EMG signals recorded from forearm muscles is therefore a viable solution. Since the user does not need to learn any new gestures and a large range of words can be formed by concatenating these letters, it is generalizable to a wider population. There has been limited work in recognition of airwriting using EMG signals and forms the core idea of the current work. The SurfMyoAiR dataset comprising of EMG signals recorded during writing English uppercase alphabets is constructed. Several different time-domain features to construct EMG envelope and two different time-frequency image representations: Short-Time Fourier Transform and Continuous Wavelet Transform were explored to form the input to a deep learning model for airwriting recognition. Several different deep learning architectures were exploited for this task. Additionally, the effect of various parameters such as signal length, window length and interpolation techniques on the recognition performance is comprehensively explored. The best-achieved accuracy was 78.50% and 62.19% in user-dependent and independent scenarios respectively by using Short-Time Fourier Transform in conjunction with a 2D Convolutional Neural Network based classifier. Airwriting has great potential as a user-friendly modality to be used as an alternate input method in Human-Computer Interaction applications.|
|**2022-10-27**|**Light-weighted CNN-Attention based architecture for Hand Gesture Recognition via ElectroMyography**|Soheil Zabihi et.al.|[2210.15119v1](http://arxiv.org/abs/2210.15119v1)|null|Advancements in Biological Signal Processing (BSP) and Machine-Learning (ML) models have paved the path for development of novel immersive Human-Machine Interfaces (HMI). In this context, there has been a surge of significant interest in Hand Gesture Recognition (HGR) utilizing Surface-Electromyogram (sEMG) signals. This is due to its unique potential for decoding wearable data to interpret human intent for immersion in Mixed Reality (MR) environments. To achieve the highest possible accuracy, complicated and heavy-weighted Deep Neural Networks (DNNs) are typically developed, which restricts their practical application in low-power and resource-constrained wearable systems. In this work, we propose a light-weighted hybrid architecture (HDCAM) based on Convolutional Neural Network (CNN) and attention mechanism to effectively extract local and global representations of the input. The proposed HDCAM model with 58,441 parameters reached a new state-of-the-art (SOTA) performance with 82.91% and 81.28% accuracy on window sizes of 300 ms and 200 ms for classifying 17 hand gestures. The number of parameters to train the proposed HDCAM architecture is 18.87 times less than its previous SOTA counterpart.|
|**2022-10-24**|**ECG Artifact Removal from Single-Channel Surface EMG Using Fully Convolutional Networks**|Kuan-Chen Wang et.al.|[2210.13271v1](http://arxiv.org/abs/2210.13271v1)|[link](https://github.com/eric-wang135/ecg-removal-from-semg-by-fcn)|Electrocardiogram (ECG) artifact contamination often occurs in surface electromyography (sEMG) applications when the measured muscles are in proximity to the heart. Previous studies have developed and proposed various methods, such as high-pass filtering, template subtraction and so forth. However, these methods remain limited by the requirement of reference signals and distortion of original sEMG. This study proposed a novel denoising method to eliminate ECG artifacts from the single-channel sEMG signals using fully convolutional networks (FCN). The proposed method adopts a denoise autoencoder structure and powerful nonlinear mapping capability of neural networks for sEMG denoising. We compared the proposed approach with conventional approaches, including high-pass filters and template subtraction, on open datasets called the Non-Invasive Adaptive Prosthetics database and MIT-BIH normal sinus rhythm database. The experimental results demonstrate that the FCN outperforms conventional methods in sEMG reconstruction quality under a wide range of signal-to-noise ratio inputs.|

## heart rate

### heart rate
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Classical simulations of noisy variational quantum circuits**|Enrico Fontana et.al.|[2306.05400v1](http://arxiv.org/abs/2306.05400v1)|null|Noise detrimentally affects quantum computations so that they not only become less accurate but also easier to simulate classically as systems scale up. We construct a classical simulation algorithm, LOWESA (low weight efficient simulation algorithm), for estimating expectation values of noisy parameterised quantum circuits. It combines previous results on spectral analysis of parameterised circuits with Pauli back-propagation and recent ideas for simulations of noisy random circuits. We show, under some conditions on the circuits and mild assumptions on the noise, that LOWESA gives an efficient, polynomial algorithm in the number of qubits (and depth), with approximation error that vanishes exponentially in the physical error rate and a controllable cut-off parameter. We also discuss the practical limitations of the method for circuit classes with correlated parameters and its scaling with decreasing error rates.|
|**2023-06-08**|**HQ-50K: A Large-scale, High-quality Dataset for Image Restoration**|Qinhong Yang et.al.|[2306.05390v1](http://arxiv.org/abs/2306.05390v1)|[link](https://github.com/littleyaang/hq-50k)|This paper introduces a new large-scale image restoration dataset, called HQ-50K, which contains 50,000 high-quality images with rich texture details and semantic diversity. We analyze existing image restoration datasets from five different perspectives, including data scale, resolution, compression rates, texture details, and semantic coverage. However, we find that all of these datasets are deficient in some aspects. In contrast, HQ-50K considers all of these five aspects during the data curation process and meets all requirements. We also present a new Degradation-Aware Mixture of Expert (DAMoE) model, which enables a single model to handle multiple corruption types and unknown levels. Our extensive experiments demonstrate that HQ-50K consistently improves the performance on various image restoration tasks, such as super-resolution, denoising, dejpeg, and deraining. Furthermore, our proposed DAMoE, trained on our \dataset, outperforms existing state-of-the-art unified models designed for multiple restoration tasks and levels. The dataset and code are available at \url{https://github.com/littleYaang/HQ-50K}.|
|**2023-06-08**|**Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across Age**|Daniela Teodorescu et.al.|[2306.05387v1](http://arxiv.org/abs/2306.05387v1)|null|Emerging psychopathology studies are showing that patterns of changes in emotional state -- emotion dynamics -- are associated with overall well-being and mental health. More recently, there has been some work in tracking emotion dynamics through one's utterances, allowing for data to be collected on a larger scale across time and people. However, several questions about how emotion dynamics change with age, especially in children, and when determined through children's writing, remain unanswered. In this work, we use both a lexicon and a machine learning based approach to quantify characteristics of emotion dynamics determined from poems written by children of various ages. We show that both approaches point to similar trends: consistent increasing intensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and dominance) with age and a consistent decreasing valence with age. We also find increasing emotional variability, rise rates (i.e., emotional reactivity), and recovery rates (i.e., emotional regulation) with age. These results act as a useful baselines for further research in how patterns of emotions expressed by children change with age, and their association with mental health.|
|**2023-06-08**|**Rate Forecaster based Energy Aware Band Assignment in Multiband Networks**|Brijesh Soni et.al.|[2306.05369v1](http://arxiv.org/abs/2306.05369v1)|null|The high frequency communication bands (mmWave and sub-THz) promise tremendous data rates, however, they also have very high power consumption which is particularly significant for battery-power-limited user-equipment (UE). In this context, we design an energy aware band assignment system which reduces the power consumption while also achieving a target sum rate of M in T time-slots. We do this by using 1) Rate forecaster(s); 2) Channel forecaster(s) which forecasts T direct multistep ahead using a stacked (long short term memory) LSTM architecture. We propose an iterative rate updating algorithm which updates the target rate based on current rate and future predicted rates in a frame. The proposed approach is validated on the publicly available `DeepMIMO' dataset. Research findings shows that the rate forecaster based approach performs better than the channel forecaster. Furthermore, LSTM based predictions outperforms well celebrated Transformer predictions in terms of NRMSE and NMAE. Research findings reveals that the power consumption with this approach is ~ 300 mW lower compared to a greedy band assignment at a 1.5Gb/s target rate.|
|**2023-06-08**|**Ordinal Potential-based Player Rating**|Nelson Vadori et.al.|[2306.05366v1](http://arxiv.org/abs/2306.05366v1)|null|A two-player symmetric zero-sum game is transitive if for any pure strategies $x$, $y$, $z$, if $x$ is better than $y$, and $y$ is better than $z$, then $x$ is better than $z$. It was recently observed that the Elo rating fails at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. Our first contribution is to show that the Elo rating actually does preserve transitivity when computed in the right space. Precisely, using a suitable invertible mapping $\varphi$, we first apply $\varphi$ to the game, then compute Elo ratings, then go back to the original space by applying $\varphi^{-1}$. We provide a characterization of transitive games as a weak variant of ordinal potential games with additively separable potential functions. Leveraging this insight, we introduce the concept of transitivity order, the minimum number of invertible mappings required to transform the payoff of a transitive game into (differences of) its potential function. The transitivity order is a tool to classify transitive games, with Elo games being an example of transitive games of order one. Most real-world games have both transitive and non-transitive (cyclic) components, and we use our analysis of transitivity to extract the transitive (potential) component of an arbitrary game. We link transitivity to the known concept of sign-rank: transitive games have sign-rank two; arbitrary games may have higher sign-rank. Using a neural network-based architecture, we learn a decomposition of an arbitrary game into transitive and cyclic components that prioritises capturing the sign pattern of the game. In particular, a transitive game always has just one component in its decomposition, the potential component. We provide a comprehensive evaluation of our methodology using both toy examples and empirical data from real-world games.|
|**2023-06-08**|**A Data-Driven Approach to Positioning Grab Bars in the Sagittal Plane for Elderly Persons**|Roberto Bolli Jr. et.al.|[2306.05343v1](http://arxiv.org/abs/2306.05343v1)|null|The placement of grab bars for elderly users is based largely on ADA building codes and does not reflect the large differences in height, mobility, and muscle power between individual persons. The goal of this study is to see if there are any correlations between an elderly user's preferred handlebar pose and various demographic indicators, self-rated mobility for tasks requiring postural change, and biomechanical markers. For simplicity, we consider only the case where the handlebar is positioned directly in front of the user, as this confines the relevant body kinematics to a 2D sagittal plane. Previous eldercare devices have been constructed to position a handlebar in various poses in space. Our work augments these devices and adds to the body of knowledge by assessing how the handlebar should be positioned based on data on actual elderly people instead of simulations.|
|**2023-06-08**|**Spontaneous Self-Constraint in Active Nematic Flows**|Louise C. Head et.al.|[2306.05328v1](http://arxiv.org/abs/2306.05328v1)|null|Active processes drive and guide biological dynamics across scales -- from subcellular cytoskeletal remodelling, through tissue development in embryogenesis, to population-level bacterial colonies expansion. In each of these, biological functionality requires collective flows to occur while self-organized structures are protected; however, the mechanisms by which active flows can spontaneously constrain their dynamics to preserve structure have not previously been explained. By studying collective flows and defect dynamics in active nematic films, we demonstrate the existence of a self-constraint -- a two-way, spontaneously arising relationship between activity-driven isosurfaces of flow boundaries and mesoscale nematic structures. Our results show that self-motile defects are tightly constrained to viscometric surfaces -- contours along which vorticity and strain-rate balance. This in turn reveals that self-motile defects break mirror symmetry when they move along a single viscometric surface, in contrast with expectations. This is explained by an interdependence between viscometric surfaces and bend walls -- elongated narrow kinks in the orientation field. Although we focus on extensile nematic films, numerical results show the constraint holds whenever activity leads to motile half-charge defects. This mesoscale cross-field self-constraint offers a new framework for tackling complex 3D active turbulence, designing dynamic control into biomimetic materials, and understanding how biological systems can employ active stress for dynamic self-organization.|
|**2023-06-08**|**Perching by hugging: an initial feasibility study**|William Stewart et.al.|[2306.05324v1](http://arxiv.org/abs/2306.05324v1)|null|Current UAVs capable of perching require added structure and mechanisms to accomplish this. These take the form of hooks, claws, needles, etc which add weight and usually drag. We propose in this paper the dual use of structures already on the vehicle to enable perching, thus reducing the weight and drag cost associated with perching UAVs. We propose a wing design capable of passively wrapping around a vertical pole to perch. We experimentally investigate the feasibility of the design, presenting results on minimum required perching speeds as well as the effect of weight distribution on the success rate of the wing wrapping. Finally, we comment on design requirements for holding onto the pole based on our findings.|
|**2023-06-08**|**Large-scale adaptive multiple testing for sequential data controlling false discovery and nondiscovery rates**|Rahul Roy et.al.|[2306.05315v1](http://arxiv.org/abs/2306.05315v1)|null|In modern scientific experiments, we frequently encounter data that have large dimensions, and in some experiments, such high dimensional data arrive sequentially rather than full data being available all at a time. We develop multiple testing procedures with simultaneous control of false discovery and nondiscovery rates when $m$-variate data vectors $\mathbf{X}_1, \mathbf{X}_2, \dots$ are observed sequentially or in groups and each coordinate of these vectors leads to a hypothesis testing. Existing multiple testing methods for sequential data uses fixed stopping boundaries that do not depend on sample size, and hence, are quite conservative when the number of hypotheses $m$ is large. We propose sequential tests based on adaptive stopping boundaries that ensure shrinkage of the continue sampling region as the sample size increases. Under minimal assumptions on the data sequence, we first develop a test based on an oracle test statistic such that both false discovery rate (FDR) and false nondiscovery rate (FNR) are nearly equal to some prefixed levels with strong control. Under a two-group mixture model assumption, we propose a data-driven stopping and decision rule based on local false discovery rate statistic that mimics the oracle rule and guarantees simultaneous control of FDR and FNR asymptotically as $m$ tends to infinity. Both the oracle and the data-driven stopping times are shown to be finite (i.e., proper) with probability 1 for all finite $m$ and converge to a finite constant as $m$ grows to infinity. Further, we compare the data-driven test with the existing gap rule proposed in He and Bartroff (2021) and show that the ratio of the expected sample sizes of our method and the gap rule tends to zero as $m$ goes to infinity. Extensive analysis of simulated datasets as well as some real datasets illustrate the superiority of the proposed tests over some existing methods.|
|**2023-06-08**|**Mode-locked laser in nanophotonic lithium niobate**|Qiushi Guo et.al.|[2306.05314v1](http://arxiv.org/abs/2306.05314v1)|null|Mode-locked lasers (MLLs) have enabled ultrafast sciences and technologies by generating ultrashort pulses with peak powers substantially exceeding their average powers. Recently, tremendous efforts have been focused on realizing integrated MLLs not only to address the challenges associated with their size and power demand, but also to enable transforming the ultrafast technologies into nanophotonic chips, and ultimately to unlock their potential for a plethora of applications. However, till now the prospect of integrated MLLs driving ultrafast nanophotonic circuits has remained elusive because of their typically low peak powers, lack of controllability, and challenges with integration with appropriate nanophotonic platforms. Here, we overcome these limitations by demonstrating an electrically-pumped actively MLL in nanophotonic lithium niobate based on its hybrid integration with a III-V semiconductor optical amplifier. Our MLL generates $\sim$4.8 ps optical pulses around 1065 nm at a repetition rate of $\sim$10 GHz, with pulse energy exceeding 2.6 pJ and a high peak power beyond 0.5 W. We show that both the repetition rate and the carrier-envelope-offset of the resulting frequency comb can be flexibly controlled in a wide range using the RF driving frequency and the pump current, paving the way for fully-stabilized on-chip frequency combs in nanophotonics. Our work marks an important step toward fully-integrated nonlinear and ultrafast photonic systems in nanophotonic lithium niobate.|
|**2023-06-08**|**Chiral EFT calculation of neutrino reactions in warm neutron-rich matter**|Eunkyoung Shin et.al.|[2306.05280v1](http://arxiv.org/abs/2306.05280v1)|null|Neutrino scattering and absorption rates of relevance to supernovae and neutron star mergers are obtained from nuclear matter dynamical structure functions that encode many-body effects from nuclear mean fields and correlations. We employ nuclear interactions from chiral effective field theory to calculate the density, spin, isospin, and spin-isospin response functions of warm beta-equilibrium nuclear matter. We include corrections to the single-particle energies in the mean field approximation as well as vertex corrections resummed in the random phase approximation (RPA), including, for the first time, both direct and exchange diagrams. We find that correlations included through the RPA redistribute the strength of the response to higher energy for neutrino absorption and lower energy for antineutrino absorption. This tends to suppress the absorption rate of electron neutrinos across all relevant energy scales. In contrast, the inclusion of RPA correlations enhances the electron antineutrino absorption rate at low energy and supresses the rate at high energy. These effects are especially important at high-density and in the vicinity of the neutrino decoupling region. Implications for heavy element nucleosynthesis, electromagnetic signatures of compact object mergers, supernova dynamics, and neutrino detection from galactic supernovae are discussed briefly.|
|**2023-06-08**|**Language-specific Acoustic Boundary Learning for Mandarin-English Code-switching Speech Recognition**|Zhiyun Fan et.al.|[2306.05279v1](http://arxiv.org/abs/2306.05279v1)|null|Code-switching speech recognition (CSSR) transcribes speech that switches between multiple languages or dialects within a single sentence. The main challenge in this task is that different languages often have similar pronunciations, making it difficult for models to distinguish between them. In this paper, we propose a method for solving the CSSR task from the perspective of language-specific acoustic boundary learning. We introduce language-specific weight estimators (LSWE) to model acoustic boundary learning in different languages separately. Additionally, a non-autoregressive (NAR) decoder and a language change detection (LCD) module are employed to assist in training. Evaluated on the SEAME corpus, our method achieves a state-of-the-art mixed error rate (MER) of 16.29% and 22.81% on the test_man and test_sge sets. We also demonstrate the effectiveness of our method on a 9000-hour in-house meeting code-switching dataset, where our method achieves a relatively 7.9% MER reduction.|
|**2023-06-08**|**Large deviations of return times and related entropy estimators on shift spaces**|Noé Cuneo et.al.|[2306.05277v1](http://arxiv.org/abs/2306.05277v1)|null|We prove the large deviation principle for several entropy and cross entropy estimators based on return times and waiting times on shift spaces over finite alphabets. In the case of standard return times, we obtain a nonconvex large-deviation rate function. We consider shift-invariant probability measures satisfying some decoupling conditions which imply no form of mixing nor ergodicity. We establish precise relations between the rate functions of the different estimators, and between these rate functions and the corresponding pressures, one of which is the R\'enyi entropy function. The results apply in particular to irreducible Markov chains, equilibrium measures for Bowen-regular potentials, g-measures, invariant Gibbs states for summable interactions in statistical mechanics, and also to probability measures that may be far from Gibbsian, including some hidden Markov models and repeated quantum measurement processes.|
|**2023-06-08**|**Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models**|Tianzhe Chu et.al.|[2306.05272v1](http://arxiv.org/abs/2306.05272v1)|[link](https://github.com/leslietrue/cpp)|The advent of large pre-trained models has brought about a paradigm shift in both visual representation learning and natural language processing. However, clustering unlabeled images, as a fundamental and classic machine learning problem, still lacks effective solution, particularly for large-scale datasets. In this paper, we propose a novel image clustering pipeline that leverages the powerful feature representation of large pre-trained models such as CLIP and cluster images effectively and efficiently at scale. We show that the pre-trained features are significantly more structured by further optimizing the rate reduction objective. The resulting features may significantly improve the clustering accuracy, e.g., from 57\% to 66\% on ImageNet-1k. Furthermore, by leveraging CLIP's image-text binding, we show how the new clustering method leads to a simple yet effective self-labeling algorithm that successfully works on unlabeled large datasets such as MS-COCO and LAION-Aesthetics. We will release the code in https://github.com/LeslieTrue/CPP.|
|**2023-06-08**|**Toward more accurate and generalizable brain deformation estimators for traumatic brain injury detection with unsupervised domain adaptation**|Xianghao Zhan et.al.|[2306.05255v1](http://arxiv.org/abs/2306.05255v1)|[link](https://github.com/xzhan96-stf/drca-mlhm)|Machine learning head models (MLHMs) are developed to estimate brain deformation for early detection of traumatic brain injury (TBI). However, the overfitting to simulated impacts and the lack of generalizability caused by distributional shift of different head impact datasets hinders the broad clinical applications of current MLHMs. We propose brain deformation estimators that integrates unsupervised domain adaptation with a deep neural network to predict whole-brain maximum principal strain (MPS) and MPS rate (MPSR). With 12,780 simulated head impacts, we performed unsupervised domain adaptation on on-field head impacts from 302 college football (CF) impacts and 457 mixed martial arts (MMA) impacts using domain regularized component analysis (DRCA) and cycle-GAN-based methods. The new model improved the MPS/MPSR estimation accuracy, with the DRCA method significantly outperforming other domain adaptation methods in prediction accuracy (p<0.001): MPS RMSE: 0.027 (CF) and 0.037 (MMA); MPSR RMSE: 7.159 (CF) and 13.022 (MMA). On another two hold-out test sets with 195 college football impacts and 260 boxing impacts, the DRCA model significantly outperformed the baseline model without domain adaptation in MPS and MPSR estimation accuracy (p<0.001). The DRCA domain adaptation reduces the MPS/MPSR estimation error to be well below TBI thresholds, enabling accurate brain deformation estimation to detect TBI in future clinical applications.|
|**2023-06-08**|**Matching Latent Encoding for Audio-Text based Keyword Spotting**|Kumari Nishu et.al.|[2306.05245v1](http://arxiv.org/abs/2306.05245v1)|null|Using audio and text embeddings jointly for Keyword Spotting (KWS) has shown high-quality results, but the key challenge of how to semantically align two embeddings for multi-word keywords of different sequence lengths remains largely unsolved. In this paper, we propose an audio-text-based end-to-end model architecture for flexible keyword spotting (KWS), which builds upon learned audio and text embeddings. Our architecture uses a novel dynamic programming-based algorithm, Dynamic Sequence Partitioning (DSP), to optimally partition the audio sequence into the same length as the word-based text sequence using the monotonic alignment of spoken content. Our proposed model consists of an encoder block to get audio and text embeddings, a projector block to project individual embeddings to a common latent space, and an audio-text aligner containing a novel DSP algorithm, which aligns the audio and text embeddings to determine if the spoken content is the same as the text. Experimental results show that our DSP is more effective than other partitioning schemes, and the proposed architecture outperformed the state-of-the-art results on the public dataset in terms of Area Under the ROC Curve (AUC) and Equal-Error-Rate (EER) by 14.4 % and 28.9%, respectively.|
|**2023-06-08**|**Precision Measurements of $D_s^+ \to ηe^+ ν_e$ and $D_s^+ \to η^\prime e^+ ν_e$**|BESIII Collaboration et.al.|[2306.05194v1](http://arxiv.org/abs/2306.05194v1)|null|Precision measurements of the semileptonic decays $D_s^+ \to \eta e^+ \nu_e$ and $D_s^+ \to \eta^\prime e^+ \nu_e$ are performed using 7.33\,fb$^{-1}$ of $e^+e^-$ collision data collected at center-of-mass energies between 4.128 and 4.226 GeV with the BESIII detector. The branching fractions obtained are $\mathcal{B}(D_s^+ \to \eta e^{+} \nu_e)$ = $(2.251\pm0.039_{\rm stat.}\pm 0.051_{\rm syst.})\%$ and $\mathcal{B}(D_s^+ \to \eta^{\prime} e^{+} \nu_e)$ = $(0.810\pm0.038_{\rm stat.}\pm 0.024_{\rm syst.})\%$. Combining these results with the $\mathcal{B}(D^+\to\eta e^+ \nu_e)$ and $\mathcal{B}(D^+\to\eta^\prime e^+ \nu_e)$ obtained from previous BESIII measurements, the $\eta-\eta^\prime$ mixing angle in the quark flavor basis is determined to be $\phi_{\rm P} = (40.0\pm2.0_{\rm stat.}\pm0.6_{\rm syst.})^\circ$. Moreover, from the fits to the partial decay rates of $D_s^+ \to \eta e^+ \nu_e$ and $D_s^+ \to \eta^\prime e^+ \nu_e$, the products of the hadronic transition form factors $f_+^{\eta^{(\prime)}}(0)$ and the modulus of the $c\to s$ Cabibbo-Kobayashi-Maskawa matrix element $|V_{cs}|$ are determined by using different hadronic transition form factor parametrizations. Based on the two-parameter series expansion, the products $f^\eta_+(0)|V_{cs}| = 0.4553\pm0.0071_{\rm stat}\pm0.0061_{\rm syst}$ and $f^{\eta^\prime}_+(0)|V_{cs}| = 0.529\pm0.024_{\rm stat}\pm0.008_{\rm syst}$ are extracted. All results determined in this work supersede those measured in the previous BESIII analyses based on the 3.19 fb$^{-1}$ subsample of data at 4.178 GeV.|
|**2023-06-08**|**Bayesian Inference for $k$-Monotone Densities with Applications to Multiple Testing**|Kang Wang et.al.|[2306.05173v1](http://arxiv.org/abs/2306.05173v1)|null|Shape restriction, like monotonicity or convexity, imposed on a function of interest, such as a regression or density function, allows for its estimation without smoothness assumptions. The concept of $k$-monotonicity encompasses a family of shape restrictions, including decreasing and convex decreasing as special cases corresponding to $k=1$ and $k=2$. We consider Bayesian approaches to estimate a $k$-monotone density. By utilizing a kernel mixture representation and putting a Dirichlet process or a finite mixture prior on the mixing distribution, we show that the posterior contraction rate in the Hellinger distance is $(n/\log n)^{- k/(2k + 1)}$ for a $k$-monotone density, which is minimax optimal up to a polylogarithmic factor. When the true $k$-monotone density is a finite $J_0$-component mixture of the kernel, the contraction rate improves to the nearly parametric rate $\sqrt{(J_0 \log n)/n}$. Moreover, by putting a prior on $k$, we show that the same rates hold even when the best value of $k$ is unknown. A specific application in modeling the density of $p$-values in a large-scale multiple testing problem is considered. Simulation studies are conducted to evaluate the performance of the proposed method.|
|**2023-06-08**|**FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems**|Herbert Woisetschläger et.al.|[2306.05172v1](http://arxiv.org/abs/2306.05172v1)|null|Federated Machine Learning (FL) has received considerable attention in recent years. FL benchmarks are predominantly explored in either simulated systems or data center environments, neglecting the setups of real-world systems, which are often closely linked to edge computing. We close this research gap by introducing FLEdge, a benchmark targeting FL workloads in edge computing systems. We systematically study hardware heterogeneity, energy efficiency during training, and the effect of various differential privacy levels on training in FL systems. To make this benchmark applicable to real-world scenarios, we evaluate the impact of client dropouts on state-of-the-art FL strategies with failure rates as high as 50%. FLEdge provides new insights, such as that training state-of-the-art FL workloads on older GPU-accelerated embedded devices is up to 3x more energy efficient than on modern server-grade GPUs.|
|**2023-06-08**|**Bayesian Optimization of Expensive Nested Grey-Box Functions**|Wenjie Xu et.al.|[2306.05150v1](http://arxiv.org/abs/2306.05150v1)|null|We consider the problem of optimizing a grey-box objective function, i.e., nested function composed of both black-box and white-box functions. A general formulation for such grey-box problems is given, which covers the existing grey-box optimization formulations as special cases. We then design an optimism-driven algorithm to solve it. Under certain regularity assumptions, our algorithm achieves similar regret bound as that for the standard black-box Bayesian optimization algorithm, up to a constant multiplicative term depending on the Lipschitz constants of the functions considered. We further extend our method to the constrained case and discuss several special cases. For the commonly used kernel functions, the regret bounds allow us to derive a convergence rate to the optimal solution. Experimental results show that our grey-box optimization method empirically improves the speed of finding the global optimal solution significantly, as compared to the standard black-box optimization algorithm.|
|**2023-06-08**|**Orthogonal Sampling based Broad-Band Signal Generation with Low-Bandwidth Electronics**|Mohamed I. Hosni et.al.|[2306.05125v1](http://arxiv.org/abs/2306.05125v1)|null|High-bandwidth signals are needed in many applications like radar, sensing, measurement and communications. Especially in optical networks, the sampling rate and analog bandwidth of digital-to-analog converters (DACs) is a bottleneck for further increasing data rates. To circumvent the sampling rate and bandwidth problem of electronic DACs, we demonstrate the generation of wide-band signals with low-bandwidth electronics. This generation is based on orthogonal sampling with sinc-pulse sequences in N parallel branches. The method not only reduces the sampling rate and bandwidth, at the same time the effective number of bits (ENOB) is improved, dramatically reducing the requirements on the electronic signal processing. In proof of concept experiments the generation of analog signals, as well as Nyquist shaped and normal data will be shown. In simulations we investigate the performance of 60 GHz data generation by 20 and 12 GHz electronics. The method can easily be integrated together with already existing electronic DAC designs and would be of great interest for all high-bandwidth applications.|
|**2023-06-08**|**Stabilizing Discontinuous Galerkin Methods Using Dafermos' Entropy Rate Criterion: II -- Systems of Conservation Laws and Entropy Inequality Predictors**|Simon-Christian Klein et.al.|[2306.05124v1](http://arxiv.org/abs/2306.05124v1)|null|A novel approach for the stabilization of the Discontinuous Galerkin method based on the Dafermos entropy rate crition is presented. First, estimates for the maximal possible entropy dissipation rate of a weak solution are derived. Second, families of conservative Hilbert-Schmidt operators are identified to dissipate entropy. Steering these operators using the bounds on the entropy dissipation results in high-order accurate shock-capturing DG schemes for the Euler equations, satisfying the entropy rate criterion and an entropy inequality.|
|**2023-06-08**|**FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving Federated Learning with Byzantine Users**|Yogachandran Rahulamathavan et.al.|[2306.05112v1](http://arxiv.org/abs/2306.05112v1)|null|The federated learning (FL) technique was initially developed to mitigate data privacy issues that can arise in the traditional machine learning paradigm. While FL ensures that a user's data always remain with the user, the gradients of the locally trained models must be communicated with the centralized server to build the global model. This results in privacy leakage, where the server can infer private information of the users' data from the shared gradients. To mitigate this flaw, the next-generation FL architectures proposed encryption and anonymization techniques to protect the model updates from the server. However, this approach creates other challenges, such as a malicious user might sabotage the global model by sharing false gradients. Since the gradients are encrypted, the server is unable to identify and eliminate rogue users which would protect the global model. Therefore, to mitigate both attacks, this paper proposes a novel fully homomorphic encryption (FHE) based scheme suitable for FL. We modify the one-to-one single-key Cheon-Kim-Kim-Song (CKKS)-based FHE scheme into a distributed multi-key additive homomorphic encryption scheme that supports model aggregation in FL. We employ a novel aggregation scheme within the encrypted domain, utilizing users' non-poisoning rates, to effectively address data poisoning attacks while ensuring privacy is preserved by the proposed encryption scheme. Rigorous security, privacy, convergence, and experimental analyses have been provided to show that FheFL is novel, secure, and private, and achieves comparable accuracy at reasonable computational cost.|
|**2023-06-08**|**Re-aligning Shadow Models can Improve White-box Membership Inference Attacks**|Ana-Maria Cretu et.al.|[2306.05093v1](http://arxiv.org/abs/2306.05093v1)|null|Machine learning models have been shown to leak sensitive information about their training datasets. As models are being increasingly used, on devices, to automate tasks and power new applications, there have been concerns that such white-box access to its parameters, as opposed to the black-box setting which only provides query access to the model, increases the attack surface. Directly extending the shadow modelling technique from the black-box to the white-box setting has been shown, in general, not to perform better than black-box only attacks. A key reason is misalignment, a known characteristic of deep neural networks. We here present the first systematic analysis of the causes of misalignment in shadow models and show the use of a different weight initialisation to be the main cause of shadow model misalignment. Second, we extend several re-alignment techniques, previously developed in the model fusion literature, to the shadow modelling context, where the goal is to re-align the layers of a shadow model to those of the target model.We show re-alignment techniques to significantly reduce the measured misalignment between the target and shadow models. Finally, we perform a comprehensive evaluation of white-box membership inference attacks (MIA). Our analysis reveals that (1) MIAs suffer from misalignment between shadow models, but that (2) re-aligning the shadow models improves, sometimes significantly, MIA performance. On the CIFAR10 dataset with a false positive rate of 1\%, white-box MIA using re-aligned shadow models improves the true positive rate by 4.5\%.Taken together, our results highlight that on-device deployment increase the attack surface and that the newly available information can be used by an attacker.|
|**2023-06-08**|**Selenium and the role of defects for photovoltaic applications**|Hadeel Moustafa et.al.|[2306.05092v1](http://arxiv.org/abs/2306.05092v1)|null|We present first principles calculations of the electronic properties of trigonal selenium with emphasis on photovoltaic applications. The band gap and optical absorption spectrum of pristine selenium is calculated from many-body perturbation theory yielding excellent agreement with experiments. We then investigate the role of intrinsic as well as extrinsic defects and estimate the equilibrium concentrations resulting from realistic synthesis conditions. The intrinsic defects are dominated by vacancies, which act as acceptor levels and implies $p$-doping in agreement with previous predictions and measurements, and we show that these do not give rise to significant non-radiative recombination. The charge balance remains dominated by vacancies when extrinsic defects are included, but these may give rise to sizable non-radiative recombination rates, which could severely limit the performance of selenium based solar cells. Our results thus imply that the pollution by external elements is a decisive factor for the photovoltaic efficiency, which will be of crucial importance when considering synthesis conditions for any type of device engineering.|
|**2023-06-08**|**Vanishing of long time average p-enstrophy dissipation rate in the inviscid limit of the 2D damped Navier-Stokes equations**|Raphael Wagner et.al.|[2306.05081v1](http://arxiv.org/abs/2306.05081v1)|null|In 2007, Constantin and Ramos proved a result on the vanishing long time average enstrophy dissipation rate in the inviscid limit of the 2D damped Navier-Stokes equations. In this work, we prove a generalization of this for the p-enstrophy, sequences of distributions of initial data and sequences of strongly converging right-hand sides. We simplify their approach by working with invariant measures on the global attractors which can be characterized via bounded complete solution trajectories. Then, working on the level of trajectories allows us to directly employ some recent results on strong convergence of the vorticity in the inviscid limit.|
|**2023-06-08**|**Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition**|Luca Arrotta et.al.|[2306.05058v1](http://arxiv.org/abs/2306.05058v1)|null|Deep Learning models are a standard solution for sensor-based Human Activity Recognition (HAR), but their deployment is often limited by labeled data scarcity and models' opacity. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate these issues by infusing knowledge about context information into HAR deep learning classifiers. However, existing NeSy methods for context-aware HAR require computationally expensive symbolic reasoners during classification, making them less suitable for deployment on resource-constrained devices (e.g., mobile devices). Additionally, NeSy approaches for context-aware HAR have never been evaluated on in-the-wild datasets, and their generalization capabilities in real-world scenarios are questionable. In this work, we propose a novel approach based on a semantic loss function that infuses knowledge constraints in the HAR model during the training phase, avoiding symbolic reasoning during classification. Our results on scripted and in-the-wild datasets show the impact of different semantic loss functions in outperforming a purely data-driven model. We also compare our solution with existing NeSy methods and analyze each approach's strengths and weaknesses. Our semantic loss remains the only NeSy solution that can be deployed as a single DNN without the need for symbolic reasoning modules, reaching recognition rates close (and better in some cases) to existing approaches.|
|**2023-06-08**|**Impact of pore-scale chaotic mixing on Darcy-scale reaction rates**|Satoshi Izumoto et.al.|[2306.05018v1](http://arxiv.org/abs/2306.05018v1)|null|Prediction of reactive transport in porous media remains challenging when pore scale incomplete mixing is at play. Previous experimental studies investigated chemical reactions in porous media by visualizing reaction product or reactants mostly in uniform flow. However, the local reaction rate, which is necessary to infer mechanisms of reaction in pore space, could not be obtained without considering transport of reaction products and reactants. Thus, the interpretation remained elusive. We visualized the reaction rate field using chemiluminescnece within index-matched 3D porous media under zero acceleration and constant acceleration flow fields to investigate how pore scale chaotic mixing and Darcy scale fluid acceleration rectify reactive transport. We found that the reaction rate kept increasing from upstream to downstream in constant acceleration field, whereas it increased only at the upstream zone in zero acceleration field. The ratio of dispersion rate and size of the mixing interface determined such an effect of acceleration. Moreover, the experimental results showed stronger dependency of reaction rate on velocity compared to the numerical simulations that assume complete mixing in pore space. To explain this, we suggested the mechanistic model that includes the pore scale folding of lamellae due to chaotic mixing and the pore scale concentration gradients against compression. Such a pore scale mechanism was consistent with the experimentally observed change in reaction rate over the space. These results give new insights on underlying mechanisms of reactive transport in porous media.|
|**2023-06-08**|**Progression Cognition Reinforcement Learning with Prioritized Experience for Multi-Vehicle Pursuit**|Xinhang Li et.al.|[2306.05016v1](http://arxiv.org/abs/2306.05016v1)|[link](https://github.com/bupt-antlab/pepcrl-mvp)|Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing suspects is important but very challenging due to its mission and safety critical nature. While multi-agent reinforcement learning (MARL) algorithms have been proposed for MVP problem in structured grid-pattern roads, the existing algorithms use randomly training samples in centralized learning, which leads to homogeneous agents showing low collaboration performance. For the more challenging problem of pursuing multiple evading vehicles, these algorithms typically select a fixed target evading vehicle for pursuing vehicles without considering dynamic traffic situation, which significantly reduces pursuing success rate. To address the above problems, this paper proposes a Progression Cognition Reinforcement Learning with Prioritized Experience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic scenes. PEPCRL-MVP uses a prioritization network to assess the transitions in the global experience replay buffer according to the parameters of each MARL agent. With the personalized and prioritized experience set selected via the prioritization network, diversity is introduced to the learning process of MARL, which can improve collaboration and task related performance. Furthermore, PEPCRL-MVP employs an attention module to extract critical features from complex urban traffic environments. These features are used to develop progression cognition method to adaptively group pursuing vehicles. Each group efficiently target one evading vehicle in dynamic driving environments. Extensive experiments conducted with a simulator over unstructured roads of an urban area show that PEPCRL-MVP is superior to other state-of-the-art methods. Specifically, PEPCRL-MVP improves pursuing efficiency by 3.95% over TD3-DMAP and its success rate is 34.78% higher than that of MADDPG. Codes are open sourced.|
|**2023-06-08**|**Dense gas and star formation in the Outer Milky Way**|Jonathan Braine et.al.|[2306.05013v1](http://arxiv.org/abs/2306.05013v1)|null|We present maps and spectra of the HCN(1-0) and HCO$^+$(1-0) lines in the extreme outer Galaxy, at galactocentric radii between 14 and 22 kpc, with the 13.7 meter Delingha telescope. The 9 molecular clouds were selected from a CO/$^{13}$CO survey of the outer quadrants. The goal is to better understand the structure of molecular clouds in these poorly studied subsolar metallicity regions and the relation with star formation. The lines are all narrow, less than 2km/s at half power, enabling detection of the HCN hyperfine structure in the stronger sources and allowing us to observationally test hyperfine collision rates. The hyperfine line ratios show that the HCN emission is optically thin with column densities estimated at N(HCN)~$3x10^{12}$\scm. The HCO$^+$ emission is approximately twice as strong as the HCN (taken as the sum of all components), in contrast with the inner Galaxy and nearby galaxies where they are similarly strong. For an abundance ratio $\chi_{HCN}/\chi_{HCO^+} = 3$, this requires a relatively low density solution for the dense gas, with n(H2) $\sim 10^3 - 10^4$\ccm. The $^{12}$CO/$^{13}$CO line ratios are similar to solar neighborhood values, roughly 7.5, despite the low $^{13}$CO abundance expected at such large radii. The HCO$^+$/CO and HCO$^+$/$^{13}$CO integrated intensity ratios are also standard at about 1/35 and 1/5 respectively. HCN is weak compared to the CO emission, with HCN/CO $\sim 1/70$ even after summing all hyperfine components. At the parsec scales observed here, the correlation between star formation, as traced by 24~$\mu$m emission as is standard in extragalactic work, and dense gas via the HCN or HCO$^+$ emission, is poor, perhaps due to the lack of dynamic range. We find that the lowest dense gas fractions are in the sources at high galactic latitude (b>2, h>300pc above the plane), possibly due to lower pressure.|

## smart ring

### smart ring
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**SmartBugs 2.0: An Execution Framework for Weakness Detection in Ethereum Smart Contracts**|Monika di Angelo et.al.|[2306.05057v1](http://arxiv.org/abs/2306.05057v1)|null|Smart contracts are blockchain programs that often handle valuable assets. Writing secure smart contracts is far from trivial, and any vulnerability may lead to significant financial losses. To support developers in identifying and eliminating vulnerabilities, methods and tools for the automated analysis have been proposed. However, the lack of commonly accepted benchmark suites and performance metrics makes it difficult to compare and evaluate such tools. Moreover, the tools are heterogeneous in their interfaces and reports as well as their runtime requirements, and installing several tools is time-consuming.   In this paper, we present SmartBugs 2.0, a modular execution framework. It provides a uniform interface to 19 tools aimed at smart contract analysis and accepts both Solidity source code and EVM bytecode as input. After describing its architecture, we highlight the features of the framework. We evaluate the framework via its reception by the community and illustrate its scalability by describing its role in a study involving 3.25 million analyses.|
|**2023-06-08**|**The toric ring of one dimensional simplicial complexes**|Antonino Ficarra et.al.|[2306.05020v1](http://arxiv.org/abs/2306.05020v1)|null|Let $\Delta$ be a 1-dimensional simplicial complex. Then $\Delta$ may be identified with a finite simple graph $G$. In this article, we investigate the toric ring $R_G$ of $G$. All graphs $G$ such that $R_G$ is a normal domain are classified. For such a graph, we determine the set $\mathcal{P}_G$ of height one monomial prime ideals of $R_G$. In the bipartite case, and in the case of whiskered cycles, this set is explicitly described. As a consequence, we determine the canonical class $[\omega_{R_G}]$ and characterize the Gorenstein property of $R_G$. For a bipartite graph $G$, we show that $R_G$ is Gorenstein if and only if $G$ is unmixed. For a subclass of non-bipartite graphs $G$, which includes whiskered cycles, $R_G$ is Gorenstein if and only if $G$ is unmixed and has an odd number of vertices. Finally, it is proved that $R_G$ is a pseudo-Gorenstein ring if $G$ is an odd cycle.|
|**2023-06-08**|**Sequence-to-Sequence Model with Transformer-based Attention Mechanism and Temporal Pooling for Non-Intrusive Load Monitoring**|Mohammad Irani Azad et.al.|[2306.05012v1](http://arxiv.org/abs/2306.05012v1)|null|This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) of smart buildings. The paper aims to improve the accuracy of NILM by using a deep learning-based method. The proposed method uses a Seq2Seq model with a transformer-based attention mechanism to capture the long-term dependencies of NILM data. Additionally, temporal pooling is used to improve the model's accuracy by capturing both the steady-state and transient behavior of appliances. The paper evaluates the proposed method on a publicly available dataset and compares the results with other state-of-the-art NILM techniques. The results demonstrate that the proposed method outperforms the existing methods in terms of both accuracy and computational efficiency.|
|**2023-06-08**|**Parallel and Asynchronous Smart Contract Execution**|Jian Liu et.al.|[2306.05007v1](http://arxiv.org/abs/2306.05007v1)|null|Today's blockchains suffer from low throughput and high latency, which impedes their widespread adoption of more complex applications like smart contracts. In this paper, we propose a novel paradigm for smart contract execution. It distinguishes between consensus nodes and execution nodes: different groups of execution nodes can execute transactions in parallel; meanwhile, consensus nodes can asynchronously order transactions and process execution results. Moreover, it requires no coordination among execution nodes and can effectively prevent livelocks. We show two ways of applying this paradigm to blockchains. First, we show how we can make Ethereum support parallel and asynchronous contract execution \emph{without hard-forks}. Then, we propose a new public, permissionless blockchain. Our benchmark shows that, with a fast consensus layer, it can provide a high throughput even for complex transactions like Cryptokitties gene mixing. It can also protect simple transactions from being starved by complex transactions.|
|**2023-06-08**|**Kähler differentials of extensions of valuation rings and deeply ramified fields**|Steven Dale Cutkosky et.al.|[2306.04967v1](http://arxiv.org/abs/2306.04967v1)|null|Assume that $(L,v)$ is a finite Galois extension of a valued field $(K,v)$. We give an explicit construction of the valuation ring $\cO_L$ of $L$ as an $\cO_K$-algebra, and an explicit description of the module of relative K\"ahler differentials $\Omega_{\cO_L |\cO_K}$ when $L|K$ is a Kummer extension of prime degree or an Artin-Schreier extension for which the valuation has a unique extension from $K$ to $L$. The case when this extension has nontrivial defect was solved in a recent paper by the authors with Anna Rzepka. Using this description, we characterize when $\Omega_{\cO_L|\cO_K}=0$ holds for an arbitrary finite Galois extension of valued fields. As an application of these results, we give a simple proof of a theorem of Gabber and Romero, which characterizes when a valued field is deeply ramified. We further give a simple characterization of deeply ramified fields whose residue field has positive characteristic $p$ in terms of the K\"ahler differentials of Galois extensions of degree $p$.|
|**2023-06-08**|**Modern Data Pricing Models: Taxonomy and Comprehensive Survey**|Xiaoye Miao et.al.|[2306.04945v1](http://arxiv.org/abs/2306.04945v1)|null|Data play an increasingly important role in smart data analytics, which facilitate many data-driven applications. The goal of various data markets aims to alleviate the issue of isolated data islands, so as to benefit data circulation. The problem of data pricing is indispensable yet challenging in data trade. In this paper, we conduct a comprehensive survey on the modern data pricing solutions. We divide the data pricing solutions into three major strategies and thirteen models, including query pricing strategy, feature-based data pricing strategy, and pricing strategy in machine learning. It is so far the first attempt to classify so many existing data pricing models. Moreover, we not only elaborate the thirteen specific pricing models within each pricing strategy, but also make in-depth analyses among these models. We also conclude five research directions for the data pricing field, and put forward some novel and interesting data pricing topics. This paper aims at gaining better insights, and directing the future research towards practical and sophisticated pricing mechanisms for better data trade and share.|
|**2023-06-08**|**A ring structure on Tor**|Jeffrey D. Carlson et.al.|[2306.04860v1](http://arxiv.org/abs/2306.04860v1)|null|We prove that within a natural class of E_3-algebras, the graded Tor group induced by a span of E_3-algebra maps carries a functorial commutative graded algebra structure generalizing the classical structure when the algebras are genuine commutative differential graded algebras.   As a topological corollary, Munkholm's Eilenberg--Moore collapse result for pullbacks of spaces with polynomial cohomology is enhanced to a ring isomorphism. New applications compute the Borel cohomology rings of homogeneous spaces and singular cohomology rings of biquotients with minimal restrictions on coefficient rings; existing results on the singular cohomology rings of free loop spaces and (generalized) homogeneous spaces are respectively recovered and strengthened.|
|**2023-06-08**|**Units of hyperelliptic curves over $\mathbb{F}_2$**|Justin Chen et.al.|[2306.04838v1](http://arxiv.org/abs/2306.04838v1)|null|We study unit groups of rings of the form $\mathbb{F}_2[x,y]/(y^2 + gy + h)$, for $g, h \in \mathbb{F}_2[x]$ -- in particular, the question of (non)triviality of such unit groups. Up to automorphisms of $\mathbb{F}_2[x,y]$ we classify such rings into 3 distinct types. For 2 of the types we show that the unit group is always trivial, and conjecture that the unit group is always nontrivial for the 3rd type. We provide support for this conjecture both theoretically and computationally, via an algorithm that has been used to compute units in large degrees.|
|**2023-06-07**|**The $\mathbb Z_3$-Symmetric Down-Up algebra**|Paul Terwilliger et.al.|[2306.04770v1](http://arxiv.org/abs/2306.04770v1)|null|In 1998, Georgia Benkart and Tom Roby introduced the down-up algebra $\mathcal A$. The algebra $\mathcal A$ is associative, noncommutative, and infinite-dimensional. It is defined by two generators $A,B$ and two relations called the down-up relations. In the present paper, we introduce the $\mathbb Z_3$-symmetric down-up algebra $\mathbb A$. We define $\mathbb A$ by generators and relations. There are three generators $A,B,C$ and any two of these satisfy the down-up relations. We describe how $\mathbb A$ is related to some familiar algebras in the literature, such as the Weyl algebra, the Lie algebras $\mathfrak{sl}_2$ and $\mathfrak{sl}_3$, the $\mathfrak{sl}_3$ loop algebra, the Kac-Moody Lie algebra $A^{(1)}_2$, the $q$-Weyl algebra, the quantized enveloping algebra $U_q(\mathfrak{sl}_2)$, and the quantized enveloping algebra $U_q (A^{(1)}_2)$. We give some open problems and conjectures.|
|**2023-06-07**|**Power-closed ideals of polynomial and Laurent polynomial rings**|Geir Agnarsson et.al.|[2306.04547v1](http://arxiv.org/abs/2306.04547v1)|null|We investigate the structure of power-closed ideals of the complex polynomial ring $R = \mathbb{C}[x_1,\ldots,x_d]$ and the Laurent polynomial ring $R^{\pm} = \mathbb{C}[x_1,\ldots,x_d]^{\pm} = M^{-1}\mathbb{C}[x_1,\ldots,x_d]$, where $M$ is the multiplicative sub-monoid $M = [x_1,\ldots,x_d]$ of $R$. Here, an ideal $I$ is {\em power-closed} if $f(x_1,\ldots,x_d)\in I$ implies $f(x_1^i,\ldots,x_d^i)\in I$ for each natural $i$. In particular, we investigate related closure and interior operators on the set of ideals of $R$ and $R^{\pm}$. Finally, we give a complete description of principal power-closed ideals and of the radicals of general power-closed ideals of $R$ and $R^{\pm}$.|
|**2023-06-07**|**High-quality amorphous Silicon Carbide for hybrid photonic integration at low temperature**|Bruno Lopez-Rodriguez et.al.|[2306.04491v1](http://arxiv.org/abs/2306.04491v1)|null|Integrated photonic platforms have proliferated in recent years, each demonstrating its own unique strengths and shortcomings. However, given the processing incompatibilities of different platforms, a formidable challenge in the field of integrated photonics still remains for combining the strength of different optical materials in one hybrid integrated platform. Silicon carbide is a material of great interest because of its high refractive index, strong second and third-order non-linearities and broad transparecy window in the visible and near infrared. However, integrating SiC has been difficult, and current approaches rely on transfer bonding techniques, that are time consuming, expensive and lacking precision in layer thickness. Here, we demonstrate high index Amorphous Silicon Carbide (a-SiC) films deposited at 150$^{\circ}$C and verify the high performance of the platform by fabricating standard photonic waveguides and ring resonators. The intrinsic quality factors of single-mode ring resonators were in the range of $Q_{int} = (4.7-5.7)\times10^5$ corresponding to optical losses between 0.78-1.06 dB/cm. We then demonstrate the potential of this platform for future heterogeneous integration with ultralow loss thin SiN and LiNbO$_3$ platforms.|
|**2023-06-07**|**Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network**|Haiyang Liu et.al.|[2306.04479v1](http://arxiv.org/abs/2306.04479v1)|null|The immutable and trustable characteristics of blockchain enable smart contracts to be applied in various fields. Unfortunately, smart contracts are subject to various vulnerabilities, which are frequently exploited by attackers, causing financial damage to users.In this paper, we study the problem of vulnerable smart contract function locating. We construct a novel Multi-Relational Nested contract Graph (MRNG) to better characterize the rich syntactic and semantic information in the smart contract code, including the relationships between data and instructions. An MRNG represents a smart contract, where each node represents a function in the smart contract and each edge describes the calling relationship between the functions. In addition, we create a Multi-Relational Function Graph (MRFG) for each function, which characterizes the corresponding function code. That is, each function is characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG uses different types of edges to represent the different control and data relationships between nodes within a function. We also propose a Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the edge-enhanced graph convolution network and self-attention mechanism. The extracted feature vector is then assigned to the corresponding node in the MRNG to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph convolution is used to further extract features from the FCG. Finally, a feed forward network with a Sigmoid function is used to locate the vulnerable functions. Experimental results on the real-world smart contract datasets show that model MRN-GCN can effectively improve the accuracy, precision, recall and F1-score performance of vulnerable smart contract function locating.|
|**2023-06-07**|**Hardening and Speeding Up Zero-interaction Pairing and Authentication**|Mikhail Fomichev et.al.|[2306.04458v1](http://arxiv.org/abs/2306.04458v1)|null|Establishing and maintaining secure communications in the Internet of Things (IoT) is vital to protect smart devices. Zero-interaction pairing (ZIP) and zero-interaction authentication (ZIA) enable IoT devices to establish and maintain secure communications without user interaction by utilizing devices' ambient context, e.g., audio. For autonomous operation, ZIP and ZIA require the context to have enough entropy to resist attacks and complete in a timely manner. Despite the low-entropy context being the norm, like inside an unoccupied room, the research community has yet to come up with ZIP and ZIA schemes operating under such conditions. We propose HARDZIPA, a novel approach that turns commodity IoT actuators into injecting devices, generating high-entropy context. Here, we combine the capability of IoT actuators to impact the environment, e.g., emitting a sound, with a pseudorandom number generator (PRNG) featured by many actuators to craft hard-to-predict context stimuli. To demonstrate the feasibility of HARDZIPA, we implement it on off-the-shelf IoT actuators, i.e., smart speakers, lights, and humidifiers. We comprehensively evaluate HARDZIPA, collecting over 80 hours of various context data in real-world scenarios. Our results show that HARDZIPA is able to thwart advanced active attacks on ZIP and ZIA schemes, while doubling the amount of context entropy in many cases, which allows two times faster pairing and authentication.|
|**2023-06-07**|**Primitive elements in the Munthe-Kaas-Wright Hopf Algebra**|Kurusch Ebrahimi-Fard et.al.|[2306.04381v1](http://arxiv.org/abs/2306.04381v1)|null|We extend Foissy's work on finite-dimensional comodules over the Butcher--Connes--Kreimer Hopf algebra of non-planar rooted trees to the Munthe-Kaas--Wright Hopf algebra of planar rooted trees. This includes the description of its endomorphisms as well as the recursive construction of its primitive elements. The findings are applied in the context of rough paths, where we describe an isomorphism between planarly branched and geometric rough paths. We also explore the geometric embedding for planar regularity structures as well as the link between the concept of bialgebras in cointeraction, the Guin--Oudom construction and the notion of translation on rough paths.|
|**2023-06-07**|**Revising deep learning methods in parking lot occupancy detection**|Anastasia Martynova et.al.|[2306.04288v2](http://arxiv.org/abs/2306.04288v2)|[link](https://github.com/eighonet/parking-research)|Parking guidance systems have recently become a popular trend as a part of the smart cities' paradigm of development. The crucial part of such systems is the algorithm allowing drivers to search for available parking lots across regions of interest. The classic approach to this task is based on the application of neural network classifiers to camera records. However, existing systems demonstrate a lack of generalization ability and appropriate testing regarding specific visual conditions. In this study, we extensively evaluate state-of-the-art parking lot occupancy detection algorithms, compare their prediction quality with the recently emerged vision transformers, and propose a new pipeline based on EfficientNet architecture. Performed computational experiments have demonstrated the performance increase in the case of our model, which was evaluated on 5 different datasets.|
|**2023-06-07**|**An Empirical Study of Impact of Solidity Compiler Updates on Vulnerabilities in Ethereum Smart Contracts**|Chihiro Kado et.al.|[2306.04250v1](http://arxiv.org/abs/2306.04250v1)|null|Vulnerabilities of Ethereum smart contracts often cause serious financial damage. Whereas the Solidity compiler has been updated to prevent vulnerabilities, its effectiveness has not been revealed so far, to the best of our knowledge. In this paper, we shed light on the impact of compiler versions of vulnerabilities of Ethereum smart contracts. To this end, we collected 503,572 contracts with Solidity source codes in the Ethereum blockchain and then analyzed their vulnerabilities. For three vulnerabilities with high severity, i.e., Locked Money, Using tx.origin, and Unchecked Call, we show that their appearance rates are decreased by virtue of major updates of the Solidity compiler. We then found the following four key insights. First, after the release of version 0.6, the appearance rate for Locked Money has decreased. Second, regardless of compiler updates, the appearance rate for Using tx.origin is significantly low. Third, although the appearance rate for Unchecked Call has decreased in version 0.8, it still remains high due to various factors, including code clones. Fourth, through analysis of code clones, our promising results show that the appearance rate for Unchecked Call can be further decreased by removing the code clones.|
|**2023-06-07**|**Cold CAS Ion Trap -- 22 pole trap with ring electrodes for astrochemistry**|Pavol Jusko et.al.|[2306.04245v1](http://arxiv.org/abs/2306.04245v1)|null|The enhancement of a cryogenic radio frequency 22 pole trap instrument by the addition of ring electrodes is presented in detail. The ring electrodes tightly surround the poles and only a fraction of the applied electric potential penetrates to the trap axis, facilitating the fine control of slow cold ions. A precise computational model, describing the effective mechanical potential created by the applied static and rf fields, governing the ion behaviour, is employed to demonstrate and understand the operation of our setup. The use of ring electrodes for improved extraction of cold stored ions is shown. Variable trapping potentials, placed on one ring electrode, can be used to control the evaporation of only those $\text{H}^+$ ions from the trap, whose kinetic energy exceeds the barrier. This ring electrode trapping opens new possibilities to study processes of minimal kinetic energy release, e. g. spin exchange. We propose a robust modified method for the determination of temperature dependent ion molecule reaction rates, resistant to effects caused by neutral gas freezing and demonstrate it on the reaction of $\text{CO}^+$/$\text{CO}_2^+$ with $\text{H}_2$/$\text{D}_2$. Finally, the use of a supercontinuum laser for quick localisation of spectroscopic bands is examined on the $\text{N}_2^+$ Meinel system.|
|**2023-06-07**|**A Threat Model for Soft Privacy on Smart Cars**|Mario Raciti et.al.|[2306.04222v1](http://arxiv.org/abs/2306.04222v1)|null|Modern cars are getting so computerised that ENISA's phrase "smart cars" is a perfect fit. The amount of personal data that they process is very large and, yet, increasing. Hence, the need to address citizens' privacy while they drive and, correspondingly, the importance of privacy threat modelling (in support of a respective risk assessment, such as through a Data Protection Impact Assessment). This paper addresses privacy threats by advancing a general modelling methodology and by demonstrating it specifically on soft privacy, which ensures citizens' full control on their personal data. By considering all relevant threat agents, the paper applies the methodology to the specific automotive domain while keeping threats at the same level of detail as ENISA's. The main result beside the modelling methodology consists of both domain-independent and automotive domain-dependent soft privacy threats. While cybersecurity has been vastly threat-modelled so far, this paper extends the literature with a threat model for soft privacy on smart cars, producing 17 domain-independent threats that, associated with 41 domain-specific assets, shape a novel set of domain-dependent threats in automotive.|
|**2023-06-07**|**Strong metric dimension of the prime ideal sum graph of a commutative ring**|Praveen Mathil et.al.|[2306.04200v1](http://arxiv.org/abs/2306.04200v1)|null|Let $R$ be a commutative ring with unity. The prime ideal sum graph of the ring $R$ is the simple undirected graph whose vertex set is the set of all nonzero proper ideals of $R$ and two distinct vertices $I$ and $J$ are adjacent if and only if $I + J$ is a prime ideal of $R$. In this paper, we obtain the strong metric dimension of the prime ideal sum graph for various classes of Artinian non-local commutative rings.|
|**2023-06-07**|**Is Homomorphic Encryption Feasible for Smart Mobility?**|Anika Hannemann et.al.|[2306.04195v1](http://arxiv.org/abs/2306.04195v1)|null|Smart mobility is a promising approach to meet urban transport needs in an environmentally and and user-friendly way. Smart mobility computes itineraries with multiple means of transportation, e.g., trams, rental bikes or electric scooters, according to customer preferences. A mobility platform cares for reservations, connecting transports, invoicing and billing. This requires sharing sensible personal data with multiple parties, and puts data privacy at risk. In this paper, we investigate if fully homomorphic encryption (FHE) can be applied in practice to mitigate such privacy issues. FHE allows to calculate on encrypted data, without having to decrypt it first. We implemented three typical distributed computations in a smart mobility scenario with SEAL, a recent programming library for FHE. With this implementation, we have measured memory consumption and execution times for three variants of distributed transactions, that are representative for a wide range of smart mobility tasks. Our evaluation shows, that FHE is indeed applicable to smart mobility: With today's processing capabilities, state-of-the-art FHE increases a smart mobility transaction by about 100 milliseconds and less than 3 microcents.|
|**2023-06-07**|**Connection between Schubert polynomials and top Lascoux polynomials**|Tianyi Yu et.al.|[2306.04159v1](http://arxiv.org/abs/2306.04159v1)|null|Schubert polynomials form a basis of the polynomial ring. This basis and its structure constants have received extensive study. Recently, Pan and Yu initiated the study of top Lascoux polynomials. These polynomials form a basis of a subalgebra of the polynomial ring where each graded piece has finite dimension. This paper connects Schubert polynomials and top Lascoux polynomials via a simple operator. We use this connection to show these two bases share the same structure constants. We also translate several results on Schubert polynomials to top Lascoux polynomials, including combinatorial formulas for their monomial expansions and supports.|
|**2023-06-07**|**UCTB: An Urban Computing Tool Box for Spatiotemporal Crowd Flow Prediction**|Liyue Chen et.al.|[2306.04144v1](http://arxiv.org/abs/2306.04144v1)|[link](https://github.com/uctb/uctb)|Spatiotemporal crowd flow prediction is one of the key technologies in smart cities. Currently, there are two major pain points that plague related research and practitioners. Firstly, crowd flow is related to multiple domain knowledge factors; however, due to the diversity of application scenarios, it is difficult for subsequent work to make reasonable and comprehensive use of domain knowledge. Secondly, with the development of deep learning technology, the implementation of relevant techniques has become increasingly complex; reproducing advanced models has become a time-consuming and increasingly cumbersome task. To address these issues, we design and implement a spatiotemporal crowd flow prediction toolbox called UCTB (Urban Computing Tool Box), which integrates multiple spatiotemporal domain knowledge and state-of-the-art models simultaneously. The relevant code and supporting documents have been open-sourced at https://github.com/uctb/UCTB.|
|**2023-06-07**|**Planar, infinite, semidistributive lattices**|George Grätzer et.al.|[2306.04113v1](http://arxiv.org/abs/2306.04113v1)|null|An FN lattice $F$ is a simple, infinite, semidistributive lattice. Its existence was recently proved by R. Freese and J.B. Nation. Let $\mathsf{B}_n$ denote the Boolean lattice with $n$ atoms. For a lattice $\mathit{K}$, let $\mathit{K}^+$ denote $\mathit{K}$ with a new unit adjoined. We prove that the finite distributive lattices: $\mathsf{B}0^+,\mathsf{B}1^+, \mathsf{B}2^+,\dots$ can be represented as congruence lattices of infinite semidistributive lattices. The case $n = 0$ is the Freese-Nation result, which is utilized in the proof.|
|**2023-06-06**|**A machine learning potential-based generative algorithm for on-lattice crystal structure prediction**|Vadim Sotskov et.al.|[2306.03989v1](http://arxiv.org/abs/2306.03989v1)|null|We propose a method for crystal structure prediction based on a new structure generation algorithm and on-lattice machine learning interatomic potentials. Our algorithm generates the atomic configurations assigning atomic species to sites of the given lattice, and uses cluster expansion or low-rank potential to evaluate their energy. We demonstrate two benefits of such approach. First, our structure generation algorithm offers a ``smart'' configurational space sampling, targeting low-energy structures which significantly reduces computational costs. Second, the application of machine learning interatomic potentials significantly reduces the number of DFT calculations. We discuss how our algorithm resembles the latent diffusion models for image generation. We demonstrate the efficiency of our method by constructing the convex hull of Nb-Mo-Ta-W system, including binary and ternary Nb-W and Mo-Ta-W subsystems. We found new binary, ternary, and quaternary stable structures that are not reported in the AFLOW database which we choose as our baseline. Due to the computational efficiency of our method we anticipate that it can pave the way towards efficient high-throughput discovery of multicomponent materials.|
|**2023-06-06**|**Villadsen algebras**|Cristian Ivanescu et.al.|[2306.03943v1](http://arxiv.org/abs/2306.03943v1)|null|C*-algebras are rings, sometimes nonunital, obeying certain axioms that ensure a very well-behaved representation theory upon Hilbert space. Moreover, there are some well-known features of the representation theory leading to subtle questions about norms on tensor products of C*-algebras, and thus to the subclass of nuclear C*-algebras. The question whether all separable nuclear C*-algebras satisfy the Universal Coefficient Theorem (UCT) remains one of the most important open problems in the structure and classification theory of such algebras. One of the most promising ways to test the UCT conjecture depends on finding C*-algebras that behave as idempotents under the tensor product, and satisfy certain additional properties. Briefly put, %it has been shown \cite{FarahCalkin} that if there exists a simple, separable, and nuclear C*-algebra that is an idempotent under the tensor product, satisfies a certain technical property, and is not one of the already known such elements $\left\{ O_\infty, O_2, \UHF , J, Z, \C, \compact \right\}$ then the UCT fails. Although we do not disprove the UCT in this publication, we do find new idempotents in the class of Villadsen algebras.|
|**2023-06-06**|**Vortex rings generated by a translating disk from start to stop**|Joanne Steiner et.al.|[2306.03867v1](http://arxiv.org/abs/2306.03867v1)|null|In this article, we investigate experimentally and numerically the time evolution of vortex rings generated by the translation of a rigid disk in a fluid initially at rest and submitted to an acceleration followed by a deceleration. The size of the disk and its motion in terms of stroke length and travel time are varied as control parameters. The start-up vortex ring created in the near wake of the disk is characterized experimentally by PIV, and the measurements agree quantitatively with axisymmetric numerical simulations performed with the Basilisk flow solver. The maximum radius and circulation of the annular vortex and its dynamics are shown to follow different power laws with the control parameters. The modeling adapted from Wedemeyer's two-dimensional theoretical calculations [E. Wedemeyer, Ausbildung eines Wirbelpaares an den Kanten einer Platte, Ingenieur-Archiv 30, (1961)] captures the observed scaling laws. Besides, after the disk stops, a secondary ``stopping" vortex ring is generated, which is shown to affect the motion of the main vortex ring.|
|**2023-06-06**|**A New Approach to Measure Fundamental Microstructural Influences on the Magnetic Properties of Electrical Steel using a Miniaturized Single Sheet Tester**|Nora Leuning et.al.|[2306.03665v1](http://arxiv.org/abs/2306.03665v1)|null|Magnetic properties of electrical steel are usually measured on Single Sheet Testers, Epstein frames or ring cores. Due to the geometric dimensions and measurement principles of these standardized setups, the fundamental microstructural influences on the magnetic behavior, e.g., deformation structures, crystal orientation or grain boundaries, are difficult to separate and quantify. In this paper, a miniaturized Single Sheet Tester is presented that allows the characterization of industrial steel sheets as well as from in size limited single, bi- and oligocrystals starting from samples with dimensions of 10x22 mm. Thereby, the measurement of global magnetic properties is coupled with microstructural analysis methods to allow the investigation of micro scale magnetic effects. An effect of grain orientation, grain boundaries and deformation structures has already been identified with the presented experimental setup. In addition, a correction function is introduced to allow quantitative comparisons between differently sized Single Sheet Testers. This approach is not limited to the presented Single Sheet Tester geometry, but applicable for the comparison of results of differently sized Single Sheet Testers. The results of the miniaturized Single Sheet Tester were validated on five industrial electrical steel grades. Furthermore, first results of differently oriented single crystals as well as measurements on grain-oriented electrical steel are shown to prove the additional value of the miniaturized Single Sheet Tester geometry.|
|**2023-06-06**|**CIN++: Enhancing Topological Message Passing**|Lorenzo Giusti et.al.|[2306.03561v1](http://arxiv.org/abs/2306.03561v1)|null|Graph Neural Networks (GNNs) have demonstrated remarkable success in learning from graph-structured data. However, they face significant limitations in expressive power, struggling with long-range interactions and lacking a principled approach to modeling higher-order structures and group interactions. Cellular Isomorphism Networks (CINs) recently addressed most of these challenges with a message passing scheme based on cell complexes. Despite their advantages, CINs make use only of boundary and upper messages which do not consider a direct interaction between the rings present in the underlying complex. Accounting for these interactions might be crucial for learning representations of many real-world complex phenomena such as the dynamics of supramolecular assemblies, neural activity within the brain, and gene regulation processes. In this work, we propose CIN++, an enhancement of the topological message passing scheme introduced in CINs. Our message passing scheme accounts for the aforementioned limitations by letting the cells to receive also lower messages within each layer. By providing a more comprehensive representation of higher-order and long-range interactions, our enhanced topological message passing scheme achieves state-of-the-art results on large-scale and long-range chemistry benchmarks.|
|**2023-06-06**|**From Data to Action: Exploring AI and IoT-driven Solutions for Smarter Cities**|Tiago Dias et.al.|[2306.04653v1](http://arxiv.org/abs/2306.04653v1)|null|The emergence of smart cities demands harnessing advanced technologies like the Internet of Things (IoT) and Artificial Intelligence (AI) and promises to unlock cities' potential to become more sustainable, efficient, and ultimately livable for their inhabitants. This work introduces an intelligent city management system that provides a data-driven approach to three use cases: (i) analyze traffic information to reduce the risk of traffic collisions and improve driver and pedestrian safety, (ii) identify when and where energy consumption can be reduced to improve cost savings, and (iii) detect maintenance issues like potholes in the city's roads and sidewalks, as well as the beginning of hazards like floods and fires. A case study in Aveiro City demonstrates the system's effectiveness in generating actionable insights that enhance security, energy efficiency, and sustainability, while highlighting the potential of AI and IoT-driven solutions for smart city development.|
|**2023-06-06**|**Correlated Pseudorandomness from the Hardness of Quasi-Abelian Decoding**|Maxime Bombar et.al.|[2306.03488v1](http://arxiv.org/abs/2306.03488v1)|null|Secure computation often benefits from the use of correlated randomness to achieve fast, non-cryptographic online protocols. A recent paradigm put forth by Boyle $\textit{et al.}$ (CCS 2018, Crypto 2019) showed how pseudorandom correlation generators (PCG) can be used to generate large amounts of useful forms of correlated (pseudo)randomness, using minimal interactions followed solely by local computations, yielding silent secure two-party computation protocols (protocols where the preprocessing phase requires almost no communication). An additional property called programmability allows to extend this to build N-party protocols. However, known constructions for programmable PCG's can only produce OLE's over large fields, and use rather new splittable Ring-LPN assumption.   In this work, we overcome both limitations. To this end, we introduce the quasi-abelian syndrome decoding problem (QA-SD), a family of assumptions which generalises the well-established quasi-cyclic syndrome decoding assumption. Building upon QA-SD, we construct new programmable PCG's for OLE's over any field $\mathbb{F}_q$ with $q>2$. Our analysis also sheds light on the security of the ring-LPN assumption used in Boyle $\textit{et al.}$ (Crypto 2020). Using our new PCG's, we obtain the first efficient N-party silent secure computation protocols for computing general arithmetic circuit over $\mathbb{F}_q$ for any $q>2$.|

## camera

### wearable camera
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Tracking Everything Everywhere All at Once**|Qianqian Wang et.al.|[2306.05422v1](http://arxiv.org/abs/2306.05422v1)|null|We present a new test-time optimization method for estimating dense and long-range motion from a video sequence. Prior optical flow or particle video tracking algorithms typically operate within limited temporal windows, struggling to track through occlusions and maintain global consistency of estimated motion trajectories. We propose a complete and globally consistent motion representation, dubbed OmniMotion, that allows for accurate, full-length motion estimation of every pixel in a video. OmniMotion represents a video using a quasi-3D canonical volume and performs pixel-wise tracking via bijections between local and canonical space. This representation allows us to ensure global consistency, track through occlusions, and model any combination of camera and object motion. Extensive evaluations on the TAP-Vid benchmark and real-world footage show that our approach outperforms prior state-of-the-art methods by a large margin both quantitatively and qualitatively. See our project page for more results: http://omnimotion.github.io/|
|**2023-06-08**|**TopoMask: Instance-Mask-Based Formulation for the Road Topology Problem via Transformer-Based Architecture**|M. Esat Kalfaoglu et.al.|[2306.05419v1](http://arxiv.org/abs/2306.05419v1)|null|Driving scene understanding task involves detecting static elements such as lanes, traffic signs, and traffic lights, and their relationships with each other. To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released. This dataset allows for the exploration of complex road connections and situations where lane markings may be absent. Instead of using traditional lane markings, the lanes in this dataset are represented by centerlines, which offer a more suitable representation of lanes and their connections. In this study, we have introduced a new approach called TopoMask for predicting centerlines in road topology. Unlike existing approaches in the literature that rely on keypoints or parametric methods, TopoMask utilizes an instance-mask based formulation with a transformer-based architecture and, in order to enrich the mask instances with flow information, a direction label representation is proposed. TopoMask have ranked 4th in the OpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction in OpenLane Topology Challenge 2023. In comparison to the current state-of-the-art method, TopoNet, the proposed method has achieved similar performance in Frechet-based lane detection and outperformed TopoNet in Chamfer-based lane detection without utilizing its scene graph neural network.|
|**2023-06-08**|**LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs**|Zezhou Cheng et.al.|[2306.05410v1](http://arxiv.org/abs/2306.05410v1)|null|A critical obstacle preventing NeRF models from being deployed broadly in the wild is their reliance on accurate camera poses. Consequently, there is growing interest in extending NeRF models to jointly optimize camera poses and scene representation, which offers an alternative to off-the-shelf SfM pipelines which have well-understood failure modes. Existing approaches for unposed NeRF operate under limited assumptions, such as a prior pose distribution or coarse pose initialization, making them less effective in a general setting. In this work, we propose a novel approach, LU-NeRF, that jointly estimates camera poses and neural radiance fields with relaxed assumptions on pose configuration. Our approach operates in a local-to-global manner, where we first optimize over local subsets of the data, dubbed mini-scenes. LU-NeRF estimates local pose and geometry for this challenging few-shot task. The mini-scene poses are brought into a global reference frame through a robust pose synchronization step, where a final global optimization of pose and scene can be performed. We show our LU-NeRF pipeline outperforms prior attempts at unposed NeRF without making restrictive assumptions on the pose prior. This allows us to operate in the general SE(3) pose setting, unlike the baselines. Our results also indicate our model can be complementary to feature-based SfM pipelines as it compares favorably to COLMAP on low-texture and low-resolution images.|
|**2023-06-08**|**SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic Understanding**|Paul-Edouard Sarlin et.al.|[2306.05407v1](http://arxiv.org/abs/2306.05407v1)|null|Semantic 2D maps are commonly used by humans and machines for navigation purposes, whether it's walking or driving. However, these maps have limitations: they lack detail, often contain inaccuracies, and are difficult to create and maintain, especially in an automated fashion. Can we use raw imagery to automatically create better maps that can be easily interpreted by both humans and machines? We introduce SNAP, a deep network that learns rich neural 2D maps from ground-level and overhead images. We train our model to align neural maps estimated from different inputs, supervised only with camera poses over tens of millions of StreetView images. SNAP can resolve the location of challenging image queries beyond the reach of traditional methods, outperforming the state of the art in localization by a large margin. Moreover, our neural maps encode not only geometry and appearance but also high-level semantics, discovered without explicit supervision. This enables effective pre-training for data-efficient semantic scene understanding, with the potential to unlock cost-efficient creation of more detailed maps.|
|**2023-06-08**|**Predictive Modeling of Equine Activity Budgets Using a 3D Skeleton Reconstructed from Surveillance Recordings**|Ernest Pokropek et.al.|[2306.05311v1](http://arxiv.org/abs/2306.05311v1)|null|In this work, we present a pipeline to reconstruct the 3D pose of a horse from 4 simultaneous surveillance camera recordings. Our environment poses interesting challenges to tackle, such as limited field view of the cameras and a relatively closed and small environment. The pipeline consists of training a 2D markerless pose estimation model to work on every viewpoint, then applying it to the videos and performing triangulation. We present numerical evaluation of the results (error analysis), as well as show the utility of the achieved poses in downstream tasks of selected behavioral predictions. Our analysis of the predictive model for equine behavior showed a bias towards pain-induced horses, which aligns with our understanding of how behavior varies across painful and healthy subjects.|
|**2023-06-08**|**EXOT: Exit-aware Object Tracker for Safe Robotic Manipulation of Moving Object**|Hyunseo Kim et.al.|[2306.05262v1](http://arxiv.org/abs/2306.05262v1)|null|Current robotic hand manipulation narrowly operates with objects in predictable positions in limited environments. Thus, when the location of the target object deviates severely from the expected location, a robot sometimes responds in an unexpected way, especially when it operates with a human. For safe robot operation, we propose the EXit-aware Object Tracker (EXOT) on a robot hand camera that recognizes an object's absence during manipulation. The robot decides whether to proceed by examining the tracker's bounding box output containing the target object. We adopt an out-of-distribution classifier for more accurate object recognition since trackers can mistrack a background as a target object. To the best of our knowledge, our method is the first approach of applying an out-of-distribution classification technique to a tracker output. We evaluate our method on the first-person video benchmark dataset, TREK-150, and on the custom dataset, RMOT-223, that we collect from the UR5e robot. Then we test our tracker on the UR5e robot in real-time with a conveyor-belt sushi task, to examine the tracker's ability to track target dishes and to determine the exit status. Our tracker shows 38% higher exit-aware performance than a baseline method. The dataset and the code will be released at https://github.com/hskAlena/EXOT.|
|**2023-06-08**|**Human Action Recognition in Egocentric Perspective Using 2D Object and Hands Pose**|Wiktor Mucha et.al.|[2306.05147v1](http://arxiv.org/abs/2306.05147v1)|null|Egocentric action recognition is essential for healthcare and assistive technology that relies on egocentric cameras because it allows for the automatic and continuous monitoring of activities of daily living (ADLs) without requiring any conscious effort from the user. This study explores the feasibility of using 2D hand and object pose information for egocentric action recognition. While current literature focuses on 3D hand pose information, our work shows that using 2D skeleton data is a promising approach for hand-based action classification, might offer privacy enhancement, and could be less computationally demanding. The study uses a state-of-the-art transformer-based method to classify sequences and achieves validation results of 94%, outperforming other existing solutions. The accuracy of the test subset drops to 76%, indicating the need for further generalization improvement. This research highlights the potential of 2D hand and object pose information for action recognition tasks and offers a promising alternative to 3D-based methods.|
|**2023-06-08**|**Variable Radiance Field for Real-Life Category-Specifc Reconstruction from Single Image**|Kun Wang et.al.|[2306.05145v1](http://arxiv.org/abs/2306.05145v1)|null|Reconstructing category-specific objects from a single image is a challenging task that requires inferring the geometry and appearance of an object from a limited viewpoint. Existing methods typically rely on local feature retrieval based on re-projection with known camera intrinsic, which are slow and prone to distortion at viewpoints distant from the input image. In this paper, we present Variable Radiance Field (VRF), a novel framework that can efficiently reconstruct category-specific objects from a single image without known camera parameters. Our key contributions are: (1) We parameterize the geometry and appearance of the object using a multi-scale global feature extractor, which avoids frequent point-wise feature retrieval and camera dependency. We also propose a contrastive learning-based pretraining strategy to improve the feature extractor. (2) We reduce the geometric complexity of the object by learning a category template, and use hypernetworks to generate a small neural radiance field for fast and instance-specific rendering. (3) We align each training instance to the template space using a learned similarity transformation, which enables semantic-consistent learning across different objects. We evaluate our method on the CO3D dataset and show that it outperforms existing methods in terms of quality and speed. We also demonstrate its applicability to shape interpolation and object placement tasks.|
|**2023-06-08**|**Neuromorphic Sampling of Signals in Shift-Invariant Spaces**|Abijith Jagannath Kamath et.al.|[2306.05103v1](http://arxiv.org/abs/2306.05103v1)|null|Neuromorphic sampling is a paradigm shift in analog-to-digital conversion where the acquisition strategy is opportunistic and measurements are recorded only when there is a significant change in the signal. Neuromorphic sampling has given rise to a new class of event-based sensors called dynamic vision sensors or neuromorphic cameras. The neuromorphic sampling mechanism utilizes low power and provides high-dynamic range sensing with low latency and high temporal resolution. The measurements are sparse and have low redundancy making it convenient for downstream tasks. In this paper, we present a sampling-theoretic perspective to neuromorphic sensing of continuous-time signals. We establish a close connection between neuromorphic sampling and time-based sampling - where signals are encoded temporally. We analyse neuromorphic sampling of signals in shift-invariant spaces, in particular, bandlimited signals and polynomial splines. We present an iterative technique for perfect reconstruction subject to the events satisfying a density criterion. We also provide necessary and sufficient conditions for perfect reconstruction. Owing to practical limitations in meeting the sufficient conditions for perfect reconstruction, we extend the analysis to approximate reconstruction from sparse events. In the latter setting, we pose signal reconstruction as a continuous-domain linear inverse problem whose solution can be obtained by solving an equivalent finite-dimensional convex optimization program using a variable-splitting approach. We demonstrate the performance of the proposed algorithm and validate our claims via experiments on synthetic signals.|
|**2023-06-08**|**Real-Time Rendering of Glinty Appearances using Distributed Binomial Laws on Anisotropic Grids**|Deliot et.al.|[2306.05051v1](http://arxiv.org/abs/2306.05051v1)|null|In this work, we render in real-time glittery materials caused by discrete flakes on the surface. To achieve this, one has to count the number of flakes reflecting the light towards the camera within every texel covered by a given pixel footprint. To do so, we derive a counting method for arbitrary footprints that, unlike previous work, outputs the correct statistics. We combine this counting method with an anisotropic parameterization of the texture space that reduces the number of texels falling under a pixel footprint. This allows our method to run with both stable performance and 1.5X to 5X faster than the state-of-the-art.|
|**2023-06-08**|**StreetSurf: Extending Multi-view Implicit Surface Reconstruction to Street Views**|Jianfei Guo et.al.|[2306.04988v1](http://arxiv.org/abs/2306.04988v1)|null|We present a novel multi-view implicit surface reconstruction technique, termed StreetSurf, that is readily applicable to street view images in widely-used autonomous driving datasets, such as Waymo-perception sequences, without necessarily requiring LiDAR data. As neural rendering research expands rapidly, its integration into street views has started to draw interests. Existing approaches on street views either mainly focus on novel view synthesis with little exploration of the scene geometry, or rely heavily on dense LiDAR data when investigating reconstruction. Neither of them investigates multi-view implicit surface reconstruction, especially under settings without LiDAR data. Our method extends prior object-centric neural surface reconstruction techniques to address the unique challenges posed by the unbounded street views that are captured with non-object-centric, long and narrow camera trajectories. We delimit the unbounded space into three parts, close-range, distant-view and sky, with aligned cuboid boundaries, and adapt cuboid/hyper-cuboid hash-grids along with road-surface initialization scheme for finer and disentangled representation. To further address the geometric errors arising from textureless regions and insufficient viewing angles, we adopt geometric priors that are estimated using general purpose monocular models. Coupled with our implementation of efficient and fine-grained multi-stage ray marching strategy, we achieve state of the art reconstruction quality in both geometry and appearance within only one to two hours of training time with a single RTX3090 GPU for each street view sequence. Furthermore, we demonstrate that the reconstructed implicit surfaces have rich potential for various downstream tasks, including ray tracing and LiDAR simulation.|
|**2023-06-08**|**Ultraviolet Photodetectors based on GaN and AlGaN/AlN Nanowire Ensembles: Effects of Planarization with Hydrogen Silsesquioxane and Nanowire Architecture**|E. Akar et.al.|[2306.04986v1](http://arxiv.org/abs/2306.04986v1)|null|The interest in nanowire photodetectors stems from their potential to improve the performance of a variety of devices, including solar cells, cameras, sensors, and communication systems. Implementing devices based on nanowire ensembles requires a planarization process which must be conceived to preserve the advantages of the nanowire geometry. This is particularly challenging in the ultraviolet (UV) range, where spin coating with hydrogen silsesquioxane (HSQ) appears as an interesting approach in terms of transmittance and refractive index. Here, we report a comprehensive study on UV photodetectors based on GaN or AlGaN/AlN nanowire ensembles encapsulated in HSQ. We show that this material is efficient for passivating the nanowire surface, it introduces a compressive strain in the nanowires and preserves their radiative efficiency. We discuss the final performance of planarized UV photodetectors based on three kinds of nanowire ensembles: (i) non-intentionally-doped (nid) GaN nanowires, (ii) Ge-doped GaN nanowires, and (iii) nid GaN nanowires terminated with an AlGaN/AlN superlattice. The incorporation of the superlattice allows tuning the spectral response with bias, which can enhance the carrier collection from the AlGaN/AlN superlattice or from the GaN stem. In all the cases, the performance of the planarized devices remains determined by the nanowire nature, since their characteristics in terms of linearity and spectral selectivity are closer to those demonstrated in single nanowires than those of planar devices. Thus, the visible rejection is several orders of magnitude and there is no indication of persistent photocurrent, which makes all the samples suitable for UV-selective photodetection applications.|
|**2023-06-08**|**Underwater Intention Recognition using Head Motion and Throat Vibration for Supernumerary Robotic Assistance**|Yuqin Guo et.al.|[2306.04928v1](http://arxiv.org/abs/2306.04928v1)|null|This study presents a multi-modal mechanism for recognizing human intentions while diving underwater, aiming to achieve natural human-robot interactions through an underwater superlimb for diving assistance. The underwater environment severely limits the divers' capabilities in intention expression, which becomes more challenging when they intend to operate tools while keeping control of body postures in 3D with the various diving suits and gears. The current literature is limited in underwater intention recognition, impeding the development of intelligent wearable systems for human-robot interactions underwater. Here, we present a novel solution to simultaneously detect head motion and throat vibrations under the water in a compact, wearable design. Experiment results show that using machine learning algorithms, we achieved high performance in integrating these two modalities to translate human intentions to robot control commands for an underwater superlimb system. This study's results paved the way for future development in underwater intention recognition and underwater human-robot interactions with supernumerary support.|
|**2023-06-08**|**Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization**|Jungwuk Park et.al.|[2306.04911v1](http://arxiv.org/abs/2306.04911v1)|null|In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully work in conjunction with various other DG schemes. Experimental results on different datasets show the effectiveness of our methods.|
|**2023-06-08**|**ViG-UNet: Vision Graph Neural Networks for Medical Image Segmentation**|Juntao Jiang et.al.|[2306.04905v1](http://arxiv.org/abs/2306.04905v1)|null|Deep neural networks have been widely used in medical image analysis and medical image segmentation is one of the most important tasks. U-shaped neural networks with encoder-decoder are prevailing and have succeeded greatly in various segmentation tasks. While CNNs treat an image as a grid of pixels in Euclidean space and Transformers recognize an image as a sequence of patches, graph-based representation is more generalized and can construct connections for each part of an image. In this paper, we propose a novel ViG-UNet, a graph neural network-based U-shaped architecture with the encoder, the decoder, the bottleneck, and skip connections. The downsampling and upsampling modules are also carefully designed. The experimental results on ISIC 2016, ISIC 2017 and Kvasir-SEG datasets demonstrate that our proposed architecture outperforms most existing classic and state-of-the-art U-shaped networks.|
|**2023-06-08**|**ExtPerFC: An Efficient 2D and 3D Perception Hardware-Software Framework for Mobile Cobot**|Tuan Dang et.al.|[2306.04853v1](http://arxiv.org/abs/2306.04853v1)|null|As the reliability of the robot's perception correlates with the number of integrated sensing modalities to tackle uncertainty, a practical solution to manage these sensors from different computers, operate them simultaneously, and maintain their real-time performance on the existing robotic system with minimal effort is needed. In this work, we present an end-to-end software-hardware framework, namely ExtPerFC, that supports both conventional hardware and software components and integrates machine learning object detectors without requiring an additional dedicated graphic processor unit (GPU). We first design our framework to achieve real-time performance on the existing robotic system, guarantee configuration optimization, and concentrate on code reusability. We then mathematically model and utilize our transfer learning strategies for 2D object detection and fuse them into depth images for 3D depth estimation. Lastly, we systematically test the proposed framework on the Baxter robot with two 7-DOF arms, a four-wheel mobility base, and an Intel RealSense D435i RGB-D camera. The results show that the robot achieves real-time performance while executing other tasks (e.g., map building, localization, navigation, object detection, arm moving, and grasping) simultaneously with available hardware like Intel onboard CPUS/GPUs on distributed computers. Also, to comprehensively control, program, and monitor the robot system, we design and introduce an end-user application. The source code is available at https://github.com/tuantdang/perception_framework.|
|**2023-06-07**|**BU-CVKit: Extendable Computer Vision Framework for Species Independent Tracking and Analysis**|Mahir Patel et.al.|[2306.04736v1](http://arxiv.org/abs/2306.04736v1)|null|A major bottleneck of interdisciplinary computer vision (CV) research is the lack of a framework that eases the reuse and abstraction of state-of-the-art CV models by CV and non-CV researchers alike. We present here BU-CVKit, a computer vision framework that allows the creation of research pipelines with chainable Processors. The community can create plugins of their work for the framework, hence improving the re-usability, accessibility, and exposure of their work with minimal overhead. Furthermore, we provide MuSeqPose Kit, a user interface for the pose estimation package of BU-CVKit, which automatically scans for installed plugins and programmatically generates an interface for them based on the metadata provided by the user. It also provides software support for standard pose estimation features such as annotations, 3D reconstruction, reprojection, and camera calibration. Finally, we show examples of behavioral neuroscience pipelines created through the sample plugins created for our framework.|
|**2023-06-07**|**ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections**|Chun-Han Yao et.al.|[2306.04619v1](http://arxiv.org/abs/2306.04619v1)|null|Estimating 3D articulated shapes like animal bodies from monocular images is inherently challenging due to the ambiguities of camera viewpoint, pose, texture, lighting, etc. We propose ARTIC3D, a self-supervised framework to reconstruct per-instance 3D shapes from a sparse image collection in-the-wild. Specifically, ARTIC3D is built upon a skeleton-based surface representation and is further guided by 2D diffusion priors from Stable Diffusion. First, we enhance the input images with occlusions/truncation via 2D diffusion to obtain cleaner mask estimates and semantic features. Second, we perform diffusion-guided 3D optimization to estimate shape and texture that are of high-fidelity and faithful to input images. We also propose a novel technique to calculate more stable image-level gradients via diffusion models compared to existing alternatives. Finally, we produce realistic animations by fine-tuning the rendered shape and texture under rigid part transformations. Extensive evaluations on multiple existing datasets as well as newly introduced noisy web image collections with occlusions and truncation demonstrate that ARTIC3D outputs are more robust to noisy images, higher quality in terms of shape and texture details, and more realistic when animated. Project page: https://chhankyao.github.io/artic3d/|
|**2023-06-07**|**Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt**|Kai Chen et.al.|[2306.04607v2](http://arxiv.org/abs/2306.04607v2)|null|Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experiments demonstrate GeoDiffusion outperforms previous L2I methods while maintaining 4x training time faster. To the best of our knowledge, this is the first work to adopt diffusion models for layout-to-image generation with geometric conditions and demonstrate that L2I-generated images can be beneficial for improving the performance of object detectors.|
|**2023-06-07**|**The CYGNO experiment, a directional detector for direct Dark Matter searches**|F. D. Amaro et.al.|[2306.04568v1](http://arxiv.org/abs/2306.04568v1)|null|The CYGNO project aims at the development of a high precision optical readout gaseous Tima Projection Chamber (TPC) for directional dark matter (DM) searches, to be hosted at Laboratori Nazionali del Gran Sasso (LNGS). CYGNO employs a He:CF$_4$ gas mixture at atmospheric pressure with a Gas Electron Multiplier (GEM) based amplification structure coupled to an optical readout comprised of sCMOS cameras and photomultiplier tubes (PMTs). This experimental setup allows to achieve 3D tracking and background rejection down to O(1) keV energy, to boost sensitivity to low WIMP masses. The characteristics of the optical readout approach in terms of the light yield will be illustrated along with the particle identification properties. The project timeline foresees, in the next 2-3 years, the realisation and installation of a 0.4 m$^3$ TPC in the underground laboratories at LNGS to act as a demonstrator. Finally, the studies of the expected DM sensitivities of the CYGNO demonstrator will be presented.|
|**2023-06-07**|**Integrated Photonic Encoder for Terapixel Image Processing**|Xiao Wang et.al.|[2306.04554v1](http://arxiv.org/abs/2306.04554v1)|null|Modern lens designs are capable of resolving >10 gigapixels, while advances in camera frame-rate and hyperspectral imaging have made Terapixel/s data acquisition a real possibility. The main bottlenecks preventing such high data-rate systems are power consumption and data storage. In this work, we show that analog photonic encoders could address this challenge, enabling high-speed image compression using orders-of-magnitude lower power than digital electronics. Our approach relies on a silicon-photonics front-end to compress raw image data, foregoing energy-intensive image conditioning and reducing data storage requirements. The compression scheme uses a passive disordered photonic structure to perform kernel-type random projections of the raw image data with minimal power consumption and low latency. A back-end neural network can then reconstruct the original images with structural similarity exceeding 90%. This scheme has the potential to process Terapixel/s data streams using less than 100 fJ/pixel, providing a path to ultra-high-resolution data and image acquisition systems.|
|**2023-06-07**|**Revising deep learning methods in parking lot occupancy detection**|Anastasia Martynova et.al.|[2306.04288v2](http://arxiv.org/abs/2306.04288v2)|[link](https://github.com/eighonet/parking-research)|Parking guidance systems have recently become a popular trend as a part of the smart cities' paradigm of development. The crucial part of such systems is the algorithm allowing drivers to search for available parking lots across regions of interest. The classic approach to this task is based on the application of neural network classifiers to camera records. However, existing systems demonstrate a lack of generalization ability and appropriate testing regarding specific visual conditions. In this study, we extensively evaluate state-of-the-art parking lot occupancy detection algorithms, compare their prediction quality with the recently emerged vision transformers, and propose a new pipeline based on EfficientNet architecture. Performed computational experiments have demonstrated the performance increase in the case of our model, which was evaluated on 5 different datasets.|
|**2023-06-07**|**Learning Probabilistic Coordinate Fields for Robust Correspondences**|Weiyue Zhao et.al.|[2306.04231v1](http://arxiv.org/abs/2306.04231v1)|null|We introduce Probabilistic Coordinate Fields (PCFs), a novel geometric-invariant coordinate representation for image correspondence problems. In contrast to standard Cartesian coordinates, PCFs encode coordinates in correspondence-specific barycentric coordinate systems (BCS) with affine invariance. To know \textit{when and where to trust} the encoded coordinates, we implement PCFs in a probabilistic network termed PCF-Net, which parameterizes the distribution of coordinate fields as Gaussian mixture models. By jointly optimizing coordinate fields and their confidence conditioned on dense flows, PCF-Net can work with various feature descriptors when quantifying the reliability of PCFs by confidence maps. An interesting observation of this work is that the learned confidence map converges to geometrically coherent and semantically consistent regions, which facilitates robust coordinate representation. By delivering the confident coordinates to keypoint/feature descriptors, we show that PCF-Net can be used as a plug-in to existing correspondence-dependent approaches. Extensive experiments on both indoor and outdoor datasets suggest that accurate geometric invariant coordinates help to achieve the state of the art in several correspondence problems, such as sparse feature matching, dense image registration, camera pose estimation, and consistency filtering. Further, the interpretable confidence map predicted by PCF-Net can also be leveraged to other novel applications from texture transfer to multi-homography classification.|
|**2023-06-07**|**StructuredMesh: 3D Structured Optimization of Façade Components on Photogrammetric Mesh Models using Binary Integer Programming**|Libin Wang et.al.|[2306.04184v1](http://arxiv.org/abs/2306.04184v1)|null|The lack of fa\c{c}ade structures in photogrammetric mesh models renders them inadequate for meeting the demands of intricate applications. Moreover, these mesh models exhibit irregular surfaces with considerable geometric noise and texture quality imperfections, making the restoration of structures challenging. To address these shortcomings, we present StructuredMesh, a novel approach for reconstructing fa\c{c}ade structures conforming to the regularity of buildings within photogrammetric mesh models. Our method involves capturing multi-view color and depth images of the building model using a virtual camera and employing a deep learning object detection pipeline to semi-automatically extract the bounding boxes of fa\c{c}ade components such as windows, doors, and balconies from the color image. We then utilize the depth image to remap these boxes into 3D space, generating an initial fa\c{c}ade layout. Leveraging architectural knowledge, we apply binary integer programming (BIP) to optimize the 3D layout's structure, encompassing the positions, orientations, and sizes of all components. The refined layout subsequently informs fa\c{c}ade modeling through instance replacement. We conducted experiments utilizing building mesh models from three distinct datasets, demonstrating the adaptability, robustness, and noise resistance of our proposed methodology. Furthermore, our 3D layout evaluation metrics reveal that the optimized layout enhances precision, recall, and F-score by 6.5%, 4.5%, and 5.5%, respectively, in comparison to the initial layout.|
|**2023-06-07**|**When to Read Documents or QA History: On Unified and Selective Open-domain QA**|Kyungjae Lee et.al.|[2306.04176v1](http://arxiv.org/abs/2306.04176v1)|null|This paper studies the problem of open-domain question answering, with the aim of answering a diverse range of questions leveraging knowledge resources. Two types of sources, QA-pair and document corpora, have been actively leveraged with the following complementary strength. The former is highly precise when the paraphrase of given question $q$ was seen and answered during training, often posed as a retrieval problem, while the latter generalizes better for unseen questions. A natural follow-up is thus leveraging both models, while a naive pipelining or integration approaches have failed to bring additional gains over either model alone. Our distinction is interpreting the problem as calibration, which estimates the confidence of predicted answers as an indicator to decide when to use a document or QA-pair corpus. The effectiveness of our method was validated on widely adopted benchmarks such as Natural Questions and TriviaQA.|
|**2023-06-07**|**BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives**|Sainan Liu et.al.|[2306.04166v1](http://arxiv.org/abs/2306.04166v1)|null|Implicit neural representation has emerged as a powerful method for reconstructing 3D scenes from 2D images. Given a set of camera poses and associated images, the models can be trained to synthesize novel, unseen views. In order to expand the use cases for implicit neural representations, we need to incorporate camera pose estimation capabilities as part of the representation learning, as this is necessary for reconstructing scenes from real-world video sequences where cameras are generally not being tracked. Existing approaches like COLMAP and, most recently, bundle-adjusting neural radiance field methods often suffer from lengthy processing times. These delays ranging from hours to days, arise from laborious feature matching, hardware limitations, dense point sampling, and long training times required by a multi-layer perceptron structure with a large number of parameters. To address these challenges, we propose a framework called bundle-adjusting accelerated neural graphics primitives (BAA-NGP). Our approach leverages accelerated sampling and hash encoding to expedite both pose refinement/estimation and 3D scene reconstruction. Experimental results demonstrate that our method achieves a more than 10 to 20 $\times$ speed improvement in novel view synthesis compared to other bundle-adjusting neural radiance field methods without sacrificing the quality of pose estimation.|
|**2023-06-07**|**Effect of viscosity on the dynamics of a non-equilibrium bubble in free-field and near a free-surface**|Y. S. Kannan et.al.|[2306.04129v1](http://arxiv.org/abs/2306.04129v1)|null|The effect of viscosity on the behaviour of a non-equilibrium bubble is investigated experimentally, in two scenarios; firstly, when the bubble is generated in the bulk of the fluid (termed as ``free-field'' bubble) and secondly when the bubble is generated near a free-surface (termed as ``free-surface'' bubble). The bubble is created using a low-voltage spark circuit and its dynamics is captured using a high-speed camera with back-lit illumination. The viscosity of the surrounding fluid is varied by using different grades of silicone oil. For a ``free-field'' bubble, the bubble oscillates radially and as the viscosity of the liquid increases, the number of oscillations, as well as the time-period of each oscillation, are increased. At high viscosities, the bubble also becomes stable and does not disintegrate into smaller bubbles. For ``free-surface'' bubbles, two parameters, namely, the initial distance of the bubble from the free-surface and the viscosity of the surrounding fluid are varied. It is observed that beyond a certain initial distance of the bubble from the free-surface, the bubble behaves as a ``free-field'' bubble with negligible influence of the free-surface on its dynamics. This limiting initial distance decreases as the liquid viscosity is increased and is not dependent on the bubble radius. For these bubbles, different behaviours of the free-surface in each liquid are also presented as a function of the two parameters.|
|**2023-06-07**|**Retrosynthesis Prediction with Local Template Retrieval**|Shufang Xie et.al.|[2306.04123v1](http://arxiv.org/abs/2306.04123v1)|null|Retrosynthesis, which predicts the reactants of a given target molecule, is an essential task for drug discovery. In recent years, the machine learing based retrosynthesis methods have achieved promising results. In this work, we introduce RetroKNN, a local reaction template retrieval method to further boost the performance of template-based systems with non-parametric retrieval. We first build an atom-template store and a bond-template store that contain the local templates in the training data, then retrieve from these templates with a k-nearest-neighbor (KNN) search during inference. The retrieved templates are combined with neural network predictions as the final output. Furthermore, we propose a lightweight adapter to adjust the weights when combing neural network and KNN predictions conditioned on the hidden representation and the retrieved templates. We conduct comprehensive experiments on two widely used benchmarks, the USPTO-50K and USPTO-MIT. Especially for the top-1 accuracy, we improved 7.1% on the USPTO-50K dataset and 12.0% on the USPTO-MIT dataset. These results demonstrate the effectiveness of our method.|
|**2023-06-06**|**Wearable Sensory Substitution for Proprioception via Deep Pressure**|Sreela Kodali et.al.|[2306.04034v1](http://arxiv.org/abs/2306.04034v1)|null|We propose a sensory substitution device that communicates one-degree-of-freedom proprioceptive feedback via deep pressure stimulation on the arm. The design is motivated by the need for a feedback modality detectable by individuals with a genetic condition known as PIEZO2 loss of function, which is characterized by absence of both proprioception and sense of light touch. We created a wearable and programmable prototype that applies up to 15 N of deep pressure stimulation to the forearm and includes an embedded force sensor. We conducted a study to evaluate the ability of participants without sensory impairment to control the position of a virtual arm to match a target angle communicated by deep pressure stimulation. A participant-specific calibration resulted in an average minimum detectable force of 0.41 N and maximum comfortable force of 6.42 N. We found that, after training, participants were able to significantly reduce angle error using the deep pressure haptic feedback compared to without it. Angle error increased only slightly with force, indicating that this sensory substitution method is a promising approach for individuals with PIEZO2 loss of function and other forms of sensory loss.|
|**2023-06-06**|**BokehOrNot: Transforming Bokeh Effect with Image Transformer and Lens Metadata Embedding**|Zhihao Yang et.al.|[2306.04032v1](http://arxiv.org/abs/2306.04032v1)|[link](https://github.com/indicator0/bokehornot)|Bokeh effect is an optical phenomenon that offers a pleasant visual experience, typically generated by high-end cameras with wide aperture lenses. The task of bokeh effect transformation aims to produce a desired effect in one set of lenses and apertures based on another combination. Current models are limited in their ability to render a specific set of bokeh effects, primarily transformations from sharp to blur. In this paper, we propose a novel universal method for embedding lens metadata into the model and introducing a loss calculation method using alpha masks from the newly released Bokeh Effect Transformation Dataset(BETD) [3]. Based on the above techniques, we propose the BokehOrNot model, which is capable of producing both blur-to-sharp and sharp-to-blur bokeh effect with various combinations of lenses and aperture sizes. Our proposed model outperforms current leading bokeh rendering and image restoration models and renders visually natural bokeh effects. Our code is available at: https://github.com/indicator0/bokehornot.|

## PPG

### Photoplethysmography
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-04**|**rPPG-MAE: Self-supervised Pre-training with Masked Autoencoders for Remote Physiological Measurement**|Xin Liu et.al.|[2306.02301v1](http://arxiv.org/abs/2306.02301v1)|null|Remote photoplethysmography (rPPG) is an important technique for perceiving human vital signs, which has received extensive attention. For a long time, researchers have focused on supervised methods that rely on large amounts of labeled data. These methods are limited by the requirement for large amounts of data and the difficulty of acquiring ground truth physiological signals. To address these issues, several self-supervised methods based on contrastive learning have been proposed. However, they focus on the contrastive learning between samples, which neglect the inherent self-similar prior in physiological signals and seem to have a limited ability to cope with noisy. In this paper, a linear self-supervised reconstruction task was designed for extracting the inherent self-similar prior in physiological signals. Besides, a specific noise-insensitive strategy was explored for reducing the interference of motion and illumination. The proposed framework in this paper, namely rPPG-MAE, demonstrates excellent performance even on the challenging VIPL-HR dataset. We also evaluate the proposed method on two public datasets, namely PURE and UBFC-rPPG. The results show that our method not only outperforms existing self-supervised methods but also exceeds the state-of-the-art (SOTA) supervised methods. One important observation is that the quality of the dataset seems more important than the size in self-supervised pre-training of rPPG. The source code is released at https://github.com/linuxsino/rPPG-MAE.|
|**2023-06-01**|**Privacy-Preserving Remote Heart Rate Estimation from Facial Videos**|Divij Gupta et.al.|[2306.01141v1](http://arxiv.org/abs/2306.01141v1)|null|Remote Photoplethysmography (rPPG) is the process of estimating PPG from facial videos. While this approach benefits from contactless interaction, it is reliant on videos of faces, which often constitutes an important privacy concern. Recent research has revealed that deep learning techniques are vulnerable to attacks, which can result in significant data breaches making deep rPPG estimation even more sensitive. To address this issue, we propose a data perturbation method that involves extraction of certain areas of the face with less identity-related information, followed by pixel shuffling and blurring. Our experiments on two rPPG datasets (PURE and UBFC) show that our approach reduces the accuracy of facial recognition algorithms by over 60%, with minimal impact on rPPG extraction. We also test our method on three facial recognition datasets (LFW, CALFW, and AgeDB), where our approach reduced performance by nearly 50%. Our findings demonstrate the potential of our approach as an effective privacy-preserving solution for rPPG estimation.|
|**2023-05-25**|**Mask Attack Detection Using Vascular-weighted Motion-robust rPPG Signals**|Chenglin Yao et.al.|[2305.15940v1](http://arxiv.org/abs/2305.15940v1)|null|Detecting 3D mask attacks to a face recognition system is challenging. Although genuine faces and 3D face masks show significantly different remote photoplethysmography (rPPG) signals, rPPG-based face anti-spoofing methods often suffer from performance degradation due to unstable face alignment in the video sequence and weak rPPG signals. To enhance the rPPG signal in a motion-robust way, a landmark-anchored face stitching method is proposed to align the faces robustly and precisely at the pixel-wise level by using both SIFT keypoints and facial landmarks. To better encode the rPPG signal, a weighted spatial-temporal representation is proposed, which emphasizes the face regions with rich blood vessels. In addition, characteristics of rPPG signals in different color spaces are jointly utilized. To improve the generalization capability, a lightweight EfficientNet with a Gated Recurrent Unit (GRU) is designed to extract both spatial and temporal features from the rPPG spatial-temporal representation for classification. The proposed method is compared with the state-of-the-art methods on five benchmark datasets under both intra-dataset and cross-dataset evaluations. The proposed method shows a significant and consistent improvement in performance over other state-of-the-art rPPG-based methods for face spoofing detection.|
|**2023-05-24**|**Promoting Generalization in Cross-Dataset Remote Photoplethysmography**|Nathan Vance et.al.|[2305.15199v1](http://arxiv.org/abs/2305.15199v1)|null|Remote Photoplethysmography (rPPG), or the remote monitoring of a subject's heart rate using a camera, has seen a shift from handcrafted techniques to deep learning models. While current solutions offer substantial performance gains, we show that these models tend to learn a bias to pulse wave features inherent to the training dataset. We develop augmentations to mitigate this learned bias by expanding both the range and variability of heart rates that the model sees while training, resulting in improved model convergence when training and cross-dataset generalization at test time. Through a 3-way cross dataset analysis we demonstrate a reduction in mean absolute error from over 13 beats per minute to below 3 beats per minute. We compare our method with other recent rPPG systems, finding similar performance under a variety of evaluation parameters.|
|**2023-05-23**|**Amplitude-Independent Machine Learning for PPG through Visibility Graphs and Transfer Learning**|Yuyang Miao et.al.|[2305.14062v1](http://arxiv.org/abs/2305.14062v1)|null|Photoplethysmography (PPG) signals are omnipresent in wearable devices, as they measure blood volume variations using LED technology. These signals provide insight into the body's circulatory system and can be employed to extract various bio-features, such as heart rate and vascular ageing. Although several algorithms have been proposed for this purpose, many exhibit limitations, including heavy reliance on human calibration, high signal quality requirements, and a lack of generalization. In this paper, we introduce a PPG signal processing framework that integrates graph theory and computer vision algorithms, which is invariant to affine transformations, offers rapid computation speed, and exhibits robust generalization across tasks and datasets.|
|**2023-05-21**|**Your smartphone could act as a pulse-oximeter and as a single-lead ECG**|Ahsan Mehmood et.al.|[2305.12583v1](http://arxiv.org/abs/2305.12583v1)|null|In the post-covid19 era, every new wave of the pandemic causes an increased concern among the masses to learn more about their state of well-being. Therefore, it is the need of the hour to come up with ubiquitous, low-cost, non-invasive tools for rapid and continuous monitoring of body vitals that reflect the status of one's overall health. In this backdrop, this work proposes a deep learning approach to turn a smartphone-the popular hand-held personal gadget-into a diagnostic tool to measure/monitor the three most important body vitals, i.e., pulse rate (PR), blood oxygen saturation level (aka SpO2), and respiratory rate (RR). Furthermore, we propose another method that could extract a single-lead electrocardiograph (ECG) of the subject. The proposed methods include the following core steps: subject records a small video of his/her fingertip by placing his/her finger on the rear camera of the smartphone, and the recorded video is pre-processed to extract the filtered and/or detrended video-photoplethysmography (vPPG) signal, which is then fed to custom-built convolutional neural networks (CNN), which eventually spit-out the vitals (PR, SpO2, and RR) as well as a single-lead ECG of the subject. To be precise, the contribution of this paper is two-fold: 1) estimation of the three body vitals (PR, SpO2, RR) from the vPPG data using custom-built CNNs, vision transformer, and most importantly by CLIP model; 2) a novel discrete cosine transform+feedforward neural network-based method that translates the recorded video- PPG signal to a single-lead ECG signal. The proposed method is anticipated to find its application in several use-case scenarios, e.g., remote healthcare, mobile health, fitness, sports, etc.|
|**2023-05-09**|**Predicting Cardiovascular Disease Risk using Photoplethysmography and Deep Learning**|Wei-Hung Weng et.al.|[2305.05648v1](http://arxiv.org/abs/2305.05648v1)|null|Cardiovascular diseases (CVDs) are responsible for a large proportion of premature deaths in low- and middle-income countries. Early CVD detection and intervention is critical in these populations, yet many existing CVD risk scores require a physical examination or lab measurements, which can be challenging in such health systems due to limited accessibility. Here we investigated the potential to use photoplethysmography (PPG), a sensing technology available on most smartphones that can potentially enable large-scale screening at low cost, for CVD risk prediction. We developed a deep learning PPG-based CVD risk score (DLS) to predict the probability of having major adverse cardiovascular events (MACE: non-fatal myocardial infarction, stroke, and cardiovascular death) within ten years, given only age, sex, smoking status and PPG as predictors. We compared the DLS with the office-based refit-WHO score, which adopts the shared predictors from WHO and Globorisk scores (age, sex, smoking status, height, weight and systolic blood pressure) but refitted on the UK Biobank (UKB) cohort. In UKB cohort, DLS's C-statistic (71.1%, 95% CI 69.9-72.4) was non-inferior to office-based refit-WHO score (70.9%, 95% CI 69.7-72.2; non-inferiority margin of 2.5%, p<0.01). The calibration of the DLS was satisfactory, with a 1.8% mean absolute calibration error. Adding DLS features to the office-based score increased the C-statistic by 1.0% (95% CI 0.6-1.4). DLS predicts ten-year MACE risk comparable with the office-based refit-WHO score. It provides a proof-of-concept and suggests the potential of a PPG-based approach strategies for community-based primary prevention in resource-limited regions.|
|**2023-04-28**|**Non-Contact Heart Rate Measurement from Deteriorated Videos**|Nhi Nguyen et.al.|[2304.14789v1](http://arxiv.org/abs/2304.14789v1)|null|Remote photoplethysmography (rPPG) offers a state-of-the-art, non-contact methodology for estimating human pulse by analyzing facial videos. Despite its potential, rPPG methods can be susceptible to various artifacts, such as noise, occlusions, and other obstructions caused by sunglasses, masks, or even involuntary facial contact, such as individuals inadvertently touching their faces. In this study, we apply image processing transformations to intentionally degrade video quality, mimicking these challenging conditions, and subsequently evaluate the performance of both non-learning and learning-based rPPG methods on the deteriorated data. Our results reveal a significant decrease in accuracy in the presence of these artifacts, prompting us to propose the application of restoration techniques, such as denoising and inpainting, to improve heart-rate estimation outcomes. By addressing these challenging conditions and occlusion artifacts, our approach aims to make rPPG methods more robust and adaptable to real-world situations. To assess the effectiveness of our proposed methods, we undertake comprehensive experiments on three publicly available datasets, encompassing a wide range of scenarios and artifact types. Our findings underscore the potential to construct a robust rPPG system by employing an optimal combination of restoration algorithms and rPPG techniques. Moreover, our study contributes to the advancement of privacy-conscious rPPG methodologies, thereby bolstering the overall utility and impact of this innovative technology in the field of remote heart-rate estimation under realistic and diverse conditions.|
|**2023-04-21**|**Heart Rate Extraction from Abdominal Audio Signals**|Jake Stuchbury-Wass et.al.|[2304.11020v1](http://arxiv.org/abs/2304.11020v1)|null|Abdominal sounds (ABS) have been traditionally used for assessing gastrointestinal (GI) disorders. However, the assessment requires a trained medical professional to perform multiple abdominal auscultation sessions, which is resource-intense and may fail to provide an accurate picture of patients' continuous GI wellbeing. This has generated a technological interest in developing wearables for continuous capture of ABS, which enables a fuller picture of patient's GI status to be obtained at reduced cost. This paper seeks to evaluate the feasibility of extracting heart rate (HR) from such ABS monitoring devices. The collection of HR directly from these devices would enable gathering vital signs alongside GI data without the need for additional wearable devices, providing further cost benefits and improving general usability. We utilised a dataset containing 104 hours of ABS audio, collected from the abdomen using an e-stethoscope, and electrocardiogram as ground truth. Our evaluation shows for the first time that we can successfully extract HR from audio collected from a wearable on the abdomen. As heart sounds collected from the abdomen suffer from significant noise from GI and respiratory tracts, we leverage wavelet denoising for improved heart beat detection. The mean absolute error of the algorithm for average HR is 3.4 BPM with mean directional error of -1.2 BPM over the whole dataset. A comparison to photoplethysmography-based wearable HR sensors shows that our approach exhibits comparable accuracy to consumer wrist-worn wearables for average and instantaneous heart rate.|
|**2023-04-21**|**IoT-Based Solution for Paraplegic Sufferer to Send Signals to Physician via Internet**|L. Srinivasan et.al.|[2304.10840v1](http://arxiv.org/abs/2304.10840v1)|null|We come across hospitals and non-profit organizations that care for people with paralysis who have experienced all or portion of their physique being incapacitated by the paralyzing attack. Due to a lack of motor coordination by their mind, these persons are typically unable to communicate their requirements because they can speak clearly or use sign language. In such a case, we suggest a system that enables a disabled person to move any area of his body capable of moving to broadcast a text on the LCD. This method also addresses the circumstance in which the patient cannot be attended to in person and instead sends an SMS message using GSM. By detecting the user part's tilt direction, our suggested system operates. As a result, patients can communicate with physicians, therapists, or their loved ones at home or work over the web. Case-specific data, such as heart rate, must be continuously reported in health centers. The suggested method tracks the body of the case's pulse rate and other comparable data. For instance, photoplethysmography is used to assess heart rate. The decoded periodic data is transmitted continually via a Microcontroller coupled to a transmitting module. The croaker's cabin contains a receiver device that obtains and deciphers data as well as constantly exhibits it on Graphical interfaces viewable on the laptop. As a result, the croaker can monitor and handle multiple situations at once.|
|**2023-04-14**|**PPG Signals for Hypertension Diagnosis: A Novel Method using Deep Learning Models**|Graham Frederick et.al.|[2304.06952v1](http://arxiv.org/abs/2304.06952v1)|null|Hypertension is a medical condition characterized by high blood pressure, and classifying it into its various stages is crucial to managing the disease. In this project, a novel method is proposed for classifying stages of hypertension using Photoplethysmography (PPG) signals and deep learning models, namely AvgPool_VGG-16. The PPG signal is a non-invasive method of measuring blood pressure through the use of light sensors that measure the changes in blood volume in the microvasculature of tissues. PPG images from the publicly available blood pressure classification dataset were used to train the model. Multiclass classification for various PPG stages were done. The results show the proposed method achieves high accuracy in classifying hypertension stages, demonstrating the potential of PPG signals and deep learning models in hypertension diagnosis and management.|
|**2023-04-05**|**Deep Learning Systems for Advanced Driving Assistance**|Francesco Rundo et.al.|[2304.06041v1](http://arxiv.org/abs/2304.06041v1)|null|Next generation cars embed intelligent assessment of car driving safety through innovative solutions often based on usage of artificial intelligence. The safety driving monitoring can be carried out using several methodologies widely treated in scientific literature. In this context, the author proposes an innovative approach that uses ad-hoc bio-sensing system suitable to reconstruct the physio-based attentional status of the car driver. To reconstruct the car driver physiological status, the author proposed the use of a bio-sensing probe consisting of a coupled LEDs at Near infrared (NiR) spectrum with a photodetector. This probe placed over the monitored subject allows to detect a physiological signal called PhotoPlethysmoGraphy (PPG). The PPG signal formation is regulated by the change in oxygenated and non-oxygenated hemoglobin concentration in the monitored subject bloodstream which will be directly connected to cardiac activity in turn regulated by the Autonomic Nervous System (ANS) that characterizes the subject's attention level. This so designed car driver drowsiness monitoring will be combined with further driving safety assessment based on correlated intelligent driving scenario understanding.|
|**2023-03-23**|**Efficient and Direct Inference of Heart Rate Variability using Both Signal Processing and Machine Learning**|Yuntong Zhang et.al.|[2303.13637v1](http://arxiv.org/abs/2303.13637v1)|null|Heart Rate Variability (HRV) measures the variation of the time between consecutive heartbeats and is a major indicator of physical and mental health. Recent research has demonstrated that photoplethysmography (PPG) sensors can be used to infer HRV. However, many prior studies had high errors because they only employed signal processing or machine learning (ML), or because they indirectly inferred HRV, or because there lacks large training datasets. Many prior studies may also require large ML models. The low accuracy and large model sizes limit their applications to small embedded devices and potential future use in healthcare. To address the above issues, we first collected a large dataset of PPG signals and HRV ground truth. With this dataset, we developed HRV models that combine signal processing and ML to directly infer HRV. Evaluation results show that our method had errors between 3.5% to 25.7% and outperformed signal-processing-only and ML-only methods. We also explored different ML models, which showed that Decision Trees and Multi-level Perceptrons have 13.0% and 9.1% errors on average with models at most hundreds of KB and inference time less than 1ms. Hence, they are more suitable for small embedded devices and potentially enable the future use of PPG-based HRV monitoring in healthcare.|
|**2023-03-23**|**PPG-based Heart Rate Estimation with Efficient Sensor Sampling and Learning Models**|Yuntong Zhang et.al.|[2303.13636v1](http://arxiv.org/abs/2303.13636v1)|null|Recent studies showed that Photoplethysmography (PPG) sensors embedded in wearable devices can estimate heart rate (HR) with high accuracy. However, despite of prior research efforts, applying PPG sensor based HR estimation to embedded devices still faces challenges due to the energy-intensive high-frequency PPG sampling and the resource-intensive machine-learning models. In this work, we aim to explore HR estimation techniques that are more suitable for lower-power and resource-constrained embedded devices. More specifically, we seek to design techniques that could provide high-accuracy HR estimation with low-frequency PPG sampling, small model size, and fast inference time. First, we show that by combining signal processing and ML, it is possible to reduce the PPG sampling frequency from 125 Hz to only 25 Hz while providing higher HR estimation accuracy. This combination also helps to reduce the ML model feature size, leading to smaller models. Additionally, we present a comprehensive analysis on different ML models and feature sizes to compare their accuracy, model size, and inference time. The models explored include Decision Tree (DT), Random Forest (RF), K-nearest neighbor (KNN), Support vector machines (SVM), and Multi-layer perceptron (MLP). Experiments were conducted using both a widely-utilized dataset and our self-collected dataset. The experimental results show that our method by combining signal processing and ML had only 5% error for HR estimation using low-frequency PPG data. Moreover, our analysis showed that DT models with 10 to 20 input features usually have good accuracy, while are several magnitude smaller in model sizes and faster in inference time.|
|**2023-03-21**|**Motion Matters: Neural Motion Transfer for Better Camera Physiological Sensing**|Akshay Paruchuri et.al.|[2303.12059v2](http://arxiv.org/abs/2303.12059v2)|[link](https://github.com/Roni-Lab/MA-rPPG-Video-Toolbox)|Machine learning models for camera-based physiological measurement can have weak generalization due to a lack of representative training data. Body motion is one of the most significant sources of noise when attempting to recover the subtle cardiac pulse from a video. We explore motion transfer as a form of data augmentation to introduce motion variation while preserving physiological changes. We adapt a neural video synthesis approach to augment videos for the task of remote photoplethysmography (PPG) and study the effects of motion augmentation with respect to 1) the magnitude and 2) the type of motion. After training on motion-augmented versions of publicly available datasets, the presented inter-dataset results on five benchmark datasets show improvements of up to 75% over existing state-of-the-art results. Our findings illustrate the utility of motion transfer as a data augmentation technique for improving the generalization of models for camera-based physiological sensing. We release our code and pre-trained models for using motion transfer as a data augmentation technique on our project page: https://motion-matters.github.io/|
|**2023-03-17**|**HDformer: A Higher Dimensional Transformer for Diabetes Detection Utilizing Long Range Vascular Signals**|Ella Lan et.al.|[2303.11340v1](http://arxiv.org/abs/2303.11340v1)|null|Diabetes mellitus is a worldwide concern, and early detection can help to prevent serious complications. Low-cost, non-invasive detection methods, which take cardiovascular signals into deep learning models, have emerged. However, limited accuracy constrains their clinical usage. In this paper, we present a new Transformer-based architecture, Higher Dimensional Transformer (HDformer), which takes long-range photoplethysmography (PPG) signals to detect diabetes. The long-range PPG contains broader and deeper signal contextual information compared to the less-than-one-minute PPG signals commonly utilized in existing research. To increase the capability and efficiency of processing the long range data, we propose a new attention module Time Square Attention (TSA), reducing the volume of the tokens by more than 10x, while retaining the local/global dependencies. It converts the 1-dimensional inputs into 2-dimensional representations and groups adjacent points into a single 2D token, using the 2D Transformer models as the backbone of the encoder. It generates the dynamic patch sizes into a gated mixture-of-experts (MoE) network as decoder, which optimizes the learning on different attention areas. Extensive experimentations show that HDformer results in the state-of-the-art performance (sensitivity 98.4, accuracy 97.3, specificity 92.8, and AUC 0.929) on the standard MIMIC-III dataset, surpassing existing studies. This work is the first time to take long-range, non-invasive PPG signals via Transformer for diabetes detection, achieving a more scalable and convenient solution compared to traditional invasive approaches. The proposed HDformer can also be scaled to analyze general long-range biomedical waveforms. A wearable prototype finger-ring is designed as a proof of concept.|
|**2023-03-16**|**Full-Body Cardiovascular Sensing with Remote Photoplethysmography**|Lu Niu et.al.|[2303.09638v1](http://arxiv.org/abs/2303.09638v1)|null|Remote photoplethysmography (rPPG) allows for noncontact monitoring of blood volume changes from a camera by detecting minor fluctuations in reflected light. Prior applications of rPPG focused on face videos. In this paper we explored the feasibility of rPPG from non-face body regions such as the arms, legs, and hands. We collected a new dataset titled Multi-Site Physiological Monitoring (MSPM), which will be released with this paper. The dataset consists of 90 frames per second video of exposed arms, legs, and face, along with 10 synchronized PPG recordings. We performed baseline heart rate estimation experiments from non-face regions with several state-of-the-art rPPG approaches, including chrominance-based (CHROM), plane-orthogonal-to-skin (POS) and RemotePulseNet (RPNet). To our knowledge, this is the first evaluation of the fidelity of rPPG signals simultaneously obtained from multiple regions of a human body. Our experiments showed that skin pixels from arms, legs, and hands are all potential sources of the blood volume pulse. The best-performing approach, POS, achieved a mean absolute error peaking at 7.11 beats per minute from non-facial body parts compared to 1.38 beats per minute from the face. Additionally, we performed experiments on pulse transit time (PTT) from both the contact PPG and rPPG signals. We found that remote PTT is possible with moderately high frame rate video when distal locations on the body are visible. These findings and the supporting dataset should facilitate new research on non-face rPPG and monitoring blood flow dynamics over the whole body with a camera.|
|**2023-03-16**|**Image Enhancement for Remote Photoplethysmography in a Low-Light Environment**|Lin Xi et.al.|[2303.09336v1](http://arxiv.org/abs/2303.09336v1)|[link](https://github.com/xilin1991/Large-scale-Multi-illumination-HR-Database)|With the improvement of sensor technology and significant algorithmic advances, the accuracy of remote heart rate monitoring technology has been significantly improved. Despite of the significant algorithmic advances, the performance of rPPG algorithm can degrade in the long-term, high-intensity continuous work occurred in evenings or insufficient light environments. One of the main challenges is that the lost facial details and low contrast cause the failure of detection and tracking. Also, insufficient lighting in video capturing hurts the quality of physiological signal. In this paper, we collect a large-scale dataset that was designed for remote heart rate estimation recorded with various illumination variations to evaluate the performance of the rPPG algorithm (Green, ICA, and POS). We also propose a low-light enhancement solution (technical solution) for remote heart rate estimation under the low-light condition. Using collected dataset, we found 1) face detection algorithm cannot detect faces in video captured in low light conditions; 2) A decrease in the amplitude of the pulsatile signal will lead to the noise signal to be in the dominant position; and 3) the chrominance-based method suffers from the limitation in the assumption about skin-tone will not hold, and Green and ICA method receive less influence than POS in dark illuminance environment. The proposed solution for rPPG process is effective to detect and improve the signal-to-noise ratio and precision of the pulsatile signal.|
|**2023-03-14**|**Non-Contrastive Unsupervised Learning of Physiological Signals from Video**|Jeremy Speth et.al.|[2303.07944v1](http://arxiv.org/abs/2303.07944v1)|[link](https://github.com/cvrl/sinc-rppg)|Subtle periodic signals such as blood volume pulse and respiration can be extracted from RGB video, enabling remote health monitoring at low cost. Advancements in remote pulse estimation -- or remote photoplethysmography (rPPG) -- are currently driven by deep learning solutions. However, modern approaches are trained and evaluated on benchmark datasets with associated ground truth from contact-PPG sensors. We present the first non-contrastive unsupervised learning framework for signal regression to break free from the constraints of labelled video data. With minimal assumptions of periodicity and finite bandwidth, our approach is capable of discovering the blood volume pulse directly from unlabelled videos. We find that encouraging sparse power spectra within normal physiological bandlimits and variance over batches of power spectra is sufficient for learning visual features of periodic signals. We perform the first experiments utilizing unlabelled video data not specifically created for rPPG to train robust pulse rate estimators. Given the limited inductive biases and impressive empirical results, the approach is theoretically capable of discovering other periodic signals from video, enabling multiple physiological measurements without the need for ground truth signals. Codes to fully reproduce the experiments are made available along with the paper.|
|**2023-03-14**|**ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario**|Alexander Heimerl et.al.|[2303.07742v1](http://arxiv.org/abs/2303.07742v1)|null|We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.|
|**2023-03-11**|**Hallucinated Heartbeats: Anomaly-Aware Remote Pulse Estimation**|Jeremy Speth et.al.|[2303.06452v1](http://arxiv.org/abs/2303.06452v1)|null|Camera-based physiological monitoring, especially remote photoplethysmography (rPPG), is a promising tool for health diagnostics, and state-of-the-art pulse estimators have shown impressive performance on benchmark datasets. We argue that evaluations of modern solutions may be incomplete, as we uncover failure cases for videos without a live person, or in the presence of severe noise. We demonstrate that spatiotemporal deep learning models trained only with live samples "hallucinate" a genuine-shaped pulse on anomalous and noisy videos, which may have negative consequences when rPPG models are used by medical personnel. To address this, we offer: (a) An anomaly detection model, built on top of the predicted waveforms. We compare models trained in open-set (unknown abnormal predictions) and closed-set (abnormal predictions known when training) settings; (b) An anomaly-aware training regime that penalizes the model for predicting periodic signals from anomalous videos. Extensive experimentation with eight research datasets (rPPG-specific: DDPM, CDDPM, PURE, UBFC, ARPM; deep fakes: DFDC; face presentation attack detection: HKBU-MARs; rPPG outlier: KITTI) show better accuracy of anomaly detection for deep learning models incorporating the proposed training (75.8%), compared to models trained regularly (73.7%) and to hand-crafted rPPG methods (52-62%).|
|**2023-03-10**|**Neuron Structure Modeling for Generalizable Remote Physiological Measurement**|Hao Lu et.al.|[2303.05955v1](http://arxiv.org/abs/2303.05955v1)|[link](https://github.com/lupaopao/nest)|Remote photoplethysmography (rPPG) technology has drawn increasing attention in recent years. It can extract Blood Volume Pulse (BVP) from facial videos, making many applications like health monitoring and emotional analysis more accessible. However, as the BVP signal is easily affected by environmental changes, existing methods struggle to generalize well for unseen domains. In this paper, we systematically address the domain shift problem in the rPPG measurement task. We show that most domain generalization methods do not work well in this problem, as domain labels are ambiguous in complicated environmental changes. In light of this, we propose a domain-label-free approach called NEuron STructure modeling (NEST). NEST improves the generalization capacity by maximizing the coverage of feature space during training, which reduces the chance for under-optimized feature activation during inference. Besides, NEST can also enrich and enhance domain invariant features across multi-domain. We create and benchmark a large-scale domain generalization protocol for the rPPG measurement task. Extensive experiments show that our approach outperforms the state-of-the-art methods on both cross-dataset and intra-dataset settings.|
|**2023-02-08**|**MMPD: Multi-Domain Mobile Video Physiology Dataset**|Jiankai Tang et.al.|[2302.03840v2](http://arxiv.org/abs/2302.03840v2)|[link](https://github.com/thu-cs-pi/mmpd_rppg_dataset)|Remote photoplethysmography (rPPG) is an attractive method for noninvasive, convenient and concomitant measurement of physiological vital signals. Public benchmark datasets have served a valuable role in the development of this technology and improvements in accuracy over recent years.However, there remain gaps in the public datasets.First, despite the ubiquity of cameras on mobile devices, there are few datasets recorded specifically with mobile phone cameras. Second, most datasets are relatively small and therefore are limited in diversity, both in appearance (e.g., skin tone), behaviors (e.g., motion) and environment (e.g., lighting conditions). In an effort to help the field advance, we present the Multi-domain Mobile Video Physiology Dataset (MMPD), comprising 11 hours of recordings from mobile phones of 33 subjects. The dataset is designed to capture videos with greater representation across skin tone, body motion, and lighting conditions. MMPD is comprehensive with eight descriptive labels and can be used in conjunction with the rPPG-toolbox. The reliability of the dataset is verified by mainstream unsupervised methods and neural methods. The GitHub repository of our dataset: https://github.com/THU-CS-PI/MMPD_rPPG_dataset.|
|**2023-02-07**|**Can gamification reduce the burden of self-reporting in mHealth applications? A feasibility study using machine learning from smartwatch data to estimate cognitive load**|Michal K. Grzeszczyk et.al.|[2302.03616v2](http://arxiv.org/abs/2302.03616v2)|null|The effectiveness of digital treatments can be measured by requiring patients to self-report their state through applications, however, it can be overwhelming and causes disengagement. We conduct a study to explore the impact of gamification on self-reporting. Our approach involves the creation of a system to assess cognitive load (CL) through the analysis of photoplethysmography (PPG) signals. The data from 11 participants is utilized to train a machine learning model to detect CL. Subsequently, we create two versions of surveys: a gamified and a traditional one. We estimate the CL experienced by other participants (13) while completing surveys. We find that CL detector performance can be enhanced via pre-training on stress detection tasks. For 10 out of 13 participants, a personalized CL detector can achieve an F1 score above 0.7. We find no difference between the gamified and non-gamified surveys in terms of CL but participants prefer the gamified version.|
|**2023-02-07**|**PhysFormer++: Facial Video-based Physiological Measurement with SlowFast Temporal Difference Transformer**|Zitong Yu et.al.|[2302.03548v1](http://arxiv.org/abs/2302.03548v1)|null|Remote photoplethysmography (rPPG), which aims at measuring heart activities and physiological signals from facial video without any contact, has great potential in many applications (e.g., remote healthcare and affective computing). Recent deep learning approaches focus on mining subtle rPPG clues using convolutional neural networks with limited spatio-temporal receptive fields, which neglect the long-range spatio-temporal perception and interaction for rPPG modeling. In this paper, we propose two end-to-end video transformer based architectures, namely PhysFormer and PhysFormer++, to adaptively aggregate both local and global spatio-temporal features for rPPG representation enhancement. As key modules in PhysFormer, the temporal difference transformers first enhance the quasi-periodic rPPG features with temporal difference guided global attention, and then refine the local spatio-temporal representation against interference. To better exploit the temporal contextual and periodic rPPG clues, we also extend the PhysFormer to the two-pathway SlowFast based PhysFormer++ with temporal difference periodic and cross-attention transformers. Furthermore, we propose the label distribution learning and a curriculum learning inspired dynamic constraint in frequency domain, which provide elaborate supervisions for PhysFormer and PhysFormer++ and alleviate overfitting. Comprehensive experiments are performed on four benchmark datasets to show our superior performance on both intra- and cross-dataset testings. Unlike most transformer networks needed pretraining from large-scale datasets, the proposed PhysFormer family can be easily trained from scratch on rPPG datasets, which makes it promising as a novel transformer baseline for the rPPG community.|
|**2023-01-16**|**A Deep Learning & Fast Wavelet Transform-based Hybrid Approach for Denoising of PPG Signals**|Rabia Ahmed et.al.|[2301.06549v1](http://arxiv.org/abs/2301.06549v1)|null|This letter presents a novel hybrid method that leverages deep learning to exploit the multi-resolution analysis capability of the wavelets, in order to denoise a photoplethysmography (PPG) signal. Under the proposed method, a noisy PPG sequence of length N is first decomposed into L detailed coefficients using the fast wavelet transform (FWT). Then, the clean PPG sequence is reconstructed as follows. A custom feedforward neural network (FFNN) provides the binary weights for each of the wavelet sub-signals outputted by the inverse-FWT block. This way, all those sub-signals which correspond to noise or artefacts are discarded during reconstruction. The FFNN is trained on the Beth Israel Deaconess Medical Center (BIDMC) dataset under the supervised learning framework, whereby we compute the mean squared-error (MSE) between the denoised sequence and the reference clean PPG signal, and compute the gradient of the MSE for the back-propagation. Numerical results show that the proposed method effectively denoises the corrupted PPG and video-PPG signal.|
|**2023-01-07**|**A Greedy-optimized Framework for Heart Rate Variability Monitoring during Daily Activities using Wearable Photoplethysmography**|Luffina C. Huang et.al.|[2301.02906v1](http://arxiv.org/abs/2301.02906v1)|null|Continuous monitoring of inter-beat-interval (IBI) and heart rate variability (HRV) provides insights in cardiovascular, neurological, and mental health. Photoplethysmography (PPG) from wearables assures convenient measurement of IBI. However, PPG is susceptible to motion artifacts, considerably deteriorating the accuracy of IBIs estimation. Although a multi-channel model in previous study improves accuracy, prevailing compact commercial wearables would favor single-channel sensors, causing benefits of multi-channel applications to have restrictions. In this paper, a greedy-optimized framework is proposed for measurement of IBI and HRV featuring single-channel and multi-channel PPG signals collected during daily activities. Utilizing the fact of continuity in heartbeats, the IBI estimation problem is converted into the shortest path problem in a directed acyclic graph, where candidate heartbeats from the noisy PPG are regarded as vertices. The framework exploits a convex penalty function to optimize weight assignment in the shortest path calculation and a greedy-optimized fusion method to mitigate overly fluctuating patterns in estimated IBIs. The results achieve correlation of 0.96 with percentage error of 3.2% for IBI estimation using single-channel PPG signals from the 2015 IEEE Signal Processing Cup dataset, where percentage error is reduced by 58.4% and correlation is improved by 11.6% in comparison to those without greedy-optimized fusion. In the multi-channel model, it achieves correlation of 0.98 with percentage error of 2.2%. Estimated and true HRV parameters are also highly correlated with low percentage errors. This paper further validates these techniques on the PPG-DaLiA dataset, indicating the robustness of the proposed framework.|
|**2022-12-22**|**Rapid Extraction of Respiratory Waveforms from Photoplethysmography: A Deep Encoder Approach**|Harry J. Davies et.al.|[2212.12578v1](http://arxiv.org/abs/2212.12578v1)|null|Much of the information of breathing is contained within the photoplethysmography (PPG) signal, through changes in venous blood flow, heart rate and stroke volume. We aim to leverage this fact, by employing a novel deep learning framework which is a based on a repurposed convolutional autoencoder. Our model aims to encode all of the relevant respiratory information contained within photoplethysmography waveform, and decode it into a waveform that is similar to a gold standard respiratory reference. The model is employed on two photoplethysmography data sets, namely Capnobase and BIDMC. We show that the model is capable of producing respiratory waveforms that approach the gold standard, while in turn producing state of the art respiratory rate estimates. We also show that when it comes to capturing more advanced respiratory waveform characteristics such as duty cycle, our model is for the most part unsuccessful. A suggested reason for this, in light of a previous study on in-ear PPG, is that the respiratory variations in finger-PPG are far weaker compared with other recording locations. Importantly, our model can perform these waveform estimates in a fraction of a millisecond, giving it the capacity to produce over 6 hours of respiratory waveforms in a single second. Moreover, we attempt to interpret the behaviour of the kernel weights within the model, showing that in part our model intuitively selects different breathing frequencies. The model proposed in this work could help to improve the usefulness of consumer PPG-based wearables for medical applications, where detailed respiratory information is required.|
|**2022-11-30**|**Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos**|Jianwei Li et.al.|[2211.16922v3](http://arxiv.org/abs/2211.16922v3)|[link](https://github.com/ljw-git/arbitrary_resolution_rppg)|Remote photoplethysmography (rPPG) enables non-contact heart rate (HR) estimation from facial videos which gives significant convenience compared with traditional contact-based measurements. In the real-world long-term health monitoring scenario, the distance of the participants and their head movements usually vary by time, resulting in the inaccurate rPPG measurement due to the varying face resolution and complex motion artifacts. Different from the previous rPPG models designed for a constant distance between camera and participants, in this paper, we propose two plug-and-play blocks (i.e., physiological signal feature extraction block (PFE) and temporal face alignment block (TFA)) to alleviate the degradation of changing distance and head motion. On one side, guided with representative-area information, PFE adaptively encodes the arbitrary resolution facial frames to the fixed-resolution facial structure features. On the other side, leveraging the estimated optical flow, TFA is able to counteract the rPPG signal confusion caused by the head movement thus benefit the motion-robust rPPG signal recovery. Besides, we also train the model with a cross-resolution constraint using a two-stream dual-resolution framework, which further helps PFE learn resolution-robust facial rPPG features. Extensive experiments on three benchmark datasets (UBFC-rPPG, COHFACE and PURE) demonstrate the superior performance of the proposed method. One highlight is that with PFE and TFA, the off-the-shelf spatio-temporal rPPG models can predict more robust rPPG signals under both varying face resolution and severe head movement scenarios. The codes are available at https://github.com/LJW-GIT/Arbitrary_Resolution_rPPG.|
|**2022-11-07**|**Cluster consistency: Simple yet effect robust learning algorithm on large-scale photoplethysmography for atrial fibrillation detection in the presence of real-world label noise**|Cheng Ding et.al.|[2211.03333v1](http://arxiv.org/abs/2211.03333v1)|null|Obtaining large-scale well-annotated is always a daunting challenge, especially in the medical research domain because of the shortage of domain expert. Instead of human annotation, in this work, we use the alarm information generated from bed-side monitor to get the pseudo label for the co-current photoplethysmography (PPG) signal. Based on this strategy, we end up with over 8 million 30-second PPG segment. To solve the label noise caused by false alarms, we propose the cluster consistency, which use an unsupervised auto-encoder (hence not subject to label noise) approach to cluster training samples into a finite number of clusters. Then the learned cluster membership is used in the subsequent supervised learning phase to force the distance in the latent space of samples in the same cluster to be small while that of samples in different clusters to be big. In the experiment, we compare with the state-of-the-art algorithms and test on external datasets. The results show the superiority of our method in both classification performance and efficiency.|

## apple

### apple watch
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-06**|**On Rado numbers for equations with unit fractions**|Collier Gaiser et.al.|[2306.04029v1](http://arxiv.org/abs/2306.04029v1)|null|Let $f_r(k)$ be the smallest positive integer $n$ such that every $r$-coloring of $\{1,2,...,n\}$ has a monochromatic solution to the nonlinear equation \[1/x_1+\cdots+1/x_k=1/y,\] where $x_1,...,x_k$ are not necessarily distinct. Brown and R\"{o}dl [Bull. Aust. Math. Soc. 43(1991): 387-392] proved that $f_2(k)=O(k^6)$. In this paper, we prove that $f_2(k)=O(k^3)$.   The main ingredient in our proof is a finite set $A\subseteq\mathbb{N}$ such that every $2$-coloring of $A$ has a monochromatic solution to the linear equation $x_1+\cdots+x_k=y$ and the least common multiple of $A$ is sufficiently small. This approach can also be used to study $f_r(k)$ with $r>2$. For example, a recent result of Boza, Mar\'{i}n, Revuelta, and Sanz [Discrete Appl. Math. 263(2019): 59-68] implies that $f_3(k)=O(k^{43})$.|
|**2023-06-06**|**Agent Performing Autonomous Stock Trading under Good and Bad Situations**|Yunfei Luo et.al.|[2306.03985v1](http://arxiv.org/abs/2306.03985v1)|[link](https://github.com/yunfeiluo/autonomous-stock-trading)|Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft, and IBM. These stocks are among the popular ones, and the changes in trends are representative in terms of having good and bad situations. We showed that before 2021, the three reinforcement methods we have tried always provide promising profit returns with total annual rates around $70\%$ to $90\%$, while maintain a positive profit return after 2021 with total annual rates around 2% to 7%.|
|**2023-06-06**|**Minimizing Hitting Time between Disparate Groups with Shortcut Edges**|Florian Adriaens et.al.|[2306.03571v1](http://arxiv.org/abs/2306.03571v1)|null|Structural bias or segregation of networks refers to situations where two or more disparate groups are present in the network, so that the groups are highly connected internally, but loosely connected to each other. In many cases it is of interest to increase the connectivity of disparate groups so as to, e.g., minimize social friction, or expose individuals to diverse viewpoints. A commonly-used mechanism for increasing the network connectivity is to add edge shortcuts between pairs of nodes. In many applications of interest, edge shortcuts typically translate to recommendations, e.g., what video to watch, or what news article to read next. The problem of reducing structural bias or segregation via edge shortcuts has recently been studied in the literature, and random walks have been an essential tool for modeling navigation and connectivity in the underlying networks. Existing methods, however, either do not offer approximation guarantees, or engineer the objective so that it satisfies certain desirable properties that simplify the optimization~task. In this paper we address the problem of adding a given number of shortcut edges in the network so as to directly minimize the average hitting time and the maximum hitting time between two disparate groups. Our algorithm for minimizing average hitting time is a greedy bicriteria that relies on supermodularity. In contrast, maximum hitting time is not supermodular. Despite, we develop an approximation algorithm for that objective as well, by leveraging connections with average hitting time and the asymmetric k-center problem.|
|**2023-06-06**|**Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation**|Xiao Lin et.al.|[2306.03392v1](http://arxiv.org/abs/2306.03392v1)|null|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|
|**2023-06-05**|**Spin Hall magnetoresistance in Pt/Y$_{3}$Fe$_{5}$O$_{12}$ bilayers grown on Si and Gd$_{3}$Ga$_{5}$O$_{12}$ substrates**|Kenta Fukushima et.al.|[2306.02575v1](http://arxiv.org/abs/2306.02575v1)|null|We study spin Hall magnetoresistance (SMR) in Pt/ferrimagnetic insulator Y$_{3}$Fe$_{5}$O$_{12}$ (YIG) bilayers by focusing on crystallinity, magnetization, and interface roughness by controlling post-annealing temperatures. The SMR in the Pt/YIG grown on Si substrate is comparable to that grown on widely used Gd$_{3}$Ga$_{5}$O$_{12}$ substrate, indicating that the large SMR can be achieved irrespective to the crystallinity. We deduced the spin mixing conductance from the Pt thickness dependence of the SMR to find the high interface quality of the optimized Pt/YIG grown on Si in terms of spin current. We also clarified that the SMR correlates well with the magnetization, the interface roughness, and carrier density. These findings highlight that optimizing YIG properties is a key to control of magnetization by spin current, leading to the development of low power consumption spintronic device based on the magnetic insulator.|
|**2023-06-05**|**Spin-orbit torque generation in bilayers composed of CoFeB and epitaxial SrIrO$_{3}$ grown on an orthorhombic DyScO$_{3}$ substrate**|Sosuke Hori et.al.|[2306.02567v1](http://arxiv.org/abs/2306.02567v1)|null|We report on the highly efficient spin-orbit torque (SOT) generation in epitaxial SrIrO$_{3}$(SIO), which is grown on an orthorhombic DyScO$_{3}$(110) substrate. By conducting harmonic Hall measurement in Co$_{20}$Fe$_{60}$B$_{20}$ (CoFeB)/SIO bilayers, we characterize two kinds of the SOTs, i.e., dampinglike (DL) and fieldlike ones to find that the former is much larger than the latter. By comparison with the Pt control sample with the same CoFeB thickness, the observed DL SOT efficiency $\xi$$_{DL}$ of SIO ($\sim$0.32) is three times higher than that of Pt ($\sim$0.093). The $\xi$$_{DL}$ is nearly constant as a function of the CoFeB thickness, suggesting that the SIO plays a crucial role in the large SOT generation. These results on the CoFeB/SIO bilayers highlight that the epitaxial SIO is promising for low-current and reliable spin-orbit torque-controlled devices.|
|**2023-06-04**|**Star dynamics: collapse vs. expansion**|Mahir Hadzic et.al.|[2306.02445v1](http://arxiv.org/abs/2306.02445v1)|null|We review a series of recent results on global dynamic properties of radially symmetric self-gravitating compressible Euler flows, which naturally arise in the mathematical description of stars. We focus on the role of scaling invariances and how they interact with nonlinearities to generate imploding finite-time singularities as well as expanding star solutions, arising from smooth initial data. This review paper is based on joint works with Y. Guo, J. Jang, and M. Schrecker.|
|**2023-06-04**|**Simple realization of a hybrid controlled-controlled-Z gate with photonic control qubits encoded via eigenstates of the photon-number parity operator**|Qi-Ping Su et.al.|[2306.02229v1](http://arxiv.org/abs/2306.02229v1)|null|We propose a simple method to realize a hybrid controlled-controlled-Z (CCZ) gate with two photonic qubits simultaneously controlling a superconducting (SC) target qubit, by employing two microwave cavities coupled to a SC ququart (a four-level quantum system). In this proposal, each control qubit is a photonic qubit, which is encoded by two arbitrary orthogonal eigenstates (with eigenvalues 1 and -1, respectively) of the photon-number parity operator. Since the two arbitrary encoding states can take various quantum states, this proposal can be applied to realize the hybrid CCZ gate, for which the two control photonic qubits can have various encodings. The gate realization is quite simple because only a basic operation is needed. During the gate operation, the higher energy intermediate levels of the ququart are not occupied, and, thus, decoherence from these levels is greatly suppressed. We further discuss how to apply this gate to generate a hybrid Greenberger-Horne-Zeilinger (GHZ) entangled state of a SC qubit and two photonic qubits, which takes a general form. As an example, our numerical simulation demonstrates that high-fidelity generation of a cat-cat-spin hybrid GHZ state is feasible within current circuit QED technology. This proposal is quite general, which can be applied to realize the hybrid CCZ gate as well as to prepare various hybrid GHZ states of a matter qubit and two photonic qubits in other physical systems, such as two microwave or optical cavities coupled to a four-level natural or artificial atom.|
|**2023-06-02**|**Group channel pruning and spatial attention distilling for object detection**|Yun Chu et.al.|[2306.01526v1](http://arxiv.org/abs/2306.01526v1)|[link](https://github.com/chumingqian/Model_Compression_For_YOLOV3-V4)|Due to the over-parameterization of neural networks, many model compression methods based on pruning and quantization have emerged. They are remarkable in reducing the size, parameter number, and computational complexity of the model. However, most of the models compressed by such methods need the support of special hardware and software, which increases the deployment cost. Moreover, these methods are mainly used in classification tasks, and rarely directly used in detection tasks. To address these issues, for the object detection network we introduce a three-stage model compression method: dynamic sparse training, group channel pruning, and spatial attention distilling. Firstly, to select out the unimportant channels in the network and maintain a good balance between sparsity and accuracy, we put forward a dynamic sparse training method, which introduces a variable sparse rate, and the sparse rate will change with the training process of the network. Secondly, to reduce the effect of pruning on network accuracy, we propose a novel pruning method called group channel pruning. In particular, we divide the network into multiple groups according to the scales of the feature layer and the similarity of module structure in the network, and then we use different pruning thresholds to prune the channels in each group. Finally, to recover the accuracy of the pruned network, we use an improved knowledge distillation method for the pruned network. Especially, we extract spatial attention information from the feature maps of specific scales in each group as knowledge for distillation. In the experiments, we use YOLOv4 as the object detection network and PASCAL VOC as the training dataset. Our method reduces the parameters of the model by 64.7 % and the calculation by 34.9%.|
|**2023-06-01**|**Digital contact tracing/notification for SARS-CoV-2: a retrospective of what went wrong**|Joanna Masel et.al.|[2306.00873v1](http://arxiv.org/abs/2306.00873v1)|null|Digital contact tracing/notification was initially hailed as a promising strategy to combat SARS-CoV-2, but in most jurisdictions it did not live up to its promise. To avert a given transmission event, both parties must have adopted the tech, it must detect the contact, the primary case must be promptly diagnosed, notifications must be triggered, and the secondary case must change their behavior to avoid the focal tertiary transmission event. Achieving a 26% reduction in R(t) requires 80% success rates at each of these six points of failure. Here we review the six failure rates experienced by a variety of digital contact tracing/notification schemes, including Singapore's TraceTogether, India's Aarogya Setu, and leading implementations of the Google Apple Exposure Notification system. This leads to a number of recommendations, e.g. that tracing/notification apps be multi-functional and integrated with testing, manual contact tracing, and the gathering of critical scientific data, and that the narrative be framed in terms of user autonomy rather than user privacy.|
|**2023-06-01**|**MindBigData 2023 MNIST-8B The 8 billion datapoints Multimodal Dataset of Brain Signals**|David Vivancos et.al.|[2306.00455v1](http://arxiv.org/abs/2306.00455v1)|null|MindBigData 2023 MNIST-8B is the largest, to date (June 1st 2023), brain signals open dataset created for Machine Learning, based on EEG signals from a single subject captured using a custom 128 channels device, replicating the full 70,000 digits from Yaan LeCun et all MNIST dataset. The brain signals were captured while the subject was watching the pixels of the original digits one by one on a screen and listening at the same time to the spoken number 0 to 9 from the real label. The data, collection procedures, hardware and software created are described in detail, background extra information and other related datasets can be found at our previous paper MindBigData 2022: A Large Dataset of Brain Signals.|
|**2023-06-01**|**BiSync: A Bilingual Editor for Synchronized Monolingual Texts**|Josep Crego et.al.|[2306.00400v1](http://arxiv.org/abs/2306.00400v1)|[link](https://github.com/jmcrego/bisync)|In our globalized world, a growing number of situations arise where people are required to communicate in one or several foreign languages. In the case of written communication, users with a good command of a foreign language may find assistance from computer-aided translation (CAT) technologies. These technologies often allow users to access external resources, such as dictionaries, terminologies or bilingual concordancers, thereby interrupting and considerably hindering the writing process. In addition, CAT systems assume that the source sentence is fixed and also restrict the possible changes on the target side. In order to make the writing process smoother, we present BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. We also include additional functionalities, such as the display of alternative prefix translations and paraphrases, which are intended to facilitate the authoring of texts. We detail the model architecture used for synchronization and evaluate the resulting tool, showing that high accuracy can be attained with limited computational resources. The interface and models are publicly available at https://github.com/jmcrego/BiSync and a demonstration video can be watched on YouTube at https://youtu.be/_l-ugDHfNgU .|
|**2023-06-01**|**Example-based Motion Synthesis via Generative Motion Matching**|Weiyu Li et.al.|[2306.00378v1](http://arxiv.org/abs/2306.00378v1)|null|We present GenMM, a generative model that "mines" as many diverse motions as possible from a single or few example sequences. In stark contrast to existing data-driven methods, which typically require long offline training time, are prone to visual artifacts, and tend to fail on large and complex skeletons, GenMM inherits the training-free nature and the superior quality of the well-known Motion Matching method. GenMM can synthesize a high-quality motion within a fraction of a second, even with highly complex and large skeletal structures. At the heart of our generative framework lies the generative motion matching module, which utilizes the bidirectional visual similarity as a generative cost function to motion matching, and operates in a multi-stage framework to progressively refine a random guess using exemplar motion matches. In addition to diverse motion generation, we show the versatility of our generative framework by extending it to a number of scenarios that are not possible with motion matching alone, including motion completion, key frame-guided generation, infinite looping, and motion reassembly. Code and data for this paper are at https://wyysf-98.github.io/GenMM/|
|**2023-06-01**|**Functional Ghobber-Jaming Uncertainty Principle**|K. Mahesh Krishna et.al.|[2306.01014v1](http://arxiv.org/abs/2306.01014v1)|null|Let $(\{f_j\}_{j=1}^n, \{\tau_j\}_{j=1}^n)$ and $(\{g_k\}_{k=1}^n, \{\omega_k\}_{k=1}^n)$ be two p-orthonormal bases for a finite dimensional Banach space $\mathcal{X}$. Let $M,N\subseteq \{1, \dots, n\}$ be such that \begin{align*}   o(M)^\frac{1}{q}o(N)^\frac{1}{p}< \frac{1}{\displaystyle \max_{1\leq j,k\leq n}|g_k(\tau_j) |}, \end{align*} where $q$ is the conjugate index of $p$. Then for all $x \in \mathcal{X}$, we show that \begin{align}\label{FGJU} (1) \quad \quad \quad \quad \|x\|\leq \left(1+\frac{1}{1-o(M)^\frac{1}{q}o(N)^\frac{1}{p}\displaystyle\max_{1\leq j,k\leq n}|g_k(\tau_j)|}\right)\left[\left(\sum_{j\in M^c}|f_j(x)|^p\right)^\frac{1}{p}+\left(\sum_{k\in N^c}|g_k(x) |^p\right)^\frac{1}{p}\right]. \end{align}   We call Inequality (1) as \textbf{Functional Ghobber-Jaming Uncertainty Principle}. Inequality (1) improves the uncertainty principle obtained by Ghobber and Jaming \textit{[Linear Algebra Appl., 2011]}.|
|**2023-05-31**|**Bytes Are All You Need: Transformers Operating Directly On File Bytes**|Maxwell Horton et.al.|[2306.00238v1](http://arxiv.org/abs/2306.00238v1)|[link](https://github.com/apple/ml-cvnets)|Modern deep learning approaches usually transform inputs into a modality-specific form. For example, the most common deep learning approach to image classification involves decoding image file bytes into an RGB tensor which is passed into a neural network. Instead, we investigate performing classification directly on file bytes, without the need for decoding files at inference time. Using file bytes as model inputs enables the development of models which can operate on multiple input modalities. Our model, \emph{ByteFormer}, achieves an ImageNet Top-1 classification accuracy of $77.33\%$ when training and testing directly on TIFF file bytes using a transformer backbone with configuration similar to DeiT-Ti ($72.2\%$ accuracy when operating on RGB images). Without modifications or hyperparameter tuning, ByteFormer achieves $95.42\%$ classification accuracy when operating on WAV files from the Speech Commands v2 dataset (compared to state-of-the-art accuracy of $98.7\%$). Additionally, we demonstrate that ByteFormer has applications in privacy-preserving inference. ByteFormer is capable of performing inference on particular obfuscated input representations with no loss of accuracy. We also demonstrate ByteFormer's ability to perform inference with a hypothetical privacy-preserving camera which avoids forming full images by consistently masking $90\%$ of pixel channels, while still achieving $71.35\%$ accuracy on ImageNet. Our code will be made available at https://github.com/apple/ml-cvnets/tree/main/examples/byteformer.|
|**2023-05-31**|**On the Simultaneous Solution of Structural Membranes on all Level Sets within a Bulk Domain**|Thomas-Peter Fries et.al.|[2305.20001v1](http://arxiv.org/abs/2305.20001v1)|null|A mechanical model and numerical method for structural membranes implied by all isosurfaces of a level-set function in a three-dimensional bulk domain are proposed. The mechanical model covers large displacements in the context of the finite strain theory and is formulated based on the tangential differential calculus. Alongside curved two-dimensional membranes embedded in three dimensions, also the simpler case of curved ropes (cables) in two-dimensional bulk domains is covered. The implicit geometries (shapes) are implied by the level sets and the boundaries of the structures are given by the intersection of the level sets with the boundary of the bulk domain. For the numerical analysis, the bulk domain is discretized using a background mesh composed by (higher-order) elements with the dimensionality of the embedding space. The elements are by no means aligned to the level sets, i.e., the geometries of the structures, which resembles a fictitious domain method, most importantly the Trace FEM. The proposed numerical method is a hybrid of the classical FEM and fictitious domain methods which may be labeled as "Bulk Trace FEM". Numerical studies confirm higher-order convergence rates and the potential for new material models with continuously embedded sub-structures in bulk domains.|
|**2023-05-31**|**Ferrimagnetic Oscillator Magnetometer**|John F. Barry et.al.|[2305.19938v1](http://arxiv.org/abs/2305.19938v1)|null|Quantum sensors offer unparalleled precision, accuracy, and sensitivity for a variety of measurement applications. We report a compact magnetometer based on a ferrimagnetic sensing element in an oscillator architecture that circumvents challenges common to other quantum sensing approaches such as limited dynamic range, limited bandwidth, and dependence on vacuum, cryogenic, or laser components. The device exhibits a fixed, calibration-free response governed by the electron gyromagnetic ratio. Exchange narrowing in the ferrimagnetic material produces sub-MHz transition linewidths despite the high unpaired spin density ($\sim 10^{22}$ cm$^{-3}$). The magnetometer achieves a minimum sensitivity of 100 fT/$\sqrt{\text{Hz}}$ to AC magnetic fields of unknown phase and a sensitivity below 200 fT/$\sqrt{\text{Hz}}$ over a bandwidth $\gtrsim \! 1$ MHz. By encoding magnetic field in frequency rather than amplitude, the device provides a dynamic range in excess of 1 mT. The passive, thermal initialization of the sensor's quantum state requires only a magnetic bias field, greatly reducing power requirements compared to laser-initialized quantum sensors. With additional development, this device promises to be a leading candidate for high-performance magnetometry outside the laboratory, and the oscillator architecture is expected to provide advantages across a wide range of sensing platforms.|
|**2023-05-31**|**Few-Shot Speaker Identification Using Lightweight Prototypical Network with Feature Grouping and Interaction**|Yanxiong Li et.al.|[2305.19541v1](http://arxiv.org/abs/2305.19541v1)|null|Existing methods for few-shot speaker identification (FSSI) obtain high accuracy, but their computational complexities and model sizes need to be reduced for lightweight applications. In this work, we propose a FSSI method using a lightweight prototypical network with the final goal to implement the FSSI on intelligent terminals with limited resources, such as smart watches and smart speakers. In the proposed prototypical network, an embedding module is designed to perform feature grouping for reducing the memory requirement and computational complexity, and feature interaction for enhancing the representational ability of the learned speaker embedding. In the proposed embedding module, audio feature of each speech sample is split into several low-dimensional feature subsets that are transformed by a recurrent convolutional block in parallel. Then, the operations of averaging, addition, concatenation, element-wise summation and statistics pooling are sequentially executed to learn a speaker embedding for each speech sample. The recurrent convolutional block consists of a block of bidirectional long short-term memory, and a block of de-redundancy convolution in which feature grouping and interaction are conducted too. Our method is compared to baseline methods on three datasets that are selected from three public speech corpora (VoxCeleb1, VoxCeleb2, and LibriSpeech). The results show that our method obtains higher accuracy under several conditions, and has advantages over all baseline methods in computational complexity and model size.|
|**2023-05-30**|**AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation**|Chuhao Jin et.al.|[2305.18898v1](http://arxiv.org/abs/2305.18898v1)|null|We propose a novel framework for learning high-level cognitive capabilities in robot manipulation tasks, such as making a smiley face using building blocks. These tasks often involve complex multi-step reasoning, presenting significant challenges due to the limited paired data connecting human instructions (e.g., making a smiley face) and robot actions (e.g., end-effector movement). Existing approaches relieve this challenge by adopting an open-loop paradigm decomposing high-level instructions into simple sub-task plans, and executing them step-by-step using low-level control models. However, these approaches are short of instant observations in multi-step reasoning, leading to sub-optimal results. To address this issue, we propose to automatically collect a cognitive robot dataset by Large Language Models (LLMs). The resulting dataset AlphaBlock consists of 35 comprehensive high-level tasks of multi-step text plans and paired observation sequences. To enable efficient data acquisition, we employ elaborated multi-round prompt designs that effectively reduce the burden of extensive human involvement. We further propose a closed-loop multi-modal embodied planning model that autoregressively generates plans by taking image observations as input. To facilitate effective learning, we leverage MiniGPT-4 with a frozen visual encoder and LLM, and finetune additional vision adapter and Q-former to enable fine-grained spatial perception for manipulation tasks. We conduct experiments to verify the superiority over existing open and closed-loop methods, and achieve a significant increase in success rate by 21.4% and 14.5% over ChatGPT and GPT-4 based robot tasks. Real-world demos are shown in https://www.youtube.com/watch?v=ayAzID1_qQk .|
|**2023-05-30**|**Terahertz emission from transient currents and coherent phonons in layered MoSe$_2$ and WSe$_2$**|Jessica Afalla et.al.|[2305.18805v1](http://arxiv.org/abs/2305.18805v1)|null|Terahertz (THz) time-domain emission spectroscopy was performed on layered 2H-MoSe2 and 2H-WSe2. The THz emission shows an initial cycle attributed to surge currents and is followed by oscillations attributed to coherent interlayer phonon modes. To obtain the frequencies of the interlayer vibrations, analysis of the THz emission waveforms were performed, separating the two contributions to the total waveform. Results of the fitting show several vibrational modes in the range of 5.87 to 32.75 cm-1 for the samples, attributed to infrared-active interlayer shear and breathing modes. This study demonstrates that THz emission spectroscopy provides a means of observing these low frequency vibrational modes in layered materials.|
|**2023-05-29**|**Super cuspy dark matter halos of massive galaxies due to baryon-driven contraction**|Pengfei Li et.al.|[2305.19289v1](http://arxiv.org/abs/2305.19289v1)|null|The interplay between dark matter (DM) and baryons has long been ignored when building galaxies semi-empirically and observationally. Here I show that baryonic gravity leads to an adiabatic contraction of DM halos, which is most significant in massive galaxies. Ignoring this effect, the derived DM halos are not guaranteed in dynamical equilibrium. I present a new approach to deriving DM halos from rotation curves, which incorporates the adiabatic contraction. The compressed halos turn out super cuspy with respect to NFW halos, which require smaller baryonic contributions and less concentrated primordial halos. I also examine the semi-empirical approach to building galaxies, and find the adiabatic contraction can shift massive galaxies from the observed radial acceleration relation dramatically. Both approaches lead to super cuspy DM halos for massive galaxies, demonstrating the importance of the baryon-driven contraction, which has to be taken into account in order to make an apple-to-apple comparison with simulations.|
|**2023-05-29**|**Counterpart Fairness -- Addressing Systematic between-group Differences in Fairness Evaluation**|Yifei Wang et.al.|[2305.18160v1](http://arxiv.org/abs/2305.18160v1)|[link](https://github.com/zhengyjo/cfair)|When using machine learning (ML) to aid decision-making, it is critical to ensure that an algorithmic decision is fair, i.e., it does not discriminate against specific individuals/groups, particularly those from underprivileged populations. Existing group fairness methods require equal group-wise measures, which however fails to consider systematic between-group differences. The confounding factors, which are non-sensitive variables but manifest systematic differences, can significantly affect fairness evaluation. To mitigate this problem, we believe that a fairness measurement should be based on the comparison between counterparts (i.e., individuals who are similar to each other with respect to the task of interest) from different groups, whose group identities cannot be distinguished algorithmically by exploring confounding factors. We have developed a propensity-score-based method for identifying counterparts, which prevents fairness evaluation from comparing "oranges" with "apples". In addition, we propose a counterpart-based statistical fairness index, termed Counterpart-Fairness (CFair), to assess fairness of ML models. Empirical studies on the Medical Information Mart for Intensive Care (MIMIC)-IV database were conducted to validate the effectiveness of CFair. We publish our code at \url{https://github.com/zhengyjo/CFair}.|
|**2023-05-29**|**minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts, Transitivities, and Lattices**|Animesh Chaturvedi et.al.|[2305.17984v1](http://arxiv.org/abs/2305.17984v1)|null|Hate speech classification has become an important problem due to the spread of hate speech on social media platforms. For a given set of Hate Terms lists (HTs-lists) and Hate Speech data (HS-data), it is challenging to understand which hate term contributes the most for hate speech classification. This paper contributes two approaches to quantitatively measure and qualitatively visualise the relationship between co-occurring Hate Terms (HTs). Firstly, we propose an approach for the classification of hate-speech by producing a Severe Hate Terms list (Severe HTs-list) from existing HTs-lists. To achieve our goal, we proposed three metrics (Hatefulness, Relativeness, and Offensiveness) to measure the severity of HTs. These metrics assist to create an Inter-agreement HTs-list, which explains the contribution of an individual hate term toward hate speech classification. Then, we used the Offensiveness metric values of HTs above a proposed threshold minimum Offense (minOffense) to generate a new Severe HTs-list. To evaluate our approach, we used three hate speech datasets and six hate terms lists. Our approach shown an improvement from 0.845 to 0.923 (best) as compared to the baseline. Secondly, we also proposed Stable Hate Rule (SHR) mining to provide ordered co-occurrence of various HTs with minimum Stability (minStab). The SHR mining detects frequently co-occurring HTs to form Stable Hate Rules and Concepts. These rules and concepts are used to visualise the graphs of Transitivities and Lattices formed by HTs.|
|**2023-05-29**|**Learning Conditional Attributes for Compositional Zero-Shot Learning**|Qingsheng Wang et.al.|[2305.17940v1](http://arxiv.org/abs/2305.17940v1)|[link](https://github.com/wqshmzh/canet-czsl)|Compositional Zero-Shot Learning (CZSL) aims to train models to recognize novel compositional concepts based on learned concepts such as attribute-object combinations. One of the challenges is to model attributes interacted with different objects, e.g., the attribute ``wet" in ``wet apple" and ``wet cat" is different. As a solution, we provide analysis and argue that attributes are conditioned on the recognized object and input image and explore learning conditional attribute embeddings by a proposed attribute learning framework containing an attribute hyper learner and an attribute base learner. By encoding conditional attributes, our model enables to generate flexible attribute embeddings for generalization from seen to unseen compositions. Experiments on CZSL benchmarks, including the more challenging C-GQA dataset, demonstrate better performances compared with other state-of-the-art approaches and validate the importance of learning conditional attributes. Code is available at https://github.com/wqshmzh/CANet-CZSL|
|**2023-05-29**|**Bayesian feedback in the framework of ecological sciences**|Mario Figueira-Pereira et.al.|[2305.17922v1](http://arxiv.org/abs/2305.17922v1)|null|In ecology we may find scenarios where the same phenomenon (species occurrence, species abundance, etc.) is observed using two different types of samplers. For instance, species data can be collected from scientific surveys with a completely random sample pattern, but also from opportunistic sampling (e.g., whale or bird watching fishery commercial vessels), in which observers tend to look for a specific species in areas where they expect to find it.   Species Distribution Models (SDMs) are a widely used tool for analyzing this kind of ecological data. Specifically, we have two models available for the above data: an independent model (IM) for the data coming from a complete random sampler and a dependent model (DM) for data from opportunistic sampling.   In this work, we propose a sequential Bayesian procedure to connect these two models through the update of prior distributions. Implementation of the Bayesian paradigm is done through the integrated nested Laplace approximation (INLA) methodology, a good option to make inference and prediction in spatial models with high performance and low computational costs. This sequential approach has been evaluated by simulating several scenarios and comparing the results of sharing information from one model to another using different criteria.   Our main results imply that, in general, it is better to share information from the independent (completely random) to the dependent model than the alternative way. However, it depends on different factors such as the spatial range or the spatial arrangement of sampling locations.|
|**2023-05-26**|**DES Y3 + KiDS-1000: Consistent cosmology combining cosmic shear surveys**|Dark Energy Survey et.al.|[2305.17173v1](http://arxiv.org/abs/2305.17173v1)|null|We present a joint cosmic shear analysis of the Dark Energy Survey (DES Y3) and the Kilo-Degree Survey (KiDS-1000) in a collaborative effort between the two survey teams. We find consistent cosmological parameter constraints between DES Y3 and KiDS-1000 which, when combined in a joint-survey analysis, constrain the parameter $S_8 = \sigma_8 \sqrt{\Omega_{\rm m}/0.3}$ with a mean value of $0.790^{+0.018}_{-0.014}$. The mean marginal is lower than the maximum a posteriori estimate, $S_8=0.801$, owing to skewness in the marginal distribution and projection effects in the multi-dimensional parameter space. Our results are consistent with $S_8$ constraints from observations of the cosmic microwave background by Planck, with agreement at the $1.7\sigma$ level. We use a Hybrid analysis pipeline, defined from a mock survey study quantifying the impact of the different analysis choices originally adopted by each survey team. We review intrinsic alignment models, baryon feedback mitigation strategies, priors, samplers and models of the non-linear matter power spectrum.|
|**2023-05-26**|**Regular access to constantly renewed online content favors radicalization of opinions**|Guillaume Deffuant et.al.|[2305.16855v1](http://arxiv.org/abs/2305.16855v1)|null|Worry over polarization has grown alongside the digital information consumption revolution. Where most scientific work considered user-generated and user-disseminated (i.e.,~Web 2.0) content as the culprit, the potential of purely increased access to information (or Web 1.0) has been largely overlooked. Here, we suggest that the shift to Web 1.0 alone could include a powerful mechanism of belief extremization. We study an empirically calibrated persuasive argument model with confirmation bias. We compare an offline setting -- in which a limited number of arguments is broadcast by traditional media -- with an online setting -- in which the agent can choose to watch contents within a very wide set of possibilities. In both cases, we assume that positive and negative arguments are balanced. The simulations show that the online setting leads to significantly more extreme opinions and amplifies initial prejudice.|
|**2023-05-26**|**The mechanism of the Silicon irradiation synergistic effect explained by multiscale simulations of Monte Carlo and excited-state first-principle calculations**|Zeng-hui Yang et.al.|[2305.16601v1](http://arxiv.org/abs/2305.16601v1)|null|Neutron and $\gamma$-ray irradiation damages to transistors are found to be non-additive, and this is denoted as the irradiation synergistic effect (ISE). Its mechanism is not well-understood. The recent defect-based model [ACS Appl. Electron. Mater. 2, 3783 (2020)] for Silicon bipolar junction transistors (BJT) achieve quantitative agreement with experiments, but it remains phenomenological and its assumptions on the defect reactions are unverified. Going beyond the phenomenological model requires directly representing the effect of $\gamma$-ray irradiation in first-principles calculations, which is not feasible previously. In this work, we examine the defect-based model of the ISE by developing a multiscale method for the simulation of the $\gamma$-ray irradiation, where the $\gamma$-ray-induced electronic excitations are treated explicitly in excited-state first-principles calculations. We find the calculations agree with experiments, and the effect of the $\gamma$-ray-induced excitation is significantly different from the effects of defect charge state and temperature. We propose a diffusion-based qualitative explanation of the mechanism of positive/negative ISE in NPN/PNP BJTs in the end.|
|**2023-05-25**|**Inequalities for totally nonnegative matrices: Gantmacher--Krein, Karlin, and Laplace**|Shaun M. Fallat et.al.|[2305.16485v2](http://arxiv.org/abs/2305.16485v2)|null|A real linear combination of products of minors which is nonnegative over all totally nonnegative (TN) matrices is called a determinantal inequality for these matrices. It is referred to as multiplicative when it compares two collections of products of minors and additive otherwise. Set theoretic operations preserving the class of TN matrices naturally translate into operations preserving determinantal inequalities in this class. We introduce set row/column operations that act directly on all determinantal inequalities for TN matrices, and yield further inequalities for these matrices. These operations assist in revealing novel additive inequalities for TN matrices embedded in the classical identities due to Laplace $[$Mem$.$ Acad$.$ Sciences Paris $1772]$ and Karlin $(1968).$ In particular, for any square TN matrix $A,$ these derived inequalities generalize -- to every $i^{\mbox{th}}$ row of $A$ and $j^{\mbox{th}}$ column of ${\rm adj} A$ -- the classical Gantmacher--Krein fluctuating inequalities $(1941)$ for $i=j=1.$ Furthermore, our row/column operations reveal additional undiscovered fluctuating inequalities for TN matrices.   The introduced set row/column operations naturally birth an algorithm that can detect certain determinantal expressions that do not form an inequality for TN matrices. However, the algorithm completely characterizes the multiplicative inequalities comparing products of pairs of minors. Moreover, the underlying row/column operations add that these inequalities are offshoots of certain ''complementary/higher'' ones. These novel results seem very natural, and in addition thoroughly describe and enrich the classification of these multiplicative inequalities due to Fallat--Gekhtman--Johnson $[$Adv$.$ Appl$.$ Math$.$ $2003]$ and later Skandera $[$J$.$ Algebraic Comb$.$ $2004].$|
|**2023-05-25**|**Break-A-Scene: Extracting Multiple Concepts from a Single Image**|Omri Avrahami et.al.|[2305.16311v1](http://arxiv.org/abs/2305.16311v1)|null|Text-to-image model personalization aims to introduce a user-provided concept to the model, allowing its synthesis in diverse contexts. However, current methods primarily focus on the case of learning a single concept from multiple images with variations in backgrounds and poses, and struggle when adapted to a different scenario. In this work, we introduce the task of textual scene decomposition: given a single image of a scene that may contain several concepts, we aim to extract a distinct text token for each concept, enabling fine-grained control over the generated scenes. To this end, we propose augmenting the input image with masks that indicate the presence of target concepts. These masks can be provided by the user or generated automatically by a pre-trained segmentation model. We then present a novel two-phase customization process that optimizes a set of dedicated textual embeddings (handles), as well as the model weights, striking a delicate balance between accurately capturing the concepts and avoiding overfitting. We employ a masked diffusion loss to enable handles to generate their assigned concepts, complemented by a novel loss on cross-attention maps to prevent entanglement. We also introduce union-sampling, a training strategy aimed to improve the ability of combining multiple concepts in generated images. We use several automatic metrics to quantitatively compare our method against several baselines, and further affirm the results using a user study. Finally, we showcase several applications of our method. Project page is available at: https://omriavrahami.com/break-a-scene/|
