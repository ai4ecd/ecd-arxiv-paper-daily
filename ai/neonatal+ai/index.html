
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../infant%2Bai/">
      
      
        <link rel="next" href="../../infant/infant/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.17">
    
    
      
        <title>Neonatal+ai - ecd-ai-paper-daily</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "hh1oiyc7g7");
</script>

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#neonatalai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ecd-ai-paper-daily" class="md-header__button md-logo" aria-label="ecd-ai-paper-daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ecd-ai-paper-daily
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neonatal+ai
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ai4ecd/ecd-arxiv-paper-daily" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ecd-ai-paper-daily" class="md-nav__button md-logo" aria-label="ecd-ai-paper-daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ecd-ai-paper-daily
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ai4ecd/ecd-arxiv-paper-daily" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        arxiv-daily latest papers around ecd arxiv paper daily
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Ai
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Ai
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../infant%2Bai/" class="md-nav__link">
        Infant+ai
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Neonatal+ai
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Neonatal+ai
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#neonatalai" class="md-nav__link">
    neonatal+ai
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Infant
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Infant
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../infant/infant/" class="md-nav__link">
        Infant
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#neonatalai" class="md-nav__link">
    neonatal+ai
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Neonatal+ai</h1>

<h3 id="neonatalai">neonatal+ai</h3>
<table>
<thead>
<tr>
<th align="center">Publish Date</th>
<th align="center">Title</th>
<th align="center">Authors</th>
<th align="center">PDF</th>
<th align="center">Code</th>
<th align="center">Abstract</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><strong>2023-06-16</strong></td>
<td align="center"><strong>MedFMC: A Real-world Dataset and Benchmark For Foundation Model Adaptation in Medical Image Classification</strong></td>
<td align="center">Dequan Wang et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2306.09579v1">2306.09579v1</a></td>
<td align="center">null</td>
<td align="center">Foundation models, often pre-trained with large-scale data, have achieved paramount success in jump-starting various vision and language applications. Recent advances further enable adapting foundation models in downstream tasks efficiently using only a few training samples, e.g., in-context learning. Yet, the application of such learning paradigms in medical image analysis remains scarce due to the shortage of publicly accessible data and benchmarks. In this paper, we aim at approaches adapting the foundation models for medical image classification and present a novel dataset and benchmark for the evaluation, i.e., examining the overall performance of accommodating the large-scale foundation models downstream on a set of diverse real-world clinical tasks. We collect five sets of medical imaging data from multiple institutes targeting a variety of real-world clinical tasks (22,349 images in total), i.e., thoracic diseases screening in X-rays, pathological lesion tissue screening, lesion detection in endoscopy images, neonatal jaundice evaluation, and diabetic retinopathy grading. Results of multiple baseline methods are demonstrated using the proposed dataset from both accuracy and cost-effective perspectives.</td>
</tr>
<tr>
<td align="center"><strong>2023-05-28</strong></td>
<td align="center"><strong>A joint estimation approach for monotonic regression functions in general dimensions</strong></td>
<td align="center">Christian Rohrbeck et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2305.17711v1">2305.17711v1</a></td>
<td align="center">null</td>
<td align="center">Regression analysis under the assumption of monotonicity is a well-studied statistical problem and has been used in a wide range of applications. However, there remains a lack of a broadly applicable methodology that permits information borrowing, for efficiency gains, when jointly estimating multiple monotonic regression functions. We introduce such a methodology by extending the isotonic regression problem presented in the article "The isotonic regression problem and its dual" (Barlow and Brunk, 1972). The presented approach can be applied to both fixed and random designs and any number of explanatory variables (regressors). Our framework penalizes pairwise differences in the values (levels) of the monotonic function estimates, with the weight of penalty being determined based on a statistical test, which results in information being shared across data sets if similarities in the regression functions exist. Function estimates are subsequently derived using an iterative optimization routine that uses existing solution algorithms for the isotonic regression problem. Simulation studies for normally and binomially distributed response data illustrate that function estimates are consistently improved if similarities between functions exist, and are not oversmoothed otherwise. We further apply our methodology to analyse two public health data sets: neonatal mortality data for Porto Alegre, Brazil, and stroke patient data for North West England.</td>
</tr>
<tr>
<td align="center"><strong>2023-05-02</strong></td>
<td align="center"><strong>Establishing a Learning Model for Correct Hand Hygiene Technique in a NICU</strong></td>
<td align="center">Irén A. Kopcsóné Németh et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2305.01366v1">2305.01366v1</a></td>
<td align="center">null</td>
<td align="center">The ability of healthcare workers to learn proper hand hygiene has been an understudied area of research. Generally, hand hygiene skills are regarded as a key contributor to reduce critical infections and healthcare-associated infections. In a clinical setup, at a Neonatal Intensive Care Unit (NICU), the outcome of a multi-modal training initiative was recorded, where objective feedback was provided to the staff. It was hypothesized that staff at the NICU are more sensitive towards applying increased patient safety measures. Outcomes were recorded as the ability to cover all hand surfaces with Alcohol-Based Handrub (ABHR), modelled as a time-series of measurements. The learning ability to rub in with 1.5 mL and with 3 mL was also assessed. As a secondary outcome, handrub consumption and infection numbers were recorded. It has been observed that some staff members were able to quickly learn the proper hand hygiene, even with the limited 1.5 mL, while others were not capable of acquiring the technique even with 3 mL. When analyzing the 1.5 mL group, it was deemed an insufficient ABHR amount, while with 3 mL, the critical necessity of skill training to achieve complete coverage was documented. Identifying these individuals helps the infection control staff to better focus their training efforts. The training led to a 157% increase in handrub consumption. The setting of the study did not allow to show a measurable reduction in the number of hospital infections. It has been concluded that the training method chosen by the staff greatly affects the quality of the outcomes.</td>
</tr>
<tr>
<td align="center"><strong>2023-04-26</strong></td>
<td align="center"><strong>ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges</strong></td>
<td align="center">Ruizhe Zheng et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2304.14919v1">2304.14919v1</a></td>
<td align="center"><a href="https://github.com/albertcheng19/scatterformer">link</a></td>
<td align="center">Patient-independent detection of epileptic activities based on visual spectral representation of continuous EEG (cEEG) has been widely used for diagnosing epilepsy. However, precise detection remains a considerable challenge due to subtle variabilities across subjects, channels and time points. Thus, capturing fine-grained, discriminative features of EEG patterns, which is associated with high-frequency textural information, is yet to be resolved. In this work, we propose Scattering Transformer (ScatterFormer), an invariant scattering transform-based hierarchical Transformer that specifically pays attention to subtle features. In particular, the disentangled frequency-aware attention (FAA) enables the Transformer to capture clinically informative high-frequency components, offering a novel clinical explainability based on visual encoding of multichannel EEG signals. Evaluations on two distinct tasks of epileptiform detection demonstrate the effectiveness our method. Our proposed model achieves median AUCROC and accuracy of 98.14%, 96.39% in patients with Rolandic epilepsy. On a neonatal seizure detection benchmark, it outperforms the state-of-the-art by 9% in terms of average AUCROC.</td>
</tr>
<tr>
<td align="center"><strong>2023-04-12</strong></td>
<td align="center"><strong>NRTS: A Client-Server architecture for supporting data recording, transmission and evaluation of multidisciplinary teams during the neonatal resuscitation simulation scenario</strong></td>
<td align="center">Manuel Striani et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2304.09860v1">2304.09860v1</a></td>
<td align="center">null</td>
<td align="center">In this technical report, we describe Neonatal Resuscitation Training Simulator (NRTS), an Android mobile app designed to support medical experts to input, transmit and record data during a High-Fidelity Simulation course for neonatal resuscitation. This mobile app allows one to automatically send all the recorded data from "Neonatal Intensive Care Unit" (NICU) of Casale Monferrato Children's Hospital, (Italy) to a server located at the Department of Science and Technological Innovation (DiSIT), University of Piemonte Orientale (Italy). Finally, the medical instructor can view statistics on a simulation exercise that may be used during the de-briefing phase for the evaluation of multidisciplinary teams involved in the simulation scenarios.</td>
</tr>
<tr>
<td align="center"><strong>2023-03-28</strong></td>
<td align="center"><strong>Predicting Adverse Neonatal Outcomes for Preterm Neonates with Multi-Task Learning</strong></td>
<td align="center">Jingyang Lin et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2303.15656v1">2303.15656v1</a></td>
<td align="center">null</td>
<td align="center">Diagnosis of adverse neonatal outcomes is crucial for preterm survival since it enables doctors to provide timely treatment. Machine learning (ML) algorithms have been demonstrated to be effective in predicting adverse neonatal outcomes. However, most previous ML-based methods have only focused on predicting a single outcome, ignoring the potential correlations between different outcomes, and potentially leading to suboptimal results and overfitting issues. In this work, we first analyze the correlations between three adverse neonatal outcomes and then formulate the diagnosis of multiple neonatal outcomes as a multi-task learning (MTL) problem. We then propose an MTL framework to jointly predict multiple adverse neonatal outcomes. In particular, the MTL framework contains shared hidden layers and multiple task-specific branches. Extensive experiments have been conducted using Electronic Health Records (EHRs) from 121 preterm neonates. Empirical results demonstrate the effectiveness of the MTL framework. Furthermore, the feature importance is analyzed for each neonatal outcome, providing insights into model interpretability.</td>
</tr>
<tr>
<td align="center"><strong>2023-03-21</strong></td>
<td align="center"><strong>The Multiscale Surface Vision Transformer</strong></td>
<td align="center">Simon Dahan et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2303.11909v1">2303.11909v1</a></td>
<td align="center"><a href="https://github.com/metrics-lab/surface-vision-transformers">link</a></td>
<td align="center">Surface meshes are a favoured domain for representing structural and functional information on the human cortex, but their complex topology and geometry pose significant challenges for deep learning analysis. While Transformers have excelled as domain-agnostic architectures for sequence-to-sequence learning, notably for structures where the translation of the convolution operation is non-trivial, the quadratic cost of the self-attention operation remains an obstacle for many dense prediction tasks. Inspired by some of the latest advances in hierarchical modelling with vision transformers, we introduce the Multiscale Surface Vision Transformer (MS-SiT) as a backbone architecture for surface deep learning. The self-attention mechanism is applied within local-mesh-windows to allow for high-resolution sampling of the underlying data, while a shifted-window strategy improves the sharing of information between windows. Neighbouring patches are successively merged, allowing the MS-SiT to learn hierarchical representations suitable for any prediction task. Results demonstrate that the MS-SiT outperforms existing surface deep learning methods for neonatal phenotyping prediction tasks using the Developing Human Connectome Project (dHCP) dataset. Furthermore, building the MS-SiT backbone into a U-shaped architecture for surface segmentation demonstrates competitive results on cortical parcellation using the UK Biobank (UKB) and manually-annotated MindBoggle datasets. Code and trained models are publicly available at https://github.com/metrics-lab/surface-vision-transformers .</td>
</tr>
<tr>
<td align="center"><strong>2023-03-14</strong></td>
<td align="center"><strong>Activity Recognition From Newborn Resuscitation Videos</strong></td>
<td align="center">Øyvind Meinich-Bache et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2303.07789v1">2303.07789v1</a></td>
<td align="center">null</td>
<td align="center">Objective: Birth asphyxia is one of the leading causes of neonatal deaths. A key for survival is performing immediate and continuous quality newborn resuscitation. A dataset of recorded signals during newborn resuscitation, including videos, has been collected in Haydom, Tanzania, and the aim is to analyze the treatment and its effect on the newborn outcome. An important step is to generate timelines of relevant resuscitation activities, including ventilation, stimulation, suction, etc., during the resuscitation episodes. Methods: We propose a two-step deep neural network system, ORAA-net, utilizing low-quality video recordings of resuscitation episodes to do activity recognition during newborn resuscitation. The first step is to detect and track relevant objects using Convolutional Neural Networks (CNN) and post-processing, and the second step is to analyze the proposed activity regions from step 1 to do activity recognition using 3D CNNs. Results: The system recognized the activities newborn uncovered, stimulation, ventilation and suction with a mean precision of 77.67 %, a mean recall of 77,64 %, and a mean accuracy of 92.40 %. Moreover, the accuracy of the estimated number of Health Care Providers (HCPs) present during the resuscitation episodes was 68.32 %. Conclusion: The results indicate that the proposed CNN-based two-step ORAAnet could be used for object detection and activity recognition in noisy low-quality newborn resuscitation videos. Significance: A thorough analysis of the effect the different resuscitation activities have on the newborn outcome could potentially allow us to optimize treatment guidelines, training, debriefing, and local quality improvement in newborn resuscitation.</td>
</tr>
<tr>
<td align="center"><strong>2023-02-14</strong></td>
<td align="center"><strong>Classification of Lung Pathologies in Neonates using Dual Tree Complex Wavelet Transform</strong></td>
<td align="center">Sagarjit Aujla et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2302.07157v2">2302.07157v2</a></td>
<td align="center">null</td>
<td align="center">Annually 8500 neonatal deaths are reported in the US due to respiratory failure. Recently, Lung Ultrasound (LUS), due to its radiation free nature, portability, and being cheaper is gaining wide acceptability as a diagnostic tool for lung conditions. However, lack of highly trained medical professionals has limited its use especially in remote areas. To address this, an automated screening system that captures characteristics of the LUS patterns can be of significant assistance to clinicians who are not experts in lung ultrasound (LUS) images. In this paper, we propose a feature extraction method designed to quantify the spatially-localized line patterns and texture patterns found in LUS images. Using the dual-tree complex wavelet transform (DTCWT) and four types of common image features we propose a method to classify the LUS images into 6 common neonatal lung conditions. These conditions are normal lung, pneumothorax (PTX), transient tachypnea of the newborn (TTN), respiratory distress syndrome (RDS), chronic lung disease (CLD) and consolidation (CON) that could be pneumonia or atelectasis. The proposed method using DTCWT decomposition extracted global statistical, grey-level co-occurrence matrix (GLCM), grey-level run length matrix (GLRLM) and linear binary pattern (LBP) features to be fed to a linear discriminative analysis (LDA) based classifier. Using 15 best DTCWT features along with 3 clinical features the proposed approach achieved a per-image classification accuracy of 92.78% with a balanced dataset containing 720 images from 24 patients and 74.39% with the larger unbalanced dataset containing 1550 images from 42 patients. Likewise, the proposed method achieved a maximum per-subject classification accuracy of 81.53% with 43 DTCWT features and 3 clinical features using the balanced dataset and 64.97% with 13 DTCWT features and 3 clinical features using the unbalanced dataset.</td>
</tr>
<tr>
<td align="center"><strong>2023-02-08</strong></td>
<td align="center"><strong>Neonatal Face and Facial Landmark Detection from Video Recordings</strong></td>
<td align="center">Ethan Grooby et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2302.04341v1">2302.04341v1</a></td>
<td align="center">null</td>
<td align="center">This paper explores automated face and facial landmark detection of neonates, which is an important first step in many video-based neonatal health applications, such as vital sign estimation, pain assessment, sleep-wake classification, and jaundice detection. Utilising three publicly available datasets of neonates in the clinical environment, 366 images (258 subjects) and 89 (66 subjects) were annotated for training and testing, respectively. Transfer learning was applied to two YOLO-based models, with input training images augmented with random horizontal flipping, photo-metric colour distortion, translation and scaling during each training epoch. Additionally, the re-orientation of input images and fusion of trained deep learning models was explored. Our proposed model based on YOLOv7Face outperformed existing methods with a mean average precision of 84.8% for face detection, and a normalised mean error of 0.072 for facial landmark detection. Overall, this will assist in the development of fully automated neonatal health assessment algorithms.</td>
</tr>
<tr>
<td align="center"><strong>2023-02-01</strong></td>
<td align="center"><strong>The Past, Current, and Future of Neonatal Intensive Care Units with Artificial Intelligence</strong></td>
<td align="center">Elif Keles et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2302.00225v1">2302.00225v1</a></td>
<td align="center">null</td>
<td align="center">Artificial intelligence (AI), specifically a branch of AI called deep learning (DL), has proven revolutionary developments in almost all fields, from computer vision to health sciences, and its effects in medicine have changed clinical applications significantly. Although some sub-fields of medicine such as pediatrics have been relatively slow in receiving critical benefits of AI, related research in pediatrics started to be accumulated to a significant level too. Hence, in this paper, we review recently developed machine learning and deep learning based systems for neonatology applications. We systematically evaluate the role of AI in neonatology applications, define the methodologies, including algorithmic developments, and describe the remaining challenges in neonatal diseases. To date, survival analysis, neuroimaging, EEG, pattern analysis of vital parameters, and retinopathy of prematurity diagnosis with AI have been the main focus in neonatology. We have categorically summarized 96 research articles, from 1996 to 2022, and discussed their pros and cons, respectively. We also discuss possible directions for new AI models and the future of neonatology with the rising power of AI, suggesting roadmaps for integration of AI into neonatal intensive care units.</td>
</tr>
<tr>
<td align="center"><strong>2022-12-26</strong></td>
<td align="center"><strong>Investigation of the aptness of newly developed epoxy-based equivalent tissues for newborn and 5-years old in paediatric radiology</strong></td>
<td align="center">Nabeel Ibrahim Ashour et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2212.13002v1">2212.13002v1</a></td>
<td align="center">null</td>
<td align="center">The varied radiological applications of tissue equivalent (TE) materials encompass quality checks, diagnostic imaging and dose evaluations. Nevertheless, the availability of compounds representative of paediatric patient tissues for scientific use in lower diagnostic photon energy spectra is limited. In this study, several TE substitutes were developed which replicate the radiographic characteristics of human tissue within these energy ranges, i.e. TE materials for neonatal soft tissue (ESST-NB), neonatal skeletal tissue (ESTB-NB), and the equivalent tissue types representative of a 5 year old child (ESST and ESBT, respectively). The ORNL stylised computational model series was used as a source for the desired elemental proportions. The density, effective atomic number, CT numbers and electron densities calculated for the developed tissue substitutes approximated those of the phantom system used as a reference. Additionally, in keeping with the material choice and production limitations, as close correlations as possible were achieved for all the materials in relation to the reference data for mass densities, mass attenuation coefficients and mass energy-absorption coefficients. The TE substitutes for the newborn over an energy range of 47 keV to 66 keV exhibited maximum discrepancies for {\mu}/\r{ho} of 1.6% to -3.01%, and for {\mu}_en/\r{ho} of 1.15% to -1.4% in relation to the ORNL reference samples. The respective equivalent data ranges were 1.09 % to -3.02% and 1.92% to -2.53% for the TE materials representative of a 5-year-old. Given the excellent concordance achieved between the newly constructed TE materials and the reference data, these compounds can subsequently be utilised to create physical phantoms representative of tissue types in neonates and children aged 5 years.</td>
</tr>
<tr>
<td align="center"><strong>2022-12-12</strong></td>
<td align="center"><strong>Estimating the timing of stillbirths in countries worldwide using a Bayesian hierarchical penalized splines regression model</strong></td>
<td align="center">Michael Y. C. Chong et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2212.06219v1">2212.06219v1</a></td>
<td align="center">null</td>
<td align="center">Reducing the global burden of stillbirths is important to improving child and maternal health. Of interest is understanding patterns in the timing of stillbirths -- that is, whether they occur in the intra- or antepartum period -- because stillbirths that occur intrapartum are largely preventable. However, data availability on the timing of stillbirths is highly variable across the world, with low- and middle-income countries generally having few reliable observations. In this paper we develop a Bayesian penalized splines regression framework to estimate the proportion of stillbirths that are intrapartum for all countries worldwide. The model accounts for known relationships with neonatal mortality, pools information across geographic regions, incorporates different errors based on data attributes, and allows for data-driven temporal trends. A weighting procedure is proposed to account for unrepresentative subnational data. Results suggest that the intrapartum proportion is generally decreasing over time, but progress is slower in some regions, particularly Sub-Saharan Africa.</td>
</tr>
<tr>
<td align="center"><strong>2022-12-05</strong></td>
<td align="center"><strong>Robust multiple method comparison and transformation</strong></td>
<td align="center">Florian Dufey et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2212.02306v1">2212.02306v1</a></td>
<td align="center">null</td>
<td align="center">A generalization of Passing-Bablok regression for the simultaneous comparison of multiple methods is proposed. Possible applications include assay migration studies or interlaboratory trials. The method is shown to reduce to the usual Passing--Bablok estimator if only two methods are compared. It is close in spirit to reduced major axis regression, which is, however, not robust. To obtain a robust estimator, the major axis is replaced by the (hyper-)spherical median axis. The method is applied to the comparison of SARS-CoV-2 serological tests, bilirubin in neonates, and to a clinical test using different instruments, sample preparations and reagent lots. Plots, similar to the well known Bland-Altman plots, are developed for a posteriori checks of the assumed variance structure.</td>
</tr>
<tr>
<td align="center"><strong>2022-11-16</strong></td>
<td align="center"><strong>Neurodevelopmental Phenotype Prediction: A State-of-the-Art Deep Learning Model</strong></td>
<td align="center">Dániel Unyi et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2211.08831v1">2211.08831v1</a></td>
<td align="center"><a href="https://github.com/daniel-unyi-42/neurodevelopmental-phenotype-prediction">link</a></td>
<td align="center">A major challenge in medical image analysis is the automated detection of biomarkers from neuroimaging data. Traditional approaches, often based on image registration, are limited in capturing the high variability of cortical organisation across individuals. Deep learning methods have been shown to be successful in overcoming this difficulty, and some of them have even outperformed medical professionals on certain datasets. In this paper, we apply a deep neural network to analyse the cortical surface data of neonates, derived from the publicly available Developing Human Connectome Project (dHCP). Our goal is to identify neurodevelopmental biomarkers and to predict gestational age at birth based on these biomarkers. Using scans of preterm neonates acquired around the term-equivalent age, we were able to investigate the impact of preterm birth on cortical growth and maturation during late gestation. Besides reaching state-of-the-art prediction accuracy, the proposed model has much fewer parameters than the baselines, and its error stays low on both unregistered and registered cortical surfaces.</td>
</tr>
<tr>
<td align="center"><strong>2022-11-08</strong></td>
<td align="center"><strong>Automated CFD shape optimization of stator blades for the PediaFlow pediatric ventricular assist device</strong></td>
<td align="center">Mansur Zhussupbekov et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2211.04401v1">2211.04401v1</a></td>
<td align="center">null</td>
<td align="center">PediaFlow is a miniature mixed-flow ventricular assist device for neonates and toddlers. PediaFlow has a fully magnetically levitated rotor which improves biocompatibility, but the increased length of the rotor creates a long annular passage where fluid energy is lost. Therefore, a set of helical stator blades was proposed immediately after the impeller stage to remove the swirling flow and recover the dynamic head as static pressure. Automated computational fluid dynamics (CFD) shape optimization of the stator blades was performed to maximize pressure recovery at the operating point of 1.5 LPM and 16,000 RPM. Additionally, the effect on hemolysis and thrombogenicity was assessed using numerical modeling. The optimization algorithm favored fewer blades of greater length over a larger number of short blades. The ratio of wrap angle to axial length emerged as a key constraint to ensure the viability of a design. The best design had 2 blades and generated 73 mmHg of pressure recovery in an isolated stage. When re-introduced to the CFD simulation of the complete flow path, the added stator stage increased the pump head by 46% and improved the pump efficiency from 21.9% to 25.7% at the selected operating point. Automated CFD shape optimization combined with in silico evaluation of hemocompatibility can be an effective tool for exploring design choices and informing early development process.</td>
</tr>
<tr>
<td align="center"><strong>2022-09-20</strong></td>
<td align="center"><strong>Unresolved excess accumulation of myelin-derived cholesterol contributes to scar formation after spinal cord injury</strong></td>
<td align="center">Bolin Zheng et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2209.09700v1">2209.09700v1</a></td>
<td align="center">null</td>
<td align="center">Background: Spinal cord injury triggers complex pathological cascades, resulting in destructive tissue damage and incomplete tissue repair. Scar formation is generally considered as a barrier for regeneration in central nervous system (CNS), while the intrinsic mechanism of scar-forming after spinal cord injury has not been completed deciphered. Methods: We assessed cholesterol hemostasis in spinal cord lesions and injured peripheral nerves using confocal reflection microscopy and real-time PCR analyses. The involvement of the proteins, which were predicted to promote cholesterol efflux in spinal cord lesions, were assessed with Liver X receptor (LXR) agonist and Apolipoprotein E (APOE) deficiency. The role of reverse cholesterol transport (RCT) in cholesterol clearance was examined in APOE KO mice injured sciatic nerves and myelin-overloaded macrophages in vitro. Finally, we determined the consequence of excess cholesterol accumulation in CNS by transplantation of myelin into neonatal spinal cord lesions. Results: We found that excess cholesterol accumulates in phagocytes and is inefficiently removed in spinal cord lesions in young-adult mice. Interestingly, we observed that excessive cholesterol also accumulates in injured peripheral nerves, but is subsequently removed by RCT. Meanwhile, preventing RCT led to macrophage accumulation and fibrosis in injured peripheral nerves. Furthermore, the neonatal mouse spinal cord lesions are devoid of myelin-derived lipids, and able to heal without excess cholesterol accumulation. We found that transplantation of myelin into neonatal lesions disrupts healing with excessive cholesterol accumulation, persistent macrophage activation and fibrosis, indicating myelin-derived cholesterol plays a critical role in impaired wound healing.</td>
</tr>
<tr>
<td align="center"><strong>2022-08-29</strong></td>
<td align="center"><strong>Slice estimation in diffusion MRI of neonatal and fetal brains in image and spherical harmonics domains using autoencoders</strong></td>
<td align="center">Hamza Kebiri et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2208.13328v1">2208.13328v1</a></td>
<td align="center">null</td>
<td align="center">Diffusion MRI (dMRI) of the developing brain can provide valuable insights into the white matter development. However, slice thickness in fetal dMRI is typically high (i.e., 3-5 mm) to freeze the in-plane motion, which reduces the sensitivity of the dMRI signal to the underlying anatomy. In this study, we aim at overcoming this problem by using autoencoders to learn unsupervised efficient representations of brain slices in a latent space, using raw dMRI signals and their spherical harmonics (SH) representation. We first learn and quantitatively validate the autoencoders on the developing Human Connectome Project pre-term newborn data, and further test the method on fetal data. Our results show that the autoencoder in the signal domain better synthesized the raw signal. Interestingly, the fractional anisotropy and, to a lesser extent, the mean diffusivity, are best recovered in missing slices by using the autoencoder trained with SH coefficients. A comparison was performed with the same maps reconstructed using an autoencoder trained with raw signals, as well as conventional interpolation methods of raw signals and SH coefficients. From these results, we conclude that the recovery of missing/corrupted slices should be performed in the signal domain if the raw signal is aimed to be recovered, and in the SH domain if diffusion tensor properties (i.e., fractional anisotropy) are targeted. Notably, the trained autoencoders were able to generalize to fetal dMRI data acquired using a much smaller number of diffusion gradients and a lower b-value, where we qualitatively show the consistency of the estimated diffusion tensor maps.</td>
</tr>
<tr>
<td align="center"><strong>2022-08-25</strong></td>
<td align="center"><strong>Development of Sleep State Trend (SST), a bedside measure of neonatal sleep state fluctuations based on single EEG channels</strong></td>
<td align="center">Saeed Montazeri Moghadam et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2208.11933v1">2208.11933v1</a></td>
<td align="center">null</td>
<td align="center">Objective: To develop and validate an automated method for bedside monitoring of sleep state fluctuations in neonatal intensive care units.   Methods: A deep learning -based algorithm was designed and trained using 53 EEG recordings from a long-term (a)EEG monitoring in 30 near-term neonates. The results were validated using an external dataset from 30 polysomnography recordings. In addition to training and validating a single EEG channel quiet sleep detector, we constructed Sleep State Trend (SST), a bedside-ready means for visualizing classifier outputs.   Results: The accuracy of quiet sleep detection in the training data was 90%, and the accuracy was comparable (85-86%) in all bipolar derivations available from the 4-electrode recordings. The algorithm generalized well to an external dataset, showing 81% overall accuracy despite different signal derivations. SST allowed an intuitive, clear visualization of the classifier output.   Conclusions: Fluctuations in sleep states can be detected at high fidelity from a single EEG channel, and the results can be visualized as a transparent and intuitive trend in the bedside monitors.   Significance: The Sleep State Trend (SST) may provide caregivers a real-time view of sleep state fluctuations and its cyclicity.</td>
</tr>
<tr>
<td align="center"><strong>2022-08-23</strong></td>
<td align="center"><strong>Regression discontinuity design in perinatal epidemiology and birth cohort research</strong></td>
<td align="center">Maja Popovic et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2208.11047v1">2208.11047v1</a></td>
<td align="center">null</td>
<td align="center">Regression discontinuity design (RDD) is a quasi-experimental approach to study the causal effects of an intervention/treatment on later health outcomes. It exploits a continuously measured assignment variable with a clearly defined cut-off above or below which the population is at least partially assigned to the intervention/treatment. We describe the RDD and outline the applications of RDD in the context of perinatal epidemiology and birth cohort research.   There is an increasing number of studies using RDD in perinatal and pediatric epidemiology. Most of these studies were conducted in the context of education, social and welfare policies, healthcare organization, insurance, and preventive programs. Additional thematic fields include clinically relevant research questions, shock events, social and environmental factors, and changes in guidelines. Maternal and perinatal characteristics, such as age, birth weight and gestational age are frequently used assignment variables to study the effects of the type and intensity of neonatal care, health insurance, and supplemental newborn benefits. Different socioeconomic measures have been used to study the effects of social, welfare and cash transfer programs, while age or date of birth served as assignment variables to study the effects of vaccination programs, pregnancy-specific guidelines, maternity and paternity leave policies and introduction of newborn-based welfare programs.   RDD has advantages, including relatively weak and testable assumptions, strong internal validity, intuitive interpretation, and transparent and simple graphical representation. However, its use in birth cohort research is hampered by the rarity of settings outside of policy and program evaluations, low statistical power, limited external validity (geographic- and time-specific settings) and potential contamination by other exposures/interventions.</td>
</tr>
<tr>
<td align="center"><strong>2022-07-25</strong></td>
<td align="center"><strong>Deep learning based non-contact physiological monitoring in Neonatal Intensive Care Unit</strong></td>
<td align="center">Nicky Nirlipta Sahoo et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2207.11886v1">2207.11886v1</a></td>
<td align="center">null</td>
<td align="center">Preterm babies in the Neonatal Intensive Care Unit (NICU) have to undergo continuous monitoring of their cardiac health. Conventional monitoring approaches are contact-based, making the neonates prone to various nosocomial infections. Video-based monitoring approaches have opened up potential avenues for contactless measurement. This work presents a pipeline for remote estimation of cardiopulmonary signals from videos in NICU setup. We have proposed an end-to-end deep learning (DL) model that integrates a non-learning based approach to generate surrogate ground truth (SGT) labels for supervision, thus refraining from direct dependency on true ground truth labels. We have performed an extended qualitative and quantitative analysis to examine the efficacy of our proposed DL-based pipeline and achieved an overall average mean absolute error of 4.6 beats per minute (bpm) and root mean square error of 6.2 bpm in the estimated heart rate.</td>
</tr>
<tr>
<td align="center"><strong>2022-07-18</strong></td>
<td align="center"><strong>Superficial White Matter Analysis: An Efficient Point-cloud-based Deep Learning Framework with Supervised Contrastive Learning for Consistent Tractography Parcellation across Populations and dMRI Acquisitions</strong></td>
<td align="center">Tengfei Xue et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2207.08975v3">2207.08975v3</a></td>
<td align="center">null</td>
<td align="center">Diffusion MRI tractography is an advanced imaging technique that enables in vivo mapping of the brain's white matter connections. White matter parcellation classifies tractography streamlines into clusters or anatomically meaningful tracts. It enables quantification and visualization of whole-brain tractography. Currently, most parcellation methods focus on the deep white matter (DWM), whereas fewer methods address the superficial white matter (SWM) due to its complexity. We propose a novel two-stage deep-learning-based framework, Superficial White Matter Analysis (SupWMA), that performs an efficient and consistent parcellation of 198 SWM clusters from whole-brain tractography. A point-cloud-based network is adapted to our SWM parcellation task, and supervised contrastive learning enables more discriminative representations between plausible streamlines and outliers for SWM. We train our model on a large-scale tractography dataset including streamline samples from labeled long- and medium-range (over 40 mm) SWM clusters and anatomically implausible streamline samples, and we perform testing on six independently acquired datasets of different ages and health conditions (including neonates and patients with space-occupying brain tumors). Compared to several state-of-the-art methods, SupWMA obtains highly consistent and accurate SWM parcellation results on all datasets, showing good generalization across the lifespan in health and disease. In addition, the computational speed of SupWMA is much faster than other methods.</td>
</tr>
<tr>
<td align="center"><strong>2022-07-14</strong></td>
<td align="center"><strong>Spatial Aggregation with Respect to a Population Distribution</strong></td>
<td align="center">John Paige et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2207.06700v1">2207.06700v1</a></td>
<td align="center"><a href="https://github.com/paigejo/summer">link</a></td>
<td align="center">Spatial aggregation with respect to a population distribution involves estimating aggregate quantities for a population based on an observation of individuals in a subpopulation. In this context, a geostatistical workflow must account for three major sources of <code>aggregation error': aggregation weights, fine scale variation, and finite population variation. However, common practice is to treat the unknown population distribution as a known population density and ignore empirical variability in outcomes. We improve common practice by introducing a</code>sampling frame model' that allows aggregation models to account for the three sources of aggregation error simply and transparently.   We compare the proposed and the traditional approach using two simulation studies that mimic neonatal mortality rate (NMR) data from the 2014 Kenya Demographic and Health Survey (KDHS2014). For the traditional approach, undercoverage/overcoverage depends arbitrarily on the aggregation grid resolution, while the new approach exhibits low sensitivity. The differences between the two aggregation approaches increase as the population of an area decreases. The differences are substantial at the second administrative level and finer, but also at the first administrative level for some population quantities. We find differences between the proposed and traditional approach are consistent with those we observe in an application to NMR data from the KDHS2014.</td>
</tr>
<tr>
<td align="center"><strong>2022-06-27</strong></td>
<td align="center"><strong>ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration</strong></td>
<td align="center">Neel Dey et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2206.13434v1">2206.13434v1</a></td>
<td align="center">null</td>
<td align="center">Establishing voxelwise semantic correspondence across distinct imaging modalities is a foundational yet formidable computer vision task. Current multi-modality registration techniques maximize hand-crafted inter-domain similarity functions, are limited in modeling nonlinear intensity-relationships and deformations, and may require significant re-engineering or underperform on new tasks, datasets, and domain pairs. This work presents ContraReg, an unsupervised contrastive representation learning approach to multi-modality deformable registration. By projecting learned multi-scale local patch features onto a jointly learned inter-domain embedding space, ContraReg obtains representations useful for non-rigid multi-modality alignment. Experimentally, ContraReg achieves accurate and robust results with smooth and invertible deformations across a series of baselines and ablations on a neonatal T1-T2 brain MRI registration task with all methods validated over a wide range of deformation regularization strengths.</td>
</tr>
<tr>
<td align="center"><strong>2022-06-20</strong></td>
<td align="center"><strong>PhaTYP: Predicting the lifestyle for bacteriophages using BERT</strong></td>
<td align="center">Jiayu Shang et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2206.09693v1">2206.09693v1</a></td>
<td align="center"><a href="https://github.com/kennthshang/phatyp">link</a></td>
<td align="center">Bacteriophages (or phages), which infect bacteria, have two distinct lifestyles: virulent and temperate. Predicting the lifestyle of phages helps decipher their interactions with their bacterial hosts, aiding phages' applications in fields such as phage therapy. Because experimental methods for annotating the lifestyle of phages cannot keep pace with the fast accumulation of sequenced phages, computational method for predicting phages' lifestyles has become an attractive alternative. Despite some promising results, computational lifestyle prediction remains difficult because of the limited known annotations and the sheer amount of sequenced phage contigs assembled from metagenomic data. In particular, most of the existing tools cannot precisely predict phages' lifestyles for short contigs. In this work, we develop PhaTYP (Phage TYPe prediction tool) to improve the accuracy of lifestyle prediction on short contigs. We design two different training tasks, self-supervised and fine-tuning tasks, to overcome lifestyle prediction difficulties. We rigorously tested and compared PhaTYP with four state-of-the-art methods: DeePhage, PHACTS, PhagePred, and BACPHLIP. The experimental results show that PhaTYP outperforms all these methods and achieves more stable performance on short contigs. In addition, we demonstrated the utility of PhaTYP for analyzing the phage lifestyle on human neonates' gut data. This application shows that PhaTYP is a useful means for studying phages in metagenomic data and helps extend our understanding of microbial communities.</td>
</tr>
<tr>
<td align="center"><strong>2022-06-15</strong></td>
<td align="center"><strong>A Deep Generative Model of Neonatal Cortical Surface Development</strong></td>
<td align="center">Abdulah Fawaz et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2206.07542v2">2206.07542v2</a></td>
<td align="center">null</td>
<td align="center">The neonatal cortical surface is known to be affected by preterm birth, and the subsequent changes to cortical organisation have been associated with poorer neurodevelopmental outcomes. Deep Generative models have the potential to lead to clinically interpretable models of disease, but developing these on the cortical surface is challenging since established techniques for learning convolutional filters are inappropriate on non-flat topologies. To close this gap, we implement a surface-based CycleGAN using mixture model CNNs (MoNet) to translate sphericalised neonatal cortical surface features (curvature and T1w/T2w cortical myelin) between different stages of cortical maturity. Results show our method is able to reliably predict changes in individual patterns of cortical organisation at later stages of gestation, validated by comparison to longitudinal data; and translate appearance between preterm and term gestation (&gt; 37 weeks gestation), validated through comparison with a trained term/preterm classifier. Simulated differences in cortical maturation are consistent with observations in the literature.</td>
</tr>
<tr>
<td align="center"><strong>2022-06-09</strong></td>
<td align="center"><strong>Neonatal EEG graded for severity of background abnormalities in hypoxic-ischaemic encephalopathy</strong></td>
<td align="center">John M O'Toole et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2206.04420v2">2206.04420v2</a></td>
<td align="center"><a href="https://github.com/otoolej/downsample_open_eeg">link</a></td>
<td align="center">This report describes a set of neonatal electroencephalogram (EEG) recordings graded according to the severity of abnormalities in the background pattern. The dataset consists of 169 hours of multichannel EEG from 53 neonates recorded in a neonatal intensive care unit. All neonates received a diagnosis of hypoxic-ischaemic encephalopathy (HIE), the most common cause of brain injury in full term infants. For each neonate, multiple 1-hour epochs of good quality EEG were selected and then graded for background abnormalities. The grading system assesses EEG attributes such as amplitude and frequency, continuity, sleep--wake cycling, symmetry and synchrony, and abnormal waveforms. Background severity was then categorised into 4 grades: normal or mildly abnormal EEG, moderately abnormal EEG, severely abnormal EEG, and inactive EEG. The data can be used as a reference set of multi-channel EEG for neonates with HIE, for EEG training purposes, or for developing and evaluating automated grading algorithms.</td>
</tr>
<tr>
<td align="center"><strong>2022-05-16</strong></td>
<td align="center"><strong>An automatic pipeline for atlas-based fetal and neonatal brain segmentation and analysis</strong></td>
<td align="center">Urru et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2205.07575v1">2205.07575v1</a></td>
<td align="center"><a href="https://github.com/urrand/perinatal-pipeline">link</a></td>
<td align="center">The automatic segmentation of perinatal brain structures in magnetic resonance imaging (MRI) is of utmost importance for the study of brain growth and related complications. While different methods exist for adult and pediatric MRI data, there is a lack for automatic tools for the analysis of perinatal imaging. In this work, a new pipeline for fetal and neonatal segmentation has been developed. We also report the creation of two new fetal atlases, and their use within the pipeline for atlas-based segmentation, based on novel registration methods. The pipeline is also able to extract cortical and pial surfaces and compute features, such as curvature, thickness, sulcal depth, and local gyrification index. Results show that the introduction of the new templates together with our segmentation strategy leads to accurate results when compared to expert annotations, as well as better performances when compared to a reference pipeline (developing Human Connectome Project (dHCP)), for both early and late-onset fetal brains.</td>
</tr>
<tr>
<td align="center"><strong>2022-04-11</strong></td>
<td align="center"><strong>Ensemble learning using individual neonatal data for seizure detection</strong></td>
<td align="center">Ana Borovac et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2204.07043v2">2204.07043v2</a></td>
<td align="center"><a href="https://github.com/anaborovac/distributed-nsda">link</a></td>
<td align="center">Sharing medical data between institutions is difficult in practice due to data protection laws and official procedures within institutions. Therefore, most existing algorithms are trained on relatively small electroencephalogram (EEG) data sets which is likely to be detrimental to prediction accuracy. In this work, we simulate a case when the data can not be shared by splitting the publicly available data set into disjoint sets representing data in individual institutions. We propose to train a (local) detector in each institution and aggregate their individual predictions into one final prediction. Four aggregation schemes are compared, namely, the majority vote, the mean, the weighted mean and the Dawid-Skene method. The method was validated on an independent data set using only a subset of EEG channels. The ensemble reaches accuracy comparable to a single detector trained on all the data when sufficient amount of data is available in each institution. The weighted mean aggregation scheme showed best performance, it was only marginally outperformed by the Dawid--Skene method when local detectors approach performance of a single detector trained on all available data.</td>
</tr>
<tr>
<td align="center"><strong>2022-04-08</strong></td>
<td align="center"><strong>NeoRS: a neonatal resting state fMRI data preprocessing pipeline</strong></td>
<td align="center">V. Enguix et.al.</td>
<td align="center"><a href="http://arxiv.org/abs/2204.05137v1">2204.05137v1</a></td>
<td align="center"><a href="https://github.com/venguix/neors">link</a></td>
<td align="center">Resting state fMRI (rsfMRI) has been shown to be a promising tool to study intrinsic functional connectivity and assess its integrity in cerebral development. In neonates, where fMRI is limited to few paradigms, rsfMRI was shown to be a relevant tool to explore regional interactions of brain networks. However, to identify the resting state networks, data needs to be carefully processed. Because of the non-collaborative nature of the neonates, the differences in brain size and the reversed contrast compared to adults, neonates can't be processed with the existing adult pipelines. Therefore, we developed NeoRS. The main processing steps include atlas registration, skull tripping, segmentation, slice timing and head motion correction and confounds regression. To address the specificity of neonatal brain imaging, particular attention was given to registration including neonatal atlas type and parameters, such as brain size variations, and contrast differences compared to adults. Furthermore, head motion was scrutinized and optimized, as it is a major issue when processing neonatal data. The pipeline includes visual quality control assessment checkpoints. To assess its effectiveness, we used the data from the Baby Connectome Project including 10 neonates. NeoRS was designed to work on both multi-band and single-band acquisitions and is applicable on smaller datasets. It also includes popular functional connectivity analysis features such as seed based correlations. Language, default mode, dorsal attention, visual, ventral attention, motor and fronto parietal networks were evaluated. The different analyzed networks were in agreement with previously published studies in the neonate. NeoRS is coded in Matlab, it is open-source and available on https://github.com/venguix/NeoRS. NeoRS allows robust image processing of the neonatal rsfMRI data that can be readily customized to different datasets.</td>
</tr>
</tbody>
</table>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.b425cdc4.min.js"></script>
      
    
  </body>
</html>